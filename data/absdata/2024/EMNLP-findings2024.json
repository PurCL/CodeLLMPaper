{
    "Are LLMs Good Annotators for Discourse-level Event Relation Extraction?": {
        "type": "INPROCEEDINGS",
        "key": "wei-etal-2024-llms",
        "author": "Wei, Kangda and Gautam, Aayush and Huang, Ruihong",
        "booktitle": "EMNLP-findings2024",
        "title": "Are LLMs Good Annotators for Discourse-level Event Relation Extraction?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have demonstrated proficiency in a wide array of natural language processing tasks. However, its effectiveness over discourse-level event relation extraction (ERE) tasks remains unexplored. In this paper, we assess the effectiveness of LLMs in addressing discourse-level ERE tasks characterized by lengthy documents and intricate relations encompassing coreference, temporal, causal, and subevent types. Evaluation is conducted using an commercial model, GPT-3.5, and an open-source model, LLaMA-2. Our study reveals a notable underperformance of LLMs compared to the baseline established through supervised learning. Although Supervised Fine-Tuning (SFT) can improve LLMs performance, it does not scale well compared to the smaller supervised baseline model. Our quantitative and qualitative analysis shows that LLMs have several weaknesses when applied for extracting event relations, including a tendency to fabricate event mentions, and failures to capture transitivity rules among relations, detect long distance relations, or comprehend contexts with dense event mentions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.1",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Transferability of Syntax-Aware Graph Neural Networks in Zero-Shot Cross-Lingual Semantic Role Labeling": {
        "type": "INPROCEEDINGS",
        "key": "devianti-miyao-2024-transferability",
        "author": "Devianti, Rachel Sidney and Miyao, Yusuke",
        "booktitle": "EMNLP-findings2024",
        "title": "Transferability of Syntax-Aware Graph Neural Networks in Zero-Shot Cross-Lingual Semantic Role Labeling",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent models in cross-lingual semantic role labeling (SRL) barely analyze the applicability of their network selection.We believe that network selection is important since it affects the transferability of cross-lingual models, i.e., how the model can extract universal features from source languages to label target languages.Therefore, we comprehensively compare the transferability of different graph neural network (GNN)-based models enriched with universal dependency trees.GNN-based models include transformer-based, graph convolutional network-based, and graph attention network (GAT)-based models.We focus our study on a zero-shot setting by training the models in English and evaluating the models in 23 target languages provided by the Universal Proposition Bank.Based on our experiments, we consistently show that syntax from universal dependency trees is essential for cross-lingual SRL models to achieve better transferability.Dependency-aware self-attention with relative position representations (SAN-RPRs) transfer best across languages, especially in the long-range dependency distance.We also show that dependency-aware two-attention relational GATs transfer better than SAN-RPRs in languages where most arguments lie in a 1-2 dependency distance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.2",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing": {
        "type": "INPROCEEDINGS",
        "key": "kang-etal-2024-cross-lingual",
        "author": "Kang, Jeongwoo and Coavoux, Maximin and Lopez, C\u00e9dric and Schwab, Didier",
        "booktitle": "EMNLP-findings2024",
        "title": "Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Cross-lingual AMR parsing is the task of predicting AMR graphs in a target language when training data is available only in a source language. Due to the small size of AMR training data and evaluation data, cross-lingual AMR parsing has only been explored in a small set of languages such as English, Spanish, German, Chinese, and Italian. Taking inspiration from Langedijk et al. (2022), who apply meta-learning to tackle cross-lingual syntactic parsing, we investigate the use of meta-learning for cross-lingual AMR parsing. We evaluate our models in k-shot scenarios (including 0-shot) and assess their effectiveness in Croatian, Farsi, Korean, Chinese, and French. Notably, Korean and Croatian test sets are developed as part of our work, based on the existing The Little Prince English AMR corpus, and made publicly available. We empirically study our method by comparing it to classical joint learning. Our findings suggest that while the meta-learning model performs slightly better in 0-shot evaluation for certain languages, the performance gain is minimal or absent when k is higher than 0.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.3",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction": {
        "type": "INPROCEEDINGS",
        "key": "bao-wang-2024-general",
        "author": "Bao, K. and Wang, Ning",
        "booktitle": "EMNLP-findings2024",
        "title": "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, unified information extraction has garnered widespread attention from the NLP community, which aims to use a unified paradigm to perform various information extraction tasks. However, prevalent unified IE approaches inevitably encounter challenges such as noise interference, abstract label semantics, and diverse span granularity. In this paper, we first present three problematic assumptions regarding the capabilities of unified information extraction model. Furthermore, we propose the General Collaborative Information Extraction (GCIE) framework to address these challenges in universal information extraction tasks. Specifically, GCIE consists of a general Recognizer as well as multiple task-specific Experts for recognizing predefined types and extracting spans respectively. The Recognizer is a large language model, while the Experts comprise a series of smaller language models. Together, they collaborate in a two-stage pipeline to perform unified information extraction. Extensive empirical experiments on 6 IE tasks and several datasets, validate the effectiveness and generality of our approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.4",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SEAVER: Attention Reallocation for Mitigating Distractions in Language Models for Conditional Semantic Textual Similarity Measurement": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-seaver",
        "author": "Li, Baixuan and Fan, Yunlong and Gao, Zhiqiang",
        "booktitle": "EMNLP-findings2024",
        "title": "SEAVER: Attention Reallocation for Mitigating Distractions in Language Models for Conditional Semantic Textual Similarity Measurement",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Conditional Semantic Textual Similarity (C-STS) introduces specific limiting conditions to the traditional Semantic Textual Similarity (STS) task, posing challenges for STS models. Language models employing cross-encoding demonstrate satisfactory performance in STS, yet their effectiveness significantly diminishes in C-STS. In this work, we argue that the failure is due to the fact that the redundant information in the text distracts language models from the required condition-relevant information. To alleviate this, we propose Self-Augmentation via Self-Reweighting (SEAVER), which, based solely on models\u2019 internal attention and without the need for external auxiliary information, adaptively reallocates the model\u2019s attention weights by emphasizing the importance of condition-relevant tokens. On the C-STS-2023 test set, SEAVER consistently improves performance of all million-scale fine-tuning baseline models (up to around 3 points), and even surpasses performance of billion-scale few-shot prompted large language models (such as GPT-4). Our code is available at https://github.com/BaixuanLi/SEAVER.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.5",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Search if you don\u2019t know! Knowledge-Augmented Korean Grammatical Error Correction with Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "koo-etal-2024-search",
        "author": "Koo, Seonmin and Kim, Jinsung and Park, Chanjun and Lim, Heuiseok",
        "booktitle": "EMNLP-findings2024",
        "title": "Search if you don\u2019t know! Knowledge-Augmented Korean Grammatical Error Correction with Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Grammatical error correction (GEC) system is a practical task used in the real world, showing high achievements alongside the development of large language models (LLMs). However, these achievements have been primarily obtained in English, and there is a relative lack of performance for non-English data, such as Korean. We hypothesize that this insufficiency occurs because relying solely on the parametric knowledge of LLMs makes it difficult to thoroughly understand the given context in the Korean GEC. Therefore, we propose a Knowledge-Augmented GEC (KAGEC) framework that incorporates evidential information from external sources into the prompt for the GEC task. KAGEC first extracts salient phrases from the given source and retrieves non-parametric knowledge based on these phrases, aiming to enhance the context-aware generation capabilities of LLMs. Furthermore, we conduct validations for fine-grained error types to identify those requiring a retrieval-augmented manner when LLMs perform Korean GEC. According to experimental results, most LLMs, including ChatGPT, demonstrate significant performance improvements when applying KAGEC.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.6",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Measuring the Robustness of NLP Models to Domain Shifts": {
        "type": "INPROCEEDINGS",
        "key": "calderon-etal-2024-measuring",
        "author": "Calderon, Nitay and Porat, Naveh and Ben-David, Eyal and Chapanin, Alexander and Gekhman, Zorik and Oved, Nadav and Shalumov, Vitaly and Reichart, Roi",
        "booktitle": "EMNLP-findings2024",
        "title": "Measuring the Robustness of NLP Models to Domain Shifts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing research on Domain Robustness (DR) suffers from disparate setups, limited task variety, and scarce research on recent capabilities such as in-context learning. Furthermore, the common practice of measuring DR might not be fully accurate. Current research focuses on challenge sets and relies solely on the Source Drop (SD): Using the source in-domain performance as a reference point for degradation. However, we argue that the Target Drop (TD), which measures degradation from the target in-domain performance, should be used as a complementary point of view. To address these issues, we first curated a DR benchmark comprised of 7 diverse NLP tasks, which enabled us to measure both the SD and the TD. We then conducted a comprehensive large-scale DR study involving over 14,000 domain shifts across 21 fine-tuned models and few-shot LLMs. We found that both model types suffer from drops upon domain shifts. While fine-tuned models excel in-domain, few-shot LLMs often surpass them cross-domain, showing better robustness. In addition, we found that a large SD can often be explained by shifting to a harder domain rather than by a genuine DR challenge, and this highlights the importance of TD as a complementary metric. We hope our study will shed light on the current DR state of NLP models and promote improved evaluation practices toward more robust models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.7",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Text2Model: Text-based Model Induction for Zero-shot Image Classification": {
        "type": "INPROCEEDINGS",
        "key": "amosy-etal-2024-text2model",
        "author": "Amosy, Ohad and Volk, Tomer and Shapira, Eilam and Ben-David, Eyal and Reichart, Roi and Chechik, Gal",
        "booktitle": "EMNLP-findings2024",
        "title": "Text2Model: Text-based Model Induction for Zero-shot Image Classification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We address the challenge of building task-agnostic classifiers using only text descriptions, demonstrating a unified approach to image classification, 3D point cloud classification, and action recognition from scenes. Unlike approaches that learn a fixed representation of the output classes, we generate at inference time a model tailored to a query classification task. To generate task-based zero-shot classifiers, we train a hypernetwork that receives class descriptions and outputs a multi-class model. The hypernetwork is designed to be equivariant with respect to the set of descriptions and the classification layer, thus obeying the symmetries of the problem and improving generalization. Our approach generates non-linear classifiers, handles rich textual descriptions, and may be adapted to produce lightweight models efficient enough for on-device applications. We evaluate this approach in a series of zero-shot classification tasks, for image, point-cloud, and action recognition, using a range of text descriptions: From single words to rich descriptions. Our results demonstrate strong improvements over previous approaches, showing that zero-shot learning can be applied with little training data. Furthermore, we conduct an analysis with foundational vision and language models, demonstrating that they struggle to generalize when describing what attributes the class lacks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.8",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem": {
        "type": "INPROCEEDINGS",
        "key": "wu-li-2024-insertgnn",
        "author": "Wu, Fang and Li, Stan Z.",
        "booktitle": "EMNLP-findings2024",
        "title": "InsertGNN: A Hierarchical Graph Neural Network for the TOEFL Sentence Insertion Problem",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The integration of sentences poses an intriguing challenge within the realm of NLP, but it has not garnered the attention it deserves. Existing methods that focus on sentence arrangement, textual consistency, and question answering have been shown to be inadequate in addressing this issue. To bridge this gap, we introduce InsertGNN which conceptualizes the problem as a graph and employ a hierarchical Graph Neural Network (GNN) to comprehend the interplay between sentences. Our approach was rigorously evaluated on a TOEFL dataset, and its efficacy was further validated on the expansive arXiv dataset using cross-domain learning. Thorough experimentation unequivocally establishes InsertGNN\u2019s superiority over all comparative benchmarks, achieving an impressive 70% accuracy\u2014a performance on par with average human test scores.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.9",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unleashing Large Language Models\u2019 Proficiency in Zero-shot Essay Scoring": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-unleashing",
        "author": "Lee, Sanwoo and Cai, Yida and Meng, Desong and Wang, Ziyang and Wu, Yunfang",
        "booktitle": "EMNLP-findings2024",
        "title": "Unleashing Large Language Models\u2019 Proficiency in Zero-shot Essay Scoring",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Advances in automated essay scoring (AES) have traditionally relied on labeled essays, requiring tremendous cost and expertise for their acquisition. Recently, large language models (LLMs) have achieved great success in various tasks, but their potential is less explored in AES. In this paper, we show that our zero-shot prompting framework, Multi Trait Specialization (MTS), elicits LLMs\u2019 ample potential for essay scoring. In particular, we automatically decompose writing proficiency into distinct traits and generate scoring criteria for each trait. Then, an LLM is prompted to extract trait scores from several conversational rounds, each round scoring one of the traits based on the scoring criteria. Finally, we derive the overall score via trait averaging and min-max scaling. Experimental results on two benchmark datasets demonstrate that MTS consistently outperforms straightforward prompting (Vanilla) in average QWK across all LLMs and datasets, with maximum gains of 0.437 on TOEFL11 and 0.355 on ASAP. Additionally, with the help of MTS, the small-sized Llama2-13b-chat substantially outperforms ChatGPT, facilitating an effective deployment in real applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.10",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?": {
        "type": "INPROCEEDINGS",
        "key": "gu-etal-2024-detectbench",
        "author": "Gu, Zhouhong and Zhang, Lin and Zhu, Xiaoxuan and Chen, Jiangjie and Huang, Wenhao and Zhang, Yikai and Wang, Shusen and Ye, Zheyu and Gao, Yan and Feng, Hongwei and Xiao, Yanghua",
        "booktitle": "EMNLP-findings2024",
        "title": "DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Detecting evidence within the context is a key step in the process of reasoning task. Evaluating and enhancing the capabilities of LLMs in evidence detection will strengthen context-based reasoning performance. This paper proposes a benchmark called DetectBench for verifying the ability to detect and piece together implicit evidence within a long context. DetectBench contains 3,928 multiple-choice questions, with an average of 994 tokens per question. Each question contains an average of 4.55 pieces of implicit evidence, and solving the problem typically requires 7.62 logical jumps to find the correct answer. To enhance the performance of LLMs in evidence detection, this paper proposes Detective Reasoning Prompt and Finetune. Experiments demonstrate that the existing LLMs\u2019 abilities to detect evidence in long contexts are far inferior to humans. However, the Detective Reasoning Prompt effectively enhances the capability of powerful LLMs in evidence detection, while the Finetuning method shows significant effects in enhancing the performance of weaker LLMs. Moreover, when the abilities of LLMs in evidence detection are improved, their final reasoning performance is also enhanced accordingly.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.11",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-improve",
        "author": "Liu, Xinyue and Gao, Yunlong and Zong, Linlin and Xu, Bo",
        "booktitle": "EMNLP-findings2024",
        "title": "Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Meta-learning has emerged as a prominent technology for few-shot text classification and has achieved promising performance. However, existing methods often encounter difficulties in drawing accurate class prototypes from support set samples, primarily due to probable large intra-class differences and small inter-class differences within the task. Recent approaches attempt to incorporate external knowledge or pre-trained language models to augment data, but this requires additional resources and thus does not suit many few-shot scenarios. In this paper, we propose a novel solution to address this issue by adequately leveraging the information within the task itself. Specifically, we utilize label information to construct a task-adaptive metric space, thereby adaptively reducing the intra-class differences and magnifying the inter-class differences. We further employ the optimal transport technique to estimate class prototypes with query set samples together, mitigating the problem of inaccurate and ambiguous support set samples caused by large intra-class differences. We conduct extensive experiments on eight benchmark datasets, and our approach shows obvious advantages over state-of-the-art models across all the tasks on all the datasets. For reproducibility, all the datasets and codes are available at https://github.com/YvoGao/LAQDA.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.12",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity": {
        "type": "INPROCEEDINGS",
        "key": "berchansky-etal-2024-cotar",
        "author": "Berchansky, Moshe and Fleischer, Daniel and Wasserblat, Moshe and Izsak, Peter",
        "booktitle": "EMNLP-findings2024",
        "title": "CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "State-of-the-art performance in QA tasks is currently achieved by systems employing Large Language Models (LLMs), however these models tend to hallucinate information in their responses. One approach focuses on enhancing the generation process by incorporating attribution from the given input to the output. However, the challenge of identifying appropriate attributions and verifying their accuracy against a source is a complex task that requires significant improvements in assessing such systems. We introduce an attribution-oriented Chain-of-Thought reasoning method to enhance the accuracy of attributions. This approach focuses the reasoning process on generating an attribution-centric output. Evaluations on two context enhanced question-answering datasets using GPT-4 demonstrate improved accuracy and correctness of attributions. In addition, the combination of our method with finetuning enhances the response and attribution accuracy of two smaller LLMs, showing their potential to outperform GPT-4 in some cases.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.13",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM": {
        "type": "INPROCEEDINGS",
        "key": "qiu-etal-2024-snapntell",
        "author": "Qiu, Jielin and Madotto, Andrea and Lin, Zhaojiang and Crook, Paul A. and Xu, Yifan Ethan and Damavandi, Babak and Dong, Xin Luna and Faloutsos, Christos and Li, Lei and Moon, Seungwhan",
        "booktitle": "EMNLP-findings2024",
        "title": "SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Vision-extended LLMs have made significant strides in Visual Question Answering (VQA). Despite these advancements, VLLMs still encounter substantial difficulties in handling queries involving long-tail entities, with a tendency to produce erroneous or hallucinated responses. In this work, we introduce a novel evaluative benchmark named SnapNTell, specifically tailored for entity-centric VQA. This task aims to test the models\u2019 capabilities in identifying entities and providing detailed, entity-specific knowledge. We have developed the SnapNTell Dataset, distinct from traditional VQA datasets: (1) It encompasses a wide range of categorized entities, each represented by images and explicitly named in the answers; (2) It features QA pairs that require extensive knowledge for accurate responses. The dataset is organized into 22 major categories, containing 7,568 unique entities in total. For each entity, we curated 10 illustrative images and crafted 10 knowledge-intensive QA pairs. To address this novel task, we devised a scalable, efficient, and transparent retrieval-augmented multimodal LLM. Our approach markedly outperforms existing methods on the SnapNTell dataset, achieving a 66.5% improvement in the BELURT score.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.14",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent": {
        "type": "INPROCEEDINGS",
        "key": "ji-etal-2024-srap",
        "author": "Ji, Jiarui and Li, Yang and Liu, Hongtao and Du, Zhicheng and Wei, Zhewei and Qi, Qi and Shen, Weiran and Lin, Yankai",
        "booktitle": "EMNLP-findings2024",
        "title": "SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Public scarce resource allocation plays a crucial role in economics as it directly influences the efficiency and equity in society. Traditional studies including theoretical model-based, empirical study-based and simulation-based methods encounter limitations due to the idealized assumption of complete information and individual rationality, as well as constraints posed by limited available data. In this work, we propose an innovative framework, SRAP-Agent, which integrates Large Language Models (LLMs) into economic simulations, aiming to bridge the gap between theoretical models and real-world dynamics. Using public housing allocation scenarios as a case study, we conduct extensive policy simulation experiments to verify the feasibility and effectiveness of the SRAP-Agent and employ the Policy Optimization Algorithm with certain optimization objectives. The source code can be found in https://github.com/jijiarui-cather/SRAPAgent_Framework.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.15",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Ukrainian Resilience: A Dataset for Detection of Help-Seeking Signals Amidst the Chaos of War": {
        "type": "INPROCEEDINGS",
        "key": "sathvik-etal-2024-ukrainian",
        "author": "Sathvik, Msvpj and Dowpati, Abhilash and Sethi, Srreyansh",
        "booktitle": "EMNLP-findings2024",
        "title": "Ukrainian Resilience: A Dataset for Detection of Help-Seeking Signals Amidst the Chaos of War",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We propose a novel dataset \u201cUkrainian Resilience\u201d that brings together a collection of social media posts in the Ukrainian language for the detection of help-seeking posts in the Russia-Ukraine war. It is designed to help us analyze and categorize subtle signals in these posts that indicate people are asking for help during times of war. We are using advanced language processing and machine learning techniques to pick up on the nuances of language that show distress or urgency. The dataset is the binary classification of the social media posts that required help and did not require help in the war. The dataset could significantly improve humanitarian efforts, allowing for quicker and more targeted help for those facing the challenges of war. Moreover, the baseline models are implemented and GPT 3.5 achieved an accuracy of 81.15%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.16",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Selective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-selective-annotation",
        "author": "Huang, Chen and Deng, Yang and Lei, Wenqiang and Lv, Jiancheng and Dagan, Ido",
        "booktitle": "EMNLP-findings2024",
        "title": "Selective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To obtain high-quality annotations under limited budget, semi-automatic annotation methods are commonly used, where a portion of the data is annotated by experts and a model is then trained to complete the annotations for the remaining data. However, these methods mainly focus on selecting informative data for expert annotations to improve the model predictive ability (i.e., triage-to-human data), while the rest of the data is indiscriminately assigned to model annotation (i.e., triage-to-model data). This may lead to inefficiencies in budget allocation for annotations, as easy data that the model could accurately annotate may be unnecessarily assigned to the expert, and hard data may be misclassified by the model. As a result, the overall annotation quality may be compromised. To address this issue, we propose a selective annotation framework called SANT. It effectively takes advantage of both the triage-to-human and triage-to-model data through the proposed error-aware triage and bi-weighting mechanisms. As such, informative or hard data is assigned to the expert for annotation, while easy data is handled by the model. Experimental results show that SANT consistently outperforms other baselines, leading to higher-quality annotation through its proper allocation of data to both expert and model workers. We provide pioneering work on data annotation within budget constraints, establishing a landmark for future triage-based annotation studies.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.17",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-document-hashing",
        "author": "Zhang, Qian and Su, Qinliang and Chen, Jiayang and Song, Zhenpeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Document Hashing with Multi-Grained Prototype-Induced Hierarchical Generative Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Document hashing plays a crucial role in large-scale information retrieval. However, existing unsupervised document hashing methods merely consider flat semantics of documents, resulting in the inability of preserving hierarchical semantics in hash codes. In this paper, we propose a hierarchical generative model that can model and leverage the hierarchical structure of semantics. Specifically, we introduce hierarchical prototypes into the model to construct a hierarchical prior distribution, which is integrated into the variational auto-encoder (VAE) framework, enabling the model to produce hash codes preserving rough hierarchical semantics. To further promote the preservation of hierarchical structure, we force the hash code to preserve as much semantic information as possible via contrastive learning, which exploits the hierarchical pseudo labels produced during VAE training. Extensive experiments on three benchmarks outperform all baseline methods, demonstrating the superiority of our proposed model on both hierarchical datasets and flat datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.18",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction": {
        "type": "INPROCEEDINGS",
        "key": "zhu-etal-2024-predictive",
        "author": "Zhu, Yuqicheng and Potyka, Nico and Nayyeri, Mojtaba and Xiong, Bo and He, Yunjie and Kharlamov, Evgeny and Staab, Steffen",
        "booktitle": "EMNLP-findings2024",
        "title": "Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Knowledge graph embedding (KGE) models are often used to predict missing links for knowledge graphs (KGs). However, multiple KG embeddings can perform almost equally well for link prediction yet give conflicting predictions for unseen queries. This phenomenon is termed predictive multiplicity in the literature. It poses substantial risks for KGE-based applications in high-stake domains but has been overlooked in KGE research. We define predictive multiplicity in link prediction, introduce evaluation metrics and measure predictive multiplicity for representative KGE methods on commonly used benchmark datasets. Our empirical study reveals significant predictive multiplicity in link prediction, with 8% to 39% testing queries exhibiting conflicting predictions. We address this issue by leveraging voting methods from social choice theory, significantly mitigating conflicts by 66% to 78% in our experiments.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.19",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs": {
        "type": "INPROCEEDINGS",
        "key": "ding-etal-2024-temporal",
        "author": "Ding, Zifeng and Wu, Jingcheng and Wu, Jingpei and Xia, Yan and Xiong, Bo and Tresp, Volker",
        "booktitle": "EMNLP-findings2024",
        "title": "Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs) provide additional key-value pairs (i.e., qualifiers) for each KG fact that help to better restrict the fact validity. In recent years, there has been an increasing interest in studying graph reasoning over HKGs. Meanwhile, as discussed in recent works that focus on temporal KGs (TKGs), world knowledge is ever-evolving, making it important to reason over temporal facts in KGs. Previous mainstream benchmark HKGs do not explicitly specify temporal information for each HKG fact. Therefore, almost all existing HKG reasoning approaches do not devise any module specifically for temporal reasoning. To better study temporal fact reasoning over HKGs, we propose a new type of data structure named hyper-relational TKG (HTKG). Every fact in an HTKG is coupled with a timestamp explicitly indicating its time validity. We develop two new benchmark HTKG datasets, i.e., Wiki-hy and YAGO-hy, and propose an HTKG reasoning model that efficiently models hyper-relational temporal facts. To support future research on this topic, we open-source our datasets and model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.20",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "GREEN: Generative Radiology Report Evaluation and Error Notation": {
        "type": "INPROCEEDINGS",
        "key": "ostmeier-etal-2024-green",
        "author": "Ostmeier, Sophie and Xu, Justin and Chen, Zhihong and Varma, Maya and Blankemeier, Louis and Bluethgen, Christian and Md, Arne Edward Michalson and Moseley, Michael and Langlotz, Curtis and Chaudhari, Akshay S. and Delbrouck, Jean-Benoit",
        "booktitle": "EMNLP-findings2024",
        "title": "GREEN: Generative Radiology Report Evaluation and Error Notation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Evaluating radiology reports is a challenging problem as factual correctness is extremely important due to its medical nature. Existing automatic evaluation metrics either suffer from failing to consider factual correctness (e.g., BLEU and ROUGE) or are limited in their interpretability (e.g., F1CheXpert and F1RadGraph). In this paper, we introduce GREEN (Generative Radiology Report Evaluation and Error Notation), a radiology report generation metric that leverages the natural language understanding of language models to identify and explain clinically significant errors in candidate reports, both quantitatively and qualitatively. Compared to current metrics, GREEN offers: 1) a score aligned with expert preferences, 2) human interpretable explanations of clinically significant errors, enabling feedback loops with end-users, and 3) a lightweight open-source method that reaches the performance of commercial counterparts. We validate our GREEN metric by comparing it to GPT-4, as well as to error counts of 6 experts and preferences of 2 experts. Our method demonstrates not only higher correlation with expert error counts, but simultaneously higher alignment with expert preferences when compared to previous approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.21",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "XRec: Large Language Models for Explainable Recommendation": {
        "type": "INPROCEEDINGS",
        "key": "ma-etal-2024-xrec",
        "author": "Ma, Qiyao and Ren, Xubin and Huang, Chao",
        "booktitle": "EMNLP-findings2024",
        "title": "XRec: Large Language Models for Explainable Recommendation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recommender systems help users navigate information overload by providing personalized recommendations aligned with their preferences. Collaborative Filtering (CF) is a widely adopted approach, but while advanced techniques like graph neural networks (GNNs) and self-supervised learning (SSL) have enhanced CF models for better user representations, they often lack the ability to provide explanations for the recommended items. Explainable recommendations aim to address this gap by offering transparency and insights into the recommendation decision-making process, enhancing users\u2019 understanding. This work leverages the language capabilities of Large Language Models (LLMs) to push the boundaries of explainable recommender systems. We introduce a model-agnostic framework called XRec, which enables LLMs to provide comprehensive explanations for user behaviors in recommender systems. By integrating collaborative signals and designing a lightweight collaborative adaptor, the framework empowers LLMs to understand complex patterns in user-item interactions and gain a deeper understanding of user preferences. Our extensive experiments demonstrate the effectiveness of XRec, showcasing its ability to generate comprehensive and meaningful explanations that outperform baseline approaches in explainable recommender systems.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.22",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM Questionnaire Completion for Automatic Psychiatric Assessment": {
        "type": "INPROCEEDINGS",
        "key": "rosenman-etal-2024-llm",
        "author": "Rosenman, Gony and Hendler, Talma and Wolf, Lior",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM Questionnaire Completion for Automatic Psychiatric Assessment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We employ a Large Language Model (LLM) to convert unstructured psychological interviews into structured questionnaires spanning various psychiatric and personality domains. The LLM is prompted to answer these questionnaires by impersonating the interviewee. The obtained answers are coded as features, which are used to predict standardized psychiatric measures of depression (PHQ-8) and PTSD (PCL-C), using a Random Forest regressor. Our approach is shown to enhance diagnostic accuracy compared to multiple baselines. It thus establishes a novel framework for interpreting unstructured psychological interviews, bridging the gap between narrative-driven and data-driven approaches for mental health assessment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.23",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts": {
        "type": "INPROCEEDINGS",
        "key": "guo-vosoughi-2024-disordered",
        "author": "Guo, Xiaobo and Vosoughi, Soroush",
        "booktitle": "EMNLP-findings2024",
        "title": "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Aspect-based summarization has seen significant advancements, especially in structured text. Yet, summarizing disordered, large-scale texts, like those found in social media and customer feedback, remains a significant challenge. Current research largely targets predefined aspects within structured texts, neglecting the complexities of dynamic and disordered environments. Addressing this gap, we introduce Disordered-DABS, a novel benchmark for dynamic aspect-based summarization tailored to unstructured text. Developed by adapting existing datasets for cost-efficiency and scalability, our comprehensive experiments and detailed human evaluations reveal that Disordered-DABS poses unique challenges to contemporary summarization models, including state-of-the-art language models such as GPT-3.5.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.24",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets": {
        "type": "INPROCEEDINGS",
        "key": "azime-etal-2024-walia",
        "author": "Azime, Israel Abebe and Tonja, Atnafu Lambebo and Belay, Tadesse Destaw and Fuge, Mitiku Yohannes and Wassie, Aman Kassahun and Jada, Eyasu Shiferaw and Chanie, Yonas and Sewunetie, Walelign Tewabe and Yimam, Seid Muhie",
        "booktitle": "EMNLP-findings2024",
        "title": "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have received a lot of attention in natural language processing (NLP) research because of their exceptional performance in understanding and generating human languages. However, low-resource languages are left behind due to the unavailability of resources. In this work, we focus on enhancing the LLaMA-2-Amharic model by integrating task-specific and generative datasets to improve language model performance for Amharic. We compile an Amharic instruction fine-tuning dataset and fine-tuned LLaMA-2-Amharic model. The fine-tuned model shows promising results in different NLP tasks. We also explore the effectiveness of translated instruction datasets compared to the dataset we created. Our dataset creation pipeline, along with instruction datasets, trained models, and evaluation outputs, is made publicly available to encourage research in language-specific models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.25",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can Large Language Models Identify Authorship?": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-large",
        "author": "Huang, Baixiang and Chen, Canyu and Shu, Kai",
        "booktitle": "EMNLP-findings2024",
        "title": "Can Large Language Models Identify Authorship?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation. Large Language Models (LLMs) have demonstrated exceptional capacity for reasoning and problem-solving. However, their potential in authorship analysis remains under-explored. Traditional studies have depended on hand-crafted stylistic features, whereas state-of-the-art approaches leverage text embeddings from pre-trained language models. These methods, which typically require fine-tuning on labeled data, often suffer from performance degradation in cross-domain applications and provide limited explainability. This work seeks to address three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship verification effectively? (2) Are LLMs capable of accurately attributing authorship among multiple candidates authors (e.g., 10 and 20)? (3) Can LLMs provide explainability in authorship analysis, particularly through the role of linguistic features? Moreover, we investigate the integration of explicit linguistic features to guide LLMs in their reasoning processes. Our assessment demonstrates LLMs\u2019 proficiency in both tasks without the need for domain-specific fine-tuning, providing explanations into their decision making via a detailed analysis of linguistic features. This establishes a new benchmark for future research on LLM-based authorship analysis.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.26",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TransLLaMa: LLM-based Simultaneous Translation System": {
        "type": "INPROCEEDINGS",
        "key": "koshkin-etal-2024-transllama",
        "author": "Koshkin, Roman and Sudoh, Katsuhito and Nakamura, Satoshi",
        "booktitle": "EMNLP-findings2024",
        "title": "TransLLaMa: LLM-based Simultaneous Translation System",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Decoder-only large language models (LLMs) have recently demonstrated impressive capabilities in text generation and reasoning. Nonetheless, they have limited applications in simultaneous machine translation (SiMT), currently dominated by encoder-decoder transformers. This study demonstrates that, after fine-tuning on a small dataset comprising causally aligned source and target sentence pairs, a pre-trained open-source LLM can control input segmentation directly by generating a special \u201cwait\u201d token. This obviates the need for a separate policy and enables the LLM to perform English-German and English-Russian SiMT tasks with BLEU scores that are comparable to those of specific state-of-the-art baselines. We also evaluated closed-source models such as GPT-4, which displayed encouraging results in performing the SiMT task without prior training (zero-shot), indicating a promising avenue for enhancing future SiMT systems.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.27",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings": {
        "type": "INPROCEEDINGS",
        "key": "yamagiwa-etal-2024-axis",
        "author": "Yamagiwa, Hiroaki and Takase, Yusuke and Shimodaira, Hidetoshi",
        "booktitle": "EMNLP-findings2024",
        "title": "Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Word embedding is one of the most important components in natural language processing, but interpreting high-dimensional embeddings remains a challenging problem. To address this problem, Independent Component Analysis (ICA) is identified as an effective solution. ICA-transformed word embeddings reveal interpretable semantic axes; however, the order of these axes are arbitrary. In this study, we focus on this property and propose a novel method, Axis Tour, which optimizes the order of the axes. Inspired by Word Tour, a one-dimensional word embedding method, we aim to improve the clarity of the word embedding space by maximizing the semantic continuity of the axes. Furthermore, we show through experiments on downstream tasks that Axis Tour yields better or comparable low-dimensional embeddings compared to both PCA and ICA.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.28",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation": {
        "type": "INPROCEEDINGS",
        "key": "vu-etal-2024-granularity",
        "author": "Vu, Doan Nam Long and Igamberdiev, Timour and Habernal, Ivan",
        "booktitle": "EMNLP-findings2024",
        "title": "Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Applying differential privacy (DP) by means of the DP-SGD algorithm to protect individual data points during training is becoming increasingly popular in NLP. However, the choice of granularity at which DP is applied is often neglected. For example, neural machine translation (NMT) typically operates on the sentence-level granularity. From the perspective of DP, this setup assumes that each sentence belongs to a single person and any two sentences in the training dataset are independent. This assumption is however violated in many real-world NMT datasets, e.g., those including dialogues. For proper application of DP we thus must shift from sentences to entire documents. In this paper, we investigate NMT at both the sentence and document levels, analyzing the privacy/utility trade-off for both scenarios, and evaluating the risks of not using the appropriate privacy granularity in terms of leaking personally identifiable information (PII). Our findings indicate that the document-level NMT system is more resistant to membership inference attacks, emphasizing the significance of using the appropriate granularity when working with DP.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.29",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "An Open-Source Data Contamination Report for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-open-source",
        "author": "Li, Yucheng and Guo, Yunhao and Guerin, Frank and Lin, Chenghua",
        "booktitle": "EMNLP-findings2024",
        "title": "An Open-Source Data Contamination Report for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Data contamination in model evaluation has become increasingly prevalent with the growing popularity of large language models. It allows models to \u201ccheat\u201d via memorisation instead of displaying true capabilities. Therefore, contamination analysis has become an crucial part of reliable model evaluation to validate results. However, existing contamination analysis is usually conducted internally by large language model developers and often lacks transparency and completeness. This paper presents an extensive data contamination report for over 15 popular large language models across six popular multiple-choice QA benchmarks. We also introduce an open-source pipeline that enables the community to perform contamination analysis on customised data and models. Our experiments reveal varying contamination levels ranging from 1% to 45% across benchmarks, with the contamination degree increasing rapidly over time. Performance analysis of large language models indicates that data contamination does not necessarily lead to increased model metrics: while significant accuracy boosts of up to 14% and 7% are observed on contaminated C-Eval and Hellaswag benchmarks, only a minimal increase is noted on contaminated MMLU. We also find larger models seem able to gain more advantages than smaller models on contaminated test sets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.30",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering": {
        "type": "INPROCEEDINGS",
        "key": "nachane-etal-2024-shot",
        "author": "Nachane, Saeel Sandeep and Gramopadhye, Ojas and Chanda, Prateek and Ramakrishnan, Ganesh and Jadhav, Kshitij Sharad and Nandwani, Yatin and Raghu, Dinesh and Joshi, Sachindra",
        "booktitle": "EMNLP-findings2024",
        "title": "Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we propose a modified version of the MedQA-USMLE dataset, named MEDQA-OPEN, which contains open-ended medical questions without options to mimic clinical scenarios, along with clinician-approved reasoned answers. Additionally, we implement a prompt driven by Chain of Thought (CoT) reasoning, CLINICR, to mirror the prospective process of incremental reasoning, reaching a correct response to medical questions. We empirically demonstrate how CLINICR outperforms the state-of-the-art 5-shot CoT-based prompt (Li\u00e9vin et al., 2022). We also present an approach that mirrors real-life clinical practice by first exploring multiple differential diagnoses through MCQ-CLINICR and subsequently narrowing down to a final diagnosis using MCQ-ELIMINATIVE. Finally, emphasizing the importance of response verification in medical settings, we utilize a reward model mechanism, replacing the elimination process performed by MCQ-ELIMINATIVE.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.31",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Reformatted Alignment": {
        "type": "INPROCEEDINGS",
        "key": "fan-etal-2024-reformatted",
        "author": "Fan, Run-Ze and Li, Xuefeng and Zou, Haoyang and Li, Junlong and He, Shwai and Chern, Ethan and Hu, Jiewen and Liu, Pengfei",
        "booktitle": "EMNLP-findings2024",
        "title": "Reformatted Alignment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The quality of finetuning data is crucial for aligning large language models (LLMs) with human values. Current methods to improve data quality are either labor-intensive or prone to factual errors caused by LLM hallucinations. This paper explores elevating the quality of existing instruction data to better align with human values, introducing a simple and effective approach named ReAlign, which reformats the responses of instruction data into a format that better aligns with pre-established criteria and the collated evidence. This approach minimizes human annotation, hallucination, and the difficulty in scaling, remaining orthogonal to existing alignment techniques. Experimentally, ReAlign significantly boosts the general alignment ability, math reasoning, factuality, and readability of the LLMs.Encouragingly, without introducing any additional data or advanced training techniques, and merely by reformatting the response, LLaMA-2-13B\u2019s mathematical reasoning ability on GSM8K can be improved **from 46.77% to 56.63%** in accuracy. Additionally, a mere 5% of ReAlign data yields a 67% boost in general alignment ability measured by the Alpaca dataset. This work highlights the need for further research into the science and mechanistic interpretability of LLMs. We have made the associated code and data publicly accessible to support future studies at https://github.com/GAIR-NLP/ReAlign.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.32",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts": {
        "type": "INPROCEEDINGS",
        "key": "boudin-aizawa-2024-unsupervised",
        "author": "Boudin, Florian and Aizawa, Akiko",
        "booktitle": "EMNLP-findings2024",
        "title": "Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Adapting keyphrase generation models to new domains typically involves few-shot fine-tuning with in-domain labeled data. However, annotating documents with keyphrases is often prohibitively expensive and impractical, requiring expert annotators. This paper presents silk, an unsupervised method designed to address this issue by extracting silver-standard keyphrases from citation contexts to create synthetic labeled data for domain adaptation. Extensive experiments across three distinct domains demonstrate that our method yields high-quality synthetic samples, resulting in significant and consistent improvements in in-domain performance over strong baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.33",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support": {
        "type": "INPROCEEDINGS",
        "key": "qiu-etal-2024-smile",
        "author": "Qiu, Huachuan and He, Hongliang and Zhang, Shuai and Li, Anqi and Lan, Zhenzhong",
        "booktitle": "EMNLP-findings2024",
        "title": "SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Developing specialized dialogue systems for mental health support requires multi-turn conversation data, which has recently garnered increasing attention. However, gathering and releasing large-scale, real-life multi-turn conversations that could facilitate advancements in mental health support presents challenges in data privacy protection and the time and cost involved in crowdsourcing. To address these challenges, we introduce SMILE, a single-turn to multi-turn inclusive language expansion technique that prompts ChatGPT to rewrite public single-turn dialogues into multi-turn ones. Our work begins by analyzing language transformation and validating the feasibility of our proposed method. We conduct a study on dialogue diversity, including lexical features, semantic features, and dialogue topics, demonstrating the effectiveness of our method. Further, we employ our method to generate a large-scale, lifelike, and diverse dialogue dataset named SMILECHAT, consisting of 55k dialogues. Finally, we utilize the collected corpus to develop a mental health chatbot, MeChat. To better assess the quality of SMILECHAT, we collect a small-scale real-life counseling dataset conducted by data anonymization. Both automatic and human evaluations demonstrate significant improvements in our dialogue system and confirm that SMILECHAT is high-quality. Code, data, and model are publicly available at https://github.com/qiuhuachuan/smile.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.34",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-docee",
        "author": "Liu, Minghui and Tong, MeiHan and Peng, Yangda and Hou, Lei and Li, Juanzi and Xu, Bin",
        "booktitle": "EMNLP-findings2024",
        "title": "DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Event extraction aims to identify events and then extract the arguments involved in those events. In recent years, there has been a gradual shift from sentence-level event extraction to document-level event extraction research. Despite the significant success achieved in English domain event extraction research, event extraction in Chinese still remains largely unexplored. However, a major obstacle to promoting Chinese document-level event extraction is the lack of fine-grained, wide domain coverage datasets for model training and evaluation. In this paper, we propose DocEE-zh, a new Chinese document-level event extraction dataset comprising over 36,000 events and more than 210,000 arguments. DocEE-zh is an extension of the DocEE dataset, utilizing the same event schema, and all data has been meticulously annotated by human experts. We highlight two features: focus on high-interest event types and fine-grained argument types. Experimental results indicate that state-of-the-art models still fail to achieve satisfactory performance, with an F1 score of 45.88% on the event argument extraction task, revealing that Chinese document-level event extraction (DocEE) remains an unresolved challenge. DocEE-zh is now available at https://github.com/tongmeihan1995/DocEE.git.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.35",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization": {
        "type": "INPROCEEDINGS",
        "key": "schnabel-neville-2024-symbolic",
        "author": "Schnabel, Tobias and Neville, Jennifer",
        "booktitle": "EMNLP-findings2024",
        "title": "Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In many modern LLM applications, such as retrieval augmented generation, prompts have become programs themselves. In these settings, prompt programs are repeatedly called with different user queries or data instances. A big practical challenge is optimizing such prompt programs. Recent work has mostly focused on either simple prompt programs or assumed that the structure of a prompt program is fixed.We introduce SAMMO, a framework to perform symbolic prompt program search for compile-time optimizations of prompt programs. SAMMO represents prompt programs on a symbolic level which allows for a rich set of transformations that can be searched over during optimization. We show that SAMMO generalizes previous methods and improves the performance of complex prompts on (1) instruction tuning, (2) RAG pipeline tuning, and (3) prompt compression, across several different LLMs. We make all code available open-source at https://anonymous.4open.science/r/sammo-4003/.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.37",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models": {
        "type": "INPROCEEDINGS",
        "key": "araujo-etal-2024-learning",
        "author": "Araujo, Vladimir and Moens, Marie-Francine and Tuytelaars, Tinne",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Parameter-efficient fine-tuning (PEFT) methods are increasingly used with pre-trained language models (PLMs) for continual learning (CL). These methods typically involve training a PEFT module for each new task and employing similarity-based selection to route modules during inference. However, they face two major limitations: 1) interference during module training with already learned modules and 2) suboptimal routing when composing modules. In this paper, we present L2R, a method that isolates the training of new PEFT modules to ensure their task specialization. L2R then learns to compose the learned modules by training a network of routers that leverages a small memory containing examples of previously seen tasks. We evaluate our method in two CL setups using various benchmarks. Our results demonstrate that L2R provides an effective composition of PEFT modules, leading to improved generalization and performance compared to other methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.38",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM-supertagger: Categorial Grammar Supertagging via Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhao-penn-2024-llm",
        "author": "Zhao, Jinman and Penn, Gerald",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM-supertagger: Categorial Grammar Supertagging via Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Supertagging is an essential task in Categorical grammar parsing and is crucial for dissecting sentence structures. Our research explores the capacity of Large Language Models (LLMs) in supertagging for both Combinatory Categorial Grammar (CCG) and Lambek Categorial Grammar (LCG). We also present a simple method that significantly boosts LLMs, enabling them to outperform LSTM and encoder-based models and achieve state-of-the-art performance. This advancement highlights LLMs\u2019 potential in classification tasks, showcasing their adaptability beyond generative capabilities. Our findings demonstrate the evolving utility of LLMs in natural language processing, particularly in complex tasks like supertagging.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.39",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Editing Conceptual Knowledge for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-editing",
        "author": "Wang, Xiaohan and Mao, Shengyu and Deng, Shumin and Yao, Yunzhi and Shen, Yue and Liang, Lei and Gu, Jinjie and Chen, Huajun and Zhang, Ningyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Editing Conceptual Knowledge for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, there has been a growing interest in knowledge editing for Large Language Models (LLMs). Current approaches and evaluations merely explore the instance-level editing, while whether LLMs possess the capability to modify concepts remains unclear. This paper pioneers the investigation of editing conceptual knowledge for LLMs, by constructing a novel benchmark dataset ConceptEdit and establishing a suite of new metrics for evaluation. The experimental results reveal that, although existing editing methods can efficiently modify concept-level definition to some extent, they also have the potential to distort the related instantial knowledge in LLMs, leading to poor performance. We anticipate this work can inspire further progress in understanding LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.40",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "RAG-Studio: Towards In-Domain Adaptation of Retrieval Augmented Generation Through Self-Alignment": {
        "type": "INPROCEEDINGS",
        "key": "mao-etal-2024-rag",
        "author": "Mao, Kelong and Liu, Zheng and Qian, Hongjin and Mo, Fengran and Deng, Chenlong and Dou, Zhicheng",
        "booktitle": "EMNLP-findings2024",
        "title": "RAG-Studio: Towards In-Domain Adaptation of Retrieval Augmented Generation Through Self-Alignment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-Augmented Generation (RAG) has proven to be an effective paradigm for enhancing the quality of text generation by integrating large language models (LLMs) with external knowledge. However, an off-the-shelf RAG system, which relies on generally pre-trained LLMs and retrievers, often falls short in specialized domains and applications. In this paper, we introduce RAG-Studio, an efficient self-aligned training framework to adapt general RAG models to specific domains solely through synthetic data, eliminating the need for expensive human-labeled in-domain data. RAG-Studio accepts a specialized domain corpus, a general LLM, and a general retriever, then autonomously generates contrastive training data for both the LLM and retriever through self-alignment. We fine-tune them to work cohesively as an integrated and effective domain-specific RAG system, where the LLM is adapted to incorporate new domain knowledge and become robust to noisy contexts, and the retriever learns to better align with the LLM\u2019s preferences, providing more useful information and minimizing the risk of misleading the LLM. Extensive experiments across diverse in-domain question-answering datasets spanning the biomedical, finance, law, and computing domains, show that RAG-Studio attains state-of-the-art performance, consistently outperforming the use of human-annotated data for fine-tuning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.41",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MMCode: Benchmarking Multimodal Large Language Models for Code Generation with Visually Rich Programming Problems": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-mmcode",
        "author": "Li, Kaixin and Tian, Yuchen and Hu, Qisheng and Luo, Ziyang and Huang, Zhiyong and Ma, Jing",
        "booktitle": "EMNLP-findings2024",
        "title": "MMCode: Benchmarking Multimodal Large Language Models for Code Generation with Visually Rich Programming Problems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Programming often involves converting detailed and complex specifications into code, a process during which developers typically utilize visual aids to more effectively convey concepts. While recent developments in Large Multimodal Models have demonstrated remarkable abilities in visual reasoning and mathematical tasks, there is little work on investigating whether these models can effectively interpret visual elements for code generation. To this end, we present MMCode, the first multi-modal coding dataset for evaluating algorithmic problem-solving skills in visually rich contexts. MMCode contains 3,548 questions and 6,620 images collected from real-world programming challenges harvested from 10 code competition websites, presenting significant challenges due to the extreme demand for reasoning abilities. Our experiment results show that current state-of-the-art models struggle to solve these problems. The results highlight the lack of powerful vision-code models, and we hope MMCode can serve as an inspiration for future works in this domain. The data and code are publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.42",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enabling Discriminative Reasoning in LLMs for Legal Judgment Prediction": {
        "type": "INPROCEEDINGS",
        "key": "deng-etal-2024-enabling",
        "author": "Deng, Chenlong and Mao, Kelong and Zhang, Yuyao and Dou, Zhicheng",
        "booktitle": "EMNLP-findings2024",
        "title": "Enabling Discriminative Reasoning in LLMs for Legal Judgment Prediction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Legal judgment prediction is essential for enhancing judicial efficiency. In this work, we identify that existing large language models (LLMs) underperform in this domain due to challenges in understanding case complexities and distinguishing between similar charges. To adapt LLMs for effective legal judgment prediction, we introduce the Ask-Discriminate-Predict (ADAPT) reasoning framework inspired by human judicial reasoning. ADAPT involves decomposing case facts, discriminating among potential charges, and predicting the final judgment. We further enhance LLMs through fine-tuning with multi-task synthetic trajectories to improve legal judgment prediction accuracy and efficiency under our ADAPT framework. Extensive experiments conducted on two widely-used datasets demonstrate the superior performance of our framework in legal judgment prediction, particularly when dealing with complex and confusing charges.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.43",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-preserving",
        "author": "Kim, Donghoon and Lee, Gusang and Shim, Kyuhong and Shim, Byonghyo",
        "booktitle": "EMNLP-findings2024",
        "title": "Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, we have observed that Large Multi-modal Models (LMMs) are revolutionizing the way machines interact with the world, unlocking new possibilities across various multi-modal applications. To adapt LMMs for downstream tasks, parameter-efficient fine-tuning (PEFT) which only trains additional prefix tokens or modules, has gained popularity. Nevertheless, there has been little analysis of how PEFT works in LMMs. In this paper, we delve into the strengths and weaknesses of each tuning strategy, shifting the focus from the efficiency typically associated with these approaches. We first discover that model parameter tuning methods such as LoRA and Adapters, distort the feature representation space learned during pre-training, limiting the full utilization of pre-trained knowledge. We also demonstrate that prefix-tuning excels at preserving the representation space, despite of its lower performance on downstream tasks. These findings suggest a simple two-step PEFT strategy called Prefix-Tuned PEFT (PT-PEFT), which successively performs prefix-tuning and then other PEFT (i.e., Adapter, LoRA), combines the benefits of both. Experimental results show that PT-PEFT not only improves performance in image captioning and visual question answering compared to vanilla PEFT methods but also helps preserve the representation space of the four pre-trained models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.44",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "What Would Happen Next? Predicting Consequences from An Event Causality Graph": {
        "type": "INPROCEEDINGS",
        "key": "zhan-etal-2024-happen",
        "author": "Zhan, Chuanhong and Xiang, Wei and Chao, Liang and Wang, Bang",
        "booktitle": "EMNLP-findings2024",
        "title": "What Would Happen Next? Predicting Consequences from An Event Causality Graph",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing script event prediction task forcasts the subsequent event based on an event script chain. However, the evolution of historical events are more complicated in real world scenarios and the limited information provided by the event script chain also make it difficult to accurately predict subsequent events. This paper introduces a Causality Graph Event Prediction(CGEP) task that forecasting consequential event based on an Event Causality Graph (ECG). We propose a Semantic Enhanced Distance-sensitive Graph Prompt Learning (SeDGPL) Model for the CGEP task. In SeDGPL, (1) we design a Distance-sensitive Graph Linearization (DsGL) module to reformulate the ECG into a graph prompt template as the input of a PLM; (2) propose an Event-Enriched Causality Encoding (EeCE) module to integrate both event contextual semantic and graph schema information; (3) propose a Semantic Contrast Event Prediction (ScEP) module to enhance the event representation among numerous candidate events and predict consequential event following prompt learning paradigm. Experiment results validate our argument our proposed SeDGPL model outperforms the advanced competitors for the CGEP task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.45",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks": {
        "type": "INPROCEEDINGS",
        "key": "an-etal-2024-llms",
        "author": "An, Shengnan and Ma, Zexiong and Cai, Siqi and Lin, Zeqi and Zheng, Nanning and Lou, Jian-Guang and Chen, Weizhu",
        "booktitle": "EMNLP-findings2024",
        "title": "Can LLMs Learn From Mistakes? An Empirical Study on Reasoning Tasks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Towards enhancing the chain-of-thought (CoT) reasoning of large language models (LLMs), much existing work has revealed the effectiveness of straightforward learning on annotated/generated CoT paths. However, there is less evidence yet that reasoning capabilities can be enhanced through a reverse learning process, i.e., learning from potential mistakes in reasoning. To investigate whether LLMs can learn from mistakes, we construct mistake-correction datasets, using GPT-4 to identify and correct the mistakes in inaccurate CoTs. With these mistake-correction datasets, we fine-tune open-source LLMs and arrive at the following conclusions. (1) LLMs can indeed learn from mistakes to enhance their CoT reasoning performances. (2) Compared to CoT data, the mistake-correction data provides additional knowledge on the explanations and reasons for the potential mistakes in CoTs, which consistently contributes to the effectiveness of learning from mistakes. (3) Evolution techniques, especially the correction-centric evolution we introduced, can further enhance the effectiveness of learning from mistakes.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.46",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction": {
        "type": "INPROCEEDINGS",
        "key": "ning-etal-2024-temporal",
        "author": "Ning, Wanting and Li, Lishuang and Qin, Xueyang and Feng, Yubo and Tang, Jingyao",
        "booktitle": "EMNLP-findings2024",
        "title": "Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Understanding and analyzing event temporal relations is a crucial task in Natural Language Processing (NLP). This task, known as Event Temporal Relation Extraction (ETRE), aims to identify and extract temporal connections between events in text. Recent studies focus on locating the relative position of event pairs on the timeline by designing logical expressions or auxiliary tasks to predict their temporal occurrence. Despite these advances, this modeling approach neglects the multidimensional information in temporal relation and the hierarchical process of reasoning. In this study, we propose a novel hierarchical modeling approach for this task by introducing a Temporal Cognitive Tree (TCT) that mimics human logical reasoning. Additionally, we also design a integrated model incorporating prompt optimization and deductive reasoning to exploit multidimensional supervised information. Extensive experiments on TB-Dense and MATRES datasets demonstrate that our approach outperforms existing methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.47",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LongGenBench: Long-context Generation Benchmark": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-longgenbench",
        "author": "Liu, Xiang and Dong, Peijie and Hu, Xuming and Chu, Xiaowen",
        "booktitle": "EMNLP-findings2024",
        "title": "LongGenBench: Long-context Generation Benchmark",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Current long-context benchmarks primarily focus on retrieval-based tests, requiring Large Language Models (LLMs) to locate specific information within extensive input contexts, such as the needle-in-a-haystack (NIAH) benchmark. Long-context generation refers to the ability of a language model to generate coherent and contextually accurate text that spans across lengthy passages or documents. While recent studies show strong performance on NIAH and other retrieval-based long-context benchmarks, there is a significant lack of benchmarks for evaluating long-context generation capabilities. To bridge this gap and offer a comprehensive assessment, we introduce a synthetic benchmark, LongGenBench, which allows for flexible configurations of customized generation context lengths. LongGenBench advances beyond traditional benchmarks by redesigning the format of questions and necessitating that LLMs respond with a single, cohesive long-context answer. Upon extensive evaluation using LongGenBench, we observe that: (1) both API accessed and open source models exhibit performance degradation in long-context generation scenarios, ranging from 1.2% to 47.1%; (2) different series of LLMs exhibit varying trends of performance degradation, with the Gemini-1.5-Flash model showing the least degradation among API accessed models, and the Qwen2 series exhibiting the least degradation in LongGenBench among open source models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.48",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "RaFe: Ranking Feedback Improves Query Rewriting for RAG": {
        "type": "INPROCEEDINGS",
        "key": "mao-etal-2024-rafe",
        "author": "Mao, Shengyu and Jiang, Yong and Chen, Boli and Li, Xiao and Wang, Peng and Wang, Xinyu and Xie, Pengjun and Huang, Fei and Chen, Huajun and Zhang, Ningyu",
        "booktitle": "EMNLP-findings2024",
        "title": "RaFe: Ranking Feedback Improves Query Rewriting for RAG",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As Large Language Models (LLMs) and Retrieval Augmentation Generation (RAG) techniques have evolved, query rewriting has been widely incorporated into the RAG system for downstream tasks like open-domain QA to enhance document retrieval by reformulating queries. Many works have attempted to improve query rewriting in smaller models to avoid rewriting with costly LLMs, and the most common method is to employ reinforcement learning for feedback training. However, current methods require annotations (labeled relevant documents or downstream answers) or predesigned rewards for feedback, lack generalization, and fail to utilize signals tailored for query rewriting. In this paper, we propose RaFe, a framework for training query rewriting models. By leveraging reranker, RaFe provides ranking feedback aligned well with the rewriting objectives without needing signals from annotations and supports both online and offline training models. Experimental results demonstrate that with a general and publicly available reranker, RaFe can effectively steer the training for rewrite models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.49",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BASES: Large-scale Web Search User Simulation with Large Language Model based Agents": {
        "type": "INPROCEEDINGS",
        "key": "ren-etal-2024-bases",
        "author": "Ren, Ruiyang and Qiu, Peng and Qu, Yingqi and Liu, Jing and Zhao, Xin and Wu, Hua and Wen, Ji-Rong and Wang, Haifeng",
        "booktitle": "EMNLP-findings2024",
        "title": "BASES: Large-scale Web Search User Simulation with Large Language Model based Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Due to the excellent capacities of large language models (LLMs), it becomes feasible to develop LLM-based agents for reliable user simulation. Considering the scarcity and limit (e.g., privacy issues) of real user data, in this paper, we conduct large-scale user simulations for the web search scenario to improve the analysis and modeling of user search behavior. Specially, we propose BASES, a novel user simulation framework with LLM-based agents, designed to facilitate comprehensive simulations of web search user behaviors. Our simulation framework can generate unique user profiles at scale, which subsequently leads to diverse search behaviors. To demonstrate the effectiveness of BASES, we conduct evaluation experiments based on two human benchmarks in both Chinese and English, demonstrating that BASES can effectively simulate large-scale human-like search behaviors. To further accommodate the research on web search, we develop WARRIORS, a new large-scale dataset encompassing web search user behaviors, including both Chinese and English versions, which can greatly bolster research in the field of information retrieval.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.50",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Make Large Language Model a Better Ranker": {
        "type": "INPROCEEDINGS",
        "key": "chao-etal-2024-make",
        "author": "Chao, Wen-Shuo and Zheng, Zhi and Zhu, Hengshu and Liu, Hao",
        "booktitle": "EMNLP-findings2024",
        "title": "Make Large Language Model a Better Ranker",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) demonstrate robust capabilities across various fields, leading to a paradigm shift in LLM-enhanced Recommender System (RS). Research to date focuses on point-wise and pair-wise recommendation paradigms, which are inefficient for LLM-based recommenders due to high computational costs. However, existing list-wise approaches also fall short in ranking tasks due to misalignment between ranking objectives and next-token prediction. Moreover, these LLM-based methods struggle to effectively address the order relation among candidates, particularly given the scale of ratings. To address these challenges, this paper introduces the large language model framework with Aligned Listwise Ranking Objectives (ALRO). ALRO is designed to bridge the gap between the capabilities of LLMs and the nuanced requirements of ranking tasks. Specifically, ALRO employs explicit feedback in a listwise manner by introducing soft lambda loss, a customized adaptation of lambda loss designed for optimizing order relations. This mechanism provides more accurate optimization goals, enhancing the ranking process. Additionally, ALRO incorporates a permutation-sensitive learning mechanism that addresses position bias, a prevalent issue in generative models, without imposing additional computational burdens during inference. Our evaluative studies reveal that ALRO outperforms both existing embedding-based recommendation methods and LLM-based recommendation baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.51",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning": {
        "type": "INPROCEEDINGS",
        "key": "imperial-tayyar-madabushi-2024-specialex",
        "author": "Imperial, Joseph Marvin and Tayyar Madabushi, Harish",
        "booktitle": "EMNLP-findings2024",
        "title": "SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Specialized lexicons are collections of words with associated constraints such as special definitions, specific roles, and intended target audiences. These constraints are necessary for content generation and documentation tasks (e.g., writing technical manuals or children\u2019s reading materials), where the goal is to reduce the ambiguity of text content and increase its overall readability for a specific group of audience. Understanding how large language models can capture these constraints can help researchers build better, more impactful tools for wider use beyond the NLP community. Towards this end, we introduce SpeciaLex, a benchmark for evaluating a language model\u2019s ability to follow specialized lexicon-based constraints across 18 diverse subtasks with 1,785 test instances covering core tasks of Checking, Identification, Rewriting, and Open Generation. We present an empirical evaluation of 15 open and closed-source LLMs and discuss insights on how factors such as model scale, openness, setup, and recency affect performance upon evaluating with the benchmark.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.52",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Devil\u2019s Advocate: Anticipatory Reflection for LLM Agents": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-devils",
        "author": "Wang, Haoyu and Li, Tao and Deng, Zhiwei and Roth, Dan and Li, Yang",
        "booktitle": "EMNLP-findings2024",
        "title": "Devil\u2019s Advocate: Anticipatory Reflection for LLM Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this work, we introduce a novel approach that equips LLM agents with introspection, enhancing consistency and adaptability in solving complex tasks. Our approach prompts LLM agents to decompose a given task into manageable subtasks (i.e., to make a plan), and to continuously introspect upon the suitability and results of their actions. We implement a three-fold introspective intervention: 1) anticipatory reflection on potential failures and alternative remedy before action execution, 2) post-action alignment with subtask objectives and backtracking with remedy to ensure utmost effort in plan execution, and 3) comprehensive review upon plan completion for future strategy refinement. By deploying and experimenting with this methodology\u2014a zero-shot approach\u2014within WebArena for practical tasks in web environments, our agent demonstrates superior performance with a success rate of 23.5% over existing zero-shot methods by 3.5%. The experimental results suggest that our introspection-driven approach not only enhances the agent\u2019s ability to navigate unanticipated challenges through a robust mechanism of plan execution, but also improves efficiency by reducing the number of trials and plan revisions by 45% needed to achieve a task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.53",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access": {
        "type": "INPROCEEDINGS",
        "key": "su-etal-2024-api",
        "author": "Su, Jiayuan and Luo, Jing and Wang, Hongwei and Cheng, Lu",
        "booktitle": "EMNLP-findings2024",
        "title": "API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) with black-box API access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs. In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance. To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage. The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity). Experimental results on both close-ended and open-ended Question Answering tasks show our approach can mostly outperform the logit-based CP baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.54",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-introducing",
        "author": "Zhang, Shuoming and Zhao, Jiacheng and Xia, Chunwei and Wang, Zheng and Chen, Yunji and Cui, Huimin",
        "booktitle": "EMNLP-findings2024",
        "title": "Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Compilers are complex software containing millions of lines of code, taking years to develop. This paper investigates to what extent Large Language Models (LLMs) can replace hand-crafted compilers in translating high-level programming languages to machine instructions, using C to x86 assembly as a case study. We identify two challenges of using LLMs for code translation and introduce two novel data pre-processing techniques to address the challenges: numerical value conversion and training data resampling. While only using a 13B model, our approach achieves a behavioral accuracy of over 91%, outperforming the much larger GPT-4 Turbo model by over 50%. Our results are encouraging, showing that LLMs have the potential to transform how compilation tools are constructed.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.55",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization": {
        "type": "INPROCEEDINGS",
        "key": "duan-etal-2024-negating",
        "author": "Duan, Shitong and Yi, Xiaoyuan and Zhang, Peng and Liu, Yan and Liu, Zheng and Lu, Tun and Xie, Xing and Gu, Ning",
        "booktitle": "EMNLP-findings2024",
        "title": "Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have revolutionized the role of AI, yet pose potential social risks. To steer LLMs towards human preference, alignment technologies have been introduced and gained increasing attention. Nevertheless, existing methods heavily rely on high-quality positive-negative training pairs, suffering from noisy positive responses that are barely distinguishable from negative ones. Given recent LLMs\u2019 proficiency in generating helpful responses, this work pivots towards a new research question: **can we achieve alignment using solely human-annotated negative samples, preserving helpfulness while reducing harmfulness?** For this purpose, we propose Distributional Dispreference Optimization (D\u00b2O), which maximizes the discrepancy between dispreferred responses and the generated non-negative ones. In this way, D\u00b2O effectively eschews harmful information without incorporating noisy positive samples, while avoiding collapse using self-generated responses as anchors. We demonstrate that D\u00b2O can be regarded as learning a distributional preference model reflecting human dispreference against negative responses, which is theoretically an upper bound of the instance-level DPO. Extensive experiments manifest that our method achieves comparable generation quality and surpasses the latest strong baselines in producing less harmful and more informative responses with better training stability and faster convergence.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.56",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "OffsetBias: Leveraging Debiased Data for Tuning Evaluators": {
        "type": "INPROCEEDINGS",
        "key": "park-etal-2024-offsetbias",
        "author": "Park, Junsoo and Jwa, Seungyeon and Meiying, Ren and Kim, Daeyoung and Choi, Sanghyuk",
        "booktitle": "EMNLP-findings2024",
        "title": "OffsetBias: Leveraging Debiased Data for Tuning Evaluators",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Employing Large Language Models (LLMs) to assess the quality of generated responses has become a widely adopted evaluation method. Specifically, instruct-tuned models and fine-tuned judge models based on open-source LLMs have been reported. While it is known that judge models are vulnerable to certain biases, such as favoring longer answers regardless of content, the specifics of these biases remain under-explored. In this work, we qualitatively identify six types of biases inherent in various judge models. We propose EvalBiasBench as a meta-evaluation collection of hand-crafted test cases for each bias type. Additionally, we present de-biasing dataset construction methods and the associated preference dataset OffsetBias. Experimental results demonstrate that fine-tuning on our dataset significantly enhances the robustness of judge models against biases and improves performance across most evaluation scenarios. We release our datasets and the fine-tuned judge model to public.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.57",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Employing Glyphic Information for Chinese Event Extraction with Vision-Language Model": {
        "type": "INPROCEEDINGS",
        "key": "bao-etal-2024-employing",
        "author": "Bao, Xiaoyi and Gu, Jinghang and Wang, Zhongqing and Qiang, Minjie and Huang, Chu-Ren",
        "booktitle": "EMNLP-findings2024",
        "title": "Employing Glyphic Information for Chinese Event Extraction with Vision-Language Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As a complex task that requires rich information input, features from various aspects have been utilized in event extraction. However, most of the previous works ignored the value of glyph, which could contain enriched semantic information and can not be fully expressed by the pre-trained embedding in hieroglyphic languages like Chinese. We argue that, compared with combining the sophisticated textual features, glyphic information from visual modality could provide us with extra and straight semantic information in extracting events. Motivated by this, we propose a glyphic multi-modal Chinese event extraction model with hieroglyphic images to capture the intra- and inter-character morphological structure from the sequence. Extensive experiments build a new state-of-the-art performance in the ACE2005 Chinese and KBP Eval 2017 dataset, which underscores the effectiveness of our proposed glyphic event extraction model, and more importantly, the glyphic feature can be obtained at nearly zero cost.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.58",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-clip",
        "author": "Zhang, Zeliang and Liu, Zhuo and Feng, Mingqian and Xu, Chenliang",
        "booktitle": "EMNLP-findings2024",
        "title": "Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "CLIP has demonstrated great versatility in adapting to various downstream tasks, such as image editing and generation, visual question answering, and video understanding. However, CLIP-based applications often suffer from misunderstandings regarding user intent, leading to discrepancies between the required number of objects and the actual outputs in image generation tasks. In this work, we empirically investigate the quantity bias in CLIP. By carefully designing different experimental settings and datasets, we comprehensively evaluate CLIP\u2019s understanding of quantity from text, image, and cross-modal perspectives. Our experimental results reveal a quantity bias in CLIP embeddings, impacting the reliability of downstream tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.59",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning": {
        "type": "INPROCEEDINGS",
        "key": "meng-etal-2024-llm",
        "author": "Meng, Silin and Wang, Yiwei and Yang, Cheng-Fu and Peng, Nanyun and Chang, Kai-Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Path planning is a fundamental scientific problem in robotics and autonomous navigation, requiring the derivation of efficient routes from starting to destination points while avoiding obstacles. Traditional algorithms like A* and its variants are capable of ensuring path validity but suffer from significant computational and memory inefficiencies as the state space grows. Conversely, large language models (LLMs) excel in broader environmental analysis through contextual understanding, providing global insights into environments. However, they fall short in detailed spatial and temporal reasoning, often leading to invalid or inefficient routes. In this work, we propose LLM-A*, an new LLM based route planning method that synergistically combines the precise pathfinding capabilities of A* with the global reasoning capability of LLMs. This hybrid approach aims to enhance pathfinding efficiency in terms of time and space complexity while maintaining the integrity of path validity, especially in large-scale scenarios. By integrating the strengths of both methodologies, LLM-A* addresses the computational and memory limitations of conventional algorithms without compromising on the validity required for effective pathfinding.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.60",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Guided Knowledge Generation with Language Models for Commonsense Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "wei-etal-2024-guided",
        "author": "Wei, Xiao and Chen, Haoran and Yu, Hang and Fei, Hao and Liu, Qian",
        "booktitle": "EMNLP-findings2024",
        "title": "Guided Knowledge Generation with Language Models for Commonsense Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have achieved notable success in commonsense reasoning tasks, benefiting from their extensive world knowledge acquired through extensive pretraining. While approaches like Chain-of-Thought (CoT) have shown promise in enhancing LLMs\u2019 reasoning capabilities, mitigating the influence of inaccurate commonsense knowledge remains a challenge, particularly for small-scale LLMs (e.g., those with less than 10B parameters). In this work, we propose a novel method named Guided Knowledge Generation (GuideKG) to address these issues. It presents three advantages: (i) Employing LLMs to generate knowledge explanations and to automatically assign labels based on the probability of correct answers eliminates the need for costly manual annotation in subsequent training. (ii) Training a new module called the \u2018Know-Filter\u2019, which is used to evaluate knowledge, and we have introduced a new loss to enhance its performance. (iii) Evaluating the effectiveness of knowledge fragments at the sentence level and fusing them allows for precise control over the generation process of LLMs. We evaluate our GuideKG on small-scale LLMs and show that it outperforms all baselines on four widely-used commonsense reasoning benchmarks. Moreover, our experiments reveal that, with proper guidance, small-scale LLMs can exhibit exceptional performance in commonsense reasoning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.61",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain": {
        "type": "INPROCEEDINGS",
        "key": "guan-etal-2024-bsharedrag",
        "author": "Guan, Kaisi and Cao, Qian and Sun, Yuchong and Wang, Xiting and Song, Ruihua",
        "booktitle": "EMNLP-findings2024",
        "title": "BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval Augmented Generation (RAG) system is important in domains such as e-commerce, which has many long-tail entities and frequently updated information. Most existing works adopt separate modules for retrieval and generation, which may be suboptimal since the retrieval task and the generation task cannot benefit from each other to improve performance. We propose a novel Backbone Shared RAG framework (BSharedRAG). It first uses a domain-specific corpus to continually pre-train a base model as a domain-specific backbone model and then trains two plug-and-play Low-Rank Adaptation (LoRA) modules based on the shared backbone to minimize retrieval and generation losses respectively. Experimental results indicate that our proposed BSharedRAG outperforms baseline models by 5% and 13% in Hit@3 upon two datasets in retrieval evaluation and by 23% in terms of BLEU-3 in generation evaluation. Our codes, models, and dataset are available at https://bsharedrag.github.io.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.62",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "NCPrompt: NSP-Based Prompt Learning and Contrastive Learning for Implicit Discourse Relation Recognition": {
        "type": "INPROCEEDINGS",
        "key": "rong-mo-2024-ncprompt",
        "author": "Rong, Yuetong and Mo, Yijun",
        "booktitle": "EMNLP-findings2024",
        "title": "NCPrompt: NSP-Based Prompt Learning and Contrastive Learning for Implicit Discourse Relation Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Implicit Discourse Relation Recognition (IDRR) is an important task to classify the discourse relation sense between argument pairs without an explicit connective. Recently, prompt learning methods have demonstrated success in IDRR. However, prior work primarily transform IDRR into a connective-cloze task based on the masked language model (MLM), which limits the predicted connective to one single token. Also, they fail to fully exploit critical semantic features shared among various forms of templates. In this paper, we propose NCPrompt, an NSP-based prompt learning and Contrastive learning method for IDRR. Specifically, we transform the IDRR task into a next sentence prediction (NSP) task, which can allow various-length answer connectives and enlarge the construction of the verbalizer for prompt-learning methods. Also, we notice that various prompt templates naturally constitute positive samples applied for self-supervised contrastive learning. And the usage of NSP naturally creates hard negative samples by introducing different candidate connectives between the same example. To our knowledge, we are the first to combine self-supervised contrastive learning with prompt learning to obtain high-quality semantic representations. Experiments on the PDTB 3.0 corpus have demonstrated the effectiveness and superiority of our model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.63",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SAFETY-J: Evaluating Safety with Critique": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-safety",
        "author": "Liu, Yixiu and Zheng, Yuxiang and Xia, Shijie and Li, Jiajun and Tu, Yi and Song, Chaoling and Liu, Pengfei",
        "booktitle": "EMNLP-findings2024",
        "title": "SAFETY-J: Evaluating Safety with Critique",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The deployment of Large Language Models (LLMs) in content generation raises significant safety concerns, particularly regarding the transparency and interpretability of content evaluations. Current methods, primarily focused on binary safety classifications, lack mechanisms for detailed critique, limiting their utility for model improvement and user trust. To address these limitations, we introduce SAFETY-J, a bilingual generative safety evaluator for English and Chinese with critique-based judgment. SAFETY-J utilizes a robust training dataset that includes diverse dialogues and augmented query-response pairs to assess safety across various scenarios comprehensively. We establish an automated meta-evaluation benchmark that objectively assesses the quality of critiques with minimal human intervention, facilitating scalable and continuous improvement. Additionally, SAFETY-Jemploys an iterative preference learning technique to dynamically refine safety assessments based on meta-evaluations and critiques. Our evaluations demonstrate that SAFETY-J provides more nuanced and accurate safety evaluations, thereby enhancing both critique quality and predictive reliability in complex content scenarios. To facilitate further research and application, we have released SAFETY-J\u2019s training protocols, datasets, and code at https://github.com/GAIR-NLP/Safety-J.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.64",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-improving-demonstration",
        "author": "Wang, Dingzirui and Dou, Longxu and Zhang, Xuanliang and Zhu, Qingfu and Che, Wanxiang",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In-context learning with large language models (LLMs) is the current mainstream method for text-to-SQL. Previous studies have explored selecting relevant demonstrations from a human-labeled demonstration pool, but these methods lack diversity and incur high labeling costs. In this work, we address measuring and enhancing the diversity of the text-to-SQL demonstration pool. First, we introduce a diversity metric and present that the diversity of the existing labeling data can be further enhanced. Motivated by these findings, we propose Fused that iteratively fuses demonstrations to create a diverse demonstration pool based on human labeling or even from scratch with LLMs, reducing labeling costs. Fused achieves an average improvement of 2.1% based on existing labeling and 5.5% from scratch on several mainstream datasets, demonstrating its effectiveness.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.65",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models": {
        "type": "INPROCEEDINGS",
        "key": "sathe-etal-2024-unified",
        "author": "Sathe, Ashutosh and Jain, Prachi and Sitaram, Sunayana",
        "booktitle": "EMNLP-findings2024",
        "title": "A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Vision-language models (VLMs) have gained widespread adoption in both industry and academia. In this study, we propose a unified framework for systematically evaluating gender, race, and age biases in VLMs with respect to professions. Our evaluation encompasses all supported inference modes of the recent VLMs, including image-to-text, text-to-text, text-to-image, and image-to-image. We create a synthetic, high-quality dataset comprising text and images that intentionally obscure gender, race, and age distinctions across various professions. The dataset includes action-based descriptions of each profession and serves as a benchmark for evaluating societal biases in vision-language models (VLMs). In our benchmarking of popular vision-language models (VLMs), we observe that different input-output modalities result in distinct bias magnitudes and directions. We hope our work will help guide future progress in improving VLMs to learn socially unbiased representations. We will release our data and code.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.66",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech": {
        "type": "INPROCEEDINGS",
        "key": "ning-etal-2024-breaking",
        "author": "Ning, Jinzhong and Sun, Yuanyuan and Xu, Bo and Yang, Zhihao and Luo, Ling and Lin, Hongfei",
        "booktitle": "EMNLP-findings2024",
        "title": "Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In recent years, with the vast and rapidly increasing amounts of spoken and textual data, Named Entity Recognition (NER) tasks have evolved into three distinct categories, i.e., text-based NER (TNER), Speech NER (SNER) and Multimodal NER (MNER). However, existing approaches typically require designing separate models for each task, overlooking the potential connections between tasks and limiting the versatility of NER methods. To mitigate these limitations, we introduce a new task named Integrated Multimodal NER (IMNER) to break the boundaries between different modal NER tasks, enabling a unified implementation of them. To achieve this, we first design a unified data format for inputs from different modalities. Then, leveraging the pre-trained MMSpeech model as the backbone, we propose an **I**ntegrated **M**ultimod**a**l **Ge**neration Framework (**IMAGE**), formulating the Chinese IMNER task as an entity-aware text generation task. Experimental results demonstrate the feasibility of our proposed IMAGE framework in the IMNER task. Our work in integrated multimodal learning in advancing the performance of NER may set up a new direction for future research in the field. Our source code is available at https://github.com/NingJinzhong/IMAGE4IMNER.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.67",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "VGA: Vision GUI Assistant - Minimizing Hallucinations through Image-Centric Fine-Tuning": {
        "type": "INPROCEEDINGS",
        "key": "ziyang-etal-2024-vga",
        "author": "Ziyang, Meng and Dai, Yu and Gong, Zezheng and Guo, Shaoxiong and Tang, Minglong and Wei, Tongquan",
        "booktitle": "EMNLP-findings2024",
        "title": "VGA: Vision GUI Assistant - Minimizing Hallucinations through Image-Centric Fine-Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Vision-Language Models (VLMs) have already been applied to the understanding of Graphical User Interfaces (GUIs) and have achieved notable results. However, existing VLMs often overly rely on internal text-based knowledge while neglecting visual inputs. This imbalance may lead models to produce answers that do not align with the visual content in GUI comprehension tasks. Such inaccuracies are termed as \u2018hallucinations\u2019 where models generate incorrect or illogical responses upon visual verification against GUI elements. These errors result in misinterpretations and diminish the model\u2019s practical utility in applied settings. To address these issues, we introduce VGA, a fine-tuned model designed for comprehensive GUI understanding. Our model aims to balance attention image and text to enhance interpretation and reduce hallucinations. We construct a Vision Question Answering (VQA) dataset of 63.8k high-quality examples with our propose *Referent Method*, focusing on response with visual content of images. We then design a two-stage fine-tuning method to enhance both the model\u2019s accuracy to extract information from image content and alignment with human intent. Experiments show that our approach enhances the model\u2019s ability to extract information from images and achieves state-of-the-art results in GUI understanding tasks. https://github.com/Linziyang1999/VGA-visual-GUI-assistant",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.68",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-understanding-therapeutic",
        "author": "Li, Anqi and Lu, Yu and Song, Nirui and Zhang, Shuai and Ma, Lizhi and Lan, Zhenzhong",
        "booktitle": "EMNLP-findings2024",
        "title": "Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Robust therapeutic relationships between counselors and clients are fundamental to counseling effectiveness. The assessment of therapeutic alliance is well-established in traditional face-to-face therapy but may not directly translate to text-based settings. With millions of individuals seeking support through online text-based counseling, understanding the relationship in such contexts is crucial.In this paper, we present an automatic approach using large language models (LLMs) to understand the development of therapeutic alliance in text-based counseling. We adapt a theoretically grounded framework specifically to the context of online text-based counseling and develop comprehensive guidelines for characterizing the alliance. We collect a comprehensive counseling dataset and conduct multiple expert evaluations on a subset based on this framework. Our LLM-based approach, combined with guidelines and simultaneous extraction of supportive evidence underlying its predictions, demonstrates effectiveness in identifying the therapeutic alliance. Through further LLM-based evaluations on additional conversations, our findings underscore the challenges counselors face in cultivating strong online relationships with clients. Furthermore, we demonstrate the potential of LLM-based feedback mechanisms to enhance counselors\u2019 ability to build relationships, supported by a small-scale proof-of-concept.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.69",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Dynamic Planning for LLM-based Graphical User Interface Automation": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-dynamic",
        "author": "Zhang, Shaoqing and Zhang, Zhuosheng and Chen, Kehai and Ma, Xinbei and Yang, Muyun and Zhao, Tiejun and Zhang, Min",
        "booktitle": "EMNLP-findings2024",
        "title": "Dynamic Planning for LLM-based Graphical User Interface Automation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The advent of large language models (LLMs) has spurred considerable interest in advancing autonomous LLMs-based agents, particularly in intriguing applications within smartphone graphical user interfaces (GUIs). When presented with a task goal, these agents typically emulate human actions within a GUI environment until the task is completed. However, a key challenge lies in devising effective plans to guide action prediction in GUI tasks, though planning have been widely recognized as effective for decomposing complex tasks into a series of steps. Specifically, given the dynamic nature of environmental GUIs following action execution, it is crucial to dynamically adapt plans based on environmental feedback and action history.We show that the widely-used ReAct approach fails due to the excessively long historical dialogues. To address this challenge, we propose a novel approach called Dynamic Planning of Thoughts (D-PoT) for LLM-based GUI agents.D-PoT involves the dynamic adjustment of planning based on the environmental feedback and execution history. Experimental results reveal that the proposed D-PoT significantly surpassed the strong GPT-4V baseline by +12.7% (34.66% \\rightarrow 47.36%) in accuracy. The analysis highlights the generality of dynamic planning in different backbone LLMs, as well as the benefits in mitigating hallucinations and adapting to unseen tasks. Code is available at https://github.com/sqzhang-lazy/D-PoT.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.70",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation": {
        "type": "INPROCEEDINGS",
        "key": "hu-etal-2024-serts",
        "author": "Hu, Minda and Zong, Licheng and Wang, Hongru and Zhou, Jingyan and Li, Jingjing and Gao, Yichen and Wong, Kam-Fai and Li, Yu and King, Irwin",
        "booktitle": "EMNLP-findings2024",
        "title": "SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have shown great potential in the biomedical domain with the advancement of retrieval-augmented generation (RAG). However, existing retrieval-augmented approaches face challenges in addressing diverse queries and documents, particularly for medical knowledge queries, resulting in sub-optimal performance. To address these limitations, we propose a novel plug-and-play LLM-based retrieval method called Self-Rewarding Tree Search (SeRTS) based on Monte Carlo Tree Search (MCTS) and a self-rewarding paradigm. By combining the reasoning capabilities of LLMs with the effectiveness of tree search, SeRTS boosts the zero-shot performance of retrieving high-quality and informative results for RAG. We further enhance retrieval performance by fine-tuning LLMs with Proximal Policy Optimization (PPO) objectives using the trajectories collected by SeRTS as feedback. Controlled experiments using the BioASQ-QA dataset with GPT-3.5-Turbo and LLama2-7b demonstrate that our method significantly improves the performance of the BM25 retriever and surpasses the strong baseline of self-reflection in both efficiency and scalability. Moreover, SeRTS generates higher-quality feedback for PPO training than self-reflection. Our proposed method effectively adapts LLMs to document retrieval tasks, enhancing their ability to retrieve highly relevant documents for RAG in the context of medical knowledge queries. This work presents a significant step forward in leveraging LLMs for accurate and comprehensive biomedical question answering.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.71",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Model-based Human-Agent Collaboration for Complex Task Solving": {
        "type": "INPROCEEDINGS",
        "key": "feng-etal-2024-large",
        "author": "Feng, Xueyang and Chen, Zhi-Yuan and Qin, Yujia and Lin, Yankai and Chen, Xu and Liu, Zhiyuan and Wen, Ji-Rong",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Model-based Human-Agent Collaboration for Complex Task Solving",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In recent developments within the research community, the integration of Large Language Models (LLMs) in creating fully autonomous agents has garnered significant interest. Despite this, LLM-based agents frequently demonstrate notable shortcomings in adjusting to dynamic environments and fully grasping human needs. In this work, we introduce the problem of LLM-based human-agent collaboration for complex task-solving, exploring their synergistic potential. To tackle the problem, we propose a Reinforcement Learning-based Human-Agent Collaboration method, ReHAC, which trains a policy model designed to determine the most opportune stages for human intervention within the task-solving process. We conduct experiments under real and simulated human-agent collaboration scenarios. Experimental results demonstrate that the synergistic efforts of humans and LLM-based agents significantly improve performance in complex tasks, primarily through well-planned, limited human intervention. Datasets and code are available at: https://github.com/XueyangFeng/ReHAC/.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.72",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation and Fine-grained Classification": {
        "type": "INPROCEEDINGS",
        "key": "sun-etal-2024-mm",
        "author": "Sun, Kai and Bai, Yushi and Qi, Ji and Hou, Lei and Li, Juanzi",
        "booktitle": "EMNLP-findings2024",
        "title": "MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation and Fine-grained Classification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To advance the evaluation of multimodal math reasoning in large multimodal models (LMMs), this paper introduces a novel benchmark, MM-MATH. MM-MATH consists of 5,929 open-ended middle school math problems with visual contexts, with fine-grained classification across difficulty, grade level, and knowledge points. Unlike existing benchmarks relying on binary answer comparison, MM-MATH incorporates both outcome and process evaluations. Process evaluation employs LMM-as-a-judge to automatically analyze solution steps, identifying and categorizing errors into specific error types. Extensive evaluation of ten models on MM-MATH reveals significant challenges for existing LMMs, highlighting their limited utilization of visual information and struggles with higher-difficulty problems. The best-performing model achieves only 31% accuracy on MM-MATH, compared to 82% for humans. This highlights the challenging nature of our benchmark for existing models and the significant gap between the multimodal reasoning capabilities of current models and humans. Our process evaluation reveals that diagram misinterpretation is the most common error, accounting for more than half of the total error cases, underscoring the need for improved image comprehension in multimodal reasoning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.73",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LongAlign: A Recipe for Long Context Alignment of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "bai-etal-2024-longalign",
        "author": "Bai, Yushi and Lv, Xin and Zhang, Jiajie and He, Yuze and Qi, Ji and Hou, Lei and Tang, Jie and Dong, Yuxiao and Li, Juanzi",
        "booktitle": "EMNLP-findings2024",
        "title": "LongAlign: A Recipe for Long Context Alignment of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Extending large language models to effectively handle long contexts requires instruction fine-tuning on input sequences of similar length. To address this, we present LongAlign\u2014a recipe of the instruction data, training, and evaluation for long context alignment. First, we construct a long instruction-following dataset using Self-Instruct. To ensure the data diversity, it covers a broad range of tasks from various long context sources. Second, we adopt the packing and sorted batching strategies to speed up supervised fine-tuning on data with varied length distributions. Additionally, we develop a loss weighting method to balance the contribution to the loss across different sequences during packing training. Third, we introduce the LongBench-Chat benchmark for evaluating instruction-following capabilities on queries of 10k-100k in length. Experiments show that LongAlign outperforms existing recipes for LLMs in long context tasks by up to 30%, while also maintaining their proficiency in handling short, generic tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.74",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Let\u2019s Ask GNN: Empowering Large Language Model for Graph In-Context Learning": {
        "type": "INPROCEEDINGS",
        "key": "hu-etal-2024-lets",
        "author": "Hu, Zhengyu and Li, Yichuan and Chen, Zhengyu and Wang, Jingang and Liu, Han and Lee, Kyumin and Ding, Kaize",
        "booktitle": "EMNLP-findings2024",
        "title": "Let\u2019s Ask GNN: Empowering Large Language Model for Graph In-Context Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Textual Attributed Graphs (TAGs) are crucial for modeling complex real-world systems, yet leveraging large language models (LLMs) for TAGs presents unique challenges due to the gap between sequential text processing and graph-structured data. We introduce AskGNN, a novel approach that bridges this gap by leveraging In-Context Learning (ICL) to integrate graph data and task-specific information into LLMs. AskGNN employs a Graph Neural Network (GNN)-powered structure-enhanced retriever to select labeled nodes across graphs, incorporating complex graph structures and their supervision signals. Our learning-to-retrieve algorithm optimizes the retriever to select example nodes that maximize LLM performance on graph. Experiments across three tasks and seven LLMs demonstrate AskGNN\u2019s superior effectiveness in graph task performance, opening new avenues for applying LLMs to graph-structured data without extensive fine-tuning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.75",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-coxql",
        "author": "Wang, Qianli and Anikina, Tatiana and Feldhus, Nils and Ostermann, Simon and M\u00f6ller, Sebastian",
        "booktitle": "EMNLP-findings2024",
        "title": "CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Conversational explainable artificial intelligence (ConvXAI) systems based on large language models (LLMs) have garnered significant interest from the research community in natural language processing (NLP) and human-computer interaction (HCI). Such systems can provide answers to user questions about explanations in dialogues, have the potential to enhance users\u2019 comprehension and offer more information about the decision-making and generation processes of LLMs. Currently available ConvXAI systems are based on intent recognition rather than free chat, as this has been found to be more precise and reliable in identifying users\u2019 intentions. However, the recognition of intents still presents a challenge in the case of ConvXAI, since little training data exist and the domain is highly specific, as there is a broad range of XAI methods to map requests onto. In order to bridge this gap, we present CoXQL, the first dataset in the NLP domain for user intent recognition in ConvXAI, covering 31 intents, seven of which require filling multiple slots. Subsequently, we enhance an existing parsing approach by incorporating template validations, and conduct an evaluation of several LLMs on CoXQL using different parsing strategies. We conclude that the improved parsing approach (MP+) surpasses the performance of previous approaches. We also discover that intents with multiple slots remain highly challenging for LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.76",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evaluating Language Model Character Traits": {
        "type": "INPROCEEDINGS",
        "key": "ward-etal-2024-evaluating",
        "author": "Ward, Francis Rhys and Yang, Zejia and Jackson, Alex and Brown, Randy and Smith, Chandler and Colverd, Grace Beaney and Thomson, Louis Alexander and Douglas, Raymond and Bartak, Patrik and Rowan, Andrew",
        "booktitle": "EMNLP-findings2024",
        "title": "Evaluating Language Model Character Traits",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language models (LMs) can exhibit human-like behaviour, but it is unclear how to describe this behaviour without undue anthropomorphism. We formalise a behaviourist view of LM character traits: qualities such as truthfulness, sycophancy, and coherent beliefs and intentions, which may manifest as consistent patterns of behaviour. Our theory is grounded in empirical demonstrations of LMs exhibiting different character traits, such as accurate and logically coherent beliefs and helpful and harmless intentions. We infer belief and intent from LM behaviour, finding their consistency varies with model size, fine-tuning, and prompting. In addition to characterising LM character traits, we evaluate how these traits develop over the course of an interaction. We find that traits such as truthfulness and harmfulness can be stationary, i.e., consistent over an interaction, in certain contexts but may be reflective in different contexts, meaning they mirror the LM\u2019s behaviour in the preceding interaction. Our formalism enables us to describe LM behaviour precisely and without undue anthropomorphism.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.77",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-Explore: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards": {
        "type": "INPROCEEDINGS",
        "key": "hwang-etal-2024-self",
        "author": "Hwang, Hyeonbin and Kim, Doyoung and Kim, Seungone and Ye, Seonghyeon and Seo, Minjoon",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-Explore: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Training on large amounts of rationales (i.e., CoT Fine-tuning) has been found effective for improving mathematical reasoning of large language models (LLMs). However, acquiring human-authored solutions or augmenting rationales from proprietary models is costly and not scalable. In this paper, we study the problem of whether LLMs could self-improve mathematical reasoning capabilities. To this end, we propose Self-Explore, where the LLM is tasked to explore the first wrong step (i.e., the first pit) within the rationale and use such signals as fine-grained rewards for further improvement. On the GSM8K and MATH test set, Self-Explore achieves 11.57% and 2.89% improvement on average across three LLMs compared to supervised fine-tuning (SFT). Our code is available here]9.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.78",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents": {
        "type": "INPROCEEDINGS",
        "key": "yuan-etal-2024-r",
        "author": "Yuan, Tongxin and He, Zhiwei and Dong, Lingzhong and Wang, Yiming and Zhao, Ruijie and Xia, Tian and Xu, Lizhen and Zhou, Binglin and Li, Fangqi and Zhang, Zhuosheng and Wang, Rui and Liu, Gongshen",
        "booktitle": "EMNLP-findings2024",
        "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have exhibited great potential in autonomously completing tasks across real-world applications. Despite this, these LLM agents introduce unexpected safety risks when operating in interactive environments. Instead of centering on the harmlessness of LLM-generated content in most prior studies, this work addresses the imperative need for benchmarking the behavioral safety of LLM agents within diverse environments. We introduce R-Judge, a benchmark crafted to evaluate the proficiency of LLMs in judging and identifying safety risks given agent interaction records. R-Judge comprises 569 records of multi-turn agent interaction, encompassing 27 key risk scenarios among 5 application categories and 10 risk types. It is of high-quality curation with annotated safety labels and risk descriptions. Evaluation of 11 LLMs on R-Judge shows considerable room for enhancing the risk awareness of LLMs: The best-performing model, GPT-4o, achieves 74.42% while no other models significantly exceed the random. Moreover, we reveal that risk awareness in open agent scenarios is a multi-dimensional capability involving knowledge and reasoning, thus challenging for LLMs. With further experiments, we find that fine-tuning on safety judgment significantly improve model performance while straightforward prompting mechanisms fail. R-Judge is publicly available at Annoymous.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.79",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "EAVE: Efficient Product Attribute Value Extraction via Lightweight Sparse-layer Interaction": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-eave",
        "author": "Yang, Li and Wang, Qifan and Chi, Jianfeng and Liu, Jiahao and Wang, Jingang and Feng, Fuli and Xu, Zenglin and Fang, Yi and Huang, Lifu and Liu, Dongfang",
        "booktitle": "EMNLP-findings2024",
        "title": "EAVE: Efficient Product Attribute Value Extraction via Lightweight Sparse-layer Interaction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Product attribute value extraction involves identifying the specific values associated with various attributes from a product profile. While existing methods often prioritize the development of effective models to improve extraction performance, there has been limited emphasis on extraction efficiency. However, in real-world scenarios, products are typically associated with multiple attributes, necessitating multiple extractions to obtain all corresponding values. In this work, we propose an Efficient product Attribute Value Extraction (EAVE) approach via lightweight sparse-layer interaction. Specifically, we employ a heavy encoder to separately encode the product context and attribute. The resulting non-interacting heavy representations of the context can be cached and reused for all attributes. Additionally, we introduce a light encoder to jointly encode the context and the attribute, facilitating lightweight interactions between them. To enrich the interaction within the lightweight encoder, we design a sparse-layer interaction module to fuse the non-interacting heavy representation into the lightweight encoder. Comprehensive evaluation on two benchmarks demonstrate that our method achieves significant efficiency gains with neutral or marginal loss in performance when the context is long and number of attributes is large. Our code is available at: https://anonymous.4open.science/r/EAVE-EA18.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.80",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MultiSkill: Evaluating Large Multimodal Models for Fine-grained Alignment Skills": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-multiskill",
        "author": "Xu, Zhenran and Shi, Senbao and Hu, Baotian and Wang, Longyue and Zhang, Min",
        "booktitle": "EMNLP-findings2024",
        "title": "MultiSkill: Evaluating Large Multimodal Models for Fine-grained Alignment Skills",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We propose MultiSkill, an evaluation protocol that assesses large multimodal models (LMMs) across multiple fine-grained skills for alignment with human values. Recent LMMs have shown various intriguing abilities, such as solving graph theory problems and explaining visual jokes. However, existing multimodal benchmarks have mainly focused on coarse-grained evaluation (e.g., accuracy), without considering the skill composition required by specific instructions. To this end, we present MultiSkill, designed to decompose coarse-level scoring to a fine-grained skill set-level scoring tailored to each instruction. MultiSkill defines five core vision-language capabilities and divides into 12 skills that are necessary to align with user instructions. For evaluation metrics on specific skills, we propose an LMM-based evaluator for open-ended outputs. Based on the diverse instructions collected from 66 datasets spanning 10 domains, we compare multiple representative open-source and proprietary LMMs and find a high correlation between model-based and human-based evaluations. Our experiments underscore the importance of fine-grained evaluation in providing a holistic view of model performance and enhancing the reliability of the evaluation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.81",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "tian-etal-2024-forget",
        "author": "Tian, Bozhong and Liang, Xiaozhuan and Cheng, Siyuan and Liu, Qingbin and Wang, Mengru and Sui, Dianbo and Chen, Xi and Chen, Huajun and Zhang, Ningyu",
        "booktitle": "EMNLP-findings2024",
        "title": "To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) trained on extensive corpora inevitably retain sensitive data, such as personal privacy information and copyrighted material. Recent advancements in knowledge unlearning involve updating LLM parameters to erase specific knowledge. However, current unlearning paradigms are mired in vague forgetting boundaries, often erasing knowledge indiscriminately. In this work, we introduce KnowUnDo, a benchmark containing copyrighted content and user privacy domains to evaluate if the unlearning process inadvertently erases essential knowledge. Our findings indicate that existing unlearning methods often suffer from excessive unlearning. To address this, we propose a simple yet effective method, MemFlex, which utilizes gradient information to precisely target and unlearn sensitive parameters. Experimental results show that MemFlex is superior to existing methods in both precise knowledge unlearning and general knowledge retaining of LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.82",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "EchoSight: Advancing Visual-Language Models with Wiki Knowledge": {
        "type": "INPROCEEDINGS",
        "key": "yan-xie-2024-echosight",
        "author": "Yan, Yibin and Xie, Weidi",
        "booktitle": "EMNLP-findings2024",
        "title": "EchoSight: Advancing Visual-Language Models with Wiki Knowledge",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Knowledge-based Visual Question Answering (KVQA) tasks require answering questions about images using extensive background knowledge. Despite significant advancements, generative models often struggle with these tasks due to the limited integration of external knowledge. In this paper, we introduce **EchoSight**, a novel multimodal Retrieval-Augmented Generation (RAG) framework that enables large language models (LLMs) to answer visual questions requiring fine-grained encyclopedic knowledge. To strive for high-performing retrieval, EchoSight first searches wiki articles by using visual-only information, subsequently, these candidate articles are further reranked according to their relevance to the combined text-image query. This approach significantly improves the integration of multimodal knowledge, leading to enhanced retrieval outcomes and more accurate VQA responses. Our experimental results on the E-VQA and InfoSeek datasets demonstrate that EchoSight establishes new state-of-the-art results in knowledge-based VQA, achieving an accuracy of 41.8% on E-VQA and 31.3% on InfoSeek.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.83",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Diversify, Rationalize, and Combine: Ensembling Multiple QA Strategies for Zero-shot Knowledge-based VQA": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-diversify",
        "author": "Li, Miaoyu and Li, Haoxin and Du, Zilin and Li, Boyang",
        "booktitle": "EMNLP-findings2024",
        "title": "Diversify, Rationalize, and Combine: Ensembling Multiple QA Strategies for Zero-shot Knowledge-based VQA",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Knowledge-based Visual Qustion-answering (K-VQA) often requires the use of background knowledge beyond the image. However, we discover that a single knowledge generation strategy is often insuffcient for all K-VQA questions. To this end, we propose Diversifcation, Evidence Truncation, and Combination for Knowledge-based Elucidation (DietCoke), which utilizes a bundle of complementary question-answering tactics and aggregates their answers using textual rationales. DietCoke comprises of three stages: diversifcation, rationalization, and ensemble. The diversification stage generates three distinctive decision contexts, each leading to its own answer candidate. The rationalization stage generates two rationales, the automatic rationale and the mechanistic rationale, for each answer candidate using decorrelated techniques. Finally, in the ensemble stage, an LLM informed by the rationales selects one answer from the three candidates. Experiments show that DietCoke significantly outperforms state-of-the-art LLM-based baselines by 2.8% on OK-VOA and 4.7% on A-OKVOA and that the strategies in the ensembles are highly complementary.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.84",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Reconfidencing LLMs from the Grouping Loss Perspective": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-reconfidencing",
        "author": "Chen, Lihu and Perez-Lebel, Alexandre and Suchanek, Fabian M. and Varoquaux, Ga\u00ebl",
        "booktitle": "EMNLP-findings2024",
        "title": "Reconfidencing LLMs from the Grouping Loss Perspective",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs), such as GPT and LLaMA, are susceptible to generating hallucinated answers in a confident tone. While previous efforts to elicit and calibrate confidence scores have shown some success, they often overlook biases towards certain groups, such as specific nationalities. Existing calibration methods typically focus on average performance, failing to address this disparity. In our study, we demonstrate that the concept of grouping loss is an effective metric for understanding and correcting the heterogeneity in confidence levels. We introduce a novel evaluation dataset, derived from a knowledge base, specifically designed to assess the confidence scores of LLM responses across different groups. Our experimental results highlight significant variations in confidence, which are accurately captured by grouping loss. To tackle this issue, we propose a new method to calibrate the confidence scores of LLMs by considering different groups, a process we term reconfidencing. Our findings indicate that this approach effectively mitigates biases against minority groups, contributing to the development of fairer LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.85",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Tokenization Falling Short: On Subword Robustness in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chai-etal-2024-tokenization",
        "author": "Chai, Yekun and Fang, Yewei and Peng, Qiwei and Li, Xuhong",
        "booktitle": "EMNLP-findings2024",
        "title": "Tokenization Falling Short: On Subword Robustness in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language models typically tokenize raw text into sequences of subword identifiers from a predefined vocabulary, a process inherently sensitive to typographical errors, length variations, and largely oblivious to the internal structure of tokens\u2014issues we term *the curse of tokenization*. In this study, we delve into these drawbacks and demonstrate that large language models (LLMs) remain susceptible to these problems. This study systematically investigates these challenges and their impact on LLMs through three critical research questions: (1) complex problem solving, (2) token structure probing, and (3) resilience to typographical variation. Our findings reveal that scaling model parameters can mitigate the issue of tokenization; however, LLMs still suffer from biases induced by typos and other text format variations. Our experiments show that subword regularization such as BPE-dropout can mitigate this issue. We release our evaluation code and data at https://github.com/FloatAI/TKEval.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.86",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wei-etal-2024-ac",
        "author": "Wei, Yuting and Xu, Yuanxing and Wei, Xinru and Yangsimin, Yangsimin and Zhu, Yangfu and Li, Yuqing and Liu, Di and Wu, Bin",
        "booktitle": "EMNLP-findings2024",
        "title": "AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Given the importance of ancient Chinese in capturing the essence of rich historical and cultural heritage, the rapid advancements in Large Language Models (LLMs) necessitate benchmarks that can effectively evaluate their understanding of ancient contexts. To meet this need, we present AC-EVAL, an innovative benchmark designed to assess the advanced knowledge and reasoning capabilities of LLMs within the context of ancient Chinese. AC-EVAL is structured across three levels of difficulty reflecting different facets of language comprehension: general historical knowledge, short text understanding, and long text comprehension. The benchmark comprises 13 tasks, spanning historical facts, geography, social customs, art, philosophy, classical poetry and prose, providing a comprehensive assessment framework. Our extensive evaluation of top-performing LLMs, tailored for both English and Chinese, reveals a substantial potential for enhancing ancient text comprehension. By highlighting the strengths and weaknesses of LLMs, AC-EVAL aims to promote their development and application forward in the realms of ancient Chinese language education and scholarly research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.87",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos": {
        "type": "INPROCEEDINGS",
        "key": "oguz-etal-2024-mmar",
        "author": "Oguz, Cennet and Denis, Pascal and Ostermann, Simon and Vincent, Emmanuel and Skachkova, Natalia and Genabith, Josef Van",
        "booktitle": "EMNLP-findings2024",
        "title": "MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multilingual anaphora resolution identifies referring expressions and implicit arguments in texts and links to antecedents that cover several languages. In the most challenging setting, cross-lingual anaphora resolution, training data, and test data are in different languages. As knowledge needs to be transferred across languages, this task is challenging, both in the multilingual and cross-lingual setting. We hypothesize that one way to alleviate some of the difficulty of the task is to include multimodal information in the form of images (i.e. frames extracted from instructional videos). Such visual inputs are by nature language agnostic, therefore cross- and multilingual anaphora resolution should benefit from visual information. In this paper, we provide the first multilingual and multimodal dataset annotated with anaphoric relations and present experimental results for end-to-end multimodal and multilingual anaphora resolution. Given gold mentions, multimodal features improve anaphora resolution results by ~10 % for unseen languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.88",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Dealing with Controversy: An Emotion and Coping Strategy Corpus Based on Role Playing": {
        "type": "INPROCEEDINGS",
        "key": "troiano-etal-2024-dealing",
        "author": "Troiano, Enrica and Labat, Sofie and Stranisci, Marco Antonio and Damiano, Rossana and Patti, Viviana and Klinger, Roman",
        "booktitle": "EMNLP-findings2024",
        "title": "Dealing with Controversy: An Emotion and Coping Strategy Corpus Based on Role Playing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "There is a mismatch between psychological and computational studies on emotions. Psychological research aims at explaining and documenting internal mechanisms of these phenomena, while computational work often simplifies them into labels. Many emotion fundamentals remain under-explored in natural language processing, particularly how emotions develop and how people cope with them. To help reduce this gap, we follow theories on coping, and treat emotions as strategies to cope with salient situations (i.e., how people deal with emotion-eliciting events). This approach allows us to investigate the link between emotions and behavior, which also emerges in language. We introduce the task of coping identification, together with a corpus to do so, constructed via role-playing. We find that coping strategies realize in text even though they are challenging to recognize, both for humans and automatic systems trained and prompted on the same task. We thus open up a promising research direction to enhance the capability of models to better capture emotion mechanisms from text.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.89",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MATE: Meet At The Embedding - Connecting Images with Long Texts": {
        "type": "INPROCEEDINGS",
        "key": "jang-etal-2024-mate",
        "author": "Jang, Young Kyun and Kang, Junmo and Lee, Yong Jae and Kim, Donghyun",
        "booktitle": "EMNLP-findings2024",
        "title": "MATE: Meet At The Embedding - Connecting Images with Long Texts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While advancements in Vision Language Models (VLMs) have significantly improved the alignment of visual and textual data, these models primarily focus on aligning images with short descriptive captions. This focus limits their ability to handle complex text interactions, particularly with longer texts such as lengthy captions or documents, which have not been extensively explored yet. In this paper, we introduce Meet At The Embedding (MATE), a novel approach that combines the capabilities of VLMs with Large Language Models (LLMs) to overcome this challenge without the need for additional image-long text pairs. Specifically, we replace the text encoder of the VLM with a pretrained LLM-based encoder that excels in understanding long texts. To bridge the gap between VLM and LLM, MATE incorporates a projection module that is trained in a multi-stage manner. It starts by aligning the embeddings from the VLM text encoder with those from the LLM using extensive text pairs. This module is then employed to seamlessly align image embeddings closely with LLM embeddings. We propose two new cross-modal retrieval benchmarks to assess the task of connecting images with long texts (lengthy captions / documents). Extensive experimental results demonstrate that MATE effectively connects images with long texts, uncovering diverse semantic relationships.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.90",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Mixed Distillation Helps Smaller Language Models Reason Better": {
        "type": "INPROCEEDINGS",
        "key": "chenglin-etal-2024-mixed",
        "author": "Chenglin, Li and Chen, Qianglong and Li, Liangyue and Wang, Caiyu and Tao, Feng and Li, Yicheng and Chen, Zulong and Zhang, Yin",
        "booktitle": "EMNLP-findings2024",
        "title": "Mixed Distillation Helps Smaller Language Models Reason Better",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As large language models (LLMs) have demonstrated impressive multiple step-by-step reasoning capabilities in recent natural language processing (NLP) reasoning tasks, many studies are interested in distilling reasoning abilities into smaller language models (SLMs) via fine-tuning. Previous distillation methods usually utilize the capabilities of LLMs to generate chain-of-thought (CoT) samples to teach SLMs. However, this distillation approach performs poorly in certain scenarios due to the limitations of CoT. In this work, we introduce a novel Mixed Distillation (MD) framework, distilling multiple step-by-step reasoning abilities into SLMs. First, we leverage LLMs to generate multiple step-by-step reasoning rationales by sampling automatically. Then, we create high-quality, well-balanced mixed thought data and design a novel multi-task loss to help SLMs better learn and adaptively activate multiple step-by-step reasoning. Our extensive experiments demonstrate that MD enhances both single-path (using either CoT or PoT) and multi-path (using both CoT and PoT) reasoning abilities of SLMs during inference across reasoning tasks. Notably, a single model generated by MD exceeds the comprehensive performance of an ensemble of two individual CoT and PoT distilled models. Mistral-7B using MD can achieve remarkable improvements of 87.5%, 74.0% and 77.1% on SVAMP, GSM8K and ASDIV, respectively, outperforming the teacher model, GPT-3.5-Turbo. We hope our work provides insight into SLMs\u2019 multiple step-by-step reasoning abilities.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.91",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-sifo",
        "author": "Chen, Xinyi and Liao, Baohao and Qi, Jirui and Eustratiadis, Panagiotis and Monz, Christof and Bisazza, Arianna and de Rijke, Maarten",
        "booktitle": "EMNLP-findings2024",
        "title": "The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Following multiple instructions is a crucial ability for large language models (LLMs). Evaluating this ability comes with significant challenges: (i) limited coherence between multiple instructions, (ii) positional bias where the order of instructions affects model performance, and (iii) a lack of objectively verifiable tasks. To address these issues, we introduce a benchmark designed to evaluate models\u2019 abilities to follow multiple instructions through sequential instruction following (SIFo) tasks. In SIFo, the successful completion of multiple instructions is verifiable by examining only the final instruction. Our benchmark evaluates instruction following using four tasks (text modification, question answering, mathematics, and security rule following), each assessing different aspects of sequential instruction following. Our evaluation of popular LLMs, both closed-source and open-source, shows that more recent and larger models significantly outperform their older and smaller counterparts on the SIFo tasks, validating the benchmark\u2019s effectiveness. All models struggle with following sequences of instructions, hinting at an important lack of robustness of today\u2019s language models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.92",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search": {
        "type": "INPROCEEDINGS",
        "key": "chenglin-etal-2024-optimizing",
        "author": "Chenglin, Li and Chen, Qianglong and Li, Zhi and FengTao, FengTao and Li, Yicheng and Chen, Hao and Yu, Fei and Zhang, Yin",
        "booktitle": "EMNLP-findings2024",
        "title": "Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Instruction tuning is a crucial technique for aligning language models with humans\u2019 actual goals in the real world. Extensive research has highlighted the quality of instruction data is essential for the success of this alignment. However, creating high-quality data manually is labor-intensive and time-consuming, which leads researchers to explore using LLMs to synthesize data. Recent studies have focused on using a stronger LLM to iteratively enhance existing instruction data, showing promising results. Nevertheless, previous work often lacks control over the evolution direction, resulting in high uncertainty in the data synthesis process and low-quality instructions. In this paper, we introduce a general and scalable framework, IDEA-MCTS (Instruction Data Enhancement using Monte Carlo Tree Search), a scalable framework for efficiently synthesizing instructions. With tree search and evaluation models, it can efficiently guide each instruction to evolve into a high-quality form, aiding in instruction fine-tuning. Experimental results show that IDEA-MCTS significantly enhances the seed instruction data, raising the average evaluation scores of quality, diversity, and complexity from 2.19 to 3.81. Furthermore, in open-domain benchmarks, experimental results show that IDEA-MCTS improves the accuracy of real-world instruction-following skills in LLMs by an average of 5% in low-resource settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.93",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Suri: Multi-constraint Instruction Following in Long-form Text Generation": {
        "type": "INPROCEEDINGS",
        "key": "pham-etal-2024-suri",
        "author": "Pham, Chau Minh and Sun, Simeng and Iyyer, Mohit",
        "booktitle": "EMNLP-findings2024",
        "title": "Suri: Multi-constraint Instruction Following in Long-form Text Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing research on instruction following largely focuses on tasks with simple instructions and short responses. In this work, we explore multi-constraint instruction following for generating long-form text. We create Suri, a dataset with 20K human-written long-form texts paired with LLM-generated backtranslated instructions that contain multiple complex constraints. Because of prohibitive challenges associated with collecting human preference judgments on long-form texts, preference-tuning algorithms such as DPO are infeasible in our setting; thus, we propose Instructional ORPO (I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving negative feedback from dispreferred responses, I-ORPO obtains negative feedback from synthetically corrupted instructions generated by an LLM. Using Suri, we perform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The resulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts (5K tokens) than base models without significant quality deterioration. Our human evaluation shows that while both SFT and I-ORPO models satisfy most constraints, Suri-I-ORPO generations are generally preferred for their coherent and informative incorporation of the constraints.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.94",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-augmenting",
        "author": "Wang, Yubo and Ma, Xueguang and Chen, Wenhu",
        "booktitle": "EMNLP-findings2024",
        "title": "Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large-scale language models (LLMs) like ChatGPT have demonstrated impressive abilities in generating responses based on human instructions. However, their use in the medical field can be challenging due to their lack of specific, in-depth knowledge. In this study, we present a system called LLMs Augmented with Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs in specialized domains. LLM-AMT integrates authoritative medical textbooks into the LLMs\u2019 framework using plug-and-play modules. These modules include a Query Augmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together, they incorporate authoritative medical knowledge. Additionally, an LLM Reader aids in contextual understanding. Our experimental results on three medical QA tasks demonstrate that LLM-AMT significantly improves response quality, with accuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as the base model, LLM-AMT outperforms the specialized Med-PaLM 2 model pre-trained on a massive amount of medical corpus by 2-3%. We found that despite being 100 smaller in size, medical textbooks as a retrieval corpus are proven to be a more effective knowledge database than Wikipedia in the medical domain, boosting performance by 7.8%-13.7%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.95",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-exploring-multilingual",
        "author": "Xu, Shaoyang and Dong, Weilong and Guo, Zishan and Wu, Xinwei and Xiong, Deyi",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prior research has revealed that certain abstract concepts are linearly represented as directions in the representation space of LLMs, predominantly centered around English. In this paper, we extend this investigation to a multilingual context, with a specific focus on human values-related concepts (i.e., value concepts) due to their significance for AI safety. Through our comprehensive exploration covering 7 types of human values, 16 languages and 3 LLM series with distinct multilinguality (e.g., monolingual, bilingual and multilingual), we first empirically confirm the presence of value concepts within LLMs in a multilingual format. Further analysis on the cross-lingual characteristics of these concepts reveals 3 traits arising from language resource disparities: cross-lingual inconsistency, distorted linguistic relationships, and unidirectional cross-lingual transfer between high- and low-resource languages, all in terms of value concepts. Moreover, we validate the feasibility of cross-lingual control over value alignment capabilities of LLMs, leveraging the dominant language as a source language. Ultimately, recognizing the significant impact of LLMs\u2019 multilinguality on our results, we consolidate our findings and provide prudent suggestions on the composition of multilingual data for LLMs pre-training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.96",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PaCoST: Paired Confidence Significance Testing for Benchmark Contamination Detection in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-pacost",
        "author": "Zhang, Huixuan and Lin, Yun and Wan, Xiaojun",
        "booktitle": "EMNLP-findings2024",
        "title": "PaCoST: Paired Confidence Significance Testing for Benchmark Contamination Detection in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) are known to be trained on vast amounts of data, which may unintentionally or intentionally include data from commonly used benchmarks. This inclusion can lead to cheatingly high scores on model leaderboards, yet result in disappointing performance in real-world applications. To address this benchmark contamination problem, we first propose a set of requirements that practical contamination detection methods should follow. Following these proposed requirements, we introduce PaCoST, a Paired Confidence Significance Testing to effectively detect benchmark contamination in LLMs. Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark. We validate the effectiveness of PaCoST and apply it on popular open-source models and benchmarks. We find that almost all models and benchmarks we tested are suspected contaminated more or less. We finally call for new LLM evaluation methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.97",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "jiang-etal-2024-urbanllm",
        "author": "Jiang, Yue and Chao, Qin and Chen, Yile and Li, Xiucheng and Liu, Shuai and Cong, Gao",
        "booktitle": "EMNLP-findings2024",
        "title": "UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Location-based services play an critical role in improving the quality of our daily lives. Despite the proliferation of numerous specialized AI models within spatio-temporal context of location-based services, these models struggle to autonomously tackle problems regarding complex urban planing and management. To bridge this gap, we introduce UrbanLLM, a fine-tuned large language model (LLM) designed to tackle diverse problems in urban scenarios. UrbanLLM functions as a problem- solver by decomposing urban-related queries into manageable sub-tasks, identifying suitable spatio-temporal AI models for each sub-task, and generating comprehensive responses to the given queries. Our experimental results indicate that UrbanLLM significantly outperforms other established LLMs, such as Llama and the GPT series, in handling problems concerning complex urban activity planning and management. UrbanLLM exhibits considerable potential in enhancing the effectiveness of solving problems in urban scenarios, reducing the workload and reliance for human experts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.98",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling": {
        "type": "INPROCEEDINGS",
        "key": "yu-etal-2024-breaking",
        "author": "Yu, Yao-Ching and Kuo, Chun Chih and Ziqi, Ye and Yucheng, Chang and Li, Yueh-Se",
        "booktitle": "EMNLP-findings2024",
        "title": "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Ensembling multiple models has always been an effective approach to push the limits of existing performance and is widely used in classification tasks by simply averaging the classification probability vectors from multiple classifiers to achieve better accuracy. However, in the thriving open-source Large Language Model (LLM) community, ensembling methods are rare and typically limited to ensembling the full-text outputs of LLMs, such as selecting the best output using a ranker, which leads to underutilization of token-level probability information. In this paper, we treat the **G**eneration of each token by LLMs **a**s a **C**lassification (**GaC**) for ensembling. This approach fully exploits the probability information at each generation step and better prevents LLMs from producing early incorrect tokens that lead to snowballing errors. In experiments, we ensemble state-of-the-art LLMs on several benchmarks, including exams, mathematics and reasoning, and observe that our method breaks the existing community performance ceiling. Furthermore, we observed that most of the tokens in the answer are simple and do not affect the correctness of the final answer. Therefore, we also experimented with ensembling only key tokens, and the results showed better performance with lower latency across benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.99",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Eliciting Instruction-tuned Code Language Models\u2019 Capabilities to Utilize Auxiliary Function for Code Generation": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-eliciting",
        "author": "Lee, Seonghyeon and Kim, Suyeon and Jang, Joonwon and Chon, HeeJae and Lee, Dongha and Yu, Hwanjo",
        "booktitle": "EMNLP-findings2024",
        "title": "Eliciting Instruction-tuned Code Language Models\u2019 Capabilities to Utilize Auxiliary Function for Code Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We study the code generation behavior of instruction-tuned models built on top of code pre-trained language models when they could access an auxiliary function to implement a function. We design several ways to provide auxiliary functions to the models by adding them to the query or providing a response prefix to incorporate the ability to utilize auxiliary functions with the instruction-following capability. Our experimental results show the effectiveness of combining the base models\u2019 auxiliary function utilization ability with the instruction following ability. In particular, the performance of adopting our approaches with the open-sourced language models surpasses that of the recent powerful language models, i.e., gpt-4o.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.100",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses": {
        "type": "INPROCEEDINGS",
        "key": "lu-etal-2024-ahp",
        "author": "Lu, Xiaotian and Li, Jiyi and Takeuchi, Koh and Kashima, Hisashi",
        "booktitle": "EMNLP-findings2024",
        "title": "AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Question answering (QA) tasks have been extensively studied in the field of natural language processing (NLP). Answers to open-ended questions are highly diverse and difficult to quantify, and cannot be simply evaluated as correct or incorrect, unlike close-ended questions with definitive answers. While large language models (LLMs) have demonstrated strong capabilities across various tasks, they exhibit relatively weaker performance in evaluating answers to open-ended questions. In this study, we propose a method that leverages LLMs and the analytic hierarchy process (AHP) to assess answers to open-ended questions. We utilized LLMs to generate multiple evaluation criteria for a question. Subsequently, answers were subjected to pairwise comparisons under each criterion with LLMs, and scores for each answer were calculated in the AHP. We conducted experiments on four datasets using both ChatGPT-3.5-turbo and GPT-4. Our results indicate that our approach more closely aligns with human judgment compared to the four baselines. Additionally, we explored the impact of the number of criteria, variations in models, and differences in datasets on the results.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.101",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Fine-Grained Image Classifications via Cascaded Vision Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wei-2024-enhancing",
        "author": "Wei, Canshi",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Fine-Grained Image Classifications via Cascaded Vision Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Fine-grained image classification, especially in zero-/few-shot scenarios, poses a considerable challenge for vision-language models (VLMs) like CLIP, which often struggle to differentiate between semantically similar classes due to insufficient supervision for fine-grained tasks. On the other hand, Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities in tasks like Visual Question Answering (VQA) but remain underexplored in the context of fine-grained image classification. This paper presents CascadeVLM, a novel framework that harnesses the complementary strengths of both CLIP-like and LVLMs VLMs to tackle these challenges. Using granular knowledge effectively in LVLMs and integrating a cascading approach, CascadeVLM dynamically allocates samples using an entropy threshold, balancing computational efficiency with classification accuracy. Experiments on multiple fine-grained datasets, particularly the Stanford Cars dataset, show that CascadeVLM outperforms existing models, achieving 92% accuracy. Our results highlight the potential of combining VLM and LVLM for robust, efficient and interpretable fine-grained image classification, offering new insights into their synergy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.102",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring the Best Practices of Query Expansion with Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-exploring-best",
        "author": "Zhang, Le and Wu, Yihong and Yang, Qian and Nie, Jian-Yun",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring the Best Practices of Query Expansion with Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are foundational in language technologies, particularly in information retrieval (IR). In this paper, we thoroughly explore the best practice of leveraging LLMs for query expansion. To this end, we introduce a training-free, straightforward yet effective framework called Multi-Text Generation Integration (MuGI). This approach leverages LLMs to generate multiple pseudo-references, which are then integrated with the original queries to enhance both sparse and dense retrieval methods. Additionally, we introduce a retrieval pipeline based on MuGI, which combines the strengths of sparse and dense retrievers to achieve superior performance without the need for costly pre-indexing. Our empirical findings reveal that: (1) Increasing the number of samples from LLMs benefits IR systems; (2) A balance between the query and pseudo-documents, and an effective integration strategy, is critical for high performance; (3) Contextual information from LLMs is essential, even boost a 23M model to outperform a 7B baseline model; (4) Pseudo relevance feedback can further calibrate queries for improved performance; and (5) Query expansion is widely applicable and versatile, consistently enhancing models ranging from 23M to 7B parameters. Our code and all generated references are made available at https://github.com/lezhang7/Retrieval_MuGI.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.103",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Chain-of-Rewrite: Aligning Question and Documents for Open-Domain Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "xin-etal-2024-chain",
        "author": "Xin, Chunlei and Lu, Yaojie and Lin, Hongyu and Zhou, Shuheng and Zhu, Huijia and Wang, Weiqiang and Liu, Zhongyi and Han, Xianpei and Sun, Le",
        "booktitle": "EMNLP-findings2024",
        "title": "Chain-of-Rewrite: Aligning Question and Documents for Open-Domain Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite the advancements made with the retrieve-then-read pipeline on open-domain question answering task, current methods still face challenges stemming from term mismatch and limited interaction between information retrieval systems and large language models. To mitigate these issues, we propose the Chain-of-Rewrite method, which leverages the guidance and feedback gained from the analysis to provide faithful and consistent extensions for effective question answering. Through a two-step rewriting process comprising Semantic Analysis and Semantic Augmentation, the Chain-of-Rewrite method effectively bridges the gap between the user question and relevant documents. By incorporating feedback from the rewriting process, our method can self-correct the retrieval and reading process to further improve the performance. Experiments on four open-domain question answering datasets demonstrate the effectiveness of our system under zero-shot settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.104",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation": {
        "type": "INPROCEEDINGS",
        "key": "yu-etal-2024-mgcl",
        "author": "Yu, Yang and Lin, Xin Alex and Li, Changqun and Huang, Shizhou and He, Liang",
        "booktitle": "EMNLP-findings2024",
        "title": "MGCL: Multi-Granularity Clue Learning for Emotion-Cause Pair Extraction via Cross-Grained Knowledge Distillation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Emotion-cause pair extraction (ECPE) aims to identify emotion clauses and their corresponding cause clauses within a document. Traditional methods often rely on coarse-grained clause-level annotations, which can overlook valuable fine-grained clues. To address this issue, we propose Multi-Granularity Clue Learning (MGCL), a novel approach designed to capture fine-grained emotion-cause clues from a weakly-supervised perspective efficiently. In MGCL, a teacher model is leveraged to give sub-clause clues without needing fine-grained annotated labels and guides a student model to identify clause-level emotion-cause pairs. Furthermore, we explore domain-invariant extra-clause clues under the teacher model\u2019s advice to enhance the learning process. Experimental results on the benchmark dataset demonstrate that our method achieves state-of-the-art performance while offering improved interpretability.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.105",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts": {
        "type": "INPROCEEDINGS",
        "key": "golany-etal-2024-efficient",
        "author": "Golany, Lotem and Galgani, Filippo and Mamo, Maya and Parasol, Nimrod and Vandsburger, Omer and Bar, Nadav and Dagan, Ido",
        "booktitle": "EMNLP-findings2024",
        "title": "Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automating data generation with Large Language Models (LLMs) has become increasingly popular. In this work, we investigate the feasibility and effectiveness of LLM-based data generation in the challenging setting of source-grounded information-seeking dialogs, with response attribution, over long documents. Our source texts consist of long and noisy meeting transcripts, adding to the task complexity. Since automating attribution remains difficult, we propose a semi-automatic approach: dialog queries and responses are generated with LLMs, followed by human verification and identification of attribution spans. Using this approach, we created MISeD \u2013 Meeting Information Seeking Dialogs dataset \u2013 a dataset of information-seeking dialogs focused on meeting transcripts. Models finetuned with MISeD demonstrate superior performance compared to off-the-shelf models, even those of larger size. Finetuning on MISeD gives comparable response generation quality to finetuning on fully manual data, while improving attribution quality and reducing time and effort.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.106",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Visual Question Decomposition on Multimodal Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-visual-question",
        "author": "Zhang, Haowei and Liu, Jianzhe and Han, Zhen and Chen, Shuo and He, Bailan and Tresp, Volker and Xu, Zhiqiang and Gu, Jindong",
        "booktitle": "EMNLP-findings2024",
        "title": "Visual Question Decomposition on Multimodal Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Question decomposition has emerged as an effective strategy for prompting Large Language Models (LLMs) to answer complex questions. However, while existing methods primarily focus on unimodal language models, the question decomposition capability of Multimodal Large Language Models (MLLMs) has yet to be explored. To this end, this paper explores visual question decomposition on MLLMs. Specifically, we introduce a systematic evaluation framework including a dataset and several evaluation criteria to assess the quality of the decomposed sub-questions, revealing that existing MLLMs struggle to produce high-quality sub-questions. To address this limitation, we propose a specific finetuning dataset, DecoVQA+, for enhancing the model\u2019s question decomposition capability. Aiming at enabling models to perform appropriate selective decomposition, we propose an efficient finetuning pipeline. The finetuning pipeline consists of our proposed dataset and a training objective for selective decomposition. Finetuned MLLMs demonstrate significant improvements in the quality of sub-questions and the policy of selective question decomposition. Additionally, the models also achieve higher accuracy with selective decomposition on VQA benchmark datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.107",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs": {
        "type": "INPROCEEDINGS",
        "key": "zhuo-etal-2024-prosa",
        "author": "Zhuo, Jingming and Zhang, Songyang and Fang, Xinyu and Duan, Haodong and Lin, Dahua and Chen, Kai",
        "booktitle": "EMNLP-findings2024",
        "title": "ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have demonstrated impressive capabilities across various tasks, but their performance is highly sensitive to the prompts utilized. This variability poses challenges for accurate assessment and user satisfaction. Current research frequently overlooks instance-level prompt variations and their implications on subjective evaluations. To address these shortcomings, we introduce ProSA, a framework designed to evaluate and comprehend prompt sensitivity in LLMs. ProSA incorporates a novel sensitivity metric, PromptSensiScore, and leverages decoding confidence to elucidate underlying mechanisms. Our extensive study, spanning multiple tasks, uncovers that prompt sensitivity fluctuates across datasets and models, with larger models exhibiting enhanced robustness. We observe that few-shot examples can alleviate this sensitivity issue, and subjective evaluations are also susceptible to prompt sensitivities, particularly in complex, reasoning-oriented tasks. Furthermore, our findings indicate that higher model confidence correlates with increased prompt robustness. We believe this work will serve as a helpful tool in studying prompt sensitivity of LLMs. The project is released at: https://github.com/open-compass/ProSA.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.108",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "yao-etal-2024-layer",
        "author": "Yao, Kai and Gao, Penglei and Li, Lichun and Zhao, Yuan and Wang, Xiaofeng and Wang, Wei and Zhu, Jianke",
        "booktitle": "EMNLP-findings2024",
        "title": "Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant popularity for adapting pre-trained Large Language Models (LLMs) to downstream tasks, primarily due to their potential to significantly reduce memory and computational overheads. However, a common limitation in most PEFT approaches is their application of a uniform architectural design across all layers. This uniformity involves identical trainable modules and ignores the varying importance of each layer, leading to sub-optimal fine-tuning results. To overcome the above limitation and obtain better performance, we develop a novel approach, Importance-aware Sparse Tuning (IST), to fully utilize the inherent sparsity and select the most important subset of full layers with effective layer-wise importance scoring. The proposed IST is a versatile and plug-and-play technique compatible with various PEFT methods that operate on a per-layer basis. By leveraging the estimated importance scores, IST dynamically updates these selected layers in PEFT modules, leading to reduced memory demands. We further provide theoretical proof of convergence and empirical evidence of superior performance to demonstrate the advantages of IST over uniform updating strategies. Extensive experiments on a range of LLMs, PEFTs, and downstream tasks substantiate the effectiveness of our proposed method, showcasing IST\u2019s capacity to enhance existing layer-based PEFT methods. Our code is available at https://github.com/Kaiseem/IST",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.109",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Abstraction-of-Thought Makes Language Models Better Reasoners": {
        "type": "INPROCEEDINGS",
        "key": "hong-etal-2024-abstraction",
        "author": "Hong, Ruixin and Zhang, Hongming and Pan, Xiaoman and Yu, Dong and Zhang, Changshui",
        "booktitle": "EMNLP-findings2024",
        "title": "Abstraction-of-Thought Makes Language Models Better Reasoners",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Abstract reasoning, the ability to reason from the abstract essence of a problem, serves as a key to generalization in human reasoning. However, eliciting language models to perform reasoning with abstraction remains unexplored. This paper seeks to bridge this gap by introducing a novel structured reasoning format called Abstraction-of-Thought (AoT). The uniqueness of AoT lies in its explicit requirement for varying levels of abstraction within the reasoning process. This approach could elicit language models to first contemplate on the abstract level before incorporating concrete details, which is overlooked by the prevailing step-by-step Chain-of-Thought (CoT) method. To align models with the AoT format, we present AoT Collection, a generic finetuning dataset consisting of 348k high-quality samples with AoT reasoning processes, collected via an automated and scalable pipeline. We finetune a wide range of language models with AoT Collection and conduct extensive evaluations on 23 unseen tasks from the challenging benchmark Big-Bench Hard. Experimental results indicate that models aligned to AoT reasoning format substantially outperform those aligned to CoT in many reasoning tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.110",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Communities in Long Form Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "kahl-etal-2024-llms",
        "author": "Kahl, Kris-Fillip and Buz, Tolga and Biswas, Russa and De Melo, Gerard",
        "booktitle": "EMNLP-findings2024",
        "title": "LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Communities in Long Form Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retail investing is on the rise, and a growing number of users is relying on online finance communities to educate themselves.However, recent years have positioned Large Language Models (LLMs) as powerful question answering (QA) tools, shifting users away from interacting in communities towards discourse with AI-driven conversational interfaces.These AI tools are currently limited by the availability of labelled data containing domain-specific financial knowledge.Therefore, in this work, we curate a QA preference dataset SocialFinanceQA for fine-tuning and aligning LLMs, extracted from more than 7.4 million submissions and 82 million comments from 2008 to 2022 in Reddit\u2019s 15 largest finance communities. Additionally, we propose a novel framework called SocialQA-Eval as a generally-applicable method to evaluate generated QA responses.We evaluate various LLMs fine-tuned on this dataset, using traditional metrics, LLM-based evaluation, and human annotation. Our results demonstrate the value of high-quality Reddit data, with even state-of-the-art LLMs improving on producing simpler and more specific responses.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.111",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Automated Tone Transcription and Clustering with Tone2Vec": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-automated",
        "author": "Yang, Yi and Wang, Yiming and Tang, ZhiQiang and Yuan, Jiahong",
        "booktitle": "EMNLP-findings2024",
        "title": "Automated Tone Transcription and Clustering with Tone2Vec",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Lexical tones play a crucial role in Sino-Tibetan languages. However, current phonetic fieldwork relies on manual effort, resulting in substantial time and financial costs. This is especially challenging for the numerous endangered languages that are rapidly disappearing, often compounded by limited funding. In this paper, we introduce pitch-based similarity representations for tone transcription, named Tone2Vec. Experiments on dialect clustering and variance show that Tone2Vec effectively captures fine-grained tone variation. Utilizing Tone2Vec, we develop the first automatic approach for tone transcription and clustering by presenting a novel representation transformation for transcriptions. Additionally, these algorithms are systematically integrated into an open-sourced and easy-to-use package, ToneLab, which facilitates automated fieldwork and cross-regional, cross-lexical analysis for tonal languages. Extensive experiments were conducted to demonstrate the effectiveness of our methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.112",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multi-dimensional Evaluation of Empathetic Dialogue Responses": {
        "type": "INPROCEEDINGS",
        "key": "xu-jiang-2024-multi",
        "author": "Xu, Zhichao and Jiang, Jiepu",
        "booktitle": "EMNLP-findings2024",
        "title": "Multi-dimensional Evaluation of Empathetic Dialogue Responses",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Empathy is critical for effective and satisfactory conversational communication. Prior efforts to measure conversational empathy mostly focus on expressed communicative intents\u2014that is, the way empathy is expressed. Yet, these works ignore the fact that conversation is also a collaboration involving both speakers and listeners. In contrast, we propose a multi-dimensional empathy evaluation framework to measure both expressed intents from the speaker\u2019s perspective and perceived empathy from the listener\u2019s perspective. We apply our analytical framework to examine internal customer-service dialogues. We find the two dimensions (expressed intent types and perceived empathy) are interconnected, while perceived empathy has high correlations with dialogue satisfaction levels.To reduce the annotation cost, we explore different options to automatically measure conversational empathy: prompting LLMs and training language model-based classifiers. Our experiments show that prompting methods with even popular models like GPT-4 and Flan family models perform relatively poorly on both public and our internal datasets. In contrast, instruction-finetuned classifiers based on FlanT5 family models outperform prior works and competitive baselines. We conduct a detailed ablation study to give more insights into instruction finetuning method\u2019s strong performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.113",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Translation of Multifaceted Data without Re-Training of Machine Translation Systems": {
        "type": "INPROCEEDINGS",
        "key": "moon-etal-2024-translation",
        "author": "Moon, Hyeonseok and Lee, Seungyoon and Hong, SeongTae and Lee, Seungjun and Park, Chanjun and Lim, Heuiseok",
        "booktitle": "EMNLP-findings2024",
        "title": "Translation of Multifaceted Data without Re-Training of Machine Translation Systems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Translating major language resources to build minor language resources becomes a widely-used approach. Particularly in translating complex data points composed of multiple components, it is common to translate each component separately. However, we argue that this practice often overlooks the interrelation between components within the same data point. To address this limitation, we propose a novel MT pipeline that considers the intra-data relation. in implementing MT for training data. In our MT pipeline, all the components in a data point are concatenated to form a single translation sequence and subsequently reconstructed to the data components after translation. We introduce a Catalyst Statement (CS) to enhance the intra-data relation, and Indicator Token (IT) to assist the decomposition of a translated sequence into its respective data components. Through our approach, we have achieved a considerable improvement in translation quality itself, along with its effectiveness as training data. Compared with the conventional approach that translates each data component separately, our method yields better training data that enhances the performance of the trained model by 2.690 points for the web page ranking (WPR) task, and 0.845 for the question generation (QG) task in the XGLUE benchmark.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.114",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Reward Difference Optimization For Sample Reweighting In Offline RLHF": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-reward",
        "author": "Wang, Shiqi and Zhang, Zhengze and Zhao, Rui and Tan, Fei and Cam-Tu, Nguyen",
        "booktitle": "EMNLP-findings2024",
        "title": "Reward Difference Optimization For Sample Reweighting In Offline RLHF",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the wide deployment of Large Language Models (LLMs), aligning LLMs with human values becomes increasingly important. Although Reinforcement Learning with Human Feedback (RLHF) proves effective, it is complicated and highly resource-intensive. As such, offline RLHF has been introduced as an alternative solution, which directly optimizes LLMs with ranking losses on a fixed preference dataset. Current offline RLHF only captures the ordering relationship between responses, overlooking the crucial aspect of \u201chow much\u201d one is preferred over the others. To address this issue, we propose a simple yet effective solution based on reward difference prediction. Specifically, we introduce reward difference coefficients to reweigh sample pairs in offline RLHF. We then propose a difference model that considers rich interactions between a pair of responses for predicting these difference coefficients. Experiments with 7B LLMs on the HH and TL;DR dataset verify the effectiveness of our method in both automatic metrics and human evaluation, highlighting its potential for aligning LLMs with human values.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.115",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories": {
        "type": "INPROCEEDINGS",
        "key": "song-etal-2024-agentbank",
        "author": "Song, Yifan and Xiong, Weimin and Zhao, Xiutian and Zhu, Dawei and Wu, Wenhao and Wang, Ke and Li, Cheng and Peng, Wei and Li, Sujian",
        "booktitle": "EMNLP-findings2024",
        "title": "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Fine-tuning on agent-environment interaction trajectory data holds significant promise for surfacing generalized agent capabilities in open-source large language models (LLMs). In this work, we introduce AgentBank, by far the largest trajectory tuning data collection featuring more than 50k diverse high-quality interaction trajectories which comprises 16 tasks covering five distinct agent skill dimensions. Leveraging a novel annotation pipeline, we are able to scale the annotated trajectories and generate a trajectory dataset with minimized difficulty bias. Furthermore, we fine-tune LLMs on AgentBank to get a series of agent models, Samoyed. Our comparative experiments demonstrate the effectiveness of scaling the interaction trajectory data to acquire generalized agent capabilities. Additional studies also reveal some key observations regarding trajectory tuning and agent skill generalization.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.116",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Are LLMs Aware that Some Questions are not Open-ended?": {
        "type": "INPROCEEDINGS",
        "key": "yang-zhao-2024-llms",
        "author": "Yang, Dongjie and Zhao, Hai",
        "booktitle": "EMNLP-findings2024",
        "title": "Are LLMs Aware that Some Questions are not Open-ended?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have shown the impressive capability of answering questions in a wide range of scenarios. However, when LLMs face different types of questions, it is worth exploring whether LLMs are aware that some questions have limited answers and need to respond more deterministically but some do not. We refer to this as question awareness of LLMs. The lack of question awareness in LLMs leads to two phenomena that LLMs are: (1) too casual to answer non-open-ended questions or (2) too boring to answer open-ended questions. In this paper, we first evaluate the question awareness in LLMs. The experimental results show that LLMs have the issues of lacking awareness of questions in certain domains, e.g. factual knowledge, resulting in hallucinations during the generation. To mitigate these, we propose a method called Question Awareness Temperature Sampling (QuATS). This method enhances the question awareness of LLMs by adaptively adjusting the output distributions based on question features. The automatic adjustment in QuATS eliminates the need for manual temperature tuning in text generation and consistently improves model performance in various benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.117",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Conditional Language Policy: A General Framework For Steerable Multi-Objective Finetuning": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-conditional",
        "author": "Wang, Kaiwen and Kidambi, Rahul and Sullivan, Ryan and Agarwal, Alekh and Dann, Christoph and Michi, Andrea and Gelmi, Marco and Li, Yunxuan and Gupta, Raghav and Dubey, Kumar Avinava and Rame, Alexandre and Ferret, Johan and Cideron, Geoffrey and Hou, Le and Yu, Hongkun and Ahmed, Amr and Mehta, Aranyak and Hussenot, Leonard and Bachem, Olivier and Leurent, Edouard",
        "booktitle": "EMNLP-findings2024",
        "title": "Conditional Language Policy: A General Framework For Steerable Multi-Objective Finetuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reward-based finetuning is crucial for aligning language policies with intended behaviors (*e.g.*, creativity and safety). A key challenge is to develop steerable language models that trade-off multiple (conflicting) objectives in a flexible and efficient manner. This paper presents Conditional Language Policy (CLP), a general framework for finetuning language models on multiple objectives. Building on techniques from multi-task training and parameter-efficient finetuning, CLP learn steerable models that effectively trade-off conflicting objectives at *inference time*. Notably, this does not require training or maintaining multiple models to achieve different trade-offs between the objectives. Through extensive experiments and ablations on two summarization datasets, we show that CLP learns steerable language models that outperform and Pareto-dominate the existing approaches for multi-objective",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.118",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer\u2019s Disease Questions with Scientific Literature": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-dalk",
        "author": "Li, Dawei and Yang, Shu and Tan, Zhen and Baik, Jae Young and Yun, Sukwon and Lee, Joseph and Chacko, Aaron and Hou, Bojian and Duong-Tran, Duy and Ding, Ying and Liu, Huan and Shen, Li and Chen, Tianlong",
        "booktitle": "EMNLP-findings2024",
        "title": "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer\u2019s Disease Questions with Scientific Literature",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in large language models (LLMs) have achieved promising performances across various applications. Nonetheless, the ongoing challenge of integrating long-tail knowledge continues to impede the seamless adoption of LLMs in specialized domains. In this work, we introduce DALK, a.k.a. Dynamic Co-Augmentation of LLMs and KG, to address this limitation and demonstrate its ability on studying Alzheimer\u2019s Disease (AD), a specialized sub-field in biomedicine and a global health priority. With a synergized framework of LLM and KG mutually enhancing each other, we first leverage LLM to construct an evolving AD-specific knowledge graph (KG) sourced from AD-related scientific literature, and then we utilize a coarse-to-fine sampling method with a novel self-aware knowledge retrieval approach to select appropriate knowledge from the KG to augment LLM inference capabilities. The experimental results, conducted on our constructed AD question answering (ADQA) benchmark, underscore the efficacy of DALK. Additionally, we perform a series of detailed analyses that can offer valuable insights and guidelines for the emerging topic of mutually enhancing KG and LLM.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.119",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can AI Relate: Testing Large Language Model Response for Mental Health Support": {
        "type": "INPROCEEDINGS",
        "key": "gabriel-etal-2024-ai",
        "author": "Gabriel, Saadia and Puri, Isha and Xu, Xuhai and Malgaroli, Matteo and Ghassemi, Marzyeh",
        "booktitle": "EMNLP-findings2024",
        "title": "Can AI Relate: Testing Large Language Model Response for Mental Health Support",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) are already being piloted for clinical use in hospital systems like NYU Langone, Dana-Farber and the NHS. A proposed deployment use case is psychotherapy, where a LLM-powered chatbot can treat a patient undergoing a mental health crisis. Deployment of LLMs for mental health response could hypothetically broaden access to psychotherapy and provide new possibilities for personalizing care. However, recent high-profile failures, like damaging dieting advice offered by the Tessa chatbot to patients with eating disorders, have led to doubt about their reliability in high-stakes and safety-critical settings.In this work, we develop an evaluation framework for determining whether LLM response is a viable and ethical path forward for the automation of mental health treatment. Our framework measures equity in empathy and adherence of LLM responses to motivational interviewing theory. Using human evaluation with trained clinicians and automatic quality-of-care metrics grounded in psychology research, we compare the responses provided by peer-to-peer responders to those provided by a state-of-the-art LLM.We show that LLMs like GPT-4 use implicit and explicit cues to infer patient demographics like race. We then show that there are statistically significant discrepancies between patient subgroups: Responses to Black posters consistently have lower empathy than for any other demographic group (2%-13% lower than the control group). Promisingly, we do find that the manner in which responses are generated significantly impacts the quality of the response. We conclude by proposing safety guidelines for the potential deployment of LLMs for mental health response.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.120",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology": {
        "type": "INPROCEEDINGS",
        "key": "tran-kretchmar-2024-towards",
        "author": "Tran, Son Quoc and Kretchmar, Matt",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper proposes a novel training method to improve the robustness of Extractive Question Answering (EQA) models. Previous research has shown that existing models, when trained on EQA datasets that include unanswerable questions, demonstrate a significant lack of robustness against distribution shifts and adversarial attacks. Despite this, the inclusion of unanswerable questions in EQA training datasets is essential for ensuring real-world reliability. Our proposed training method includes a novel loss function for the EQA problem and challenges an implicit assumption present in numerous EQA datasets. Models trained with our method maintain in-domain performance while achieving a notable improvement on out-of-domain datasets. This results in an overall F1 score improvement of 5.7 across all testing sets. Furthermore, our models exhibit significantly enhanced robustness against two types of adversarial attacks, with a performance decrease of only about one-third compared to the default models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.121",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion": {
        "type": "INPROCEEDINGS",
        "key": "ruggiero-etal-2024-enhancing",
        "author": "Ruggiero, Giuseppe and Testa, Matteo and Walle, Jurgen Van De and Di Caro, Luigi",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Polyglot Voices by Leveraging Cross-Lingual Fine-Tuning in Any-to-One Voice Conversion",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The creation of artificial polyglot voices remains a challenging task, despite considerable progress in recent years. This paper investigates self-supervised learning for voice conversion to create native-sounding polyglot voices. We introduce a novel cross-lingual any-to-one voice conversion system that is able to preserve the source accent without the need for multilingual data from the target speaker. In addition, we show a novel cross-lingual fine-tuning strategy that further improves the accent and reduces the training data requirements. Objective and subjective evaluations with English, Spanish, French and Mandarin Chinese confirm that our approach improves on state-of-the-art methods, enhancing the speech intelligibility and overall quality of the converted speech, especially in cross-lingual scenarios. Audio samples are available at: https://giuseppe-ruggiero.github.io/a2o-vc-demo/",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.122",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce": {
        "type": "INPROCEEDINGS",
        "key": "ding-etal-2024-intentionqa",
        "author": "Ding, Wenxuan and Wang, Weiqi and Kwok, Sze Heng Douglas and Liu, Minghao and Fang, Tianqing and Bai, Jiaxin and Liu, Xin and Yu, Changlong and Li, Zheng and Luo, Chen and Yin, Qingyu and Yin, Bing and He, Junxian and Song, Yangqiu",
        "booktitle": "EMNLP-findings2024",
        "title": "IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Enhancing Language Models\u2019 (LMs) ability to understand purchase intentions in E-commerce scenarios is crucial for their effective assistance in various downstream tasks. However, previous approaches that distill intentions from LMs often fail to generate meaningful and human-centric intentions applicable in real-world E-commerce contexts. This raises concerns about the true comprehension and utilization of purchase intentions by LMs. In this paper, we present IntentionQA, a double-task multiple-choice question answering benchmark to evaluate LMs\u2019 comprehension of purchase intentions in E-commerce. Specifically, LMs are tasked to infer intentions based on purchased products and utilize them to predict additional purchases. IntentionQA consists of 4,360 carefully curated problems across three difficulty levels, constructed using an automated pipeline to ensure scalability on large E-commerce platforms. Human evaluations demonstrate the high quality and low false-negative rate of our benchmark. Extensive experiments across 19 language models show that they still struggle with certain scenarios, such as understanding products and intentions accurately, jointly reasoning with products and intentions, and more, in which they fall far behind human performances.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.123",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Draft on the Fly: Adaptive Self-Speculative Decoding using Cosine Similarity": {
        "type": "INPROCEEDINGS",
        "key": "metel-etal-2024-draft",
        "author": "Metel, Michael R. and Lu, Peng and Chen, Boxing and Rezagholizadeh, Mehdi and Kobyzev, Ivan",
        "booktitle": "EMNLP-findings2024",
        "title": "Draft on the Fly: Adaptive Self-Speculative Decoding using Cosine Similarity",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We present a simple on the fly method for faster inference of large language models. Unlike other (self-)speculative decoding techniques, our method does not require fine-tuning or black-box optimization to generate a fixed draft model, relying instead on simple rules to generate varying draft models adapted to the input context. We show empirically that our light-weight algorithm is competitive with the current SOTA for self-speculative decoding, while being a truly plug-and-play method.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.124",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "quan-liu-2024-econlogicqa",
        "author": "Quan, Yinzhu and Liu, Zefang",
        "booktitle": "EMNLP-findings2024",
        "title": "EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we introduce EconLogicQA, a rigorous benchmark designed to assess the sequential reasoning capabilities of large language models (LLMs) within the intricate realms of economics, business, and supply chain management. Diverging from traditional benchmarks that predict subsequent events individually, EconLogicQA poses a more challenging task: it requires models to discern and sequence multiple interconnected events, capturing the complexity of economic logics. EconLogicQA comprises an array of multi-event scenarios derived from economic articles, which necessitate an insightful understanding of both temporal and logical event relationships. Through comprehensive evaluations, we exhibit that EconLogicQA effectively gauges a LLM\u2019s proficiency in navigating the sequential complexities inherent in economic contexts. We provide a detailed description of EconLogicQA dataset and shows the outcomes from evaluating the benchmark across various leading-edge LLMs, thereby offering a thorough perspective on their sequential reasoning potential in economic contexts. Our benchmark dataset is available at https://huggingface.co/datasets/yinzhu-quan/econ_logic_qa.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.125",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance": {
        "type": "INPROCEEDINGS",
        "key": "moore-etal-2024-base",
        "author": "Moore, Kyle and Roberts, Jesse and Pham, Thao and Ewaleifoh, Oseremhen and Fisher, Douglas",
        "booktitle": "EMNLP-findings2024",
        "title": "The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Cloze testing is a common method for measuring the behavior of large language models on a number of benchmark tasks. Using the MMLU dataset, we show that the base-rate probability (BRP) differences across answer tokens are significant and affect task performance ie. guess A if uncertain. We find that counterfactual prompting does sufficiently mitigate the BRP effect. The BRP effect is found to have a similar effect to test taking strategies employed by humans leading to the conflation of task performance and test-taking ability. We propose the Nvr-X-MMLU task, a variation of MMLU, which helps to disambiguate test-taking ability from task performance and reports the latter.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.126",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can LLM Graph Reasoning Generalize beyond Pattern Memorization?": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-llm-graph",
        "author": "Zhang, Yizhuo and Wang, Heng and Feng, Shangbin and Tan, Zhaoxuan and Han, Xiaochuang and He, Tianxing and Tsvetkov, Yulia",
        "booktitle": "EMNLP-findings2024",
        "title": "Can LLM Graph Reasoning Generalize beyond Pattern Memorization?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) demonstrate great potential for problems with implicit graphical structures, while recent works seek to enhance the graph reasoning capabilities of LLMs through specialized instruction tuning. The resulting \u201cgraph LLMs\u201d are evaluated with in-distribution settings only, thus it remains underexplored whether LLMs are learning generalizable graph reasoning skills or merely memorizing patterns in the synthetic training data. To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph reasoning generalization: whether LLMs could go beyond semantic, numeric, structural, reasoning patterns in the synthetic training data and improve utility on real-world graph-based tasks. Extensive experiments with two LLMs across four graph reasoning tasks demonstrate that while generalization on simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to generalize across reasoning and real-world patterns, casting doubt on the benefit of synthetic graph tuning for real-world tasks with underlying network structures. We explore three strategies to improve LLM graph reasoning generalization, and we find that while post-training alignment is most promising for real-world tasks, empowering LLM graph reasoning to go beyond pattern memorization remains an open research question.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.127",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets": {
        "type": "INPROCEEDINGS",
        "key": "indurthi-etal-2024-improving",
        "author": "Indurthi, Sathish Reddy and Zhou, Wenxuan and Chollampatt, Shamil and Agrawal, Ravi and Song, Kaiqiang and Zhao, Lingxiao and Zhu, Chenguang",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Advancements in Large Language Models (LLMs) have significantly enhanced instruction-following capabilities. However, most Instruction Fine-Tuning (IFT) datasets are predominantly in English, limiting model performance in other languages. Traditional methods for creating multilingual IFT datasets\u2014such as translating existing English IFT datasets or converting existing NLP datasets into IFT datasets by templating\u2014struggle to capture linguistic nuances and ensure prompt (instruction) diversity. To address this issue, we propose a novel method for collecting multilingual IFT datasets that preserves linguistic naturalness and ensures prompt diversity. This approach leverages English-focused LLMs, monolingual corpora, and a scoring function to create high-quality, diversified IFT datasets in multiple languages. Experiments demonstrate that LLMs finetuned using these IFT datasets show notable improvements in both generative and discriminative tasks, indicating enhanced language comprehension by LLMs in non-English contexts. Specifically, on the multilingual summarization task, LLMs using our IFT dataset achieved 17.57% and 15.23% improvements over LLMs fine-tuned with translation-based and template-based datasets, respectively.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.128",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ASTE-Transformer: Modelling Dependencies in Aspect-Sentiment Triplet Extraction": {
        "type": "INPROCEEDINGS",
        "key": "naglik-lango-2024-aste",
        "author": "Naglik, Iwo and Lango, Mateusz",
        "booktitle": "EMNLP-findings2024",
        "title": "ASTE-Transformer: Modelling Dependencies in Aspect-Sentiment Triplet Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of aspect-based sentiment analysis that consists in extracting (aspect phrase, opinion phrase, sentiment polarity) triples from a given sentence. Recent state-of-the-art methods approach this task by first extracting all possible text spans from a given text, then filtering the potential aspect and opinion phrases with a classifier, and finally considering all their pairs with another classifier that additionally assigns sentiment polarity to them. Although several variations of the above scheme have been proposed, the common feature is that the final result is constructed by a sequence of independent classifier decisions. This hinders the exploitation of dependencies between extracted phrases and prevents the use of knowledge about the interrelationships between classifier predictions to improve performance. In this paper, we propose a new ASTE approach consisting of three transformer-inspired layers, which enables the modelling of dependencies both between phrases and between the final classifier decisions. Experimental results show that the method achieves higher performance in terms of F1 measure than other methods studied on popular benchmarks. In addition, we show that a simple pre-training technique further improves the performance of the model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.129",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach": {
        "type": "INPROCEEDINGS",
        "key": "wojciechowski-etal-2024-faithful",
        "author": "Wojciechowski, Adam and Lango, Mateusz and Dusek, Ondrej",
        "booktitle": "EMNLP-findings2024",
        "title": "Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing explanation methods for image classification struggle to provide faithful and plausible explanations. This paper addresses this issue by proposing a post-hoc natural language explanation method that can be applied to any CNN-based classifier without altering its training process or affecting predictive performance. By analysing influential neurons and the corresponding activation maps, the method generates a faithful description of the classifier\u2019s decision process in the form of a structured meaning representation, which is then converted into text by a language model. Through this pipeline approach, the generated explanations are grounded in the neural network architecture, providing accurate insight into the classification process while remaining accessible to non-experts. Experimental results show that the NLEs constructed by our method are significantly more plausible and faithful than baselines. In particular, user interventions in the neural network structure (masking of neurons) are three times more effective.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.130",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SynTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-syntqa",
        "author": "Zhang, Siyue and Luu, Anh Tuan and Zhao, Chen",
        "booktitle": "EMNLP-findings2024",
        "title": "SynTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Text-to-SQL parsing and end-to-end question answering (E2E TQA) are two main approaches for Table-based Question Answering task. Despite success on multiple benchmarks, they have yet to be compared and their synergy remains unexplored. In this paper, we identify different strengths and weaknesses through evaluating state-of-the-art models on benchmark datasets: Text-to-SQL demonstrates superiority in handling questions involving arithmetic operations and long tables; E2E TQA excels in addressing ambiguous questions, non-standard table schema, and complex table contents. To combine both strengths, we propose a Synergistic Table-based Question Answering approach that integrate different models via answer selection, which is agnostic to any model types. Further experiments validate that ensembling models by either feature-based or LLM-based answer selector significantly improves the performance over individual models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.131",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "OpenGraph: Towards Open Graph Foundation Models": {
        "type": "INPROCEEDINGS",
        "key": "xia-etal-2024-opengraph",
        "author": "Xia, Lianghao and Kao, Ben and Huang, Chao",
        "booktitle": "EMNLP-findings2024",
        "title": "OpenGraph: Towards Open Graph Foundation Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Graph learning has become essential in various domains, including recommendation systems and social network analysis. Graph Neural Networks (GNNs) have emerged as promising techniques for encoding structural information and improving performance in tasks like link prediction and node classification. However, a key challenge remains: the difficulty of generalizing to unseen graph data with different properties. In this work, we propose a novel graph foundation model, called OpenGraph, to address this challenge. Our approach tackles several technical obstacles. Firstly, we enhance data augmentation using a large language model (LLM) to overcome data scarcity in real-world scenarios. Secondly, we introduce a unified graph tokenizer that enables the model to generalize effectively to diverse graph data, even when encountering unseen properties during training. Thirdly, our developed scalable graph transformer captures node-wise dependencies within the global topological context. Extensive experiments validate the effectiveness of our framework. By adapting OpenGraph to new graph characteristics and comprehending diverse graphs, our approach achieves remarkable zero-shot graph learning performance across various settings. We release the model implementation at https://github.com/HKUDS/OpenGraph.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.132",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-controlling",
        "author": "Chen, Lu and Zhang, Ruqing and Guo, Jiafeng and Fan, Yixing and Cheng, Xueqi",
        "booktitle": "EMNLP-findings2024",
        "title": "Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-augmented generation (RAG) has emerged as a popular solution to mitigate the hallucination issues of large language models. However, existing studies on RAG seldom address the issue of predictive uncertainty, i.e., how likely it is that a RAG model\u2019s prediction is incorrect, resulting in uncontrollable risks in real-world applications. In this work, we emphasize the importance of risk control, ensuring that RAG models proactively refuse to answer questions with low confidence. Our research identifies two critical latent factors affecting RAG\u2019s confidence in its predictions: the quality of the retrieved results and the manner in which these results are utilized. To guide RAG models in assessing their own confidence based on these two latent factors, we develop a counterfactual prompting framework that induces the models to alter these factors and analyzes the effect on their answers. We also introduce a benchmarking procedure to collect answers with the option to abstain, facilitating a series of experiments. For evaluation, we introduce several risk-related metrics and the experimental results demonstrate the effectiveness of our approach. Our code and benchmark dataset are available at https://github.com/ict-bigdatalab/RC-RAG.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.133",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Paraphrase for Alignment with LLM Preference": {
        "type": "INPROCEEDINGS",
        "key": "fu-etal-2024-learning",
        "author": "Fu, Junbo and Zhao, Guoshuai and Deng, Yimin and Mi, Yunqi and Qian, Xueming",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Paraphrase for Alignment with LLM Preference",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) exhibit the issue of paraphrase divergence. This means that when a question is phrased in a slightly different but semantically similar way, LLM may output a wrong response despite being able to answer the original question correctly. Previous research has regarded this issue as a problem of the model\u2019s robustness to question paraphrase and proposed a retraining method to address it. However, retraining faces challenges in meeting the computational costs and privacy security demands of LLMs. In this paper, we regard this issue as a problem of alignment with model preferences and propose PEARL (Preference-drivEn pAraphRase Learning). This is a black-box method that enhances model performance by paraphrasing questions in expressions preferred by the model. We validate PEARL across six datasets spanning three tasks: open-domain QA, commonsense reasoning, and math word problem. Extensive experiments demonstrated not only the outstanding performance but also the composability, transferability, and immense potential of PEARL, shedding new light on the black-box tuning of LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.134",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Mirror-Consistency: Harnessing Inconsistency in Majority Voting": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-mirror",
        "author": "Huang, Siyuan and Ma, Zhiyuan and Du, Jintao and Meng, Changhua and Wang, Weiqiang and Lin, Zhouhan",
        "booktitle": "EMNLP-findings2024",
        "title": "Mirror-Consistency: Harnessing Inconsistency in Majority Voting",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Self-Consistency, a widely-used decoding strategy, significantly boosts the reasoning capabilities of Large Language Models (LLMs). However, it depends on the plurality voting rule, which focuses on the most frequent answer while overlooking all other minority responses. These inconsistent minority views often illuminate areas of uncertainty within the model\u2019s generation process. To address this limitation, we present Mirror-Consistency, an enhancement of the standard Self-Consistency approach. Our method incorporates a \u2018reflective mirror\u2019 into the self-ensemble decoding process and enables LLMs to critically examine inconsistencies among multiple generations. Additionally, just as humans use the mirror to better understand themselves, we propose using Mirror-Consistency to enhance the sample-based confidence calibration methods, which helps to mitigate issues of overconfidence. Our experimental results demonstrate that Mirror-Consistency yields superior performance in both reasoning accuracy and confidence calibration compared to Self-Consistency.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.135",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-adaptive",
        "author": "Kim, Youna and Kim, Hyuhng Joon and Park, Cheonbok and Park, Choonghyun and Cho, Hyunsoo and Kim, Junyeob and Yoo, Kang Min and Lee, Sang-goo and Kim, Taeuk",
        "booktitle": "EMNLP-findings2024",
        "title": "Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "When using large language models (LLMs) in knowledge-intensive tasks, such as open-domain question answering, external context can bridge the gap between external knowledge and the LLMs\u2019 parametric knowledge.Recent research has been developed to amplify contextual knowledge over the parametric knowledge of LLMs with contrastive decoding approaches.While these approaches could yield truthful responses when relevant context is provided, they are prone to vulnerabilities when faced with noisy contexts.We extend the scope of previous studies to encompass noisy contexts and propose adaptive contrastive decoding (ACD) to leverage contextual influence effectively.ACD demonstrates improvements in open-domain question answering tasks compared to baselines, especially in robustness by remaining undistracted by noisy contexts in retrieval-augmented generation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.136",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AnyTrans: Translate AnyText in the Image with Large Scale Models": {
        "type": "INPROCEEDINGS",
        "key": "qian-etal-2024-anytrans",
        "author": "Qian, Zhipeng and Zhang, Pei and Yang, Baosong and Fan, Kai and Ma, Yiwei and Wong, Derek F. and Sun, Xiaoshuai and Ji, Rongrong",
        "booktitle": "EMNLP-findings2024",
        "title": "AnyTrans: Translate AnyText in the Image with Large Scale Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper introduces AnyText, an all-encompassing framework for the task\u2013In-Image Machine Translation (IIMT), which includes multilingual text translation and text fusion within images. Our framework leverages the strengths of large-scale models, such as Large Language Models (LLMs) and text-guided diffusion models, to incorporate contextual cues from both textual and visual elements during translation. The few-shot learning capability of LLMs allows for the translation of fragmented texts by considering the overall context. Meanwhile, diffusion models\u2019 advanced inpainting and editing abilities make it possible to fuse translated text seamlessly into the original image while preserving its style and realism. Our framework can be constructed entirely using open-source models and requires no training, making it highly accessible and easily expandable. To encourage advancement in the IIMT task, we have meticulously compiled a test dataset called MTIT6, which consists of multilingual text image translation data from six language pairs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.137",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "In-Context Former: Lightning-fast Compressing Context for Large Language Model": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-context-former",
        "author": "Wang, Xiangfeng and Chen, Zaiyi and Xu, Tong and Xie, Zheyong and He, Yongyi and Chen, Enhong",
        "booktitle": "EMNLP-findings2024",
        "title": "In-Context Former: Lightning-fast Compressing Context for Large Language Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the rising popularity of Transformer-based large language models (LLMs), reducing their high inference costs has become a significant research focus. One effective approach to mitigate these costs is compressing the long input contexts. Existing methods typically leverage the self-attention mechanism of the large model itself for context compression. While these methods have achieved notable results, the compression process still entails quadratic complexity. To mitigate this limitation, we propose the In-Context Former (IC-Former). This method does not rely on the target large model but instead utilizes cross-attention mechanisms to extract and condense information from the contextual embeddings. The computational overhead of our method grows linearly with the compression range. Experimental results indicate that our method requires only 1/32 of the floating-point operations of the baseline during compression and improves processing speed by 68 to 112 times while achieving 90% of the baseline performance on evaluation metrics. Additionally, IC-Former demonstrates strong regularity in its interactions with the context, enhancing its interpretability. Overall, IC-Former significantly reduces compression costs, making real-time compression scenarios feasible.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.138",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States": {
        "type": "INPROCEEDINGS",
        "key": "zhou-etal-2024-alignment",
        "author": "Zhou, Zhenhong and Yu, Haiyang and Zhang, Xinghua and Xu, Rongwu and Huang, Fei and Li, Yongbin",
        "booktitle": "EMNLP-findings2024",
        "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) rely on safety alignment to avoid responding to malicious user inputs. Unfortunately, jailbreak can circumvent safety guardrails, resulting in LLMs generating harmful content and raising concerns about LLM safety. Due to language models with intensive parameters often regarded as black boxes, the mechanisms of alignment and jailbreak are challenging to elucidate. In this paper, we employ weak classifiers to explain LLM safety through the intermediate hidden states. We first confirm that LLMs learn ethical concepts during pre-training rather than alignment and can identify malicious and normal inputs in the early layers. Alignment actually associates the early concepts with emotion guesses in the middle layers and then refines them to the specific reject tokens for safe generations. Jailbreak disturbs the transformation of early unethical classification into negative emotions. We conduct experiments on models from 7B to 70B across various model families to prove our conclusion. Overall, our paper indicates the intrinsical mechanism of LLM safety and how jailbreaks circumvent safety guardrails, offering a new perspective on LLM safety and reducing concerns.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.139",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Coarse-to-Fine Prototype Learning Approach for Multi-Label Few-Shot Intent Detection": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-coarse",
        "author": "Zhang, Xiaotong and Li, Xinyi and Zhang, Feng and Wei, Zhiyi and Liu, Junfeng and Liu, Han",
        "booktitle": "EMNLP-findings2024",
        "title": "A Coarse-to-Fine Prototype Learning Approach for Multi-Label Few-Shot Intent Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Few-shot intent detection is a challenging task, particularly in scenarios involving multiple labels and diverse domains. This paper presents a novel prototype learning approach that combines the label synset augmentation and the coarse-to-fine prototype distillation for multi-label few-shot intent detection. To tackle the data scarcity issue and the lack of information for unseen domains, we propose to enhance the representations of utterances with label synset augmentation and refine the prototypes by distilling the coarse domain knowledge from a universal teacher model. To solve the multilingual intent detection in real-world dialogue systems, we fine-tune a cross-lingual teacher model to make our method fast adapt to different languages and re-annotate two non-English task-oriented dialogue datasets CrossWOZ and JMultiWOZ in multi-label form. Experimental results on one English and two non-English datasets demonstrate that our approach significantly outperforms existing methods in terms of accuracy and generalization across different domains.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.140",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-large-language-models-understand",
        "author": "Wang, Keyu and Qi, Guilin and Li, Jiaqi and Zhai, Songlin",
        "booktitle": "EMNLP-findings2024",
        "title": "Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have shown significant achievements in solving a wide range of tasks. Recently, LLMs\u2019 capability to store, retrieve and infer with symbolic knowledge has drawn a great deal of attention, showing their potential to understand structured information. However, it is not yet known whether LLMs can understand Description Logic (DL) ontologies. In this work, we empirically analyze the LLMs\u2019 capability of understanding DL-Lite ontologies covering 6 representative tasks from syntactic and semantic aspects. With extensive experiments, we demonstrate both the effectiveness and limitations of LLMs in understanding DL-Lite ontologies. We find that LLMs can understand formal syntax and model-theoretic semantics of concepts and roles. However, LLMs struggle with understanding TBox NI transitivity and handling ontologies with large ABoxes. We hope that our experiments and analyses provide more insights into LLMs and inspire to build more faithful knowledge engineering solutions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.141",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration": {
        "type": "INPROCEEDINGS",
        "key": "qin-etal-2024-enhancing",
        "author": "Qin, Jeremy and Liu, Bang and Nguyen, Quoc Dinh",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Black-box large language models (LLMs) are increasingly deployed in various environments, making it essential for these models to effectively convey their confidence and uncertainty, especially in high-stakes settings. However, these models often exhibit overconfidence, leading to potential risks and misjudgments. Existing techniques for eliciting and calibrating LLM confidence have primarily focused on general reasoning datasets, yielding only modest improvements. Accurate calibration is crucial for informed decision-making and preventing adverse outcomes but remains challenging due to the complexity and variability of tasks these models perform. In this work, we investigate the miscalibration behavior of black-box LLMs within the healthcare setting. We propose a novel method, Atypical Presentations Recalibration, which leverages atypical presentations to adjust the model\u2019s confidence estimates. Our approach significantly improves calibration, reducing calibration errors by approximately 60% on three medical question answering datasets and outperforming existing methods such as vanilla verbalized confidence, CoT verbalized confidence and others. Additionally, we provide an in-depth analysis of the role of atypicality within the recalibration framework.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.142",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "EvoR: Evolving Retrieval for Code Generation": {
        "type": "INPROCEEDINGS",
        "key": "su-etal-2024-evor",
        "author": "Su, Hongjin and Jiang, Shuyang and Lai, Yuhang and Wu, Haoyuan and Shi, Boao and Liu, Che and Liu, Qian and Yu, Tao",
        "booktitle": "EMNLP-findings2024",
        "title": "EvoR: Evolving Retrieval for Code Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently the retrieval-augmented generation (RAG) has been successfully applied in code generation. However, existing pipelines for retrieval-augmented code generation (RACG) employ static knowledge bases with a single source, limiting the adaptation capabilities of Large Language Models (LLMs) to domains they have insufficient knowledge of. In this work, we develop a novel pipeline, EVOR, that employs the synchronous evolution of both queries and diverse knowledge bases. On two realistic settings where the external knowledge is required to solve code generation tasks, we compile four new datasets associated with frequently updated libraries and long-tail programming languages, named EVOR-BENCH. Extensive experiments demonstrate that EVOR achieves two to four times of execution accuracy compared to other methods such as Reflexion (Shinn et al., 2024), DocPrompting (Zhou et al., 2023), etc. We demonstrate that EVOR is flexible and can be easily combined with them to achieve further improvement. Further analysis reveals that EVOR benefits from the synchronous evolution of queries and documents and the diverse information sources in the knowledge base. We hope that our studies will inspire more insights into the design of advanced RACG pipelines in future research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.143",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Head-wise Shareable Attention for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "cao-etal-2024-head",
        "author": "Cao, Zouying and Yang, Yifei and Zhao, Hai",
        "booktitle": "EMNLP-findings2024",
        "title": "Head-wise Shareable Attention for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.144",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Divide-or-Conquer? Which Part Should You Distill Your LLM?": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-divide",
        "author": "Wu, Zhuofeng and Bai, Richard He and Zhang, Aonan and Gu, Jiatao and Vydiswaran, V.G.Vinod and Jaitly, Navdeep and Zhang, Yizhe",
        "booktitle": "EMNLP-findings2024",
        "title": "Divide-or-Conquer? Which Part Should You Distill Your LLM?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent methods have demonstrated that Large Language Models (LLMs) can solve reasoning tasks better when they are encouraged to solve subtasks of the main task first. In this paper we devise a similar strategy that breaks down reasoning tasks into a problem decomposition phase and a problem solving phase and show that the strategy is able to outperform a single stage solution. Further, we hypothesize that the decomposition should be easier to distill into a smaller model compared to the problem solving because the latter requires large amounts of domain knowledge while the former only requires learning general problem solving strategies. We propose methods to distill these two capabilities and evaluate their impact on reasoning outcomes and inference cost. We find that we can distill the problem decomposition phase and at the same time achieve good generalization across tasks, datasets, and models. However, it is harder to distill the problem solving capability without losing performance and the resulting distilled model struggles with generalization. These results indicate that by using smaller, distilled problem decomposition models in combination with problem solving LLMs we can achieve reasoning with cost-efficient inference and local adaptation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.145",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhou-etal-2024-navigating-shortcut",
        "author": "Zhou, Yuqing and Tang, Ruixiang and Yao, Ziyu and Zhu, Ziwei",
        "booktitle": "EMNLP-findings2024",
        "title": "Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language models (LMs), despite their advances, often depend on spurious correlations, undermining their accuracy and generalizability. This study addresses the overlooked impact of subtler, more complex shortcuts that compromise model reliability beyond oversimplified shortcuts. We introduce a comprehensive benchmark that categorizes shortcuts into occurrence, style, and concept, aiming to explore the nuanced ways in which these shortcuts influence the performance of LMs. Through extensive experiments across traditional LMs, large language models, and state-of-the-art robust models, our research systematically investigates models\u2019 resilience and susceptibilities to sophisticated shortcuts. Our benchmark and code can be found at: https://github.com/yuqing-zhou/shortcut-learning-in-text-classification.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.146",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Privacy Evaluation Benchmarks for NLP Models": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-privacy",
        "author": "Huang, Wei and Wang, Yinggui and Chen, Cen",
        "booktitle": "EMNLP-findings2024",
        "title": "Privacy Evaluation Benchmarks for NLP Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "By inducing privacy attacks on NLP models, attackers can obtain sensitive information such as training data and model parameters, etc. Although researchers have studied, in-depth, several kinds of attacks in NLP models, they are non-systematic analyses. It lacks a comprehensive understanding of the impact caused by the attacks. For example, we must consider which scenarios can apply to which attacks, what the common factors are that affect the performance of different attacks, the nature of the relationships between different attacks, and the influence of various datasets and models on the effectiveness of the attacks, etc. Therefore, we need a benchmark to holistically assess the privacy risks faced by NLP models. In this paper, we present a privacy attack and defense evaluation benchmark in the field of NLP, which includes the conventional/small models and large language models (LLMs). This benchmark supports a variety of models, datasets, and protocols, along with standardized modules for comprehensive evaluation of attacks and defense strategies. Based on the above framework, we present a study on the association between auxiliary data from different domains and the strength of privacy attacks. And we provide an improved attack method in this scenario with the help of Knowledge Distillation (KD). Furthermore, we propose a chained framework for privacy attacks. Allowing a practitioner to chain multiple attacks to achieve a higher-level attack objective. Based on this, we provide some defense and enhanced attack strategies. The code for reproducing the results can be found at https://anonymous.4open.science/r/nlp_doctor-AF48",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.147",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MM-ChatAlign: A Novel Multimodal Reasoning Framework based on Large Language Models for Entity Alignment": {
        "type": "INPROCEEDINGS",
        "key": "jiang-etal-2024-mm",
        "author": "Jiang, Xuhui and Shen, Yinghan and Shi, Zhichao and Xu, Chengjin and Li, Wei and Zihe, Huang and Guo, Jian and Wang, Yuanzhuo",
        "booktitle": "EMNLP-findings2024",
        "title": "MM-ChatAlign: A Novel Multimodal Reasoning Framework based on Large Language Models for Entity Alignment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal entity alignment (MMEA) integrates multi-source and cross-modal knowledge graphs, a crucial yet challenging task for data-centric applications.Traditional MMEA methods derive the visual embeddings of entities and combine them with other modal data for alignment by embedding similarity comparison.However, these methods are hampered by the limited comprehension of visual attributes and deficiencies in realizing and bridging the semantics of multimodal data. To address these challenges, we propose MM-ChatAlign, a novel framework that utilizes the visual reasoning abilities of MLLMs for MMEA.The framework features an embedding-based candidate collection module that adapts to various knowledge representation strategies, effectively filtering out irrelevant reasoning candidates. Additionally, a reasoning and rethinking module, powered by MLLMs, enhances alignment by efficiently utilizing multimodal information.Extensive experiments on four MMEA datasets demonstrate MM-ChatAlign\u2019s superiority and underscore the significant potential of MLLMs in MMEA tasks.The source code is available at https://github.com/jxh4945777/MMEA/.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.148",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Explainable Computerized Adaptive Testing with Large Language Model": {
        "type": "INPROCEEDINGS",
        "key": "cheng-etal-2024-towards",
        "author": "Cheng, Cheng and Zhao, GuanHao and Huang, Zhenya and Zhuang, Yan and Pan, Zhaoyuan and Liu, Qi and Li, Xin and Chen, Enhong",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Explainable Computerized Adaptive Testing with Large Language Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As intelligent education evolves, it will provide students with multiple personalized learning services based on their individual abilities. Computerized adaptive testing (CAT) is designed to accurately measure a student\u2019s ability using the least questions, providing an efficient and personalized testing method. However, existing methods mainly focus on minimizing the number of questions required to assess ability, often lacking clear and reliable explanations for the question selection process. Educators and students can hardly trust and accept CAT systems without an understanding of the rationale behind the question selection process. To address this issue, we introduce LLM-Agent-Based CAT (LACAT), a novel agent powered by large language models to enhance CAT with human-like interpretability and explanation capabilities. LACAT consists of three key modules: the Summarizer, which generates interpretable student profiles; the Reasoner, which personalizes questions and provides human-readable explanations; and the Critic, which learns from past choices to optimize future question selection. We conducted extensive experiments on three real-world educational datasets. The results demonstrate that LACAT can perform comparably or superior to traditional CAT methods in accuracy and significantly improve the transparency and acceptability of the testing process. Human evaluations further confirm that LACAT can generate high-quality, understandable explanations, thereby enhancing student trust and satisfaction.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.149",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing": {
        "type": "INPROCEEDINGS",
        "key": "dong-etal-2024-mc",
        "author": "Dong, Kuicai and Goh Xin Deik, Derrick and Lee, Yi Quan and Zhang, Hao and Li, Xiangyang and Zhang, Cong and Liu, Yong",
        "booktitle": "EMNLP-findings2024",
        "title": "MC-indexing: Effective Long Document Retrieval via Multi-view Content-aware Indexing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Long document question answering (DocQA) aims to answer questions from long documents over 10k words. They usually contain content structures such as sections, sub-sections, and paragraph demarcations. However, the indexing methods of long documents remain under-explored, while existing systems generally employ fixed-length chunking. As they do not consider content structures, the resultant chunks can exclude vital information or include irrelevant content. Motivated by this, we propose the **M**ulti-view **C**ontent-aware indexing (**MC-indexing**) for more effective long DocQA via (i) segment structured document into content chunks, and (ii) represent each content chunk in raw-text, keywords, and summary views. We highlight that MC-indexing requires neither training nor fine-tuning. Having plug-and-play capability, it can be seamlessly integrated with any retrievers to boost their performance. Besides, we propose a long DocQA dataset that includes not only question-answer pair, but also document structure and answer scope. When compared to state-of-art chunking schemes, MC-indexing has significantly increased the recall by **42.8%**, **30.0%**, **23.9%**, and **16.3%** via top k = 1.5, 3, 5, and 10 respectively. These improved scores are the average of 8 widely used retrievers (2 sparse and 6 dense) via extensive experiments.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.150",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems": {
        "type": "INPROCEEDINGS",
        "key": "mitsui-etal-2024-pslm",
        "author": "Mitsui, Kentaro and Mitsuda, Koh and Wakatsuki, Toshiaki and Hono, Yukiya and Sawada, Kei",
        "booktitle": "EMNLP-findings2024",
        "title": "PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal language models that process both text and speech have a potential for applications in spoken dialogue systems. However, current models face two major challenges in response generation latency: (1) generating a spoken response requires the prior generation of a written response, and (2) speech sequences are significantly longer than text sequences. This study addresses these issues by extending the input and output sequences of the language model to support the parallel generation of text and speech. Our experiments on spoken question answering tasks demonstrate that our approach improves latency while maintaining the quality of response content. Additionally, we show that latency can be further reduced by generating speech in multiple sequences. Demo samples are available at https://rinnakk.github.io/research/publications/PSLM.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.151",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Are Large Language Models (LLMs) Good Social Predictors?": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-large-language-models-llms",
        "author": "Yang, Kaiqi and Li, Hang and Wen, Hongzhi and Peng, Tai-Quan and Tang, Jiliang and Liu, Hui",
        "booktitle": "EMNLP-findings2024",
        "title": "Are Large Language Models (LLMs) Good Social Predictors?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the recent advancement of Large Language Models (LLMs), efforts have been made to leverage LLMs in crucial social science study methods, including predicting human features of social life such as presidential voting. Existing works suggest that LLMs are capable of generating human-like responses. Nevertheless, it is unclear how well LLMs work and where the plausible predictions derive from. This paper critically examines the performance of LLMs as social predictors, pointing out the source of correct predictions and limitations. Based on the notion of mutability that classifies social features, we design three realistic settings and a novel social prediction task, where the LLMs make predictions with input features of the same mutability and accessibility with the response feature. We find that the promising performance achieved by previous studies is because of input shortcut features to the response, which are hard to capture in reality; the performance degrades dramatically to near-random after removing the shortcuts. With the comprehensive investigations on various LLMs, we reveal that LLMs struggle to work as expected on social prediction when given ordinarily available input features without shortcuts. We further investigate possible reasons for this phenomenon and suggest potential ways to enhance LLMs for social prediction.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.153",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Bahasa Harmony: A Comprehensive Dataset for Bahasa Text-to-Speech Synthesis with Discrete Codec Modeling of EnGen-TTS.": {
        "type": "INPROCEEDINGS",
        "key": "susladkar-etal-2024-bahasa",
        "author": "Susladkar, Onkar Kishor and Tripathi, Vishesh and Ahmed, Biddwan",
        "booktitle": "EMNLP-findings2024",
        "title": "Bahasa Harmony: A Comprehensive Dataset for Bahasa Text-to-Speech Synthesis with Discrete Codec Modeling of EnGen-TTS.",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This research introduces a comprehensive Bahasa text-to-speech (TTS) dataset and a novel TTS model, EnGen-TTS, designed to enhance the quality and versatility of synthetic speech in the Bahasa language. The dataset, spanning 55.00 hours and 52K audio recordings, integrates diverse textual sources, ensuring linguistic richness. A meticulous recording setup captures the nuances of Bahasa phonetics, employing professional equipment to ensure high-fidelity audio samples. Statistical analysis reveals the dataset\u2019s scale and diversity, laying the foundation for model training and evaluation. The proposed EnGen-TTS model performs better than established baselines, achieving a Mean Opinion Score (MOS) of 4.45 \\pm 0.13. Additionally, our investigation on real-time factor and model size highlights EnGen-TTS as a compelling choice, with efficient performance. This research marks a significant advancement in Bahasa TTS technology, with implications for diverse language applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.154",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MINERS: Multilingual Language Models as Semantic Retrievers": {
        "type": "INPROCEEDINGS",
        "key": "winata-etal-2024-miners",
        "author": "Winata, Genta Indra and Zhang, Ruochen and Adelani, David Ifeoluwa",
        "booktitle": "EMNLP-findings2024",
        "title": "MINERS: Multilingual Language Models as Semantic Retrievers",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Words have been represented in a high-dimensional vector space that encodes their semantic similarities, enabling downstream applications such as retrieving synonyms, antonyms, and relevant contexts. However, despite recent advances in multilingual language models (LMs), the effectiveness of these models\u2019 representations in semantic retrieval contexts has not been comprehensively explored. To fill this gap, this paper introduces the MINERS, a benchmark designed to evaluate the ability of multilingual LMs in semantic retrieval tasks, including bitext mining and classification via retrieval-augmented contexts. We create a comprehensive framework to assess the robustness of LMs in retrieving samples across over 200 diverse languages, including extremely low-resource languages in challenging cross-lingual and code-switching settings. Our results demonstrate that by solely retrieving semantically similar embeddings yields performance competitive with state-of-the-art approaches, without requiring any fine-tuning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.155",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BoolQuestions: Does Dense Retrieval Understand Boolean Logic in Language?": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-boolquestions",
        "author": "Zhang, Zongmeng and Zhu, Jinhua and Zhou, Wengang and Qi, Xiang and Zhang, Peng and Li, Houqiang",
        "booktitle": "EMNLP-findings2024",
        "title": "BoolQuestions: Does Dense Retrieval Understand Boolean Logic in Language?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Dense retrieval, which aims to encode the semantic information of arbitrary text into dense vector representations or embeddings, has emerged as an effective and efficient paradigm for text retrieval, consequently becoming an essential component in various natural language processing systems. These systems typically focus on optimizing the embedding space by attending to the relevance of text pairs, while overlooking the Boolean logic inherent in language, which may not be captured by current training objectives. In this work, we first investigate whether current retrieval systems can comprehend the Boolean logic implied in language. To answer this question, we formulate the task of Boolean Dense Retrieval and collect a benchmark dataset, BoolQuestions, which covers complex queries containing basic Boolean logic and corresponding annotated passages. Through extensive experimental results on the proposed task and benchmark dataset, we draw the conclusion that current dense retrieval systems do not fully understand Boolean logic in language, and there is a long way to go to improve our dense retrieval systems. Furthermore, to promote further research on enhancing the understanding of Boolean logic for language models, we explore Boolean operation on decomposed query and propose a contrastive continual training method that serves as a strong baseline for the research community.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.156",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "McCrolin: Multi-consistency Cross-lingual Training for Retrieval Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "limkonchotiwat-etal-2024-mccrolin",
        "author": "Limkonchotiwat, Peerat and Ponwitayarat, Wuttikorn and Lowphansirikul, Lalita and Manakul, Potsawee and Udomcharoenchaikit, Can and Chuangsuwanich, Ekapol and Nutanong, Sarana",
        "booktitle": "EMNLP-findings2024",
        "title": "McCrolin: Multi-consistency Cross-lingual Training for Retrieval Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automated question answering (QA) systems are increasingly relying on robust cross-lingual retrieval to identify and utilize information from multilingual sources, ensuring comprehensive and contextually accurate responses. Existing approaches often struggle with consistency across multiple languages and multi-size input scenarios. To address these challenges, we propose McCrolin, a Multi-consistency Cross-lingual training framework, leveraging multi-task learning to enhance cross-lingual consistency, ranking stability, and input-size robustness. Experimental results demonstrate that McCrolin achieves state-of-the-art performance on standard cross-lingual retrieval QA datasets. Furthermore, McCrolin outperforms competitors when dealing with various input sizes on downstream tasks. In terms of generalizability, results from further analysis show that our method is effective for various encoder architectures and sizes.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.157",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios": {
        "type": "INPROCEEDINGS",
        "key": "ackerman-etal-2024-novel",
        "author": "Ackerman, Samuel and Rabinovich, Ella and Farchi, Eitan and Anaby Tavor, Ateret",
        "booktitle": "EMNLP-findings2024",
        "title": "A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We evaluate the robustness of several large language models on multiple datasets. Robustness here refers to the relative insensitivity of the model\u2019s answers to meaning-preserving variants of their input. Benchmark datasets are constructed by introducing naturally-occurring, non-malicious perturbations, or by generating semantically equivalent paraphrases of input questions or statements. We further propose a novel metric for assessing a model robustness, and demonstrate its benefits in the non-adversarial scenario by empirical evaluation of several models on the created datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.158",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning Musical Representations for Music Performance Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "diao-etal-2024-learning",
        "author": "Diao, Xingjian and Zhang, Chunhui and Wu, Tingxuan and Cheng, Ming and Ouyang, Zhongyu and Wu, Weiyi and Gui, Jiang",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning Musical Representations for Music Performance Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Music performances are representative scenarios for audio-visual modeling. Unlike common scenarios with sparse audio, music performances continuously involve dense audio signals throughout. While existing multimodal learning methods on the audio-video QA demonstrate impressive capabilities on general scenarios, they are incapable of dealing with fundamental problems within the music performances: they underexplore the interaction between the multimodal signals in performance, and fail to consider the distinctive characteristics of instruments and music. Therefore, existing methods tend to inaccurately answer questions regarding musical performances. To bridge the above research gaps, first, given the intricate multimodal interconnectivity inherent to music data, our primary backbone is designed to incorporate multimodal interactions within the context of music; second, to enable the model to learn music characteristics, we annotate and release rhythmic and music sources in the current music datasets; third, for time-aware audio-visual modelling, we align the model\u2019s music predictions with the temporal dimension. Our experiments show state-of-the-art effects on the Music AVQA datasets. Our code is available at: https://github.com/xid32/Amuse.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.159",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Transfer Learning for Text Classification via Model Risk Analysis": {
        "type": "INPROCEEDINGS",
        "key": "sun-etal-2024-transfer",
        "author": "Sun, Yujie and Fan, Chuyi and Chen, Qun",
        "booktitle": "EMNLP-findings2024",
        "title": "Transfer Learning for Text Classification via Model Risk Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "It has been well recognized that text classification can be satisfactorily performed by Deep Neural Network (DNN) models, provided that there are sufficient in-distribution training data. However, in the presence of distribution drift, a well trained DNN model may not perform well on a new dataset even though class labels are aligned between training and target datasets. To alleviate this limitation, we propose a novel approach based on model risk analysis to adapt a pre-trained DNN model towards a new dataset given only a small set of representative data. We first present a solution of model risk analysis for text classification, which can effectively quantify misprediction risk of a classifier on a dataset. Built upon the existing framework of LearnRisk, the proposed solution, denoted by LearnRisk-TC, first generates interpretable risk features, then constructs a risk model by aggregating these features, and finally trains the risk model on a small set of labeled data. Furthermore, we present a transfer learning solution based on model risk analysis, which can effectively fine-tune a pre-trained model toward a target dataset by minimizing its misprediction risk. We have conducted extensive experiments on real datasets. Our experimental results show that the proposed solution performs considerably better than the existing alternative approaches. By using text classification as a test case, we demonstrate the potential applicability of risk-based transfer learning to various challenging NLP tasks. Our codes are available at https://github.com/syjcomputer/LRTC.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.160",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Typos that Broke the RAG\u2019s Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations": {
        "type": "INPROCEEDINGS",
        "key": "cho-etal-2024-typos",
        "author": "Cho, Sukmin and Jeong, Soyeong and Seo, Jeongyeon and Hwang, Taeho and Park, Jong C.",
        "booktitle": "EMNLP-findings2024",
        "title": "Typos that Broke the RAG\u2019s Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The robustness of recent Large Language Models (LLMs) has become increasingly crucial as their applicability expands across various domains and real-world applications. Retrieval-Augmented Generation (RAG) is a promising solution for addressing the limitations of LLMs, yet existing studies on the robustness of RAG often overlook the interconnected relationships between RAG components or the potential threats prevalent in real-world databases, such as minor textual errors. In this work, we investigate two underexplored aspects when assessing the robustness of RAG: 1) vulnerability to noisy documents through low-level perturbations and 2) a holistic evaluation of RAG robustness. Furthermore, we introduce a novel attack method, the Genetic Attack on RAG (GARAG), which targets these aspects. Specifically, GARAG is designed to reveal vulnerabilities within each component and test the overall system functionality against noisy documents. We validate RAG robustness by applying our GARAG to standard QA datasets, incorporating diverse retrievers and LLMs. The experimental results show that GARAG consistently achieves high attack success rates. Also, it significantly devastates the performance of each component and their synergy, highlighting the substantial risk that minor textual inaccuracies pose in disrupting RAG systems in the real world. Code is available at https://github.com/zomss/GARAG.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.161",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Temporal Modeling of Video LLMs via Time Gating": {
        "type": "INPROCEEDINGS",
        "key": "hu-etal-2024-enhancing",
        "author": "Hu, Zi-Yuan and Zhong, Yiwu and Huang, Shijia and Lyu, Michael and Wang, Liwei",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Temporal Modeling of Video LLMs via Time Gating",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Video Large Language Models (Video LLMs) have achieved impressive performance on video-and-language tasks, such as video question answering. However, most existing Video LLMs neglect temporal information in video data, leading to struggles with temporal-aware video understanding. To address this gap, we propose a Time Gating Video LLM (TG-Vid) designed to enhance temporal modeling through a novel Time Gating module (TG). The TG module employs a time gating mechanism on its sub-modules, comprising gating spatial attention, gating temporal attention, and gating MLP. This architecture enables our model to achieve a robust understanding of temporal information within videos. Extensive evaluation of temporal-sensitive video benchmarks (i.e., MVBench, TempCompass, and NExT-QA) demonstrates that our TG-Vid model significantly outperforms the existing Video LLMs. Further, comprehensive ablation studies validate that the performance gains are attributed to the designs of our TG module. Our code is available at https://github.com/LaVi-Lab/TG-Vid.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.162",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-alignedcot",
        "author": "Yang, Zhicheng and Huang, Yinya and Xiong, Jing and Feng, Liang and Liang, Xiaodan and Wang, Yiwei and Tang, Jing",
        "booktitle": "EMNLP-findings2024",
        "title": "AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models prompting, such as using in-context demonstrations, is a mainstream technique for invoking LLMs to perform high-performance and solid complex reasoning (e.g., mathematical reasoning, commonsense reasoning), and has the potential for further human-machine collaborative scientific findings. However, current LLMs are delicate and elusive in prompt words and styles. And there is an unseen gap between LLM understanding and human-written prompts. This paper introduces AlignedCoT, an LLM-acquainted prompting technique that includes proficient \u201cnative-speaking\u201d in in-context learning for the LLMs. Specifically, it achieves consistent and correct step-wise prompts in zero-shot scenarios by progressively probing, refining, and formatting the LLM chain of thoughts so that free from handcrafted few-shot demonstrations while maintaining the prompt quality. We conduct experiments on mathematical reasoning and commonsense reasoning. We find that LLMs with AlignedCoT perform significantly superior to them with human-crafted demonstrations. We further apply AlignedCoT for rewriting the GSM8k training set, resulting in a GSM8k-Align dataset. We observe its benefits for retrieval augmented generation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.163",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On the Empirical Complexity of Reasoning and Planning in LLMs": {
        "type": "INPROCEEDINGS",
        "key": "kang-etal-2024-empirical",
        "author": "Kang, Liwei and Zhao, Zirui and Hsu, David and Lee, Wee Sun",
        "booktitle": "EMNLP-findings2024",
        "title": "On the Empirical Complexity of Reasoning and Planning in LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Chain-of-thought (CoT), tree-of-thought (ToT), and related techniques work surprisingly well in practice for some complex reasoning tasks with Large Language Models (LLMs), but why? This work seeks the underlying reasons by conducting experimental case studies and linking the performance benefits to well-established sample and computational complexity principles in machine learning. We experimented with six reasoning tasks, ranging from grade school math, air travel planning, ..., to Blocksworld. The results suggest that (i) both CoT and ToT benefit significantly from task decomposition, which breaks a complex reasoning task into a sequence of steps with low sample complexity and explicitly outlines the reasoning structure; (ii) for computationally hard reasoning tasks, the more sophisticated tree structure of ToT outperforms the linear structure of CoT; (iii) explicitly annotating important variables is important for good performance. These findings provide useful guidelines for using LLM in solving reasoning tasks in practice.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.164",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning from Mistakes: Iterative Prompt Relabeling for Text-to-Image Diffusion Model Training": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-learning-mistakes",
        "author": "Chen, Xinyan and Ge, Jiaxin and Zhang, Tianjun and Liu, Jiaming and Zhang, Shanghang",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning from Mistakes: Iterative Prompt Relabeling for Text-to-Image Diffusion Model Training",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Diffusion models have shown impressive performance in many domains. However, the model\u2019s capability to follow natural language instructions (e.g., spatial relationships between objects, generating complex scenes) is still unsatisfactory. In this work, we propose Iterative Prompt Relabeling (IPR), a novel algorithm that aligns images to text through iterative image sampling and prompt relabeling with feedback. IPR first samples a batch of images conditioned on the text, then relabels the text prompts of unmatched text-image pairs with classifier feedback. We conduct thorough experiments on SDv2 and SDXL, testing their capability to follow instructions on spatial relations. With IPR, we improved up to 15.22% (absolute improvement) on the challenging spatial relation VISOR benchmark, demonstrating superior performance compared to previous RL methods. Our code is publicly available at https://github.com/cxy000000/IPR-RLDF.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.165",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Are modern neural ASR architectures robust for polysynthetic languages?": {
        "type": "INPROCEEDINGS",
        "key": "le-ferrand-etal-2024-modern",
        "author": "Le Ferrand, Eric and Liu, Zoey and Arppe, Antti and Prud\u2019hommeaux, Emily",
        "booktitle": "EMNLP-findings2024",
        "title": "Are modern neural ASR architectures robust for polysynthetic languages?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automatic speech recognition (ASR) technology is frequently proposed as a means of preservation and documentation of endangered languages, with promising results thus far. Among the endangered languages spoken today, a significant number exhibit complex morphology. The models employed in contemporary language documentation pipelines that utilize ASR, however, are predominantly based on isolating or inflectional languages, often from the Indo-European family. This raises a critical concern: building models exclusively on such languages may introduce a bias, resulting in better performance with simpler morphological structures. In this paper, we investigate the performance of modern ASR architectures on morphologically complex languages. Results indicate that modern ASR architectures appear less robust in managing high OOV rates for morphologically complex languages in terms of word error rate, while character error rates are consistently higher for isolating languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.166",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Notion of Complexity for Theory of Mind via Discrete World Models": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-notion",
        "author": "Huang, X. Angelo and La Malfa, Emanuele and Marro, Samuele and Asperti, Andrea and Cohn, Anthony G. and Wooldridge, Michael J.",
        "booktitle": "EMNLP-findings2024",
        "title": "A Notion of Complexity for Theory of Mind via Discrete World Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Theory of Mind (ToM) can be used to assess the capabilities of Large Language Models (LLMs) in complex scenarios where social reasoning is required. While the research community has proposed many ToM benchmarks, their hardness varies greatly, and their complexity is not well defined. This work proposes a framework inspired by cognitive load theory to measure the complexity of ToM tasks. We quantify a problem\u2019s complexity as the number of states necessary to solve it correctly. Our complexity measure also accounts for spurious states of a ToM problem designed to make it apparently harder. We use our method to assess the complexity of five widely adopted ToM benchmarks. On top of this framework, we design a prompting technique that augments the information available to a model with a description of how the environment changes with the agents\u2019 interactions. We name this technique Discrete World Models (DWM) and show how it elicits superior performance on ToM tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.167",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning Dynamic Multi-attribute Interest for Personalized Product Search": {
        "type": "INPROCEEDINGS",
        "key": "bai-etal-2024-learning",
        "author": "Bai, Yutong and Dou, Zhicheng and Wen, Ji-Rong",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning Dynamic Multi-attribute Interest for Personalized Product Search",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Personalized product search aims to learn personalized preferences from search logs and adjust the ranking lists returned by engines. Previous studies have extensively explored excavating valuable features to build accurate interest profiles. However, they overlook that the user\u2019s attention varies on product attributes(e.g., brand, category). Users may especially prefer specific attributes or switch their preferences between attributes dynamically. Instead, existing approaches mix up all attribute features and let the model automatically extract useful ones from rather complex scenarios. To solve this problem, in this paper, we propose a dynamic multi-attribute interest learning model to tackle the influences from attributes to user interests. Specifically, we design two interest profiling modules: attribute-centered and attribute-aware profiling. The former focuses on capturing the user\u2019s preferences on a single attribute, while the latter focuses on addressing the interests correlated with multi-attribute within the search history. Besides, we devise a dynamic contribution weights strategy that sends explicit signals to the model to determine the impacts of different attributes better. Experimental results on large-scale datasets illustrate that our model significantly improves the results of existing methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.168",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evaluating Automatic Metrics with Incremental Machine Translation Systems": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-evaluating-automatic",
        "author": "Wu, Guojun and Cohen, Shay B. and Sennrich, Rico",
        "booktitle": "EMNLP-findings2024",
        "title": "Evaluating Automatic Metrics with Incremental Machine Translation Systems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We introduce a dataset comprising commercial machine translations, gathered weekly over six years across 12 translation directions. Since human A/B testing is commonly used, we assume commercial systems improve over time, which enables us to evaluate machine translation (MT) metrics based on their preference for more recent translations. Our study not only confirms several prior findings, such as the advantage of neural metrics over non-neural ones, but also explores the debated issue of how MT quality affects metric reliability\u2014an investigation that smaller datasets in previous research could not sufficiently explore. Overall, our research demonstrates the dataset\u2019s value as a testbed for metric evaluation. We release our code.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.169",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-llm",
        "author": "Lee, Yujeong and Shin, Sangwoo and Park, Wei-Jin and Woo, Honguk",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Employing large language models (LLMs) to enable embodied agents has become popular, yet it presents several limitations in practice. In this work, rather than using LLMs directly as agents, we explore their use as tools for embodied agent learning. Specifically, to train separate agents via offline reinforcement learning (RL), an LLM is used to provide dense reward feedback on individual actions in training datasets. In doing so, we present a consistency-guided reward ensemble framework (CoREN), designed for tackling difficulties in grounding LLM-generated estimates to the target environment domain. The framework employs an adaptive ensemble of spatio-temporally consistent rewards to derive domain-grounded rewards in the training datasets, thus enabling effective offline learning of embodied agents in different environment domains. Experiments with the VirtualHome benchmark demonstrate that CoREN significantly outperforms other offline RL agents, and it also achieves comparable performance to state-of-the-art LLM-based agents with 8B parameters, despite CoREN having only 117M parameters for the agent policy network and using LLMs only for training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.170",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-Renewal Prompt Optimizing with Implicit Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "liang-etal-2024-self",
        "author": "Liang, Zihan and Chen, Ben and Ran, Zhuoran and Wang, Zihan and Dai, Huangyu and Ma, Yufei and Gao, Dehong and Cai, Xiaoyan and Yang, Libin",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-Renewal Prompt Optimizing with Implicit Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The effectiveness of Large Language Models (LLMs) relies on their capacity to understand instructions and generate human-like responses. However, aligning LLMs with complex human preferences remains a significant challenge due to the potential misinterpretation of user prompts. Current methods for aligning LLM behaviors fall into two categories: output optimization (such as RLHF, RLAIF, and DPO) and input optimization (like OPRO and BPO). While both approaches aim to guide LLMs towards generating responses that align with desired objectives, the labor-intensive and intentions-inconsistent data annotation, as well as the strict and tedious training supervision, make them struggle to yield optimal results across all models. To address these shortcomings, we introduce a novel self-renewal approach called Prompt Optimization with Implicit Reasoning (POIR). It consists of two key components: 1) a model-specific and self-recirculating data collection method that leverages self-evaluation to enhance prompts in accordance with the model\u2019s intrinsic logits, and 2) a prompt rewrite schema that injects implicit reasoning for direct preference learning. Through self-renewal optimization, POIR refines LLM outputs to better align with human preferences across various LLMs and tasks, without relying on supervised fine-tuning. Extensive experiments on a range of LLMs and tasks demonstrate POIR\u2019s superior performance. We believe this advancement offers a novel paradigm for developing LLMs that are more attuned to user intentions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.171",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-ruler",
        "author": "Li, Jiaming and Zhang, Lei and Li, Yunshui and Liu, Ziqiang and Bai, Yuelin and Luo, Run and Chen, Longze and Yang, Min",
        "booktitle": "EMNLP-findings2024",
        "title": "Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The instruction-following ability of large language models enables humans to interact with AI agents in a natural way. However, when required to generate responses of a specific length, large language models often struggle to meet users\u2019 needs due to their inherent difficulty in accurately perceiving numerical constraints. To explore the ability of large language models to control the length of generated responses, we propose the Target Length Generation Task (TLG) and design two metrics, Precise Match (PM) and Flexible Match (FM) to evaluate the model\u2019s performance in adhering to specified response lengths. Furthermore, we introduce a novel, model-agnostic approach called Ruler, which employs Meta Length Tokens (MLTs) to enhance the instruction-following ability of large language models under length-constrained instructions. Specifically, Ruler equips LLMs with the ability to generate responses of a specified length based on length constraints within the instructions. Moreover, Ruler can automatically generate appropriate MLT when length constraints are not explicitly provided, demonstrating excellent versatility and generalization. Comprehensive experiments show the effectiveness of Ruler across different LLMs on Target Length Generation Task, e.g., at All Level 27.97 average gain on PM, 29.57 average gain on FM. In addition, we conduct extensive ablation experiments to further substantiate the efficacy and generalization of Ruler. Our code and data is available on the internet.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.172",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling": {
        "type": "INPROCEEDINGS",
        "key": "pikuliak-etal-2024-women",
        "author": "Pikuliak, Mat\u00fa\u0161 and Oresko, Stefan and Hrckova, Andrea and Simko, Marian",
        "booktitle": "EMNLP-findings2024",
        "title": "Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We present GEST \u2013 a new manually created dataset designed to measure gender-stereotypical reasoning in language models and machine translation systems. GEST contains samples for 16 gender stereotypes about men and women (e.g., Women are beautiful, Men are leaders) that are compatible with the English language and 9 Slavic languages. The definition of said stereotypes was informed by gender experts. We used GEST to evaluate English and Slavic masked LMs, English generative LMs, and machine translation systems. We discovered significant and consistent amounts of gender-stereotypical reasoning in almost all the evaluated models and languages. Our experiments confirm the previously postulated hypothesis that the larger the model, the more stereotypical it usually is.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.173",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Recent Trends in Linear Text Segmentation: A Survey": {
        "type": "INPROCEEDINGS",
        "key": "ghinassi-etal-2024-recent",
        "author": "Ghinassi, Iacopo and Wang, Lin and Newell, Chris and Purver, Matthew",
        "booktitle": "EMNLP-findings2024",
        "title": "Recent Trends in Linear Text Segmentation: A Survey",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Linear Text Segmentation is the task of automatically tagging text documents with topic shifts, i.e. the places in the text where the topics change. A well-established area of research in Natural Language Processing, drawing from well-understood concepts in linguistic and computational linguistic research, the field has recently seen a lot of interest as a result of the surge of text, video, and audio available on the web, which in turn require ways of summarising and categorizing the mole of content for which linear text segmentation is a fundamental step. In this survey, we provide an extensive overview of current advances in linear text segmentation, describing the state of the art in terms of resources and approaches for the task. Finally, we highlight the limitations of available resources and of the task itself, while indicating ways forward based on the most recent literature and under-explored research directions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.174",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding": {
        "type": "INPROCEEDINGS",
        "key": "hu-etal-2024-mplug",
        "author": "Hu, Anwen and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Zhang, Liang and Zhang, Bo and Zhang, Ji and Jin, Qin and Huang, Fei and Zhou, Jingren",
        "booktitle": "EMNLP-findings2024",
        "title": "mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Structure information is critical for understanding the semantics of text-rich images, such as documents, tables, and charts. Existing Multimodal Large Language Models (MLLMs) for Visual Document Understanding are equipped with text recognition ability but lack general structure understanding abilities for text-rich document images. In this work, we emphasize the importance of structure information in Visual Document Understanding and propose Unified Structure Learning to boost the performance of MLLMs. Based on publicly available text-rich images, we build a comprehensive training set DocStruct4M to support structure-aware parsing tasks and multi-grained text localization tasks across 5 domains: document, webpage, table, chart, and natural image. To better encode structure information, we design a simple and effective vision-to-text module H-Reducer, which can not only maintain the layout information but also reduce the length of visual features by merging horizontal adjacent patches through convolution, enabling the LLM to understand high-resolution images more efficiently. Our model DocOwl 1.5 achieves state-of-the-art performance on 10 visual document understanding benchmarks. All codes, models, and datasets are publicly available at https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/DocOwl1.5.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.175",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring Question Guidance and Answer Calibration for Visually Grounded Video Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-exploring-question",
        "author": "Xu, Yuanxing and Wei, Yuting and Zhong, Shuai and Chen, Xinming and Qi, Jinsheng and Wu, Bin",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring Question Guidance and Answer Calibration for Visually Grounded Video Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Video Question Answering (VideoQA) tasks require not only correct answers but also visual evidence. The \u201clocalize-then-answer\u201d strategy, while enhancing accuracy and interpretability, faces challenges due to the lack of temporal localization labels in VideoQA datasets. Existing methods often train the models\u2019 localization capabilities indirectly using QA labels, leading to inaccurate localization. Moreover, our experiments show that despite high accuracy, current models depend too heavily on language shortcuts or spurious correlations with irrelevant visual context. To address these issues, we propose a Question-Guided and Answer-Calibrated TRansformer (QGAC-TR), which guides and calibrates localization using question and option texts without localization labels. Furthermore, we design two self-supervised learning tasks to further enhance the model\u2019s refined localization capabilities. Extensive experiments on three public datasets focused on temporal and causal reasoning show that our model not only achieves accuracy comparable to large-scale pretrained models but also leads in localization aspects. Code will be available on GitHub.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.176",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LoRAN: Improved Low-Rank Adaptation by a Non-Linear Transformation": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-loran",
        "author": "Li, Yinqiao and Song, Linqi and Hou, Hanxu",
        "booktitle": "EMNLP-findings2024",
        "title": "LoRAN: Improved Low-Rank Adaptation by a Non-Linear Transformation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we study parameter-efficient fine-tuning methods for large pre-trained models. Specifically, we improve LoRA approaches to alleviate the performance loss from the constrained adapter by introducing a non-linear transformation (call it LoRAN). For a better adaptation, we also design a new non-linear function to appropriately fit the accumulated weight updates. We test our method in multiple advanced large language models. Experimental results show that our LoRAN significantly outperforms a strong baseline on SAMSum and 20 Newsgroups tasks. Moreover, when a lower rank is applied, our approach even yields a 1.95-point improvement in the classification task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.177",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Models are Limited in Out-of-Context Knowledge Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "hu-etal-2024-large",
        "author": "Hu, Peng and Gao, Changjiang and Gao, Ruiqi and Chen, Jiajun and Huang, Shujian",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Models are Limited in Out-of-Context Knowledge Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) possess extensive knowledge and strong capabilities in performing in-context reasoning. However, previous work challenges their out-of-context reasoning ability, i.e., the ability to infer information from their training data, instead of from the context or prompt. This paper focuses on a significant aspect of out-of-context reasoning: Out-of-Context Knowledge Reasoning (OCKR), which is to combine multiple knowledge to infer new knowledge. We designed a synthetic dataset with seven representative OCKR tasks to systematically assess the OCKR capabilities of LLMs. Using this dataset, we evaluated several LLMs and discovered that their proficiency in this aspect is limited, regardless of whether the knowledge is trained in a separate or adjacent training settings. Moreover, training the model to reason with reasoning examples does not result in significant improvement, while training the model to perform explicit knowledge retrieval helps for retrieving attribute knowledge but not the relation knowledge, indicating that the model\u2019s limited OCKR capabilities are due to difficulties in knowledge retrieval. Furthermore, we treat cross-lingual knowledge transfer as a distinct form of OCKR, and evaluate this ability. Our results show that the evaluated model also exhibits limited ability in transferring knowledge across languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.178",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks": {
        "type": "INPROCEEDINGS",
        "key": "zeng-etal-2024-bikt",
        "author": "Zeng, Hang and Niu, Chaoyue and Wu, Fan and Tang, Shaojie and Pei, Leihao and Lv, Chengfei and Chen, Guihai",
        "booktitle": "EMNLP-findings2024",
        "title": "BiKT: Enabling Bidirectional Knowledge Transfer Between Pretrained Models and Sequential Downstream Tasks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Adapting pretrained models to downstream tasks is important in practical applications. Existing frameworks adapt from an initial pretrained model to each downstream task directly, but ignore the sequential nature of the downstream tasks and their feedback effect on the pretrained model. In this work, we propose a new framework, called BiKT, to enable bidirectional knowledge transfer between pretrained models and downstream tasks in rounds. We model each downstream task in the current round as a target task for adaptation and treat all the tasks in the previous rounds as source tasks for feedback. We design a feedback algorithm by multi-task learning over the labeled data of the source tasks, where task-specific prompts are plugged into the backbone network for decoupling task-exclusive knowledge from task-shared knowledge. We further utilize the good initiation of the new backbone network updated in the feedback phase and the trained prompts of the source tasks for adaptation. Evaluation over 9 GLUE datasets, 6 SuperGLUE datasets, and 8 other datasets using models with different pretraining levels and different parameter scales shows remarkable improvement in full-shot and few-shot adaptation settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.179",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-double",
        "author": "Chen, Wei and Zhao, Lili and Zheng, Zhi and Xu, Tong and Wang, Yang and Chen, Enhong",
        "booktitle": "EMNLP-findings2024",
        "title": "Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, few-shot Named Entity Recognition (NER) has attracted significant attention due to the high cost of obtaining high-quality labeled data. Decomposition-based methods have demonstrated remarkable performance on this task, which initially train a type-independent span detector and subsequently classify the detected spans based on their types. However, this framework has an evident drawback as a domain-agnostic detector cannot ensure the identification of only those entity spans that are specific to the target domain. To address this issue, we propose Double-Checker, which leverages collaboration between Large Language Models (LLMs) and small models. Specifically, we employ LLMs to verify candidate spans predicted by the small model and eliminate any spans that fall outside the scope of the target domain. Extensive experiments validate the effectiveness of our method, consistently yielding improvements over two baseline approaches. Our code is available at https://github.com/fanshu6hao/Double-Checker.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.180",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Scaling Sentence Embeddings with Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "jiang-etal-2024-scaling",
        "author": "Jiang, Ting and Huang, Shaohan and Luan, Zhongzhi and Wang, Deqing and Zhuang, Fuzhen",
        "booktitle": "EMNLP-findings2024",
        "title": "Scaling Sentence Embeddings with Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have recently gained significant interest due to their impressive results in various natural language tasks. However, their application to sentence embeddings is still under active research. In this work, we introduce PromptEOL, a simple and efficient method designed to enhance LLM performance on sentence embeddings with a one-word limitation. We further integrate PromptEOL with in-context learning and alignment to leverage LLMs in two settings: without fine-tuning and with fine-tuning. Our extensive experiments show that PromptEOL enables LLMs to generate superior sentence embeddings without fine-tuning, outperforming contrastive learning methods. Additionally, with fine-tuning, a 2.7B parameter model using PromptEOL surpasses the performance of a 4.8B parameter model from previous methods. We also analyze how scaling model parameters, from 125 million to 66 billion, impacts sentence embedding performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.181",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring the Relationship between In-Context Learning and Instruction Tuning": {
        "type": "INPROCEEDINGS",
        "key": "duan-etal-2024-exploring",
        "author": "Duan, Hanyu and Tang, Yixuan and Yang, Yi and Abbasi, Ahmed and Tam, Kar Yan",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring the Relationship between In-Context Learning and Instruction Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In-Context Learning (ICL) and Instruction Tuning (IT) are two primary paradigms of adopting Large Language Models (LLMs) to downstream applications. However, they are significantly different. In ICL, a set of demonstrations is provided at the inference time, but the LLM\u2019s parameters are not updated. In IT, a set of demonstrations is used to adjust the parameters of the LLM during training, but no demonstrations are provided at the inference time. Although a growing body of literature has explored ICL and IT, studies on these topics have largely been conducted in isolation, leading to a disconnect between these two paradigms. In this work, we explore the relationship between ICL and IT by examining how the hidden states of LLMs change in these two paradigms. Through carefully designed experiments conducted with LLaMA-2 and LLaMA-2-Chat (7B and 13B), we find that ICL and IT converge in LLM hidden states despite their apparent differences in implementation. Specifically, ICL changes an LLM\u2019s hidden states as if its accompanying demonstrations were used to instructionally tune the model. Furthermore, the convergence between ICL and IT is largely contingent upon several factors related to the demonstration. Overall, this work offers a unique perspective to explore the connection between ICL and IT and sheds light on understanding the behaviors of LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.182",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-granular",
        "author": "Wang, Ziqi and Zhu, Chen and Zheng, Zhi and Li, Xinhang and Xu, Tong and He, Yongyi and Liu, Qi and Yu, Ying and Chen, Enhong",
        "booktitle": "EMNLP-findings2024",
        "title": "Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal Named Entity Recognition and Grounding (MNERG) aims to extract paired textual and visual entities from texts and images. It has been well explored through a two-step paradigm: initially identifying potential visual entities using object detection methods and then aligning the extracted textual entities with their corresponding visual entities. However, when it comes to fine-grained MNERG, the long-tailed distribution of textual entity categories and the performance of object detectors limit the effectiveness of traditional methods. Specifically, more detailed classification leads to many low-frequency categories, and existing object detection methods often fail to pinpoint subtle regions within images. To address these challenges, we propose the Granular Entity Mapper (GEM) framework. Firstly, we design a multi-granularity entity recognition module, followed by a reranking module based on the Multimodal Large Language Model (MLLM) to incorporate hierarchical information of entity categories, visual cues, and external textual resources collectively for accurate fine-grained textual entity recognition. Then, we utilize a pre-trained Large Visual Language Model (LVLM) as an implicit visual entity grounder that directly deduces relevant visual entity regions from the entire image without the need for bounding box training. Experimental results on the GMNER and FMNERG datasets demonstrate that our GEM framework achieves state-of-the-art results on the fine-grained content extraction task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.183",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-jobfair",
        "author": "Wang, Ze and Wu, Zekun and Guan, Xin and Thaler, Michael and Koshiyama, Adriano and Lu, Skylar and Beepath, Sachin and Ertekin, Ediz and Perez-Ortiz, Maria",
        "booktitle": "EMNLP-findings2024",
        "title": "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The use of Large Language Models (LLMs) in hiring has led to legislative actions to protect vulnerable demographic groups. This paper presents a novel framework for benchmarking hierarchical gender hiring bias in Large Language Models (LLMs) for resume scoring, revealing significant issues of reverse gender hiring bias and overdebiasing. Our contributions are fourfold: Firstly, we introduce a new construct grounded in labour economics, legal principles, and critiques of current bias benchmarks: hiring bias can be categorized into two types: Level bias (difference in the average outcomes between demographic counterfactual groups) and Spread bias (difference in the variance of outcomes between demographic counterfactual groups); Level bias can be further subdivided into statistical bias (i.e. changing with non-demographic content) and taste-based bias (i.e. consistent regardless of non-demographic content). Secondly, the framework includes rigorous statistical and computational hiring bias metrics, such as Rank After Scoring (RAS), Rank-based Impact Ratio, Permutation Test, and Fixed Effects Model. Thirdly, we analyze gender hiring biases in ten state-of-the-art LLMs. Seven out of ten LLMs show significant biases against males in at least one industry. An industry-effect regression reveals that the healthcare industry is the most biased against males. Moreover, we found that the bias performance remains invariant with resume content for eight out of ten LLMs. This indicates that the bias performance measured in this paper might apply to other resume datasets with different resume qualities. Fourthly, we provide a user-friendly demo and resume dataset to support the adoption and practical use of the framework, which can be generalized to other social traits and tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.184",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation": {
        "type": "INPROCEEDINGS",
        "key": "dai-etal-2024-contrastive",
        "author": "Dai, Huangyu and Chen, Ben and Chen, Kaidi and Han, Ying and Liang, Zihan and Jiang, Wen",
        "booktitle": "EMNLP-findings2024",
        "title": "Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "For crosslingual conversation and trade, Neural Machine Translation (NMT) is pivotal yet faces persistent challenges with monotony and repetition in generated content. Traditional solutions that rely on penalizing text redundancy or token reoccurrence have shown limited efficacy, particularly for lengthy article and e-commerce descriptions with inherent redundancy, even with the advent of Large Language Models (LLMs). This paper investigates the underlying causes of textual repetition through the lens of information entropy, attributing the phenomenon to the elevated uncertainty within the input text. To address this, a novel algorithm named Contrastive Token Learning with Similarity Decay (CTSD) is introduced, which modulates the suppression of tokens dynamically, informed by varying attention weights and inter-token distances. Furthermore, an e-commerce dataset comprised of title texts of online real items is compiled and released susceptible to hallucination translations to benchmark the algorithm. Extensive evaluations demonstrate that CTSD significantly outperforms existing approaches in precision and generalizability. Additional online A/B testing underscores its practical value, showing marked improvements in user engagement and conversion. Notably, this method has been implemented with full traffic on eight multilingual sites of alibaba.com, the largest B2B e-commerce platform in the world.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.185",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Psycholinguistic Evaluation of Language Models\u2019 Sensitivity to Argument Roles": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-psycholinguistic",
        "author": "Lee, Eun-Kyoung Rosa and Nair, Sathvik and Feldman, Naomi",
        "booktitle": "EMNLP-findings2024",
        "title": "A Psycholinguistic Evaluation of Language Models\u2019 Sensitivity to Argument Roles",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.186",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Tending Towards Stability: Convergence Challenges in Small Language Models": {
        "type": "INPROCEEDINGS",
        "key": "diehl-martinez-etal-2024-tending",
        "author": "Diehl Martinez, Richard and Lesci, Pietro and Buttery, Paula",
        "booktitle": "EMNLP-findings2024",
        "title": "Tending Towards Stability: Convergence Challenges in Small Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Increasing the number of parameters in language models is a common strategy to enhance their performance. However, smaller language models remain valuable due to their lower operational costs. Despite their advantages, smaller models frequently underperform compared to their larger counterparts, even when provided with equivalent data and computational resources. Specifically, their performance tends to degrade in the late pretraining phase. This is anecdotally attributed to their reduced representational capacity. Yet, the exact causes of this performance degradation remain unclear. We use the Pythia model suite to analyse the training dynamics that underlie this phenomenon. Across different model sizes, we investigate the convergence of the Attention and MLP activations to their final state and examine how the effective rank of their parameters influences this process. We find that nearly all layers in larger models stabilise early in training - within the first 20% - whereas layers in smaller models exhibit slower and less stable convergence, especially when their parameters have lower effective rank. By linking the convergence of layers\u2019 activations to their parameters\u2019 effective rank, our analyses can guide future work to address inefficiencies in the learning dynamics of small models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.187",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-multitude",
        "author": "Li, Rui and Wang, Peiyi and Ma, Jingyuan and Zhang, Di and Sha, Lei and Sui, Zhifang",
        "booktitle": "EMNLP-findings2024",
        "title": "Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have gained increasing attention for their remarkable capacity, alongside concerns about safety arising from their potential to produce harmful content. Red teaming aims to find prompts that could elicit harmful responses from LLMs, and is essential to discover and mitigate safety risks before real-world deployment. However, manual red teaming is both time-consuming and expensive, rendering it unscalable. In this paper, we propose RTPE, a scalable evolution framework to evolve red teaming prompts across both breadth and depth dimensions, facilitating the automatic generation of numerous high-quality and diverse red teaming prompts. Specifically, in-breadth evolving employs a novel enhanced in-context learning method to create a multitude of quality prompts, whereas in-depth evolving applies customized transformation operations to enhance both content and form of prompts, thereby increasing diversity. Extensive experiments demonstrate that RTPE surpasses existing representative automatic red teaming methods on both attack success rate and diversity. In addition, based on 4,800 red teaming prompts created by RTPE, we further provide a systematic analysis of 8 representative LLMs across 8 sensitive topics.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.188",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Modeling News Interactions and Influence for Financial Market Prediction": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-modeling",
        "author": "Wang, Mengyu and Cohen, Shay B. and Ma, Tiejun",
        "booktitle": "EMNLP-findings2024",
        "title": "Modeling News Interactions and Influence for Financial Market Prediction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The diffusion of financial news into market prices is a complex process, making it challenging to evaluate the connections between news events and market movements. This paper introduces FININ (Financial Interconnected News Influence Network), a novel market prediction model that captures not only the links between news and prices but also the interactions among news items themselves. FININ effectively integrates multi-modal information from both market data and news articles. We conduct extensive experiments on two datasets, encompassing the S&amp;P 500 and NASDAQ 100 indices over a 15-year period and over 2.7 million news articles. The results demonstrate FININ\u2019s effectiveness, outperforming advanced market prediction models with an improvement of 0.429 and 0.341 in the daily Sharpe ratio for the two markets respectively. Moreover, our results reveal insights into the financial news, including the delayed market pricing of news, the long memory effect of news, and the limitations of financial sentiment analysis in fully extracting predictive power from news data.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.189",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation": {
        "type": "INPROCEEDINGS",
        "key": "zhou-etal-2024-multi",
        "author": "Zhou, Yuhang and Zhu, Jing and Xu, Paiheng and Liu, Xiaoyu and Wang, Xiyao and Koutra, Danai and Ai, Wei and Huang, Furong",
        "booktitle": "EMNLP-findings2024",
        "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have significantly advanced various natural language processing tasks, but deploying them remains computationally expensive. Knowledge distillation (KD) is a promising solution, enabling the transfer of capabilities from larger teacher LLMs to more compact student models. Particularly, sequence-level KD, which distills rationale-based reasoning processes instead of merely final outcomes, shows great potential in enhancing students\u2019 reasoning capabilities. However, current methods struggle with sequence-level KD under long-tailed data distributions, adversely affecting generalization on sparsely represented domains. We introduce the Multi-Stage Balanced Distillation (BalDistill) framework, which iteratively balances training data within a fixed computational budget. By dynamically selecting representative head domain examples and synthesizing tail domain examples, BalDistill achieves state-of-the-art performance across diverse long-tailed datasets, enhancing both the efficiency and efficacy of the distilled models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.190",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "islam-etal-2024-large",
        "author": "Islam, Mohammed Saidul and Rahman, Raian and Masry, Ahmed and Laskar, Md Tahmid Rahman and Nayeem, Mir Tafseer and Hoque, Enamul",
        "booktitle": "EMNLP-findings2024",
        "title": "Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Natural language is a powerful complementary modality of communication for data visualizations, such as bar and line charts. To facilitate chart-based reasoning using natural language, various downstream tasks have been introduced recently such as chart question answering, chart summarization, and fact-checking with charts. These tasks pose a unique challenge, demanding both vision-language reasoning and a nuanced understanding of chart data tables, visual encodings, and natural language instructions. Despite the recent success of Large Language Models (LLMs) across diverse NLP tasks, their abilities and limitations in the realm of data visualization remain under-explored, possibly due to their lack of multi-modal capabilities. To bridge the gap, this paper presents one of the first comprehensive evaluations of the recently developed large vision language models (LVLMs) for chart understanding and reasoning tasks. Our evaluation includes a comprehensive assessment of both closed and open-sourced LVLMs across five major chart reasoning tasks. Furthermore, we perform a qualitative evaluation of LVLMs\u2019 performance on a diverse range of charts, aiming to provide a thorough analysis. Our findings reveal that while LVLMs demonstrate impressive abilities in generating fluent texts covering high-level data insights, they also encounter common problems like hallucinations, factual errors, and data bias. We highlight the key strengths and limitations of LVLMs in chart comprehension tasks, offering insights for future research",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.191",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HoneyComb: A Flexible LLM-Based Agent System for Materials Science": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-honeycomb",
        "author": "Zhang, Huan and Song, Yu and Hou, Ziyu and Miret, Santiago and Liu, Bang",
        "booktitle": "EMNLP-findings2024",
        "title": "HoneyComb: A Flexible LLM-Based Agent System for Materials Science",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The emergence of specialized large language models (LLMs) has shown promise in addressing complex tasks in materials science. Many LLMs, however, often struggle with the distinct complexities of materials science tasks, such as computational challenges, and rely heavily on outdated implicit knowledge, leading to inaccuracies and hallucinations. To address these challenges, we introduce HoneyComb, the first LLM-based agent system specifically designed for materials science. HoneyComb leverages a reliable, high-quality materials science knowledge base (MatSciKB) and a sophisticated tool hub (ToolHub) tailored specifically for materials science to enhance its reasoning and computational capabilities. MatSciKB is a curated, structured knowledge collection based on reliable literature, while ToolHub employs an Inductive Tool Construction method to generate, decompose, and refine API tools for materials science. Additionally, HoneyComb leverages a retriever module that adaptively selects the appropriate knowledge source or tools for specific tasks, thereby ensuring accuracy and relevance. Our results demonstrate that HoneyComb significantly outperforms baseline models across various tasks in materials science, effectively bridging the gap between current LLM capabilities and the specialized needs of this domain. Furthermore, our adaptable framework can be easily extended to other scientific domains, highlighting its potential for broad applicability in advancing scientific research and applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.192",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Revealing COVID-19\u2019s Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-revealing",
        "author": "Wang, Zeqiang and Wu, Jiageng and Wang, Yuqi and Xjtlu, Wei Wang and Yang, Jie and Sastry, Nishanth R. and Johnson, Jon and De, Suparna",
        "booktitle": "EMNLP-findings2024",
        "title": "Revealing COVID-19\u2019s Social Dynamics: Diachronic Semantic Analysis of Vaccine and Symptom Discourse on Twitter",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Social media is recognized as an important source for deriving insights into public opinion dynamics and social impacts due to the vast textual data generated daily and the \u2018unconstrained\u2019 behavior of people interacting on these platforms. However, such analyses prove challenging due to the semantic shift phenomenon, where word meanings evolve over time. This paper proposes an unsupervised dynamic word embedding method to capture longitudinal semantic shifts in social media data without predefined anchor words. The method leverages word co-occurrence statistics and dynamic updating to adapt embeddings over time, addressing the challenges of data sparseness, imbalanced distributions, and synergistic semantic effects. Evaluated on a large COVID-19 Twitter dataset, the method reveals semantic evolution patterns of vaccine- and symptom-related entities across different pandemic stages, and their potential correlations with real-world statistics. Our key contributions include the dynamic embedding technique, empirical analysis of COVID-19 semantic shifts, and discussions on enhancing semantic shift modeling for computational social science research. This study enables capturing longitudinal semantic dynamics on social media to understand public discourse and collective phenomena.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.193",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Divide and Conquer: Legal Concept-guided Criminal Court View Generation": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-divide",
        "author": "Xu, Qi and Wei, Xiao and Yu, Hang and Liu, Qian and Fei, Hao",
        "booktitle": "EMNLP-findings2024",
        "title": "Divide and Conquer: Legal Concept-guided Criminal Court View Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The Criminal Court View Generation task aims to produce explanations that inform judicial decisions. This necessitates a nuanced understanding of diverse legal concepts, such as Recidivism, Confess, and Robbery, which often coexist within cases, complicating holistic analysis. However, existing methods mainly rely on the generation capability of language models, without paying enough attention to the important legal concepts.To enhance the precision and depth of such explanations, we introduce Legal Concept-guided Criminal Court Views Generation (LeGen), a three-stage approach designed for iterative reasoning tailored to individual legal constructs.Specifically, in the first stage, we design a decomposer to divide the court views into focused sub-views, each anchored around a distinct legal concept. Next, a concept reasoning module generates targeted rationales by intertwining the deconstructed facts with their corresponding legal frameworks, ensuring contextually relevant interpretations.Finally, a verifier and a generator are employed to align the rationale with the case fact and obtain synthesized comprehensive and legally sound final court views, respectively.We evaluate LeGen by conducting extensive experiments on a real-world dataset and experimental results validate the effectiveness of our proposed model. Our codes are available at https://anonymous.4open.science/r/LeGen-5625.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.194",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Data Diversity Matters for Robust Instruction Tuning": {
        "type": "INPROCEEDINGS",
        "key": "bukharin-etal-2024-data",
        "author": "Bukharin, Alexander and Li, Shiyang and Wang, Zhengyang and Yang, Jingfeng and Yin, Bing and Li, Xian and Zhang, Chao and Zhao, Tuo and Jiang, Haoming",
        "booktitle": "EMNLP-findings2024",
        "title": "Data Diversity Matters for Robust Instruction Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent works have shown that by curating high quality and diverse instruction tuning datasets, we can significantly improve instruction-following capabilities. However, creating such datasets is difficult and most works rely on manual curation or proprietary language models. Automatic data curation is difficult as it is still not clear how we can define diversity for instruction tuning, how diversity and quality depend on one other, and how we can optimize dataset quality and diversity. To resolve these issue, we propose a new algorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT provides a simple method to simultaneously control dataset diversity and quality, allowing us to conduct an in-depth study on the effect of diversity and quality on instruction tuning performance. From this study we draw two key insights (1) there is a natural tradeoff between data diversity and quality and (2) increasing data diversity significantly improves the worst case instruction following performance, therefore improving robustness. We validate the performance of QDIT on several large scale instruction tuning datasets, where we find it can substantially improve worst and average case performance compared to quality-driven data selection.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.195",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion": {
        "type": "INPROCEEDINGS",
        "key": "rahmati-sameti-2024-ge2pe",
        "author": "Rahmati, Elnaz and Sameti, Hossein",
        "booktitle": "EMNLP-findings2024",
        "title": "GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Text-to-Speech (TTS) systems have made significant strides, enabling the generation of speech from grapheme sequences. However, for low-resource languages, these models still struggle to produce natural and intelligible speech. Grapheme-to-Phoneme conversion (G2P) addresses this challenge by enhancing the input sequence with phonetic information. Despite these advancements, existing G2P systems face limitations when dealing with Persian texts due to the complexity of Persian transcription. In this study, we focus on enriching resources for the Persian language. To achieve this, we introduce two novel G2P training datasets: one manually labeled and the other machine-generated. These datasets comprise over five million sentences alongside their corresponding phoneme sequences. Additionally, we propose two evaluation datasets tailored for Persian sub-tasks, including Kasre-Ezafe detection, homograph disambiguation, and handling out-of-vocabulary (OOV) words. To tackle the unique challenges of the Persian language, we develop a new sentence-level End-to-End (E2E) model leveraging a two-step training approach, as outlined in our paper, to maximize the impact of manually labeled data. The results show that our model surpasses the state-of-the-art performance by 1.86% in word error rate, 4.03% in Kasre-Ezafe detection recall, and 3.42% in homograph disambiguation accuracy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.196",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Characterizing LLM Abstention Behavior in Science QA with Context Perturbations": {
        "type": "INPROCEEDINGS",
        "key": "wen-etal-2024-characterizing",
        "author": "Wen, Bingbing and Howe, Bill and Wang, Lucy Lu",
        "booktitle": "EMNLP-findings2024",
        "title": "Characterizing LLM Abstention Behavior in Science QA with Context Perturbations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The correct model response in the face of uncertainty is to abstain from answering a question so as not to mislead the user. In this work, we study the ability of LLMs to abstain from answering context-dependent science questions when provided insufficient or incorrect context. We probe model sensitivity in several settings: removing gold context, replacing gold context with irrelevant context, and providing additional context beyond what is given. In experiments on four QA datasets with six LLMs, we show that performance varies greatly across models, across the type of context provided, and also by question type; in particular, many LLMs seem unable to abstain from answering boolean questions using standard QA prompts. Our analysis also highlights the unexpected impact of abstention performance on QA task accuracy. Counter-intuitively, in some settings, replacing gold context with irrelevant context or adding irrelevant context to gold context can improve abstention performance in a way that results in improvements in task performance. Our results imply that changes are needed in QA dataset design and evaluation to more effectively assess the correctness and downstream impacts of model abstention.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.197",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation": {
        "type": "INPROCEEDINGS",
        "key": "golazizian-etal-2024-cost",
        "author": "Golazizian, Preni and Salkhordeh Ziabari, Alireza and Omrani, Ali and Dehghani, Morteza",
        "booktitle": "EMNLP-findings2024",
        "title": "Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In subjective NLP tasks, where a single ground truth does not exist, the inclusion of diverse annotators becomes crucial as their unique perspectives significantly influence the annotations. In realistic scenarios, the annotation budget often becomes the main determinant of the number of perspectives (i.e., annotators) included in the data and subsequent modeling. We introduce a novel framework for annotation collection and modeling in subjective tasks that aims to minimize the annotation budget while maximizing the predictive performance for each annotator. Our framework has a two-stage design: first, we rely on a small set of annotators to build a multitask model, and second, we augment the model for a new perspective by strategically annotating a few samples per annotator. To test our framework at scale, we introduce and release a unique dataset, Moral Foundations Subjective Corpus, of 2000 Reddit posts annotated by 24 annotators for moral sentiment. We demonstrate that our framework surpasses the previous SOTA in capturing the annotators\u2019 individual perspectives with as little as 25% of the original annotation budget on two datasets. Furthermore, our framework results in more equitable models, reducing the performance disparity among annotators.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.199",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "EDEN: Empathetic Dialogues for English Learning": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-eden",
        "author": "Li, Siyan and Shao, Teresa and Yu, Zhou and Hirschberg, Julia",
        "booktitle": "EMNLP-findings2024",
        "title": "EDEN: Empathetic Dialogues for English Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Dialogue systems have been used as conversation partners in English learning, but few have studied whether these systems improve learning outcomes. Student passion and perseverance, or grit, has been associated with language learning success. Recent work establishes that as students perceive their English teachers to be more supportive, their grit improves. Hypothesizing that the same pattern applies to English-teaching chatbots, we create EDEN, a robust open-domain chatbot for spoken conversation practice that provides empathetic feedback. To construct EDEN, we first train a specialized spoken utterance grammar correction model and a high-quality social chit-chat conversation model. We then conduct a preliminary user study with a variety of strategies for empathetic feedback. Our experiment suggests that using adaptive empathetic feedback leads to higher *perceived affective support*. Furthermore, elements of perceived affective support positively correlate with student grit.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.200",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Language Models Still Struggle to Zero-shot Reason about Time Series": {
        "type": "INPROCEEDINGS",
        "key": "merrill-etal-2024-language",
        "author": "Merrill, Mike A. and Tan, Mingtian and Gupta, Vinayak and Hartvigsen, Thomas and Althoff, Tim",
        "booktitle": "EMNLP-findings2024",
        "title": "Language Models Still Struggle to Zero-shot Reason about Time Series",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Time series are critical for decision-making in fields like finance and healthcare. Their importance has driven a recent influx of works passing time series into language models, leading to non-trivial forecasting on some datasets. But it remains unknown whether non-trivial forecasting implies that language models can reason about time series. To address this gap, we generate a first-of-its-kind evaluation framework for time series reasoning, including formal tasks and a corresponding dataset of multi-scale time series paired with text captions across ten domains. Using these data, we probe whether language models achieve three forms of reasoning: (1) Etiological Reasoning\u2014given an input time series, can the language model identify the scenario that most likely created it? (2) Question Answering\u2014can a language model answer factual questions about time series? (3) Context-Aided Forecasting\u2013does highly relevant textual context improve a language model\u2019s time series forecasts? We find that otherwise highly-capable language models demonstrate surprisingly limited time series reasoning: they score marginally above random on etiological and question answering tasks (up to 30 percentage points worse than humans) and show modest success in using context to improve forecasting. These weakness showcase that time series reasoning is an impactful, yet deeply underdeveloped direction for language model research. We also make our datasets public to support further research in this direction.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.201",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Agent Learning through World Dynamics Modeling": {
        "type": "INPROCEEDINGS",
        "key": "sun-etal-2024-enhancing-agent",
        "author": "Sun, Zhiyuan and Shi, Haochen and C\u00f4t\u00e9, Marc-Alexandre and Berseth, Glen and Yuan, Xingdi and Liu, Bang",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Agent Learning through World Dynamics Modeling",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs), trained on vast amounts of internet data, have developed a broad understanding of the world, enhancing the decision-making capabilities of embodied agents. This success is largely due to the comprehensive and in-depth domain knowledge within their training datasets. However, the extent of this knowledge can vary across different domains, and existing methods often assume that LLMs have a complete understanding of their environment, overlooking potential gaps in their grasp of actual world dynamics. To address this gap, we introduce Discover, Verify, and Evolve (DiVE), a framework that discovers world dynamics from a small number of demonstrations, verifies the correctness of these dynamics, and evolves new, advanced dynamics tailored to the current situation. Through extensive evaluations, we analyze the impact of each component on performance and compare the automatically generated dynamics from with human-annotated world dynamics. Our results demonstrate that LLMs guided by can make better decisions, achieving rewards comparable to human players in the Crafter environment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.202",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization": {
        "type": "INPROCEEDINGS",
        "key": "nahid-rafiei-2024-normtab",
        "author": "Nahid, Md and Rafiei, Davood",
        "booktitle": "EMNLP-findings2024",
        "title": "NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in parsing textual data and generating code. However, their performance in tasks involving tabular data, especially those requiring symbolic reasoning, faces challenges due to the structural variance and inconsistency in table cell values often found in web tables. In this paper, we introduce NormTab, a novel framework aimed at enhancing the symbolic reasoning performance of LLMs by normalizing web tables. We study table normalization as a stand-alone, one-time preprocessing step using LLMs to support symbolic reasoning on tabular data. Our experimental evaluation, conducted on challenging web table datasets such as WikiTableQuestion and TabFact, demonstrates that leveraging NormTab significantly improves symbolic reasoning performance, showcasing the importance and effectiveness of web table normalization for enhancing LLM-based symbolic reasoning tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.203",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Zero-Resource Hallucination Prevention for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "luo-etal-2024-zero-resource",
        "author": "Luo, Junyu and Xiao, Cao and Ma, Fenglong",
        "booktitle": "EMNLP-findings2024",
        "title": "Zero-Resource Hallucination Prevention for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The prevalent use of large language models (LLMs) in various domains has drawn attention to the issue of \u201challucination\u201d, which refers to instances where LLMs generate factually inaccurate or ungrounded information. Existing techniques usually identify hallucinations post-generation that cannot prevent their occurrence and suffer from inconsistent performance due to the influence of the instruction format and model style. In this paper, we introduce a novel pre-detection self-evaluation technique, referred to as SELF-FAMILIARITY, which focuses on evaluating the model\u2019s familiarity with the concepts present in the input instruction and withholding the generation of response in case of unfamiliar concepts under the zero-resource setting, where external ground-truth or background information is not available. We also propose a new dataset Concept-7 focusing on the hallucinations caused by limited inner knowledge. We validate SELF-FAMILIARITY across four different large language models, demonstrating consistently superior performance compared to existing techniques. Our findings propose a significant shift towards preemptive strategies for hallucination mitigation in LLM assistants, promising improvements in reliability, applicability, and interpretability.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.204",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals": {
        "type": "INPROCEEDINGS",
        "key": "elazar-etal-2024-measuring",
        "author": "Elazar, Yanai and Paranjape, Bhargavi and Peng, Hao and Wiegreffe, Sarah and Chandu, Khyathi and Srikumar, Vivek and Singh, Sameer and Smith, Noah A.",
        "booktitle": "EMNLP-findings2024",
        "title": "Measuring and Improving Attentiveness to Partial Inputs with Counterfactuals",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The inevitable appearance of spurious correlations in training datasets hurts the generalization of NLP models on unseen data. Previous work has found that datasets with paired inputs are prone to correlations between a specific part of the input (e.g., the hypothesis in NLI) and the label; consequently, models trained only on those outperform chance. Are these correlations picked up by models trained on the full input data? To address this question, we propose a new evaluation method, Counterfactual Attentiveness Test (CAT). CAT uses counterfactuals by replacing part of the input with its counterpart from a different example (subject to some restrictions), expecting an attentive model to change its prediction. Using CAT, we systematically investigate established supervised and in-context learning models on ten datasets spanning four tasks: natural language inference, reading comprehension, paraphrase detection, and visual &amp; language reasoning. CAT reveals that reliance on such correlations is mainly data-dependent. Surprisingly, we find that GPT3 becomes less attentive with an increased number of demonstrations, while its accuracy on the test data improves. Our results demonstrate that augmenting training or demonstration data with counterfactuals is effective in improving models\u2019 attentiveness. We show that models\u2019 attentiveness measured by CAT reveals different conclusions from solely measuring correlations in data.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.205",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-lars",
        "author": "Xu, Zifan and Wang, Haozhu and Bespalov, Dmitriy and Wu, Xian and Stone, Peter and Qi, Yanjun",
        "booktitle": "EMNLP-findings2024",
        "title": "LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Chain-of-thought (CoT) prompting is a popular in-context learning (ICL) approach for large language models (LLMs), especially when tackling complex reasoning tasks. Traditional ICL approaches construct prompts using examples that contain questions similar to the input question. However, CoT prompting, which includes crucial intermediate reasoning steps (rationales) within its examples, necessitates selecting examples based on these rationales rather than the questions themselves. Existing methods require human experts or pre-trained LLMs to describe the skill, a high-level abstraction of rationales, to guide the selection. These methods, however, are often costly and difficult to scale. Instead, this paper introduces a new approach named Latent Reasoning Skills (LaRS) that employs unsupervised learning to create a latent space representation of rationales, with a latent variable called a reasoning skill. Concurrently, LaRS learns a reasoning policy to determine the required reasoning skill for a given question. Then the ICL examples are selected by aligning the reasoning skills between past examples and the question. This approach is theoretically grounded and compute-efficient, eliminating the need for auxiliary LLM inference or manual prompt design. Empirical results demonstrate that LaRS consistently outperforms SOTA skill-based selection methods, processing example banks four times faster, reducing LLM inferences during the selection stage by half, and showing greater robustness to sub-optimal example banks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.206",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning": {
        "type": "INPROCEEDINGS",
        "key": "feinglass-yang-2024-trope",
        "author": "Feinglass, Joshua and Yang, Yezhou",
        "booktitle": "EMNLP-findings2024",
        "title": "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Zero-shot inference, where pre-trained models perform tasks without specific training data, is an exciting emergent ability of large models like CLIP. Although there has been considerable exploration into enhancing zero-shot abilities in image captioning (IC) for popular datasets such as MSCOCO and Flickr8k, these approaches fall short with fine-grained datasets like CUB, FLO, UCM-Captions, and Sydney-Captions. These datasets require captions to discern between visually and semantically similar classes, focusing on detailed object parts and their attributes. To overcome this challenge, we introduce TRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption with additional object-part details using object detector proposals and natural language processing techniques. It complements rather than alters the base caption, allowing seamless integration with other captioning methods and offering users enhanced flexibility. Our evaluations show that TROPE consistently boosts performance across all tested zero-shot IC approaches and achieves state-of-the-art results on fine-grained IC datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.207",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases": {
        "type": "INPROCEEDINGS",
        "key": "t-y-s-s-etal-2024-craft",
        "author": "T.y.s.s, Santosh and Chowdhury, Irtiza and Xu, Shanshan and Grabmair, Matthias",
        "booktitle": "EMNLP-findings2024",
        "title": "The Craft of Selective Prediction: Towards Reliable Case Outcome Classification - An Empirical Study on European Court of Human Rights Cases",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In high-stakes decision-making tasks within legal NLP, such as Case Outcome Classification (COC), quantifying a model\u2019s predictive confidence is crucial. Confidence estimation enables humans to make more informed decisions, particularly when the model\u2019s certainty is low, or where the consequences of a mistake are significant. However, most existing COC works prioritize high task performance over model reliability. This paper conducts an empirical investigation into how various design choices\u2014including pre-training corpus, confidence estimator and fine-tuning loss\u2014affect the reliability of COC models within the framework of selective prediction. Our experiments on the multi-label COC task, focusing on European Court of Human Rights (ECtHR) cases, highlight the importance of a diverse yet domain-specific pre-training corpus for better calibration. Additionally, we demonstrate that larger models tend to exhibit overconfidence, Monte Carlo dropout methods produce reliable confidence estimates, and confident error regularization effectively mitigates overconfidence. To our knowledge, this is the first systematic exploration of selective prediction in legal NLP. Our findings underscore the need for further research on enhancing confidence measurement and improving the trustworthiness of models in the legal domain.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.208",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-infuserki",
        "author": "Wang, Fali and Bao, Runxue and Wang, Suhang and Yu, Wenchao and Liu, Yanchi and Cheng, Wei and Chen, Haifeng",
        "booktitle": "EMNLP-findings2024",
        "title": "InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have achieved exceptional capabilities in open generation across various domains, yet they encounter difficulties with tasks that require intensive knowledge. To address these challenges, methods for integrating knowledge have been developed, which augment LLMs with domain-specific knowledge graphs through external modules. These approaches, however, face data inefficiency issues as they necessitate the processing of both known and unknown knowledge for fine-tuning. Thus, our research focuses on a novel problem: efficiently integrating unknown knowledge into LLMs without unnecessary overlap of known knowledge. A risk of introducing new knowledge is the potential forgetting of existing knowledge. To mitigate this risk, we propose the innovative InfuserKI framework. This framework employs transformer internal states to determine when to enrich LLM outputs with additional information, effectively preventing knowledge forgetting. Performance evaluations using the UMLS-2.5k and MetaQA domain knowledge graphs reveal that InfuserKI not only successfully integrates new knowledge but also outperforms state-of-the-art baselines, reducing knowledge forgetting by 9% and 6%, respectively.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.209",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization": {
        "type": "INPROCEEDINGS",
        "key": "luo-etal-2024-summacoz",
        "author": "Luo, Ge and Fan, Weisi and Li, Miaoran and Sun, Guoruizhe and Zhang, Runlong and Xu, Chenyu and Bao, Forrest Sheng",
        "booktitle": "EMNLP-findings2024",
        "title": "SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Summarization is an important application of Large Language Models (LLMs). When judging the quality of a summary, factual consistency holds a significant weight. Despite numerous efforts dedicated to building factual inconsistency detectors, the exploration of explanability remains limited among existing effort. In this study, we incorporate both human-annotated and model-generated natural language explanations elucidating how a summary deviates and thus becomes inconsistent with its source article. We build our explanation-augmented dataset on top of the widely used SummaC summarization consistency benchmark. Additionally, we develop an inconsistency detector that is jointly trained with the collected explanations. Our findings demonstrate that integrating explanations during training not only enables the model to provide rationales for its judgments but also enhances its accuracy significantly.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.210",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model": {
        "type": "INPROCEEDINGS",
        "key": "cheng-etal-2024-precision",
        "author": "Cheng, Sheng and Patel, Maitreya and Yang, Yezhou",
        "booktitle": "EMNLP-findings2024",
        "title": "Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite advancements in text-to-image models, generating images that precisely align with textual descriptions remains challenging due to misalignment in training data. In this paper, we analyze the critical role of caption precision and recall in text-to-image model training. Our analysis of human-annotated captions shows that both precision and recall are important for text-image alignment, but precision has a more significant impact. Leveraging these insights, we utilize Large Vision Language Models to generate synthetic captions for training. Models trained with these synthetic captions show similar behavior to those trained on human-annotated captions, underscores the potential for synthetic data in text-to-image training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.211",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Deciphering the Factors Influencing the Efficacy of Chain-of-Thought: Probability, Memorization, and Noisy Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "prabhakar-etal-2024-deciphering",
        "author": "Prabhakar, Akshara and Griffiths, Thomas L. and McCoy, R. Thomas",
        "booktitle": "EMNLP-findings2024",
        "title": "Deciphering the Factors Influencing the Efficacy of Chain-of-Thought: Probability, Memorization, and Noisy Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Chain-of-Thought (CoT) prompting has been shown to enhance the multi-step reasoning capabilities of Large Language Models (LLMs). However, debates persist about whether LLMs exhibit *abstract generalization* or rely on *shallow heuristics* when given CoT prompts. To understand the factors influencing CoT reasoning we provide a detailed case study of the symbolic reasoning task of decoding shift ciphers, where letters are shifted forward some number of steps in the alphabet. We analyze the pattern of results produced by three LLMs\u2014GPT-4, Claude 3, and Llama 3.1\u2014performing this task using CoT prompting. By focusing on a single relatively simple task, we are able to identify three factors that systematically affect CoT performance: the probability of the task\u2019s expected output (probability), what the model has implicitly learned during pre-training (memorization), and the number of intermediate operations involved in reasoning (noisy reasoning). We show that these factors can drastically influence task accuracy across all three LLMs; e.g., when tested with GPT-4, varying the output\u2019s probability of occurrence shifts accuracy from 26% to 70%. Overall, we conclude that CoT prompting performance reflects both memorization and a probabilistic version of genuine reasoning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.212",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-contradictory reasoning evaluation and detection": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-self-contradictory",
        "author": "Liu, Ziyi and Sanyal, Soumya and Lee, Isabelle and Du, Yongkang and Gupta, Rahul and Liu, Yang and Zhao, Jieyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-contradictory reasoning evaluation and detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In a plethora of recent work, large language models (LLMs) demonstrated impressive reasoning ability, but many proposed downstream reasoning tasks only focus on performance-wise evaluation. Two fundamental questions persist: 1) how consistent is the reasoning, and 2) can models detect unreliable reasoning? In this paper, we investigate self-contradictory (Self-Contra) reasoning, where the model reasoning does not support answers. To answer 1), we define and assess the Self-Contra rate across three datasets and delve into finer-grained categories of Self-Contra reasoning. We find that LLMs often contradict themselves in reasoning tasks involving contextual information understanding or commonsense. The model may generate correct answers by taking shortcuts in reasoning or overlooking contextual evidence, leading to compromised reasoning. For 2), we task the state-of-the-art model GPT-4 with identifying Self-Contra reasoning and finer-grained fallacies. We find that finer-grained aided detection can improve GPT-4\u2019s ability to detect Self-Contra. However, it is only able to detect Self-Contra with a 52.2% F1 score, much lower compared to 66.7% for humans. Our results indicate that current LLMs lack the robustness necessary for reliable reasoning and we emphasize the urgent need for establishing best practices in comprehensive reasoning evaluations beyond pure performance-based metrics.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.213",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases": {
        "type": "INPROCEEDINGS",
        "key": "t-y-s-s-etal-2024-incorporating",
        "author": "T.y.s.s, Santosh and Elganayni, Mohamed Hesham and S\u00f3jka, Stanis\u0142aw and Grabmair, Matthias",
        "booktitle": "EMNLP-findings2024",
        "title": "Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Inspired by the legal doctrine of stare decisis, which leverages precedents (prior cases) for informed decision-making, we explore methods to integrate them into LJP models. To facilitate precedent retrieval, we train a retriever with a fine-grained relevance signal based on the overlap ratio of alleged articles between cases. We investigate two strategies to integrate precedents: direct incorporation at inference via label interpolation based on case proximity and during training via a precedent fusion module using a stacked-cross attention model. We employ joint training of the retriever and LJP models to address latent space divergence between them. Our experiments on LJP tasks from the ECHR jurisdiction reveal that integrating precedents during training coupled with joint training of the retriever and LJP model, outperforms models without precedents or with precedents incorporated only at inference, particularly benefiting sparser articles.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.214",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification": {
        "type": "INPROCEEDINGS",
        "key": "gunjal-durrett-2024-molecular",
        "author": "Gunjal, Anisha and Durrett, Greg",
        "booktitle": "EMNLP-findings2024",
        "title": "Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automatic factuality verification of large language model (LLM) generations is becoming more and more widely used to combat hallucinations. A major point of tension in the literature is the granularity of this fact-checking: larger chunks of text are hard to fact-check, but more atomic facts like propositions may lack context to interpret correctly. In this work, we assess the role of context in these atomic facts. We argue that fully atomic facts are not the right representation, and define two criteria for molecular facts: decontextuality, or how well they can stand alone, and minimality, or how little extra information is added to achieve decontexuality. We quantify the impact of decontextualization on minimality, then present a baseline methodology for generating molecular facts automatically, aiming to add the right amount of information. We compare against various methods of decontextualization and find that molecular facts balance minimality with fact verification accuracy in ambiguous settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.215",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension": {
        "type": "INPROCEEDINGS",
        "key": "lu-etal-2024-moleculeqa",
        "author": "Lu, Xingyu and Cao, He and Liu, Zijing and Bai, Shengyuan and Chen, Leqing and Yao, Yuan and Zheng, Hai-Tao and Li, Yu",
        "booktitle": "EMNLP-findings2024",
        "title": "MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models are playing an increasingly significant role in molecular research, yet existing models often generate erroneous information. Traditional evaluations fail to assess a model\u2019s factual correctness. To rectify this absence, we present MoleculeQA, a novel question answering (QA) dataset which possesses 62K QA pairs over 23K molecules. Each QA pair, composed of a manual question, a positive option and three negative options, has consistent semantics with a molecular description from authoritative corpus. MoleculeQA is not only the first benchmark to evaluate molecular factual correctness but also the largest molecular QA dataset. A comprehensive evaluation on MoleculeQA for existing molecular LLMs exposes their deficiencies in specific aspects and pinpoints crucial factors for molecular modeling. Furthermore, we employ MoleculeQA in reinforcement learning to mitigate model hallucinations, thereby enhancing the factual correctness of generated information.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.216",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Sanitizing Large Language Models in Bug Detection with Data-Flow": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-sanitizing",
        "author": "Wang, Chengpeng and Zhang, Wuqi and Su, Zian and Xu, Xiangzhe and Zhang, Xiangyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Sanitizing Large Language Models in Bug Detection with Data-Flow",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) show potential in code reasoning tasks, facilitating the customization of detecting bugs in software development. However, the hallucination effect can significantly compromise the reliability of bug reports. This work formulates a new schema of bug detection and presents a novel sanitization technique that detects false positives for hallucination mitigation. Our key idea is to enforce LLMs to emit data-flow paths in few-shot chain-of-thought prompting and validate them via the program-property decomposition. Specifically, we dissect data-flow paths into basic properties upon concise code snippets and leverage parsing-based analysis and LLMs for validation. Our approach averagely achieves 91.03% precision and 74.00% recall upon synthetic benchmarks and boosts the precision by 21.99% with the sanitization. The evaluation upon real-world Android malware applications also demonstrates the superiority over an industrial analyzer, surpassing the precision and recall by 15.36% and 3.61%, respectively.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.217",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context": {
        "type": "INPROCEEDINGS",
        "key": "noriega-atala-etal-2024-happen",
        "author": "Noriega-Atala, Enrique and Vacareanu, Robert and Ashton, Salena Torres and Pyarelal, Adarsh and Morrison, Clayton T. and Surdeanu, Mihai",
        "booktitle": "EMNLP-findings2024",
        "title": "When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We introduce a neural architecture finetuned for the task of scenario context generation: The relevant location and time of an event or entity mentioned in text. Contextualizing information extraction helps to scope the validity of automated finings when aggregating them as knowledge graphs. Our approach uses a high-quality curated dataset of time and location annotations in a corpus of epidemiology papers to train an encoder-decoder architecture. We also explored the use of data augmentation techniques during training. Our findings suggest that a relatively small fine-tuned encoder-decoder model performs better than out-of-the-box LLMs and semantic role labeling parsers to accurate predict the relevant scenario information of a particular entity or event.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.219",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Incremental Summarization with Structured Representations": {
        "type": "INPROCEEDINGS",
        "key": "hwang-etal-2024-enhancing",
        "author": "Hwang, EunJeong and Zhou, Yichao and Wendt, James Bradley and Gunel, Beliz and Vo, Nguyen and Xie, Jing and Tata, Sandeep",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Incremental Summarization with Structured Representations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) often struggle with processing extensive input contexts, which can lead to redundant, inaccurate, or incoherent summaries. Recent methods have used unstructured memory to incrementally process these contexts, but they still suffer from information overload due to the volume of unstructured data handled. In our study, we introduce structured knowledge representations (GU_json), which significantly improve summarization performance by 40% and 14% across two public datasets. Most notably, we propose the Chain-of-Key strategy (CoK_json) that dynamically updates or augments these representations with new information, rather than recreating the structured memory for each new source. This method further enhances performance by 7% and 4% on the datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.220",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models": {
        "type": "INPROCEEDINGS",
        "key": "jiang-etal-2024-med",
        "author": "Jiang, Songtao and Zheng, Tuo and Zhang, Yan and Jin, Yeying and Yuan, Li and Liu, Zuozhu",
        "booktitle": "EMNLP-findings2024",
        "title": "Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in general-purpose or domain-specific multimodal large language models (LLMs) have witnessed remarkable progress for medical decision-making. However, they are designated for specific classification or generative tasks, and require model training or finetuning on large-scale datasets with sizeable parameters and tremendous computing, hindering their clinical utility across diverse resource-constrained scenarios in practice. In this paper, we propose a novel and lightweight framework Med-MoE (Mixture-of-Experts) that tackles both discriminative and generative multimodal medical tasks. The learning of Med-MoE consists of three steps: multimodal medical alignment, Instruction tuning and routing, and domain-specific MoE tuning. After aligning multimodal medical images with LLM tokens, we then enable the model for different multimodal medical tasks with instruction tuning, together with a trainable router tailored for expert selection across input modalities. Finally, the model is tuned by integrating the router with multiple domain-specific experts, which are selectively activated and further empowered by meta experts. Comprehensive experiments on both open- and close-end medical question answering (Med-VQA) and image classification tasks across datasets such as VQA-RAD, SLAKE and Path-VQA demonstrate that our model can achieve performance superior to or on par with state-of-the-art baselines, while only requiring approximately 30%-50% of activated model parameters. Extensive analysis and ablations corroborate the effectiveness and practical utility of our method.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.221",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multiple Knowledge-Enhanced Interactive Graph Network for Multimodal Conversational Emotion Recognition": {
        "type": "INPROCEEDINGS",
        "key": "tu-etal-2024-multiple",
        "author": "Tu, Geng and Wang, Jun and Li, Zhenyu and Chen, Shiwei and Liang, Bin and Zeng, Xi and Yang, Min and Xu, Ruifeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Multiple Knowledge-Enhanced Interactive Graph Network for Multimodal Conversational Emotion Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal Emotion Recognition in Conversations (ERC) aims to identify emotions in conversational videos. Current efforts focus on modeling both context-sensitive and speaker-sensitive dependencies and multimodal fusion. Despite the progress, models in Multimodal ERC (MERC) still struggle due to a lack of CommonSense Knowledge (CSK). In contrast, models in textual ERC typically employ CSK to enhance emotion inference. However, in multimodal scenarios, relying solely on textual CSK while neglecting visual CSK may hinder the understanding of visual emotional cues. To address this, we introduce a novel approach called Multiple Knowledge Enhanced Interactive Graph Network (MKE-IGN) to integrate multiple knowledge, such as textual and visual CSK, into the edge representations, thereby facilitating the modeling of relations between utterances and different types of CSK. Furthermore, considering that irrelevant CSK might be retained as noise, MKE-IGN adaptively selects this CSK guided by the mood-congruent effect and refines it based on contexts. Experimental results show that MKE-IGN outperforms state-of-the-art methods on two popular datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.222",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation": {
        "type": "INPROCEEDINGS",
        "key": "fu-etal-2024-autorag",
        "author": "Fu, Jia and Qin, Xiaoting and Yang, Fangkai and Wang, Lu and Zhang, Jue and Lin, Qingwei and Chen, Yubo and Zhang, Dongmei and Rajmohan, Saravan and Zhang, Qi",
        "booktitle": "EMNLP-findings2024",
        "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in Large Language Models have transformed ML/AI development, necessitating a reevaluation of AutoML principles for the Retrieval-Augmented Generation (RAG) systems. To address the challenges of hyper-parameter optimization and online adaptation in RAG, we propose the AutoRAG-HP framework, which formulates the hyper-parameter tuning as an online multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical MAB (Hier-MAB) method for efficient exploration of large search spaces. We conduct extensive experiments on tuning hyper-parameters, such as top-k retrieved documents, prompt compression ratio, and embedding methods, using the ALCE-ASQA and Natural Questions datasets. Our evaluation from jointly optimization all three hyper-parameters demonstrate that MAB-based online learning methods can achieve Recall@5 \\approx 0.8 for scenarios with prominent gradients in search space, using only ~20% of the LLM API calls required by the Grid Search approach. Additionally, the proposed Hier-MAB approach outperforms other baselines in more challenging optimization scenarios. The code will be made available at https://aka.ms/autorag.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.223",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unleashing the Potential of Large Language Models through Spectral Modulation": {
        "type": "INPROCEEDINGS",
        "key": "sun-etal-2024-unleashing",
        "author": "Sun, Peng and Zhu, Yao and Zhang, Yunjian and Yan, Xiu and Wang, Zizhe and Ji, Xiangyang",
        "booktitle": "EMNLP-findings2024",
        "title": "Unleashing the Potential of Large Language Models through Spectral Modulation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across various domains, garnering significant attention from both academia and industry. However, enhancing the performance of LLMs typically requires scaling up model sizes or fine-tuning with additional datasets, which results in substantial computational costs. This paper poses an intriguing question: Can we improve the performance of LLMs without additional training? Drawing inspiration from signal processing principles, which suggest that noise often resides in high-frequency components while low-frequency components carry the essence of signals, we propose uncovering untapped potential in LLMs from a frequency perspective. We hypothesize that the high-frequency components in the weight matrices of LLMs\u2019 linear layers may conceal noise that interferes with predictive accuracy. Therefore, we propose conducting spectral modulation in the parameter space of LLMs, which can seamlessly integrate with various models in a plug-and-play manner. Extensive experiments have demonstrated the superiority of our approach, with spectral modulation yielding an average performance improvement of up to 10.12%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.224",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization": {
        "type": "INPROCEEDINGS",
        "key": "adilazuarda-etal-2024-lingualchemy",
        "author": "Adilazuarda, Muhammad Farid and Cahyawijaya, Samuel and Winata, Genta Indra and Purwarianti, Ayu and Aji, Alham Fikri",
        "booktitle": "EMNLP-findings2024",
        "title": "LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Pretrained language models (PLMs) have shown remarkable generalization toward multiple tasks and languages. Nonetheless, the generalization of PLMs towards unseen languages is poor, resulting in significantly worse language performance, or even generating nonsensical responses that are comparable to a random baseline. This limitation has been a longstanding problem of PLMs raising the problem of diversity and equal access to language modeling technology. In this work, we solve this limitation by introducing LinguAlchemy, a regularization technique that incorporates various aspects of languages covering typological, geographical, and phylogenetic constraining the resulting representation of PLMs to better characterize the corresponding linguistics constraints. LinguAlchemy significantly improves the accuracy performance of mBERT and XLM-R on unseen languages by ~18% and ~2%, respectively compared to fully finetuned models and displaying a high degree of unseen language generalization. We further introduce AlchemyScale and AlchemyTune, extension of LinguAlchemy which adjusts the linguistic regularization weights automatically, alleviating the need for hyperparameter search. LinguAlchemy enables better cross-lingual generalization to unseen languages which is vital for better inclusivity and accessibility of PLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.225",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware": {
        "type": "INPROCEEDINGS",
        "key": "zhou-etal-2024-quest",
        "author": "Zhou, Chuang and Dong, Junnan and Huang, Xiao and Liu, Zirui and Zhou, Kaixiong and Xu, Zhaozhuo",
        "booktitle": "EMNLP-findings2024",
        "title": "QUEST: Efficient Extreme Multi-Label Text Classification with Large Language Models on Commodity Hardware",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Extreme multi-label text classification (EMTC) involves predicting multiple labels from a vast pool of candidates based on a user\u2019s textual query. While traditional BERT-based methods have shown limited success, large language models (LLMs) have brought new possibilities. It is promising to leverage their remarkable comprehension ability to understand textual queries. However, implementing LLMs is non-trivial for two main reasons. Firstly, real-world EMTC datasets can be extremely large, with candidate product pairs reaching up to ten million in real-world scenarios, which poses significant challenges in data ingestion. Secondly, the large size of LLMs makes computation and memory demands prohibitive for EMTC applications. To this end, we propose QUEST, a Quantized and Efficient Learning with Sampling Technique. QUEST includes a tailored hash sampling module that reduces the data volume to one-fourth of its original size. Additionally, we perform compressive fine-tuning LLMs with only twenty thousand trainable parameters, largely reducing computational requirements. Extensive experiments demonstrate that QUEST outperforms existing methods while requiring fewer computational resources, unlocking efficient EMTC on commodity hardware such as a single Nvidia RTX 3090 GPU with 24 GB of memory.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.226",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "UniSumEval: Towards Unified, Fine-grained, Multi-dimensional Summarization Evaluation for LLMs": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-unisumeval",
        "author": "Lee, Yuho and Yun, Taewon and Cai, Jason and Su, Hang and Song, Hwanjun",
        "booktitle": "EMNLP-findings2024",
        "title": "UniSumEval: Towards Unified, Fine-grained, Multi-dimensional Summarization Evaluation for LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing benchmarks for summarization quality evaluation often lack diverse input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and struggle with subjective and coarse-grained annotation schemes. To address these shortcomings, we create UniSumEval benchmark, which extends the range of input context (e.g., domain, length) and provides fine-grained, multi-dimensional annotations. We use AI assistance in data creation, identifying potentially hallucinogenic input texts, and also helping human annotators reduce the difficulty of fine-grained annotation tasks. With UniSumEval, we benchmark nine latest language models as summarizers, offering insights into their performance across varying input contexts and evaluation dimensions. Furthermore, we conduct a thorough comparison of SOTA automated summary evaluators. Our benchmark data will be available at https://github.com/DISL-Lab/UniSumEval-v1.0.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.227",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data": {
        "type": "INPROCEEDINGS",
        "key": "lim-etal-2024-enhancing",
        "author": "Lim, Jinsu and Hwang, Yechan and Lee, Young-Jun and Choi, Ho-Jin",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Arguments Recognition for Financial Mathematical Reasoning over Hybrid Data",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Mathematical question answering over long-form documents is challenging across domains like finance or Wikipedia due to the abundance of candidate arguments within evidence, which complicates recognizing proper arguments for mathematical reasoning and poses hard to learning. In this paper, we propose an approach for training a generator to improve argument recognition. Our method enhances the probabilities of proper arguments in a reasoning program generation so that the arguments comprising the ground truth have higher weights. The proposed approach consists of an argument aggregator to model the probabilities in each candidate generation and an argument set loss to compute the cross-entropy between that probability and the candidates\u2019 existence in the ground truth in terms of the argument set. In our experiments, we show performance improvements of 3.62% and 3.98% in execution accuracy and program accuracy, respectively, over the existing FinQANet model based on a financial mathematical QA dataset. Also, we observed that the similarity of argument sets between the generated program and the ground truth improved by about 2.9%, indicating a mitigation of the misrecognition problem.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.228",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-bi",
        "author": "Wu, Haiming and Zhang, Hanqing and Xuan, Richeng and Song, Dawei",
        "booktitle": "EMNLP-findings2024",
        "title": "Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Chinese Spelling Check (CSC) aims to detect and correct potentially misspelled characters in Chinese sentences. Naturally, it involves the detection and correction subtasks, which interact with each other dynamically. Such interactions are bi-directional, i.e., the detection result would help reduce the risk of over-correction and under-correction while the knowledge learnt from correction would help prevent false detection. Current CSC approaches are of two types: correction-only or single-directional detection-to-correction interactive frameworks. Nonetheless, they overlook the bi-directional interactions between detection and correction. This paper aims to fill the gap by proposing a Bi-directional Detector-Corrector framework for CSC (Bi-DCSpell). Notably, Bi-DCSpell contains separate detection and correction encoders, followed by a novel interactive learning module facilitating bi-directional feature interactions between detection and correction to improve each other\u2019s representation learning. Extensive experimental results demonstrate a robust correction performance of Bi-DCSpell on widely used benchmarking datasets while possessing a satisfactory detection ability.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.229",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "qiu-etal-2024-clongeval",
        "author": "Qiu, Zexuan and Li, Jingjing and Huang, Shijue and Jiao, Xiaoqi and Zhong, Wanjun and King, Irwin",
        "booktitle": "EMNLP-findings2024",
        "title": "CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Developing Large Language Models (LLMs) with robust long-context capabilities has been the recent research focus, resulting in the emergence of long-context LLMs proficient in Chinese. However, the evaluation of these models remains underdeveloped due to a lack of benchmarks. To address this gap, we present CLongEval, a comprehensive Chinese benchmark for evaluating long-context LLMs. CLongEval is characterized by three key features: (1) Sufficient data volume, comprising 7 distinct tasks and 7,267 examples; (2) Broad applicability, accommodating to models with context windows size from 1K to 100K; (3) High quality, with over 2,000 manually annotated question-answer pairs in addition to the automatically constructed labels. With CLongEval, we undertake a comprehensive assessment of 6 open-source long-context LLMs and 2 leading commercial counterparts that feature both long-context abilities and proficiency in Chinese. We also provide in-depth analysis based on the empirical results, trying to shed light on the critical capabilities that present challenges in long-context settings. The dataset, evaluation scripts, and model outputs will be released.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.230",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Guided Profile Generation Improves Personalization with Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhang-2024-guided",
        "author": "Zhang, Jiarui",
        "booktitle": "EMNLP-findings2024",
        "title": "Guided Profile Generation Improves Personalization with Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In modern commercial systems, including Recommendation, Ranking, and E-Commerce platforms, there is a trend towards improving customer experiences by incorporating Personalization context as input into Large Language Models (LLM). However, LLMs often struggle to effectively parse and utilize sparse and complex personal context without additional processing or contextual enrichment, underscoring the need for more sophisticated context understanding mechanisms. In this work, we propose Guided Profile Generation (GPG), a general method designed to generate personal profiles in natural language. As is observed, intermediate guided profile generation enables LLMs to summarize, and extract the important, distinctive features from the personal context into concise, descriptive sentences, precisely tailoring their generation more closely to an individual\u2019s unique habits and preferences. Our experimental results show that GPG improves LLM\u2019s personalization ability across different tasks, for example, it increases 37% accuracy in predicting personal preference compared to directly feeding the LLMs with raw personal context.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.231",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "mABC: Multi-Agent Blockchain-inspired Collaboration for Root Cause Analysis in Micro-Services Architecture": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-mabc",
        "author": "Zhang, Wei and Guo, Hongcheng and Yang, Jian and Tian, Zhoujin and Zhang, Yi and Chaoran, Yan and Li, Zhoujun and Li, Tongliang and Shi, Xu and Zheng, Liangfan and Zhang, Bo",
        "booktitle": "EMNLP-findings2024",
        "title": "mABC: Multi-Agent Blockchain-inspired Collaboration for Root Cause Analysis in Micro-Services Architecture",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Root cause analysis (RCA) in Micro-services architecture (MSA) with escalating complexity encounters complex challenges in maintaining system stability and efficiency due to fault propagation and circular dependencies among nodes. Diverse root cause analysis faults require multi-agents with diverse expertise. To mitigate the hallucination problem of large language models (LLMs), we design blockchain-inspired voting to ensure the reliability of the analysis by using a decentralized decision-making process. To avoid non-terminating loops led by common circular dependency in MSA, we objectively limit steps and standardize task processing through Agent Workflow. We propose a pioneering framework, multi-Agent Blockchain-inspired Collaboration for root cause analysis in micro-services architecture (mABC), where multiple agents based on the powerful LLMs follow Agent Workflow and collaborate in blockchain-inspired voting. Specifically, seven specialized agents derived from Agent Workflow each provide valuable insights towards root cause analysis based on their expertise and the intrinsic software knowledge of LLMs collaborating within a decentralized chain. Our experiments on the AIOps challenge dataset and a newly created Train-Ticket dataset demonstrate superior performance in identifying root causes and generating effective resolutions. The ablation study further highlights Agent Workflow, multi-agent, and blockchain-inspired voting is crucial for achieving optimal performance. mABC offers a comprehensive automated root cause analysis and resolution in micro-services architecture and significantly improves the IT Operation domain.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.232",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Taking a Deep Breath: Enhancing Language Modeling of Large Language Models with Sentinel Tokens": {
        "type": "INPROCEEDINGS",
        "key": "luo-etal-2024-taking",
        "author": "Luo, Weiyao and Zheng, Suncong and Xia, Heming and Wang, Weikang and Lei, Yan and Liu, Tianyu and Chen, Shuang and Sui, Zhifang",
        "booktitle": "EMNLP-findings2024",
        "title": "Taking a Deep Breath: Enhancing Language Modeling of Large Language Models with Sentinel Tokens",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have shown promising efficacy across various tasks, becoming powerful tools in numerous aspects of human life. However, Transformer-based LLMs suffer a performance degradation when modeling long-term contexts due to they discard some information to reduce computational overhead. In this work, we propose a simple yet effective method to enable LLMs to take a deep breath, encouraging them to summarize information contained within discrete text chunks. Specifically, we segment the text into multiple chunks and insert special token \\textlessSR\\textgreater at the end of each chunk. We then modify the attention mask to integrate the chunk\u2019s information into the corresponding \\textlessSR\\textgreater token. This facilitates LLMs to interpret information not only from historical individual tokens but also from the \\textlessSR\\textgreater token, aggregating the chunk\u2019s semantic information. Experiments on language modeling and out-of-domain downstream tasks validate the superiority of our approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.233",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Reward Modeling Requires Automatic Adjustment Based on Data Quality": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-reward-modeling",
        "author": "Wang, Binghai and Zheng, Rui and Chen, Lu and Xi, Zhiheng and Shen, Wei and Zhou, Yuhao and Yan, Dong and Gui, Tao and Zhang, Qi and Huang, Xuanjing",
        "booktitle": "EMNLP-findings2024",
        "title": "Reward Modeling Requires Automatic Adjustment Based on Data Quality",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In Reinforcement Learning from Human Feedback (RLHF), the reward model plays a crucial role in aligning language model outputs with human values. The human preference data used to train the reward model consists of a prompt and a response pair, with humans annotating which response better aligns with human value preferences. Due to the complexity and subjectivity of the annotation task, multiple organizations including OpenAI and Anthropic report significant noise in the human preference datasets, leading to instability and deviation in reward model training from human values. We discover that the difference in scores assigned to response pairs by the reward model effectively indicates the quality of data, and data of varying qualities show significant distinctions in reward model training. We introduce a method that automatically adjusts reward modeling based on data quality, reducing the impact of noise and making full use of dataset. Experiments on multiple human preference datasets demonstrate that our method stabilizes reward model training and significantly enhances the alignment performance of RLHF.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.234",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference": {
        "type": "INPROCEEDINGS",
        "key": "wan-etal-2024-look",
        "author": "Wan, Zhongwei and Wu, Ziang and Liu, Che and Huang, Jinfa and Zhu, Zhihong and Jin, Peng and Wang, Longyue and Yuan, Li",
        "booktitle": "EMNLP-findings2024",
        "title": "LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Long-context Multimodal Large Language Models (MLLMs) demand substantial computational resources for inference as the growth of their multimodal Key-Value (KV) cache, in response to increasing input lengths, challenges memory and time efficiency. Unlike single-modality LLMs that manage only textual contexts, the KV cache of long-context MLLMs includes representations from multiple images with temporal and spatial relationships and related textual contexts. The predominance of image tokens means traditional optimizations for LLMs\u2019 KV caches are unsuitable for multimodal long-context settings, and no prior works have addressed this challenge.In this work, we introduce **LOOK-M**, a pioneering, fine-tuning-free approach that efficiently reduces the multimodal KV cache size while maintaining performance comparable to a full cache. We observe that during prompt prefill, the model prioritizes more textual attention over image features, and based on the multimodal interaction observation, a new proposed text-prior method is explored to compress the KV cache. Furthermore, to mitigate the degradation of image contextual information, we propose several compensatory strategies using KV pairs merging. **LOOK-M** demonstrates that with a significant reduction in KV Cache memory usage, such as reducing it by **80%** in some cases, it not only achieves approximately **1.3x** faster decoding but also maintains or even **enhances** performance across a variety of long context multimodal tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.235",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Fall of ROME: Understanding the Collapse of LLMs in Model Editing": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-fall",
        "author": "Yang, Wanli and Sun, Fei and Tan, Jiajun and Ma, Xinyu and Su, Du and Yin, Dawei and Shen, Huawei",
        "booktitle": "EMNLP-findings2024",
        "title": "The Fall of ROME: Understanding the Collapse of LLMs in Model Editing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite significant progress in model editing methods, their application in real-world scenarios remains challenging as they often cause large language models (LLMs) to collapse. Among them, ROME is particularly concerning, as it could disrupt LLMs with only a single edit. In this paper, we study the root causes of such collapse. Through extensive analysis, we identify two primary factors that contribute to the collapse: i) inconsistent handling of prefixed and unprefixed keys in the parameter update equation may result in very small denominators, causing excessively large parameter updates; ii) the subject of collapse cases is usually the first token, whose unprefixed key distribution significantly differs from the prefixed key distribution in autoregressive transformers, causing the aforementioned issue to materialize. To validate our findings, we propose a simple yet effective approach: uniformly using prefixed keys during editing phase and adding prefixes during testing phase to ensure the consistency between training and testing. The experimental results show that the proposed solution can prevent model collapse while maintaining the effectiveness of the edits.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.236",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-onegen",
        "author": "Zhang, Jintian and Peng, Cheng and Sun, Mengshu and Chen, Xiang and Liang, Lei and Zhang, Zhiqiang and Zhou, Jun and Chen, Huajun and Zhang, Ningyu",
        "booktitle": "EMNLP-findings2024",
        "title": "OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite the recent advancements in Large Language Models (LLMs), which have significantly enhanced the generative capabilities for various NLP tasks, LLMs still face limitations in directly handling retrieval tasks. However, many practical applications demand the seamless integration of both retrieval and generation. This paper introduces a novel and efficient One-pass Generation and retrieval framework (OneGen), designed to improve LLMs\u2019 performance on tasks that require both generation and retrieval. The proposed framework bridges the traditionally separate training approaches for generation and retrieval by incorporating retrieval tokens generated autoregressively. This enables a single LLM to handle both tasks simultaneously in a unified forward pass. We conduct experiments on two distinct types of composite tasks, RAG and Entity Linking, to validate the pluggability, effectiveness, and efficiency of OneGen in training and inference. Furthermore, our results show that integrating generation and retrieval within the same context preserves the generative capabilities of LLMs while improving retrieval performance. To the best of our knowledge, OneGen is the first to enable LLMs to conduct vector retrieval during the generation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.237",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-Evolution Fine-Tuning for Policy Optimization": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-self-evolution",
        "author": "Chen, Ruijun and Liang, Jiehao and Gao, Shiping and Wan, Fanqi and Quan, Xiaojun",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-Evolution Fine-Tuning for Policy Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The alignment of large language models (LLMs) is crucial not only for unlocking their potential in specific tasks but also for ensuring that responses meet human expectations and adhere to safety and ethical principles. To address the challenges of current alignment methodologies, we introduce self-evolution fine-tuning (SEFT) for LLM alignment, aiming to eliminate the need for annotated samples while retaining the stability and efficiency of SFT. SEFT first trains an adaptive reviser to elevate low-quality responses while maintaining high-quality ones. The reviser then gradually guides the policy\u2019s optimization by fine-tuning it with enhanced responses. The method excels in utilizing unlimited unannotated data to optimize policies via supervised fine-tuning. Our experiments on AlpacaEval and MT-Bench demonstrate the effectiveness of SEFT and its advantages over existing alignment techniques.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.238",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning": {
        "type": "INPROCEEDINGS",
        "key": "yin-etal-2024-deeper",
        "author": "Yin, Qingyu and He, Xuzheng and Leong, Chak Tou and Wang, Fan and Yan, Yanzhao and Shen, Xiaoyu and Zhang, Qiang",
        "booktitle": "EMNLP-findings2024",
        "title": "Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Fine-tuning and in-context learning (ICL) are two prevalent methods in imbuing large language models with task-specific knowledge. It is commonly believed that fine-tuning can surpass ICL given sufficient training samples as it allows the model to adjust its internal parameters based on the data. However, this paper presents a counterintuitive finding: For tasks with implicit patterns, ICL captures these patterns significantly better than fine-tuning. We developed several datasets featuring implicit patterns, such as sequences determining answers through parity or identifying reducible terms in calculations. We then evaluated the models\u2019 understanding of these patterns under both fine-tuning and ICL across models ranging from 0.5B to 7B parameters. The results indicate that models employing ICL can quickly grasp deep patterns and significantly improve accuracy. In contrast, fine-tuning, despite utilizing thousands of times more training samples than ICL, achieved only limited improvements. We also proposed circuit shift theory from a mechanistic interpretability\u2019s view to explain why ICL wins.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.239",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Adaptive Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization": {
        "type": "INPROCEEDINGS",
        "key": "ji-etal-2024-adaptive",
        "author": "Ji, Yixin and Xiang, Yang and Li, Juntao and Xia, Qingrong and Ye, Zi and Duan, Xinyu and Wang, Zhefeng and Chen, Kehai and Zhang, Min",
        "booktitle": "EMNLP-findings2024",
        "title": "Adaptive Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In recent years, large language models (LLMs) have driven advances in natural language processing. Still, their growing scale has increased the computational burden, necessitating a balance between efficiency and performance. Low-rank compression, a promising technique, reduces non-essential parameters by decomposing weight matrices into products of two low-rank matrices. Yet, its application in LLMs has not been extensively studied. The key to low-rank compression lies in low-rank factorization and low-rank dimensions allocation. To address the challenges of low-rank compression in LLMs, we conduct empirical research on the low-rank characteristics of large models. We propose a low-rank compression method suitable for LLMs. This approach involves precise estimation of feature distributions through pooled covariance matrices and a Bayesian optimization strategy for allocating low-rank dimensions. Experiments on the LLaMA-2 models demonstrate that our method outperforms existing strong structured pruning and low-rank compression techniques in maintaining model performance at the same compression ratio.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.240",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Emosical: An Emotion-Annotated Musical Theatre Dataset": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-emosical",
        "author": "Kim, Hayoon and Choi, Ahyeon and Lee, Sungho and Jung, Hyun Jin and Lee, Kyogu",
        "booktitle": "EMNLP-findings2024",
        "title": "Emosical: An Emotion-Annotated Musical Theatre Dataset",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper presents Emosical, a multimodal open-source dataset of musical films. Emosical comprises video, vocal audio, text, and character identity paired samples with annotated emotion tags. Emosical provides rich emotion annotations for each sample by inferring the background story of the characters. To achieve this, we leverage the musical theatre script, which contains the characters\u2019 complete background stories and narrative contexts. The annotation pipeline includes feeding the speaking character, text, global persona, and context of the dialogue and song track into a large language model. To verify the effectiveness of our tagging scheme, we perform an ablation study by bypassing each step of the pipeline. The ablation results show the usefulness of each component in generating accurate emotion tags. A subjective test is conducted to compare the generated tags of each ablation result. We also perform a statistical analysis to find out the global characteristics of the collected emotion tags. Emosical would enable expressive synthesis and tagging of the speech and singing voice in the musical theatre domain in future research. Emosical is publicly available at https://github.com/gillosae/emosical.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.241",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Inference-Time Language Model Alignment via Integrated Value Guidance": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-inference",
        "author": "Liu, Zhixuan and Zhou, Zhanhui and Wang, Yuanfu and Yang, Chao and Qiao, Yu",
        "booktitle": "EMNLP-findings2024",
        "title": "Inference-Time Language Model Alignment via Integrated Value Guidance",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models are typically fine-tuned to align with human preferences, but tuning large models is computationally intensive and complex. In this work, we introduce **Integrated Value Guidance (IVG)**, a method that uses implicit and explicit value functions to guide language model decoding at token and chunk-level respectively, efficiently aligning large language models purely at inference time.This approach circumvents the complexities of direct fine-tuning and outperforms traditional methods.Empirically, we demonstrate the versatility of IVG across various tasks. In controlled sentiment generation and summarization tasks, our method significantly improves the alignment of large models using inference-time guidance from **gpt2**-based value functions. Moreover, in a more challenging instruction-following benchmark AlpacaEval 2.0, we show that both specifically tuned and off-the-shelf value functions greatly improve the length-controlled win rates of large models against gpt-4-turbo (e.g., 19.51 % \\rightarrow 26.51% for **Mistral-7B-Instruct-v0.2** and 25.58 % \\rightarrow 33.75 % for **Mixtral-8x7B-Instruct-v0.1** with Tulu guidance).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.242",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "cao-etal-2024-tonggu",
        "author": "Cao, Jiahuan and Peng, Dezhi and Zhang, Peirong and Shi, Yongxin and Liu, Yang and Ding, Kai and Jin, Lianwen",
        "booktitle": "EMNLP-findings2024",
        "title": "TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Classical Chinese is a gateway to the rich heritage and wisdom of ancient China, yet its complexities pose formidable comprehension barriers for most modern people without specialized knowledge. While Large Language Models (LLMs) have shown remarkable capabilities in Natural Language Processing (NLP), they struggle with Classical Chinese Understanding (CCU), especially in data-demanding and knowledge-intensive tasks. In response to this dilemma, we propose TongGu (mean understanding ancient and modern), the first CCU-specific LLM, underpinned by three core contributions. First, we construct a two-stage instruction-tuning dataset ACCN-INS derived from rich classical Chinese corpora, aiming to unlock the full CCU potential of LLMs. Second, we propose Redundancy-Aware Tuning (RAT) to prevent catastrophic forgetting, enabling TongGu to acquire new capabilities while preserving its foundational knowledge. Third, we present a CCU Retrieval-Augmented Generation (CCU-RAG) technique to reduce hallucinations based on knowledge-grounding. Extensive experiments across 24 diverse CCU tasks validate TongGu\u2019s superior ability, underscoring the effectiveness of RAT and CCU-RAG. The model and dataset are available at https://github.com/SCUT-DLVCLab/TongGu-LLM.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.243",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding": {
        "type": "INPROCEEDINGS",
        "key": "chan-etal-2024-negotiationtom",
        "author": "Chan, Chunkit and Jiayang, Cheng and Yim, Yauwai and Deng, Zheye and Fan, Wei and Li, Haoran and Liu, Xin and Zhang, Hongming and Wang, Weiqi and Song, Yangqiu",
        "booktitle": "EMNLP-findings2024",
        "title": "NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have sparked substantial interest and debate concerning their potential emergence of Theory of Mind (ToM) ability. Theory of mind evaluations currently focuses on testing models using machine-generated data or game settings prone to shortcuts and spurious correlations, which lacks evaluation of machine ToM ability in real-world human interaction scenarios. This poses a pressing demand to develop new real-world scenario benchmarks. We introduce NegotiationToM, a new benchmark designed to stress-test machine ToM in real-world negotiation surrounding covered multi-dimensional mental states (i.e., desires, beliefs, and intentions). Our benchmark builds upon the Belief-Desire-Intention (BDI) agent modeling theory and conducts the necessary empirical experiments to evaluate large language models. Our findings demonstrate that NegotiationToM is challenging for state-of-the-art LLMs, as they consistently perform significantly worse than humans, even when employing the chain-of-thought (CoT) method.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.244",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Robust Dual-debiasing VQA Model based on Counterfactual Causal Effect": {
        "type": "INPROCEEDINGS",
        "key": "song-etal-2024-robust",
        "author": "Song, Lingyun and Yang, Chengkun and Li, Xuanyu and Shang, Xuequn",
        "booktitle": "EMNLP-findings2024",
        "title": "A Robust Dual-debiasing VQA Model based on Counterfactual Causal Effect",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Traditional VQA models are inherently vulnerable to language bias, resulting in a significant performance drop when encountering out-of-distribution datasets. The conventional VQA models suffer from language bias that indicates a spurious correlation between textual questions and answers. Given the outstanding effectiveness of counterfactual causal inference in eliminating bias, we propose a model agnostic dual-debiasing framework based on Counterfactual Causal Effect (DCCE), which explicitly models two types of language bias(i.e., shortcut and distribution bias) by separate branches under the counterfactual inference framework. The effects of both types ofbias on answer prediction can be effectively mitigated by subtracting direct effect of textual questions on answers from total effect ofvisual questions on answers. Experimental results demonstrate that our proposed DCCE framework significantly reduces language biasand achieves state-of-the-art performance on the benchmark datasets without requiring additional augmented data. Our code is available inhttps://github.com/sxycyck/dcce.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.245",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-pyramidcodec",
        "author": "Chen, Jianyi and Dai, Zheqi and Ye, Zhen and Tan, Xu and Liu, Qifeng and Guo, Yike and Xue, Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generating well-structured long music compositions, spanning several minutes, remains a challenge due to inefficient representation and the lack of structured representation. In this paper, we propose PyramidCodec, a hierarchical discrete representation of audio, for long audio-domain music generation. Specifically, we employ residual vector quantization on different levels of features to obtain the hierarchical discrete representation. The highest level of features has the largest hop size, resulting in the most compact token sequence. The quantized higher-level representation is up-sampled and combined with lower-level features to apply residual vector quantization and obtain lower-level discrete representations. Furthermore, we design a hierarchical training strategy to ensure that the details are gradually added with more levels of tokens. By performing hierarchical tokenization, the overall token sequence represents information at various scales, facilitating long-context modeling in music and enabling the generation of well-structured compositions. The experimental results demonstrate that our proposed PyramidCodec achieves competitive performance in terms of reconstruction quality and token per second (TPS). By enabling ultra-long music modeling at the lowest level, the proposed approach facilitates training a language model that can generate well-structured long-form music for up to 3 minutes, whose quality is further demonstrated by subjective and objective evaluations. The samples can be found at https://pyramidcodec.github.io/.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.246",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations": {
        "type": "INPROCEEDINGS",
        "key": "qin-etal-2024-beyond",
        "author": "Qin, Peixin and Huang, Chen and Deng, Yang and Lei, Wenqiang and Chua, Tat-Seng",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the aid of large language models, current conversational recommender system (CRS) has gaining strong abilities to persuade users to accept recommended items. While these CRSs are highly persuasive, they can mislead users by incorporating incredible information in their explanations, ultimately damaging the long-term trust between users and the CRS. To address this, we propose a simple yet effective method, called PC-CRS, to enhance the credibility of CRS\u2019s explanations during persuasion. It guides the explanation generation through our proposed credibility-aware persuasive strategies and then gradually refines explanations via post-hoc self-reflection. Experimental results demonstrate the efficacy of PC-CRS in promoting persuasive and credible explanations. Further analysis reveals the reason behind current methods producing incredible explanations and the potential of credible explanations to improve recommendation accuracy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.247",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Revisiting Query Variation Robustness of Transformer Models": {
        "type": "INPROCEEDINGS",
        "key": "hagen-etal-2024-revisiting",
        "author": "Hagen, Tim and Scells, Harrisen and Potthast, Martin",
        "booktitle": "EMNLP-findings2024",
        "title": "Revisiting Query Variation Robustness of Transformer Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The most commonly used transformers for retrieval at present, BERT and T5, have been shown not to be robust to query variations such as typos or paraphrases. Although this is an important prerequisite for their practicality, this problem has hardly been investigated. More recent large language models (LLMs), including instruction-tuned LLMs, have not been analyzed yet, and only one study looks beyond typos. We close this gap by reproducing this study and extending it with a systematic analysis of more recent models, including Sentence-BERT, CharacterBERT, E5-Mistral, AnglE, and Ada v2. We further investigate if instruct-LLMs can be prompted for robustness. Our results are mixed in that the previously observed robustness issues for cross-encoders also apply to bi-encoders that use much larger LLMs, albeit to a lesser extent. While further LLM scaling may improve their embeddings, their cost-effective use for all but large deployments is limited. Training data that includes query variations allows LLMs to be fine-tuned for more robustness, but focusing on a single category of query variation may even degrade the effectiveness on others. Our code, results, and artifacts can be found at https://github.com/webis-de/EMNLP-24",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.248",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Revisiting Catastrophic Forgetting in Large Language Model Tuning": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-revisiting",
        "author": "Li, Hongyu and Ding, Liang and Fang, Meng and Tao, Dacheng",
        "booktitle": "EMNLP-findings2024",
        "title": "Revisiting Catastrophic Forgetting in Large Language Model Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Catastrophic Forgetting (CF) means models forgetting previously acquired knowledge when learning new data. It compromises the effectiveness of large language models (LLMs) during fine-tuning, yet the underlying causes have not been thoroughly investigated. This paper takes the first step to reveal the direct link between the flatness of the model loss landscape and the extent of CF in the field of LLMs. Based on this, we introduce the sharpness-aware minimization to mitigate CF by flattening the loss landscape. Experiments on three widely-used fine-tuning datasets, spanning different model scales, demonstrate the effectiveness of our method in alleviating CF. Analyses show that we nicely complement the existing anti-forgetting strategies, further enhancing the resistance of LLMs to CF.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.249",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks": {
        "type": "INPROCEEDINGS",
        "key": "schneider-sitaram-2024-m5",
        "author": "Schneider, Florian and Sitaram, Sunayana",
        "booktitle": "EMNLP-findings2024",
        "title": "M5 \u2013 A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Since the release of ChatGPT, the field of Natural Language Processing has experienced rapid advancements, particularly in Large Language Models (LLMs) and their multimodal counterparts, Large Multimodal Models (LMMs). Despite their impressive capabilities, LLMs often exhibit significant performance disparities across different languages and cultural contexts, as demonstrated by various text-only benchmarks. However, current research lacks such benchmarks for multimodal visio-linguistic settings. This work fills this gap by introducing M5, the first comprehensive benchmark designed to evaluate LMMs on diverse vision-language tasks within a multilingual and multicultural context. M5 includes eight datasets covering five tasks and 41 languages, with a focus on underrepresented languages and culturally diverse images. Furthermore, we introduce two novel datasets, M5-VGR and M5-VLOD, including a new Visio-Linguistic Outlier Detection task, in which all evaluated open-source models fail to significantly surpass the random baseline. Through extensive evaluation and analyses, we highlight substantial task-agnostic performance disparities between high- and low-resource languages. Moreover, we show that larger models do not necessarily outperform smaller ones in a multilingual setting.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.250",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "plaza-del-arco-etal-2024-divine",
        "author": "Plaza-del-Arco, Flor Miriam and Curry, Amanda Cercas and Paoli, Susanna and Cercas Curry, Alba and Hovy, Dirk",
        "booktitle": "EMNLP-findings2024",
        "title": "Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions. Previous work has shown that LLMs display biases in emotion attribution along gender lines. However, unlike gender, which says little about our values, religion, as a socio-cultural system, prescribes a set of beliefs and values for its followers. Religions, therefore, cultivate certain emotions. Moreover, these rules are explicitly laid out and interpreted by religious leaders. Using emotion attribution, we explore how different religions are represented in LLMs. We find that:Major religions in the US and European countries are represented with more nuance, displaying a more shaded model of their beliefs.Eastern religions like Hinduism and Buddhism are strongly stereotyped.Judaism and Islam are stigmatized \u2013 the models\u2019 refusal skyrocket. We ascribe these to cultural bias in LLMs and the scarcity of NLP literature on religion. In the rare instances where religion is discussed, it is often in the context of toxic language, perpetuating the perception of these religions as inherently toxic. This finding underscores the urgent need to address and rectify these biases. Our research emphasizes the crucial role emotions play in shaping our lives and how our values influence them.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.251",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis": {
        "type": "INPROCEEDINGS",
        "key": "ding-etal-2024-boosting",
        "author": "Ding, Xuanwen and Zhou, Jie and Dou, Liang and Chen, Qin and Wu, Yuanbin and Chen, Arlene and He, Liang",
        "booktitle": "EMNLP-findings2024",
        "title": "Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Aspect-based sentiment analysis (ABSA) is an important subtask of sentiment analysis, which aims to extract the aspects and predict their sentiments. Most existing studies focus on improving the performance of the target domain by fine-tuning domain-specific models (trained on source domains) based on the target domain dataset. Few works propose continual learning tasks for ABSA, which aim to learn the target domain\u2019s ability while maintaining the history domains\u2019 abilities. In this paper, we propose a Large Language Model-based Continual Learning (LLM-CL) model for ABSA. First, we design a domain knowledge decoupling module to learn a domain-invariant adapter and separate domain-variant adapters dependently with an orthogonal constraint. Then, we introduce a domain knowledge warmup strategy to align the representation between domain-invariant and domain-variant knowledge. In the test phase, we index the corresponding domain-variant knowledge via domain positioning to not require each sample\u2019s domain ID. Extensive experiments over 19 datasets indicate that our LLM-CL model obtains new state-of-the-art performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.252",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context": {
        "type": "INPROCEEDINGS",
        "key": "wu-feng-2024-protrix",
        "author": "Wu, Zirui and Feng, Yansong",
        "booktitle": "EMNLP-findings2024",
        "title": "ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Tables play a crucial role in conveying information in various domains. We propose a Plan-then-Reason framework to answer different types of user queries over tables with sentence context. The framework first plans the reasoning paths over the context, then assigns each step to program-based or textual reasoning to reach the final answer. This framework enhances the table reasoning abilities for both in-context learning and fine-tuning methods. GPT-3.5-Turbo following Plan-then-Reason framework surpasses other prompting baselines without self-consistency while using less API calls and in-context demonstrations. We also construct an instruction tuning set TrixInstruct to evaluate the effectiveness of fine-tuning with this framework. We present ProTrix model family by finetuning models on TrixInstruct. Our experiments show that ProTrix family generalizes to diverse unseen tabular tasks with only 6k training instances. We further demonstrate that ProTrix can generate accurate and faithful explanations to answer complex free-form questions. Our work underscores the importance of the planning and reasoning abilities towards a model over tabular tasks with generalizability and interpretability. We will open-source our dataset and models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.253",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models": {
        "type": "INPROCEEDINGS",
        "key": "hee-etal-2024-recent",
        "author": "Hee, Ming Shan and Sharma, Shivam and Cao, Rui and Nandi, Palash and Nakov, Preslav and Chakraborty, Tanmoy and Lee, Roy Ka-Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Moderating hate speech (HS) in the evolving online landscape is a complex challenge, compounded by the multimodal nature of digital content. This survey examines recent advancements in HS moderation, focusing on the burgeoning role of large language models (LLMs) and large multimodal models (LMMs) in detecting, explaining, debiasing, and countering HS. We begin with a comprehensive analysis of current literature, uncovering how text, images, and audio interact to spread HS. The combination of these modalities adds complexity and subtlety to HS dissemination. We also identified research gaps, particularly in underrepresented languages and cultures, and highlight the need for solutions in low-resource settings. The survey concludes with future research directions, including novel AI methodologies, ethical AI governance, and the development of context-aware systems. This overview aims to inspire further research and foster collaboration towards responsible and human-centric approaches to HS moderation in the digital age.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.254",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles": {
        "type": "INPROCEEDINGS",
        "key": "trhlik-stenetorp-2024-quantifying",
        "author": "Trhl\u00edk, Filip and Stenetorp, Pontus",
        "booktitle": "EMNLP-findings2024",
        "title": "Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) are increasingly being utilised across a range of tasks and domains, with a burgeoning interest in their application within the field of journalism. This trend raises concerns due to our limited understanding of LLM behaviour in this domain, especially with respect to political bias. Existing studies predominantly focus on LLMs undertaking political questionnaires, which offers only limited insights into their biases and operational nuances. To address this gap, our study establishes a new curated dataset that contains 2,100 human-written articles and utilises their descriptions to generate 56,700 synthetic articles using nine LLMs. This enables us to analyse shifts in properties between human-authored and machine-generated articles, with this study focusing on political bias, detecting it using both supervised models and LLMs. Our findings reveal significant disparities between base and instruction-tuned LLMs, with instruction-tuned models exhibiting consistent political bias. Furthermore, we are able to study how LLMs behave as classifiers, observing their display of political bias even in this role. Overall, for the first time within the journalistic domain, this study outlines a framework and provides a structured dataset for quantifiable experiments, serving as a foundation for further research into LLM political bias and its implications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.255",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "OEE-CFC: A Dataset for Open Event Extraction from Chinese Financial Commentary": {
        "type": "INPROCEEDINGS",
        "key": "wan-etal-2024-oee",
        "author": "Wan, Qizhi and Wan, Changxuan and Hu, Rong and Liu, Dexi and Wenwu, Xu and Xu, Kang and Meihua, Zou and Tao, Liu and Yang, Jie and Xiong, Zhenwei",
        "booktitle": "EMNLP-findings2024",
        "title": "OEE-CFC: A Dataset for Open Event Extraction from Chinese Financial Commentary",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To meet application needs, event extraction has shifted from simple entities to unconventional entities serving as event arguments. However, current corpora with unconventional entities as event arguments are limited in event types and lack rich multi-events and shared arguments. Financial commentary not only describes the basic elements of an event but also states the background, scope, manner, condition, result, and tool used for the event, as well as the tense, intensity, and emotions of actions or state changes. Therefore, it is not suitable to develop event types that include only a few specific roles, as these cannot comprehensively capture the event\u2019s semantics. Also, there are affluent complex entities serving as event arguments, multiple events, and shared event arguments. To advance the practicality of event extraction technology, this paper first develops a general open event template from the perspective of understanding the meaning of events, aiming to comprehensively reveal useful information about events. This template includes 21 event argument roles, divided into three categories: core event roles, situational event roles, and adverbial roles. Then, based on the constructed event template, Chinese financial commentaries are collected and manually annotated to create a corpus OEE-CFC supporting open event extraction. This corpus includes 17,469 events, 44,221 arguments, 3,644 complex arguments, and 5,898 shared arguments. Finally, based on the characteristics of OEE-CFC, we design four types of prompts, and two models for event argument extraction are developed, with experiments conducted on the prompts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.256",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification": {
        "type": "INPROCEEDINGS",
        "key": "singha-roy-etal-2024-graph",
        "author": "Singha Roy, Sudipta and Wang, Xindi and Mercer, Robert and Rudzicz, Frank",
        "booktitle": "EMNLP-findings2024",
        "title": "Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Long document classification presents challenges in capturing both local and global dependencies due to their extensive content and complex structure. Existing methods often struggle with token limits and fail to adequately model hierarchical relationships within documents. To address these constraints, we propose a novel model leveraging a graph-tree structure. Our approach integrates syntax trees for sentence encodings and document graphs for document encodings, which capture fine-grained syntactic relationships and broader document contexts, respectively. We use Tree Transformers to generate sentence encodings, while a graph attention network models inter- and intra-sentence dependencies. During training, we implement bidirectional information propagation from word-to-sentence-to-document and vice versa, which enriches the contextual representation. Our proposed method enables a comprehensive understanding of content at all hierarchical levels and effectively handles arbitrarily long contexts without token limit constraints. Experimental results demonstrate the effectiveness of our approach in all types of long document classification tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.257",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BookWorm: A Dataset for Character Description and Analysis": {
        "type": "INPROCEEDINGS",
        "key": "papoudakis-etal-2024-bookworm",
        "author": "Papoudakis, Argyrios and Lapata, Mirella and Keller, Frank",
        "booktitle": "EMNLP-findings2024",
        "title": "BookWorm: A Dataset for Character Description and Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Characters are at the heart of every story, driving the plot and engaging readers. In this study, we explore the understanding of characters in full-length books, which contain complex narratives and numerous interacting characters. We define two tasks: character description, which generates a brief factual profile, and character analysis, which offers an in-depth interpretation, including character development, personality, and social context. We introduce the BookWorm dataset, pairing books from the Gutenberg Project with human-written descriptions and analyses. Using this dataset, we evaluate state-of-the-art long-context models in zero-shot and fine-tuning settings, utilizing both retrieval-based and hierarchical processing for book-length inputs. Our findings show that retrieval-based approaches outperform hierarchical ones in both tasks. Additionally, fine-tuned models using coreference-based retrieval produce the most factual descriptions, as measured by fact- and entailment-based metrics. We hope our dataset, experiments, and analysis will inspire further research in character-based narrative understanding.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.258",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Leveraging Grammar Induction for Language Understanding and Generation": {
        "type": "INPROCEEDINGS",
        "key": "kai-etal-2024-leveraging",
        "author": "Kai, Jushi and Hou, Shengyuan and Huang, Yusheng and Lin, Zhouhan",
        "booktitle": "EMNLP-findings2024",
        "title": "Leveraging Grammar Induction for Language Understanding and Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Grammar induction has made significant progress in recent years. However, it is not clear how the application of induced grammar could enhance practical performance in downstream tasks. In this work, we introduce an unsupervised grammar induction method for language understanding and generation. We construct a grammar parser to induce constituency structures and dependency relations, which is simultaneously trained on downstream tasks without additional syntax annotations. The induced grammar features are subsequently incorporated into Transformer as a syntactic mask to guide self-attention. We evaluate and apply our method to multiple machine translation tasks and natural language understanding tasks. Our method demonstrates superior performance compared to the original Transformer and other models enhanced with external parsers. Experimental results indicate that our method is effective in both from-scratch and pre-trained scenarios. Additionally, our research highlights the contribution of explicitly modeling the grammatical structure of texts to neural network models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.259",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully": {
        "type": "INPROCEEDINGS",
        "key": "kai-etal-2024-sh2",
        "author": "Kai, Jushi and Zhang, Tianhang and Hu, Hai and Lin, Zhouhan",
        "booktitle": "EMNLP-findings2024",
        "title": "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) demonstrate great performance in text generation. However, LLMs are still suffering from hallucinations. In this work, we propose an inference-time method, Self-Highlighted Hesitation (SH2), to help LLMs decode more truthfully. SH2 is based on a simple fact rooted in information theory that for an LLM, the tokens predicted with lower probabilities are prone to be more informative than others. Our analysis shows that these low-confidence tokens are more likely to be closely related to factual information, such as nouns, proper nouns, and adjectives. Therefore, we propose to \u201dhighlight\u201d the factual information by selecting key tokens with the lowest probabilities and concatenating them to the original context, thus forcing the model to repeatedly read and hesitate on these tokens before generation. During decoding, we also adopt contrastive decoding to emphasize the difference in output probabilities brought by the hesitation. Experimental results demonstrate that our SH2, requiring no additional data or models, can effectively help LLMs elicit factual knowledge and distinguish hallucinated contexts by themselves. Significant and consistent improvements are achieved by SH2 for LLaMA-7b, LLaMA2-7b and Mistral-7b on various hallucination tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.260",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "RoQLlama: A Lightweight Romanian Adapted Language Model": {
        "type": "INPROCEEDINGS",
        "key": "dima-etal-2024-roqllama",
        "author": "Dima, George-Andrei and Avram, Andrei-Marius and Craciun, Cristian-George and Cercel, Dumitru-Clementin",
        "booktitle": "EMNLP-findings2024",
        "title": "RoQLlama: A Lightweight Romanian Adapted Language Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The remarkable achievements obtained by open-source large language models (LLMs) in recent years have predominantly been concentrated on tasks involving the English language. In this paper, we aim to advance the performance of Llama2 models on Romanian tasks. We tackle the problem of reduced computing resources by using QLoRA for training. We release RoQLlama-7b, a quantized LLM, which shows equal or improved results compared to its full-sized counterpart when tested on seven Romanian downstream tasks in the zero-shot setup. Also, it consistently achieves higher average scores across all few-shot prompts. Additionally, we introduce a novel Romanian dataset, namely RoMedQA, which contains single-choice medical questions in Romanian.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.261",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Reference-free Hallucination Detection for Large Vision-Language Models": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-reference",
        "author": "Li, Qing and Geng, Jiahui and Lyu, Chenyang and Zhu, Derui and Panov, Maxim and Karray, Fakhri",
        "booktitle": "EMNLP-findings2024",
        "title": "Reference-free Hallucination Detection for Large Vision-Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large vision-language models (LVLMs) have made significant progress in recent years. While LVLMs exhibit excellent ability in language understanding, question answering, and conversations of visual inputs, they are prone to producing hallucinations. While several methods are proposed to evaluate the hallucinations in LVLMs, most are reference-based and depend on external tools, which complicates their practical application. To assess the viability of alternative methods, it is critical to understand whether the reference-free approaches, which do not rely on any external tools, can efficiently detect hallucinations. Therefore, we initiate an exploratory study to demonstrate the effectiveness of different reference-free solutions in detecting hallucinations in LVLMs. In particular, we conduct an extensive study on three kinds of techniques: uncertainty-based, consistency-based, and supervised uncertainty quantification methods on four representative LVLMs across two different tasks. The empirical results show that the reference-free approaches are capable of effectively detecting non-factual responses in LVLMs, with the supervised uncertainty quantification method outperforming the others, achieving the best performance across different settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.262",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "WavLLM: Towards Robust and Adaptive Speech Large Language Model": {
        "type": "INPROCEEDINGS",
        "key": "hu-etal-2024-wavllm",
        "author": "Hu, Shujie and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Meng, Lingwei and Hao, Hongkun and Pan, Jing and Liu, Xunying and Li, Jinyu and Sivasankaran, Sunit and Liu, Linquan and Wei, Furu",
        "booktitle": "EMNLP-findings2024",
        "title": "WavLLM: Towards Robust and Adaptive Speech Large Language Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in large language models (LLMs) have expanded their scope in natural language processing (NLP) to encompass multimodal functions. However, integrating listening capabilities effectively remains a significant challenge for generalization and complex auditory task execution. In this work, we introduce WavLLM, a robust and adaptive speech large language model featuring dual encoders\u2014a Whisper encoder for semantics and a WavLM encoder for speaker characteristics. Within the two-stage curriculum learning framework, WavLLM first builds its foundational capabilities by optimizing on mixed elementary single tasks, followed by advanced multi-task training on more complex tasks such as combinations of the elementary tasks. To enhance the flexibility and adherence to different tasks and instructions, a prompt-aware LoRA weight adapter is introduced in the second advanced multi-task training stage. We validate the proposed model on universal speech benchmarks and also apply it to specialized speech-question-answer (SQA) dataset, and speech Chain-of-Thought (CoT) evaluation set. Experiments demonstrate that the proposed model achieves state-of-the-art performance across a range of speech tasks on the same model size, exhibiting robust generalization capabilities in executing complex tasks using CoT approach. The codes, models, audio samples, and SQA evaluation set can be accessed at https://github.com/microsoft/SpeechT5/tree/main/WavLLM.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.263",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues": {
        "type": "INPROCEEDINGS",
        "key": "petrak-etal-2024-learning",
        "author": "Petrak, Dominic and Tran, Thy Thy and Gurevych, Iryna",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Implicit user feedback, user emotions and demographic information have shown to be promising sources for improving the accuracy and user engagement of responses generated by dialogue systems. However, the influence of such information on task completion and factual consistency, which are important criteria for task-oriented and document-grounded dialogues, is not yet known. To address this, we introduce FEDI, the first English task-oriented and document-grounded dialogue dataset annotated with this information. Our experiments with Flan-T5, GPT-2 and Llama 2 show a particularly positive impact on task completion and factual consistency. Participants in our human evaluation reported that the responses generated by the feedback-trained models were more informative (Flan-T5 and GPT-2), relevant and factual consistent (Llama 2).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.264",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Argument Effectiveness Across Ideologies using Instruction-tuned Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "el-baff-etal-2024-improving",
        "author": "El Baff, Roxanne and Khatib, Khalid Al and Alshomary, Milad and Konen, Kai and Stein, Benno and Wachsmuth, Henning",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Argument Effectiveness Across Ideologies using Instruction-tuned Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Different political ideologies (e.g., liberal and conservative Americans) hold different worldviews, which leads to opposing stances on different issues (e.g., gun control) and, thereby, fostering societal polarization. Arguments are a means of bringing the perspectives of people with different ideologies closer together, depending on how well they reach their audience. In this paper, we study how to computationally turn ineffective arguments into effective arguments for people with certain ideologies by using instruction-tuned large language models (LLMs), looking closely at style features. For development and evaluation, we collect ineffective arguments per ideology from debate.org, and we generate about 30k, which we rewrite using three LLM methods tailored to our task: zero-shot prompting, few-shot prompting, and LLM steering. Our experiments provide evidence that LLMs naturally improve argument effectiveness for liberals. Our LLM-based and human evaluation show a clear preference towards the rewritten arguments. Code and link to the data are available here: https://github.com/roxanneelbaff/emnlp2024-iesta.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.265",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches": {
        "type": "INPROCEEDINGS",
        "key": "yuan-etal-2024-kv",
        "author": "Yuan, Jiayi and Liu, Hongyi and Zhong, Shaochen and Chuang, Yu-Neng and Li, Songchen and Wang, Guanchu and Le, Duy and Jin, Hongye and Chaudhary, Vipin and Xu, Zhaozhuo and Liu, Zirui and Hu, Xia",
        "booktitle": "EMNLP-findings2024",
        "title": "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Long context capability is a crucial competency for large language models (LLMs) as it mitigates the human struggle to digest long-form texts. This capability enables complex task-solving scenarios such as book summarization, code assistance, and many more tasks that are traditionally manpower-intensive. However, transformer-based LLMs face significant challenges with long context input due to the growing size of the KV cache and the intrinsic complexity of attending to extended inputs; where multiple schools of efficiency-driven approaches \u2014 such as KV cache quantization, token dropping, prompt compression, linear-time sequence models, and hybrid architectures \u2014 have been proposed to produce efficient yet long context-capable models. Despite these advancements, no existing work has comprehensively benchmarked these methods in a reasonably aligned environment. In this work, we fill this gap by providing a taxonomy of current methods and evaluating 10+ state-of-the-art approaches across seven categories of long context tasks. Our work reveals numerous previously unknown phenomena and offers insights \u2014 as well as a friendly workbench \u2014 for the future development of long context-capable LLMs. The source code is available at https://github.com/henryzhongsc/longctx_bench.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.266",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "An Evaluation Mechanism of LLM-based Agents on Manipulating APIs": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-evaluation-mechanism",
        "author": "Liu, Bing and Jianxiang, Zhou and Meng, Dan and Lu, Haonan",
        "booktitle": "EMNLP-findings2024",
        "title": "An Evaluation Mechanism of LLM-based Agents on Manipulating APIs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "LLM-based agents can greatly extend the abilities of LLMs and thus attract sharply increased studies. An ambitious vision \u2013 serving users by manipulating massive API-based tools \u2013 has been proposed and explored. However, we find a widely accepted evaluation mechanism for generic agents is still missing. This work aims to fill this gap. We decompose tool use capability into seven aspects and form a thorough evaluation schema. In addition, we design and release an instruction dataset and a toolset \u2013 the two sides that the agents bridge between \u2013 following the principle of reflecting real-world challenges. Furthermore, we evaluate multiple generic agents. Our findings can inspire future research in improving LLM-based agents and rethink the philosophy of API design.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.267",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "shi-etal-2024-math",
        "author": "Shi, Wenhao and Hu, Zhiqiang and Bin, Yi and Liu, Junhua and Yang, Yang and Ng, See-Kiong and Bing, Lidong and Lee, Roy Ka-Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have demonstrated impressive reasoning capabilities, particularly in textual mathematical problem-solving. However, existing open-source image instruction fine-tuning datasets, containing limited question-answer pairs per image, do not fully exploit visual information to enhance the multimodal mathematical reasoning capabilities of Multimodal LLMs (MLLMs). To bridge this gap, we address the lack of high-quality, diverse multimodal mathematical datasets by collecting 40K high-quality images with question-answer pairs from 24 existing datasets and synthesizing 320K new pairs, creating the MathV360K dataset, which enhances both the breadth and depth of multimodal mathematical questions. We introduce Math-LLaVA, a LLaVA-1.5-based model fine-tuned with MathV360K. This novel approach significantly improves the multimodal mathematical reasoning capabilities of LLaVA-1.5, achieving a 19-point increase and comparable performance to GPT-4V on MathVista\u2019s minitest split, and yielding leading performance on Math-V and MathVerse. Furthermore, Math-LLaVA demonstrates enhanced generalizability, showing substantial improvements on the MMMU benchmark. Our research highlights the importance of dataset diversity and synthesis in advancing MLLMs\u2019 mathematical reasoning abilities. The code and data are available at: https://github.com/HZQ950419/Math-LLaVA.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.268",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-navigating",
        "author": "Wang, Zehao and Wu, Minye and Cao, Yixin and Ma, Yubo and Chen, Meiqi and Tuytelaars, Tinne",
        "booktitle": "EMNLP-findings2024",
        "title": "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This study presents a novel evaluation framework for the Vision-Language Navigation (VLN) task. It aims to diagnose current models for various instruction categories at a finer-grained level. The framework is structured around the context-free grammar (CFG) of the task. The CFG serves as the basis for the problem decomposition and the core premise of the instruction categories design. We propose a semi-automatic method for CFG construction with the help of Large-Language Models (LLMs). Then, we induct and generate data spanning five principal instruction categories (i.e. direction change, landmark recognition, region recognition, vertical movement, and numerical comprehension). Our analysis of different models reveals notable performance discrepancies and recurrent issues. The stagnation of numerical comprehension, heavy selective biases over directional concepts, and other interesting findings contribute to the development of future language-guided navigation systems. The project is now available at https://zehao-wang.github.io/navnuances.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.269",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-invoke",
        "author": "Chen, Yanfei and Yoon, Jinsung and Sachan, Devendra Singh and Wang, Qingze and Cohen-Addad, Vincent and Bateni, Mohammadhossein and Lee, Chen-Yu and Pfister, Tomas",
        "booktitle": "EMNLP-findings2024",
        "title": "Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advances in large language models (LLMs) have enabled autonomous agents with complex reasoning and task-fulfillment capabilities using a wide range of tools. However, effectively identifying the most relevant tools for a given task becomes a key bottleneck as the toolset size grows, hindering reliable tool utilization. To address this, we introduce Re-Invoke, an unsupervised tool retrieval method designed to scale effectively to large toolsets without training. Specifically, we first generate a diverse set of synthetic queries that comprehensively cover different aspects of the query space associated with each tool document during the tool indexing phase. Second, we leverage LLM\u2019s query understanding capabilities to extract key tool-related context and underlying intents from user queries during the inference phase. Finally, we employ a novel multi-view similarity ranking strategy based on intents to pinpoint the most relevant tools for each query. Our evaluation demonstrates that Re-Invoke significantly outperforms state-of-the-art alternatives in both single-tool and multi-tool scenarios, all within a fully unsupervised setting. Notably, on the ToolE datasets, we achieve a 20% relative improvement in nDCG@5 for single-tool retrieval and a 39% improvement for multi-tool retrieval.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.270",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Rethinking Evaluation Methods for Machine Unlearning": {
        "type": "INPROCEEDINGS",
        "key": "wichert-sikdar-2024-rethinking",
        "author": "Wichert, Leon and Sikdar, Sandipan",
        "booktitle": "EMNLP-findings2024",
        "title": "Rethinking Evaluation Methods for Machine Unlearning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Machine *unlearning* refers to methods for deleting information about specific training instances from a trained machine learning model. This enables models to delete user information and comply with privacy regulations. While retraining the model from scratch on the training set excluding the instances to be \u201c*forgotten*\u201d would result in a desired unlearned model, owing to the size of datasets and models, it is infeasible. Hence, unlearning algorithms have been developed, where the goal is to obtain an unlearned model that behaves as closely as possible to the retrained model. Consequently, evaluating an unlearning method involves - (i) randomly selecting a *forget* set (i.e., the training instances to be unlearned), (ii) obtaining an unlearned and a retrained model, and (iii) comparing the performance of the unlearned and the retrained model on the test and forget set. However, when the forget set is randomly selected, the unlearned model is almost often similar to the original (i.e., prior to unlearning) model. Hence, it is unclear if the model did really unlearn or simply copied the weights from the original model. For a more robust evaluation, we instead propose to consider training instances with significant influence on the trained model. When such influential instances are considered in the forget set, we observe that the unlearned model deviates significantly from the retrained model. Such deviations are also observed when the size of the forget set is increased. Lastly, choice of dataset for evaluation could also lead to misleading interpretation of results.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.271",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evaluating Moral Beliefs across LLMs through a Pluralistic Framework": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-evaluating-moral",
        "author": "Liu, Xuelin and Zhu, Yanfei and Zhu, Shucheng and Liu, Pengyuan and Liu, Ying and Yu, Dong",
        "booktitle": "EMNLP-findings2024",
        "title": "Evaluating Moral Beliefs across LLMs through a Pluralistic Framework",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Proper moral beliefs are fundamental for language models, yet assessing these beliefs poses a significant challenge. This study introduces a novel three-module framework to evaluate the moral beliefs of four prominent large language models. Initially, we constructed a dataset containing 472 moral choice scenarios in Chinese, derived from moral words. The decision-making process of the models in these scenarios reveals their moral principle preferences. By ranking these moral choices, we discern the varying moral beliefs held by different language models. Additionally, through moral debates, we investigate the firmness of these models to their moral choices. Our findings indicate that English language models, namely ChatGPT and Gemini, closely mirror moral decisions of the sample of Chinese university students, demonstrating strong adherence to their choices and a preference for individualistic moral beliefs. In contrast, Chinese models such as Ernie and ChatGLM lean towards collectivist moral beliefs, exhibiting ambiguity in their moral choices and debates. This study also uncovers gender bias embedded within the moral beliefs of all examined language models. Our methodology offers an innovative means to assess moral beliefs in both artificial and human intelligence, facilitating a comparison of moral values across different cultures.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.272",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Knowledge Editing in Language Models via Adapted Direct Preference Optimization": {
        "type": "INPROCEEDINGS",
        "key": "rozner-etal-2024-knowledge",
        "author": "Rozner, Amit and Battash, Barak and Wolf, Lior and Lindenbaum, Ofir",
        "booktitle": "EMNLP-findings2024",
        "title": "Knowledge Editing in Language Models via Adapted Direct Preference Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) can become outdated over time as they may lack updated world knowledge, leading to factual knowledge errors and gaps. Knowledge Editing (KE) aims to overcome this challenge using weight updates that do not require expensive retraining. We propose treating KE as an LLM alignment problem. Toward this goal, we introduce Knowledge Direct Preference Optimization (KDPO), a variation of the Direct Preference Optimization (DPO) that is more effective for knowledge modifications. Our method is based on an online approach that continually updates the knowledge stored in the model. We use the current knowledge as a negative sample and the new knowledge we want to introduce as a positive sample in a process called DPO. We also use teacher-forcing for negative sample generation and optimize using the positive sample, which helps maintain localized changes. We tested our KE method on various datasets and models, comparing it to several cutting-edge methods, with 100 and 500 sequential edits. Additionally, we conducted an ablation study comparing our method to the standard DPO approach. Our experimental results show that our modified DPO method allows for more refined KE, achieving similar or better performance compared to previous methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.273",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Disentangling Questions from Query Generation for Task-Adaptive Retrieval": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-disentangling",
        "author": "Lee, Yoonsang and Kim, Minsoo and Hwang, Seung-won",
        "booktitle": "EMNLP-findings2024",
        "title": "Disentangling Questions from Query Generation for Task-Adaptive Retrieval",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper studies the problem of information retrieval, to adapt to unseen tasks. Existing work generates synthetic queries from domain-specific documents to jointly train the retriever. However, the conventional query generator assumes the query as a question, thus failing to accommodate general search intents. A more lenient approach incorporates task-adaptive elements, such as few-shot learning with an 137B LLM. In this paper, we challenge a trend equating query and question, and instead conceptualize query generation task as a \u201ccompilation\u201d of high-level intent into task-adaptive query. Specifically, we propose EGG, a query generator that better adapts to wide search intents expressed in the BeIR benchmark. Our method outperforms baselines and existing models on four tasks with underexplored intents, while utilizing a query generator 47 times smaller than the previous state-of-the-art. Our findings reveal that instructing the LM with explicit search intent is a key aspect of modeling an effective query generator.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.274",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora": {
        "type": "INPROCEEDINGS",
        "key": "markus-etal-2024-reap",
        "author": "Markus, Dror Kris and Levi, Effi and Sheafer, Tamir and Shenhav, Shaul Rafael",
        "booktitle": "EMNLP-findings2024",
        "title": "Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Media storms, dramatic outbursts of attention to a story, are central components of media dynamics and the attention landscape. Despite their importance, there has been little systematic and empirical research on this concept due to issues of measurement and operationalization. We introduce an iterative human-in-the-loop method to identify media storms in a large-scale corpus of news articles. The text is first transformed into signals of dispersion based on several textual characteristics. In each iteration, we apply unsupervised anomaly detection to these signals; each anomaly is then validated by an expert to confirm the presence of a storm, and those results are then used to tune the anomaly detection in the next iteration. We make available the resulting media storm dataset. Both the method and dataset provide a basis for comprehensive empirical study of media storms.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.275",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Survey on Natural Language Counterfactual Generation": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-survey",
        "author": "Wang, Yongjie and Qiu, Xiaoqi and Yue, Yu and Guo, Xu and Zeng, Zhiwei and Feng, Yuhong and Shen, Zhiqi",
        "booktitle": "EMNLP-findings2024",
        "title": "A Survey on Natural Language Counterfactual Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Natural language counterfactual generation aims to minimally modify a given text such that the modified text will be classified into a different class. The generated counterfactuals provide insight into the reasoning behind a model\u2019s predictions by highlighting which words significantly influence the outcomes. Additionally, they can be used to detect model fairness issues and augment the training data to enhance the model\u2019s robustness. A substantial amount of research has been conducted to generate counterfactuals for various NLP tasks, employing different models and methodologies. With the rapid growth of studies in this field, a systematic review is crucial to guide future researchers and developers. To bridge this gap, this survey provides a comprehensive overview of textual counterfactual generation methods, particularly those based on Large Language Models. We propose a new taxonomy that systematically categorizes the generation methods into four groups and summarizes the metrics for evaluating the generation quality. Finally, we discuss ongoing research challenges and outline promising directions for future work.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.276",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-geneverse",
        "author": "Liu, Tianyu and Xiao, Yijia and Luo, Xiao and Xu, Hua and Zheng, Wenjin and Zhao, Hongyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Geneverse: A Collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The applications of large language models (LLMs) are promising for biomedical and healthcare research. Despite the availability of open-source LLMs trained using a wide range of biomedical data, current research on the applications of LLMs to genomics and proteomics is still limited. To fill this gap, we propose a collection of finetuned LLMs and multimodal LLMs (MLLMs), known as Geneverse, for three novel tasks in genomic and proteomic research. The models in Geneverse are trained and evaluated based on domain-specific datasets, and we use advanced parameter-efficient finetuning techniques to achieve the model adaptation for tasks including the generation of descriptions for gene functions, protein function inference from its structure, and marker gene selection from spatial transcriptomic data. We demonstrate that adapted LLMs and MLLMs perform well for these tasks and may outperform closed-source large-scale models based on our evaluations focusing on both truthfulness and structural correctness. All of the training strategies and base models we used are freely accessible. Our codes can be found at https://github.com/HelloWorldLTY/Geneverse.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.277",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-qrmem",
        "author": "Wang, Bo and Huang, Heyan and Cao, Yixin and Ying, Jiahao and Tang, Wei and Feng, Chong",
        "booktitle": "EMNLP-findings2024",
        "title": "QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While LLMs have made notable advancements in natural language processing, they continue to struggle with processing extensive text. Memory mechanisms offer a flexible solution for managing long contexts, utilizing techniques such as compression, summarization, and structuring to facilitate nuanced and efficient handling of large volumes of text. However, existing techniques face challenges with static knowledge integration, leading to insufficient adaptation to task-specific needs and missing multi-segmentation relationships, which hinders the dynamic reorganization and logical combination of relevant segments during the response process. To address these issues, we introduce a novel strategy, Question then Reflection Memory Mechanism (QRMeM), which incorporates a dual-structured memory pool. This pool synergizes static textual content with structured graph guidance, fostering a reflective trial-and-error approach for navigating and identifying relevant segments. Our evaluation across multiple-choice questions (MCQ) and multi-document question answering (Multi-doc QA) benchmarks showcases QRMeM\u2019s enhanced performance compared to existing approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.278",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "IndoCL: Benchmarking Indonesian Language Development Assessment": {
        "type": "INPROCEEDINGS",
        "key": "lin-etal-2024-indocl",
        "author": "Lin, Nankai and Wu, Hongyan and Zheng, Weixiong and Liao, Xingming and Jiang, Shengyi and Yang, Aimin and Xiao, Lixian",
        "booktitle": "EMNLP-findings2024",
        "title": "IndoCL: Benchmarking Indonesian Language Development Assessment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, the field of language acquisition (LA) has significantly benefited from natural language processing technologies. A crucial task in LA involves tracking the evolution of language learners\u2019 competence, namely language development assessment (LDA). However, the majority of LDA research focuses on high-resource languages, with limited attention directed toward low-resource languages. Moreover, existing methodologies primarily depend on linguistic rules and language characteristics, with a limited exploration of exploiting pre-trained language models (PLMs) for LDA. In this paper, we construct the IndoCL corpus (Indonesian Corpus of L2 Learners), which comprises compositions written by undergraduate students majoring in Indonesian language. Moreover, we propose a model for LDA tasks, which automatically extracts language-independent features, relieving laborious computation and reliance on specific language. The proposed model uses sequential information attention and similarity representation learning to capture the differences and common information from the first-written and second-written essays, respectively. It has demonstrated remarkable performance on both our self-constructed corpus and publicly available corpora. Our work could serve as a novel benchmark for Indonesian LDA tasks. We also explore the feasibility of using existing large-scale language models (LLMs) for LDA tasks. The results show significant potential for improving LLM performance in LDA tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.280",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs": {
        "type": "INPROCEEDINGS",
        "key": "ma-etal-2024-context",
        "author": "Ma, Kexin and Jin, Ruochun and Haotian, Wang and Xi, Wang and Chen, Huan and Tang, Yuhua and Wang, Qian",
        "booktitle": "EMNLP-findings2024",
        "title": "Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-Augmented Large Language Models(RALMs) have made significant strides in enhancing the accuracy of generated responses. However, existing research often overlooks the data quality issues within retrieval results, often caused by inaccurate existing vector-distance-based retrieval methods. We propose to boost the precision of RALMs\u2019 answers from a data quality perspective through the Context-Driven Index Trimming (CDIT) framework, where Context Matching Dependencies (CMDs) are employed as logical data quality rules to capture and regulate the consistency between retrieved contexts. Based on the semantic comprehension capabilities of Large Language Models (LLMs), CDIT can effectively identify and discard retrieval results that are inconsistent with the query context and further modify indexes in the database, thereby improving answer quality. Experiments demonstrate average improvement of 3.75% in accuracy on challenging open-domain question-answering tasks. Also, the flexibility of CDIT is verified through its compatibility with various language models and indexing methods, which offers a promising approach to bolster RALMs\u2019 data quality and retrieval precision jointly.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.281",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Counter Turing Test (CT\u00b2): Investigating AI-Generated Text Detection for Hindi - Ranking LLMs based on Hindi AI Detectability Index (ADI_hi)": {
        "type": "INPROCEEDINGS",
        "key": "kavathekar-etal-2024-counter",
        "author": "Kavathekar, Ishan and Rani, Anku and Chamoli, Ashmit and Kumaraguru, Ponnurangam and Sheth, Amit P. and Das, Amitava",
        "booktitle": "EMNLP-findings2024",
        "title": "Counter Turing Test (CT\u00b2): Investigating AI-Generated Text Detection for Hindi - Ranking LLMs based on Hindi AI Detectability Index (ADI_hi)",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.282",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Generating Media Background Checks for Automated Source Critical Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "schlichtkrull-2024-generating",
        "author": "Schlichtkrull, Michael Sejr",
        "booktitle": "EMNLP-findings2024",
        "title": "Generating Media Background Checks for Automated Source Critical Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Not everything on the internet is true. This unfortunate fact requires both humans and models to perform complex reasoning about credibility when working with retrieved information. In NLP, this problem has seen little attention. Indeed, retrieval-augmented models are not typically expected to distrust retrieved documents. Human experts overcome the challenge by gathering signals about the context, reliability, and tendency of source documents - that is, they perform *source criticism*. We propose a novel NLP task focused on finding and summarising such signals. We introduce a new dataset of 6,709 \u201cmedia background checks\u201d derived from Media Bias / Fact Check, a volunteer-run website documenting media bias. We test open-source and closed-source LLM baselines with and without retrieval on this dataset, finding that retrieval greatly improves performance. We furthermore carry out human evaluation, demonstrating that 1) media background checks are helpful for humans, and 2) media background checks are helpful for retrieval-augmented models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.283",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "In Defense of Structural Sparse Adapters for Concurrent LLM Serving": {
        "type": "INPROCEEDINGS",
        "key": "su-etal-2024-defense",
        "author": "Su, Junda and Liu, Zirui and Qiu, Zeju and Liu, Weiyang and Xu, Zhaozhuo",
        "booktitle": "EMNLP-findings2024",
        "title": "In Defense of Structural Sparse Adapters for Concurrent LLM Serving",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Adapting large language models (LLMs) to specific tasks remains challenging due to the extensive retraining required, prompting the need for efficient adapter techniques. Despite this, the concurrent serving of multiple adapters, each with unique matrix shapes, poses significant system-level challenges. To address these issues, we identify an opportunity in structurally sparse adapters, which, unlike low-rank adapters, maintain consistent matrix shapes while varying in sparsity patterns. Leveraging this characteristic, we introduce SpartanServe, a system designed for efficient concurrent serving of LLMs using multiple structurally sparse adapters. SpartanServe employs a unified matrix multiplication operation and a novel memory management technique to enable effective batching. Furthermore, the incorporation of Triton kernels enhances the acceleration of matrix multiplication in the serving process. Experimental results demonstrate that SpartanServe achieves 2.12\\times speedup over S-LoRA when serving 96 adapters using a single NVIDIA A100 GPU (40GB), showcasing its efficacy in concurrent LLM serving.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.284",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zha-etal-2024-constructure",
        "author": "Zha, Zhiwei and Zhu, Xiangru and Xu, Yuanyi and Huang, Chenghua and Liu, Jingping and Li, Zhixu and Wang, Xuwu and Xiao, Yanghua and Yang, Bei and Xu, Xiaoxiao",
        "booktitle": "EMNLP-findings2024",
        "title": "CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal Large Language Models (MLLMs) have shown promising results in various tasks, but their ability to perceive the visual world with deep, hierarchical understanding similar to humans remains uncertain. To address this gap, we introduce CONSTRUCTURE, a novel concept-level benchmark to assess MLLMs\u2019 hierarchical concept understanding and reasoning abilities. Our goal is to evaluate MLLMs across four key aspects: 1) Understanding atomic concepts at different levels of abstraction; 2) Performing upward abstraction reasoning across concepts; 3) Achieving downward concretization reasoning across concepts; and 4) Conducting multi-hop reasoning between sibling or common ancestor concepts. Our findings indicate that even state-of-the-art multimodal models struggle with concept structure reasoning (e.g., GPT-4o averages a score of 62.1%). We summarize key findings of MLLMs in concept structure reasoning evaluation. Morever, we provide key insights from experiments using CoT prompting and fine-tuning to enhance their abilities.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.285",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Stanceformer: Target-Aware Transformer for Stance Detection": {
        "type": "INPROCEEDINGS",
        "key": "garg-caragea-2024-stanceformer",
        "author": "Garg, Krishna and Caragea, Cornelia",
        "booktitle": "EMNLP-findings2024",
        "title": "Stanceformer: Target-Aware Transformer for Stance Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The task of Stance Detection involves discerning the stance expressed in a text towards a specific subject or target. Prior works have relied on existing transformer models that lack the capability to prioritize targets effectively. Consequently, these models yield similar performance regardless of whether we utilize or disregard target information, undermining the task\u2019s significance. To address this challenge, we introduce Stanceformer, a target-aware transformer model that incorporates enhanced attention towards the targets during both training and inference. Specifically, we design a Target Awareness matrix that increases the self-attention scores assigned to the targets. We demonstrate the efficacy of the Stanceformer with various BERT-based models, including state-of-the-art models and Large Language Models (LLMs), and evaluate its performance across three stance detection datasets, alongside a zero-shot dataset. Our approach Stanceformer not only provides superior performance but also generalizes even to other domains, such as Aspect-based Sentiment Analysis. We make the code publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.286",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "ma-etal-2024-learning",
        "author": "Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Cui, Can and Mei, Kai and Wang, Ziran",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Traditional autonomous driving systems have mainly focused on making driving decisions without human interaction, overlooking human-like decision-making and human preference required in complex traffic scenarios. To bridge this gap, we introduce a novel framework leveraging Large Language Models (LLMs) for learning human-centered driving decisions from diverse simulation scenarios and environments that incorporate human feedback. Our contributions include a GPT-4-based programming planner that integrates seamlessly with the existing CARLA simulator to understand traffic scenes and react to human instructions. Specifically, we build a human-guided learning pipeline that incorporates human driver feedback directly into the learning process and stores optimal driving programming policy using Retrieval Augmented Generation (RAG). Impressively, our programming planner, with only 50 saved code snippets, can match the performance of baseline extensively trained reinforcement learning (RL) models. Our paper highlights the potential of an LLM-powered shared-autonomy system, pushing the frontier of autonomous driving system development to be more interactive and intuitive.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.287",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies": {
        "type": "INPROCEEDINGS",
        "key": "shi-etal-2024-culturebank",
        "author": "Shi, Weiyan and Li, Ryan and Zhang, Yutong and Ziems, Caleb and Yu, Sunny and Horesh, Raya and Paula, Rog\u00e9rio Abreu De and Yang, Diyi",
        "booktitle": "EMNLP-findings2024",
        "title": "CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To enhance language models\u2019 cultural awareness, we design a generalizable pipeline to construct cultural knowledge bases from different online communities on a massive scale. With the pipeline, we construct CultureBank, a knowledge base built upon users\u2019 self-narratives with 12K cultural descriptors sourced from TikTok and 11K from Reddit. Unlike previous cultural knowledge resources, CultureBank contains diverse views on cultural descriptors to allow flexible interpretation of cultural knowledge, and contextualized cultural scenarios to help grounded evaluation. With CultureBank, we evaluate different LLMs\u2019 cultural awareness, and identify areas for improvement. We also fine-tune a language model on CultureBank: experiments show that it achieves better performances on two downstream cultural tasks in a zero-shot setting. Finally, we offer recommendations for future culturally aware language technologies. We release the CultureBank dataset, code and models at https://github.com/SALT-NLP/CultureBank. Our project page is at culturebank.github.io",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.288",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TOOLVERIFIER: Generalization to New Tools via Self-Verification": {
        "type": "INPROCEEDINGS",
        "key": "mekala-etal-2024-toolverifier",
        "author": "Mekala, Dheeraj and Weston, Jason E. and Lanchantin, Jack and Raileanu, Roberta and Lomeli, Maria and Shang, Jingbo and Dwivedi-Yu, Jane",
        "booktitle": "EMNLP-findings2024",
        "title": "TOOLVERIFIER: Generalization to New Tools via Self-Verification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Teaching language models to use tools is an important milestone towards building general assistants, but remains an open problem. While there has been significant progress on learning to use specific tools via fine-tuning, language models still struggle with learning how to robustly use new tools from only a few demonstrations. In this work we introduce a self-verification method which distinguishes between close candidates by self-asking contrastive questions during (1) tool selection; and parameter generation. We construct synthetic, high-quality, self-generated data for this goal using Llama-2 70B, which we intend to release publicly. Extensive experiments on 4 tasks from the ToolBench benchmark, consisting of 17 unseen tools, demonstrate an average improvement of 22% over few-shot baselines, even in scenarios where the distinctions between candidate tools are finely nuanced.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.289",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "FaithScore: Fine-grained Evaluations of Hallucinations in Large Vision-Language Models": {
        "type": "INPROCEEDINGS",
        "key": "jing-etal-2024-faithscore",
        "author": "Jing, Liqiang and Li, Ruosen and Chen, Yunmo and Du, Xinya",
        "booktitle": "EMNLP-findings2024",
        "title": "FaithScore: Fine-grained Evaluations of Hallucinations in Large Vision-Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We introduce FaithScore (Faithfulness to Atomic Image Facts Score), a reference-free and fine-grained evaluation metric that measures the faithfulness of the generated free-form answers from large vision-language models (LVLMs). The FaithScore evaluation first identifies sub-sentences containing descriptive statements that need to be verified, then extracts a comprehensive list of atomic facts from these sub-sentences, and finally conducts consistency verification between fine-grained atomic facts and the input image. Meta-evaluation demonstrates that our metric highly correlates with human judgments of faithfulness. We collect two benchmark datasets (i.e. LLaVA-1k and MSCOCO-Cap) for evaluating LVLMs instruction-following hallucinations. We measure hallucinations in state-of-the-art LVLMs with FaithScore on the datasets. Results reveal that current systems are prone to generate hallucinated content unfaithful to the image, which leaves room for future improvements. We hope our metric FaithScore can help evaluate future LVLMs in terms of faithfulness and provide insightful advice for enhancing LVLMs\u2019 faithfulness.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.290",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain": {
        "type": "INPROCEEDINGS",
        "key": "mazzaccara-etal-2024-learning",
        "author": "Mazzaccara, Davide and Testoni, Alberto and Bernardi, Raffaella",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Questions are essential tools for acquiring the necessary information to complete information-seeking tasks. However, large language models (LLMs), especially open-source models, often perform poorly in generating informative questions, as measured by expected information gain (EIG). In this paper, we propose a method to enhance the informativeness of LLM-generated questions in 20-question game dialogues. We sample multiple questions from the same model (LLaMA 2-Chat 7B) for each game and create pairs of low-EIG and high-EIG questions to apply a Direct Preference Optimization (DPO) algorithm. Our results show that this method produces more effective questions (in terms of EIG), even in domains different from those used to train the DPO model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.291",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Adversarial Math Word Problem Generation": {
        "type": "INPROCEEDINGS",
        "key": "xie-etal-2024-adversarial",
        "author": "Xie, Roy and Huang, Chengxuan and Wang, Junlin and Dhingra, Bhuwan",
        "booktitle": "EMNLP-findings2024",
        "title": "Adversarial Math Word Problem Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have significantly transformed the educational landscape. As current plagiarism detection tools struggle to keep pace with LLMs\u2019 rapid advancements, the educational community faces the challenge of assessing students\u2019 true problem-solving abilities in the presence of LLMs. In this work, we explore a new paradigm for ensuring fair evaluation\u2014generating adversarial examples which preserve the structure and difficulty of the original questions aimed for assessment, but are unsolvable by LLMs. Focusing on the domain of math word problems, we leverage abstract syntax trees to structurally generate adversarial examples that cause LLMs to produce incorrect answers by simply editing the numeric values in the problems. We conduct experiments on various open- and closed-source LLMs, quantitatively and qualitatively demonstrating that our method significantly degrades their math problem-solving ability. We identify shared vulnerabilities among LLMs and propose a cost-effective approach to attack high-cost models. Additionally, we conduct automatic analysis to investigate the cause of failure, providing further insights into the limitations of LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.292",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-defending-large",
        "author": "Zhao, Wei and Li, Zhe and Li, Yige and Zhang, Ye and Sun, Jun",
        "booktitle": "EMNLP-findings2024",
        "title": "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) are increasingly being adopted in a wide range of real-world applications. Despite their impressive performance, recent studies have shown that LLMs are vulnerable to deliberately crafted adversarial prompts even when aligned via Reinforcement Learning from Human Feedback or supervised fine-tuning. While existing defense methods focus on either detecting harmful prompts or reducing the likelihood of harmful responses through various means, defending LLMs against jailbreak attacks based on the inner mechanisms of LLMs remains largely unexplored. In this work, we investigate how LLMs respond to harmful prompts and propose a novel defense method termed Layer-specific Editing (LED) to enhance the resilience of LLMs against jailbreak attacks. Through LED, we reveal that several critical safety layers exist among the early layers of LLMs. We then show that realigning these safety layers (and some selected additional layers) with the decoded safe response from identified toxic layers can significantly improve the alignment of LLMs against jailbreak attacks. Extensive experiments across various LLMs (e.g., Llama2, Mistral) show the effectiveness of LED, which effectively defends against jailbreak attacks while maintaining performance on benign prompts. Our code is available at https://github.com/ledllm/ledllm.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.293",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Promoting Constructive Deliberation: Reframing for Receptiveness": {
        "type": "INPROCEEDINGS",
        "key": "kambhatla-etal-2024-promoting",
        "author": "Kambhatla, Gauri and Lease, Matthew and Rajadesingan, Ashwin",
        "booktitle": "EMNLP-findings2024",
        "title": "Promoting Constructive Deliberation: Reframing for Receptiveness",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To promote constructive discussion of controversial topics online, we propose automatic reframing of disagreeing responses to signal receptiveness to a preceding comment. Drawing on research from psychology, communications, and linguistics, we identify six strategies for reframing. We automatically reframe replies to comments according to each strategy, using a Reddit dataset. Through human-centered experiments, we find that the replies generated with our framework are perceived to be significantly more receptive than the original replies and a generic receptiveness baseline. We illustrate how transforming receptiveness, a particular social science construct, into a computational framework, can make LLM generations more aligned with human perceptions. We analyze and discuss the implications of our results, and highlight how a tool based on our framework might be used for more teachable and creative content moderation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.294",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-simple",
        "author": "Li, Yinghao and Ramprasad, Rampi and Zhang, Chao",
        "booktitle": "EMNLP-findings2024",
        "title": "A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have demonstrated impressive abilities in generating unstructured natural language according to instructions. However, their performance can be inconsistent when tasked with producing text that adheres to specific structured formats, which is crucial in applications like named entity recognition (NER) or relation extraction (RE). To address this issue, this paper introduces an efficient method, G&amp;O, to enhance their structured text generation capabilities. It breaks the generation into a two-step pipeline: initially, LLMs generate answers in natural language as intermediate responses. Subsequently, LLMs are asked to organize the output into the desired structure, using the intermediate responses as context. G&amp;O effectively separates the generation of content from the structuring process, reducing the pressure of completing two orthogonal tasks simultaneously. Tested on zero-shot NER and RE, the results indicate a significant improvement in LLM performance with minimal additional efforts. This straightforward and adaptable prompting technique can also be combined with other strategies, like self-consistency, to further elevate LLM capabilities in various structured text generation tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.295",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Rater Cohesion and Quality from a Vicarious Perspective": {
        "type": "INPROCEEDINGS",
        "key": "pandita-etal-2024-rater",
        "author": "Pandita, Deepak and Weerasooriya, Tharindu Cyril and Dutta, Sujan and Luger, Sarah K. K. and Ranasinghe, Tharindu and KhudaBukhsh, Ashiqur R. and Zampieri, Marcos and Homan, Christopher M.",
        "booktitle": "EMNLP-findings2024",
        "title": "Rater Cohesion and Quality from a Vicarious Perspective",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Human feedback is essential for building human-centered AI systems across domains where disagreement is prevalent, such as AI safety, content moderation, or sentiment analysis. Many disagreements, particularly in politically charged settings, arise because raters have opposing values or beliefs. Vicarious annotation is a method for breaking down disagreement by asking raters how they think others would annotate the data. In this paper, we explore the use of vicarious annotation with analytical methods for moderating rater disagreement. We employ rater cohesion metrics to study the potential influence of political affiliations and demographic backgrounds on raters\u2019 perceptions of offense. Additionally, we utilize CrowdTruth\u2019s rater quality metrics, which consider the demographics of the raters, to score the raters and their annotations. We study how the rater quality metrics influence the in-group and cross-group rater cohesion across the personal and vicarious levels.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.296",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-shall",
        "author": "Wu, Zengqing and Peng, Run and Zheng, Shuyuan and Liu, Qianying and Han, Xu and Kwon, Brian I. and Onizuka, Makoto and Tang, Shaojie and Xiao, Chuan",
        "booktitle": "EMNLP-findings2024",
        "title": "Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have increasingly been utilized in social simulations, where they are often guided by carefully crafted instructions to stably exhibit human-like behaviors during simulations. Nevertheless, we doubt the necessity of shaping agents\u2019 behaviors for accurate social simulations. Instead, this paper emphasizes the importance of spontaneous phenomena, wherein agents deeply engage in contexts and make adaptive decisions without explicit directions. We explored spontaneous cooperation across three competitive scenarios and successfully simulated the gradual emergence of cooperation, findings that align closely with human behavioral data. This approach not only aids the computational social science community in bridging the gap between simulations and real-world dynamics but also offers the AI community a novel method to assess LLMs\u2019 capability of deliberate reasoning.Our source code is available at https://github.com/wuzengqing001225/SABM_ShallWeTeamUp",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.297",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Normalized Narrow Jump To Conclusions: Normalized Narrow Shortcuts for Parameter Efficient Early Exit Transformer Prediction": {
        "type": "INPROCEEDINGS",
        "key": "seshadri-2024-normalized",
        "author": "Seshadri, Amrit Diggavi",
        "booktitle": "EMNLP-findings2024",
        "title": "Normalized Narrow Jump To Conclusions: Normalized Narrow Shortcuts for Parameter Efficient Early Exit Transformer Prediction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the size and cost of large transformer-based language models growing, recently, there has been interest in shortcut casting of early transformer hidden-representations to final-representations for cheaper model inference. In particular, shortcutting pre-trained transformers with linear transformations over early layers has been shown to improve precision in early inference. However, for large language models, even this becomes computationally expensive. In this work, we propose Narrow Jump to Conclusions (NJTC) and Normalized Narrow Jump to Conclusions (N-NJTC) - parameter efficient alternatives to standard linear shortcutting that reduces shortcut parameter count by over 97%. We show that N-NJTC reliably outperforms Identity shortcuts at early stages and offers stable precision from all transformer block levels for GPT-2-XL, Phi3-Mini and Llama2-7B transformer models, demonstrating the viability of more parameter efficient short-cutting approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.298",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items": {
        "type": "INPROCEEDINGS",
        "key": "roemmele-gordon-2024-test",
        "author": "Roemmele, Melissa and Gordon, Andrew",
        "booktitle": "EMNLP-findings2024",
        "title": "From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "LLMs can now perform a variety of complex writing tasks. They also excel in answering questions pertaining to natural language inference and commonsense reasoning. Composing these questions is itself a skilled writing task, so in this paper we consider LLMs as authors of commonsense assessment items. We prompt LLMs to generate items in the style of a prominent benchmark for commonsense reasoning, the Choice of Plausible Alternatives (COPA). We examine the outcome according to analyses facilitated by the LLMs and human annotation. We find that LLMs that succeed in answering the original COPA benchmark are also more successful in authoring their own items.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.299",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "\u201dI Never Said That\u201d: A dataset, taxonomy and baselines on response clarity classification": {
        "type": "INPROCEEDINGS",
        "key": "thomas-etal-2024-never",
        "author": "Thomas, Konstantinos and Filandrianos, Giorgos and Lymperaiou, Maria and Zerva, Chrysoula and Stamou, Giorgos",
        "booktitle": "EMNLP-findings2024",
        "title": "\u201dI Never Said That\u201d: A dataset, taxonomy and baselines on response clarity classification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Equivocation and ambiguity in public speech are well-studied discourse phenomena, especially in political science and analysis of political interviews. Inspired by the well-grounded theory on equivocation, we aim to resolve the closely related problem of response clarity in questions extracted from political interviews, leveraging the capabilities of Large Language Models (LLMs) and human expertise. To this end, we introduce a novel taxonomy that frames the task of detecting and classifying response clarity and a corresponding clarity classification dataset which consists of question-answer (QA) pairs drawn from political interviews and annotated accordingly. Our proposed two-level taxonomy addresses the clarity of a response in terms of the information provided for a given question (high-level) and also provides a fine-grained taxonomy of evasion techniques that relate to unclear, ambiguous responses (lower-level). We combine ChatGPT and human annotators to collect, validate and annotate discrete QA pairs from political interviews, to be used for our newly introduced response clarity task. We provide a detailed analysis and conduct several experiments with different model architectures, sizes and adaptation methods to gain insights and establish new baselines over the proposed dataset and task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.300",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Immunization against harmful fine-tuning attacks": {
        "type": "INPROCEEDINGS",
        "key": "rosati-etal-2024-immunization",
        "author": "Rosati, Domenic and Wehner, Jan and Williams, Kai and Bartoszcze, Lukasz and Sajjad, Hassan and Rudzicz, Frank",
        "booktitle": "EMNLP-findings2024",
        "title": "Immunization against harmful fine-tuning attacks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are often trained with safety guards intended to prevent harmful text generation. However, such safety training can be removed by fine-tuning the LLM on harmful datasets. While this emerging threat (harmful fine-tuning attacks) has been characterized by previous work, there is little understanding of how we should proceed in constructing and validating defenses against these attacks especially in the case where defenders would not have control of the fine-tuning process. We introduce a formal framework based on the training budget of an attacker which we call \u201cImmunization\u201d conditions. Using a formal characterisation of the harmful fine-tuning problem, we provide a thorough description of what a successful defense must comprise of and establish a set of guidelines on how rigorous defense research that gives us confidence should proceed.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.301",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause": {
        "type": "INPROCEEDINGS",
        "key": "hu-etal-2024-unimeec",
        "author": "Hu, Guimin and Zhu, Zhihong and Hershcovich, Daniel and Hu, Lijie and Seifi, Hasti and Xie, Jiayuan",
        "booktitle": "EMNLP-findings2024",
        "title": "UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion Cause",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal emotion recognition in conversation (MERC) and multimodal emotion-cause pair extraction (MECPE) have recently garnered significant attention. Emotions are the expression of affect or feelings; responses to specific events, or situations \u2013 known as emotion causes. Both collectively explain the causality between human emotion and intents. However, existing works treat emotion recognition and emotion cause extraction as two individual problems, ignoring their natural causality. In this paper, we propose a Unified Multimodal Emotion recognition and Emotion-Cause analysis framework (UniMEEC) to explore the causality between emotion and emotion cause. Concretely, UniMEEC reformulates the MERC and MECPE tasks as mask prediction problems and unifies them with a causal prompt template. To differentiate the modal effects, UniMEEC proposes a multimodal causal prompt to probe the pre-trained knowledge specified to modality and implements cross-task and cross-modality interactions under task-oriented settings. Experiment results on four public benchmark datasets verify the model performance on MERC and MECPE tasks and achieve consistent improvements compared with the previous state-of-the-art methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.302",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CodeFort: Robust Training for Code Generation Models": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-codefort",
        "author": "Zhang, Yuhao and Wang, Shiqi and Qian, Haifeng and Wang, Zijian and Shang, Mingyue and Liu, Linbo and Gouda, Sanjay Krishna and Ray, Baishakhi and Ramanathan, Murali Krishna and Ma, Xiaofei and Deoras, Anoop",
        "booktitle": "EMNLP-findings2024",
        "title": "CodeFort: Robust Training for Code Generation Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Code generation models are not robust to small perturbations, which often lead to incorrect generations and significantly degrade the performance of these models. Although improving the robustness of code generation models is crucial to enhancing user experience in real-world applications, existing research efforts do not address this issue. To fill this gap, we propose CodeFort, a framework to improve the robustness of code generation models, generalizing a large variety of code perturbations to enrich the training data and enabling various robust training strategies, mixing data augmentation, batch augmentation, adversarial logits pairing, and contrastive learning, all carefully designed to support high-throughput training. Extensive evaluations show that we increase the average robust pass rates of baseline CodeGen models from 14.79 to 21.74. We notably decrease the robustness drop rate from 95.02% to 54.95% against code-syntax perturbations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.303",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction": {
        "type": "INPROCEEDINGS",
        "key": "yang-li-2024-mp",
        "author": "Yang, Heng and Li, Ke",
        "booktitle": "EMNLP-findings2024",
        "title": "MP-RNA: Unleashing Multi-species RNA Foundation Model via Calibrated Secondary Structure Prediction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "RNA foundation models (FMs) have been extensively used to interpret genomic sequences and address a wide range of in-silico genomic tasks. However, current RNA FMs often overlook the incorporation of secondary structures in the pretraining of FMs, which impedes the effectiveness in various genomic tasks. To address this problem, we leverage filtered high-fidelity structure annotations for structure pretraining to enhance the modeling ability of FMs in single nucleotide resolution tasks. Experimental evaluations across four comprehensive genomic benchmarks demonstrate that our RNA FM consistently outperforms existing RNA FMs, achieving a 40% improvement in RNA secondary structure prediction and obtaining top-tier results on DNA genomic benchmarks even though it has not been pretrained on any DNA genome. We release the code and models to encourage further research to bridge the gap between in-silico predictions and biological reality.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.304",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "\u201cAny Other Thoughts, Hedgehog?\u201d Linking Deliberation Chains in Collaborative Dialogues": {
        "type": "INPROCEEDINGS",
        "key": "nath-etal-2024-thoughts",
        "author": "Nath, Abhijnan and Venkatesha, Videep and Bradford, Mariah and Chelle, Avyakta and Youngren, Austin C. and Mabrey, Carlos and Blanchard, Nathaniel and Krishnaswamy, Nikhil",
        "booktitle": "EMNLP-findings2024",
        "title": "\u201cAny Other Thoughts, Hedgehog?\u201d Linking Deliberation Chains in Collaborative Dialogues",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Question-asking in collaborative dialogue has long been established as key to knowledge construction, both in internal and collaborative problem solving. In this work, we examine probing questions in collaborative dialogues: questions that explicitly elicit responses from the speaker\u2019s interlocutors. Specifically, we focus on modeling the causal relations that lead directly from utterances earlier in the dialogue to the emergence of the probing question. We model these relations using a novel graph-based framework of *deliberation chains*, and realize the problem of constructing such chains as a coreference-style clustering problem. Our framework jointly models probing and causal utterances and the links between them, and we evaluate on two challenging collaborative task datasets: the Weights Task and DeliData. Our results demonstrate the effectiveness of our theoretically-grounded approach compared to both baselines and stronger coreference approaches, and establish a standard of performance in this novel task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.305",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evaluation of Question Answer Generation for Portuguese: Insights and Datasets": {
        "type": "INPROCEEDINGS",
        "key": "paula-etal-2024-evaluation",
        "author": "Paula, Felipe and Michelin, Cassiana Roberta Lizzoni and Moreira, Viviane",
        "booktitle": "EMNLP-findings2024",
        "title": "Evaluation of Question Answer Generation for Portuguese: Insights and Datasets",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automatic question generation is an increasingly important task that can be applied in different settings, including educational purposes, data augmentation for question-answering (QA), and conversational systems. More specifically, we focus on question answer generation (QAG), which produces question-answer pairs given an input context. We adapt and apply QAG approaches to generate question-answer pairs for different domains and assess their capacity to generate accurate, diverse, and abundant question-answer pairs. Our analyses combine both qualitative and quantitative evaluations that allow insights into the quality and types of errors made by QAG methods. We also look into strategies for error filtering and their effects. Our work concentrates on Portuguese, a widely spoken language that is underrepresented in natural language processing research. To address the pressing need for resources, we generate and make available human-curated extractive QA datasets in three diverse domains.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.306",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evolutionary Contrastive Distillation for Language Model Alignment": {
        "type": "INPROCEEDINGS",
        "key": "katz-samuels-etal-2024-evolutionary",
        "author": "Katz-Samuels, Julian and Li, Zheng and Yun, Hyokun and Nigam, Priyanka and Xu, Yi and Petricek, Vaclav and Yin, Bing and Chilimbi, Trishul",
        "booktitle": "EMNLP-findings2024",
        "title": "Evolutionary Contrastive Distillation for Language Model Alignment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The ability of large language models (LLMs) to execute complex instructions is essential for their real-world applications. However, several recent studies indicate that LLMs struggle with challenging instructions. In this paper, we propose Evolutionary Contrastive Distillation (ECD), a novel method for generating high-quality synthetic preference data designed to enhance the complex instruction-following capability of language models. ECD generates data that specifically illustrates the difference between a response that successfully follows a set of complex instructions and a response that is high-quality, but nevertheless makes some subtle mistakes. This is done by prompting LLMs to progressively evolve simple instructions to more complex instructions. When the complexity of an instruction is increased, the original successful response to the original instruction becomes a \u201chard negative\u201d response for the new instruction, mostly meeting requirements of the new instruction, but barely missing one or two. By pairing a good response with such a hard negative response, and employing contrastive learning algorithms such as DPO, we improve language models\u2019 ability to follow complex instructions. Empirically, we observe that our method yields a 7B model that exceeds the complex instruction-following performance of current SOTA 7B models and is competitive even with open-source 70B models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.307",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies": {
        "type": "INPROCEEDINGS",
        "key": "shea-yu-2024-fairness",
        "author": "Shea, Ryan and Yu, Zhou",
        "booktitle": "EMNLP-findings2024",
        "title": "A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite recent advancements in AI and NLP, negotiation remains a difficult domain for AI agents. Traditional game theoretic approaches that have worked well for two-player zero-sum games struggle in the context of negotiation due to their inability to learn human-compatible strategies. On the other hand, approaches that only use human data tend to be domain-specific and lack the theoretical guarantees provided by strategies grounded in game theory. Motivated by the notion of fairness as a criterion for optimality in general sum games, we propose a negotiation framework called FDHC which incorporates fairness into both the reward design and search to learn human-compatible negotiation strategies. Our method includes a novel, RL+search technique called LGM-Zero which leverages a pre-trained language model to retrieve human-compatible offers from large action spaces. Our results show that our method is able to achieve more egalitarian negotiation outcomes and improve negotiation quality.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.308",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media": {
        "type": "INPROCEEDINGS",
        "key": "mehta-goldwasser-2024-using",
        "author": "Mehta, Nikhil and Goldwasser, Dan",
        "booktitle": "EMNLP-findings2024",
        "title": "Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The large scale usage of social media, combined with its significant impact, has made it increasingly important to understand it. In particular, identifying user communities, can be helpful for many downstream tasks. However, particularly when models are trained on past data and tested on future, doing this is difficult.In this paper, we hypothesize to take advantage of Large Language Models (LLMs), to better identify user communities. Due to the fact that many LLMs, such as ChatGPT, are fixed and must be treated as black-boxes, we propose an approach to better prompt them, by training a smaller LLM to do this. We devise strategies to train this smaller model, showing how it can improve the larger LLMs ability to detect communities. Experimental results show improvements on Reddit and Twitter data, and the tasks of community detection, bot detection, and news media profiling.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.309",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues": {
        "type": "INPROCEEDINGS",
        "key": "kwon-etal-2024-llms",
        "author": "Kwon, Deuksin and Weiss, Emily and Kulshrestha, Tara and Chawla, Kushal and Lucas, Gale and Gratch, Jonathan",
        "booktitle": "EMNLP-findings2024",
        "title": "Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "A successful negotiation requires a range of capabilities, including comprehension of the conversation context, Theory-of-Mind (ToM) skills to infer the partner\u2019s motives, strategic reasoning, and effective communication, making it challenging for automated systems. Despite the remarkable performance of LLMs in various NLP tasks, there is no systematic evaluation of their capabilities in negotiation. Such an evaluation is critical for advancing AI negotiation agents and negotiation research, ranging from designing dialogue systems to providing pedagogical feedback and scaling up data collection practices. This work aims to systematically analyze the multifaceted capabilities of LLMs across diverse dialogue scenarios throughout the stages of a typical negotiation interaction. Our analysis highlights GPT-4\u2019s superior performance in many tasks while identifying specific challenges, such as making subjective assessments and generating contextually appropriate, strategically advantageous responses.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.310",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?": {
        "type": "INPROCEEDINGS",
        "key": "gao-etal-2024-raw",
        "author": "Gao, Yanjun and Myers, Skatje and Chen, Shan and Dligach, Dmitriy and Miller, Timothy A. and Bitterman, Danielle and Churpek, Matthew and Afshar, Majid",
        "booktitle": "EMNLP-findings2024",
        "title": "When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The introduction of Large Language Models (LLMs) has advanced data representation and analysis, bringing significant progress in their use for medical questions and answering. Despite these advancements, integrating tabular data, especially numerical data pivotal in clinical contexts, into LLM paradigms has not been thoroughly explored. In this study, we examine the effectiveness of vector representations from last hidden states of LLMs for medical diagnostics and prognostics using electronic health record (EHR) data. We compare the performance of these embeddings with that of raw numerical EHR data when used as feature inputs to traditional machine learning (ML) algorithms that excel at tabular data learning, such as eXtreme Gradient Boosting. We focus on instruction-tuned LLMs in a zero-shot setting to represent abnormal physiological data and evaluating their utilities as feature extractors to enhance ML classifiers for predicting diagnoses, length of stay, and mortality. Furthermore, we examine prompt engineering techniques on zero-shot and few-shot LLM embeddings to measure their impact comprehensively. Although findings suggest the raw data features still prevail in medical ML tasks, zero-shot LLM embeddings demonstrate competitive results, suggesting a promising avenue for future research in medical applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.311",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts": {
        "type": "INPROCEEDINGS",
        "key": "sharma-etal-2024-losing",
        "author": "Sharma, Aditya and Saxon, Michael and Wang, William Yang",
        "booktitle": "EMNLP-findings2024",
        "title": "Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We present LoCoVQA, a dynamic benchmark generator for evaluating long-context reasoning in vision language models (VLMs). LoCoVQA augments test examples for mathematical reasoning, VQA, and character recognition tasks with increasingly long visual contexts composed of both in-distribution and out-of-distribution distractor images.Across these tasks, a diverse set of VLMs rapidly lose performance as the visual context length grows, often exhibiting a striking logarithmic decay trend. This test assesses how well VLMs can ignore irrelevant information when answering queries\u2014a task that is quite easy for language models (LMs) in the text domain\u2014demonstrating that current state-of-the-art VLMs lack this essential capability for many long-context applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.312",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-calibrating",
        "author": "Li, Jiazheng and Xu, Hainiu and Sun, Zhaoyue and Zhou, Yuxiang and West, David and Aloisi, Cesare and He, Yulan",
        "booktitle": "EMNLP-findings2024",
        "title": "Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generating rationales that justify scoring decisions has been a promising way to facilitate explainability in automated scoring systems. However, existing methods do not match the accuracy of classifier-based methods. Plus, the generated rationales often contain hallucinated information. To address these issues, we propose a novel framework capable of generating more faithful rationales and, more importantly, matching performance with classifier-based black-box scoring systems. We first mimic the human assessment process by querying Large Language Models (LLMs) to generate a thought tree. We then summarise intermediate assessment decisions from each thought tree path for creating synthetic rationale data and rationale preference data. Finally, we utilise the generated synthetic data to calibrate LLMs through a two-step training process: supervised fine-tuning and preference optimization. Extensive experimental results demonstrate that our framework achieves a 38% assessment performance improvement in the QWK score compared to prior work while producing higher-quality rationales, as recognised by human evaluators and LLMs. Our work sheds light on the effectiveness of performing preference optimization using synthetic preference data obtained from thought tree paths. Data and code are available at: https://github.com/lijiazheng99/thought_tree_assessment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.313",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LOCR: Location-Guided Transformer for Optical Character Recognition": {
        "type": "INPROCEEDINGS",
        "key": "sun-etal-2024-locr",
        "author": "Sun, Yu and Zhou, Dongzhan and Lin, Chen and He, Conghui and Ouyang, Wanli and Zhong, Han-Sen",
        "booktitle": "EMNLP-findings2024",
        "title": "LOCR: Location-Guided Transformer for Optical Character Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues, especially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this issue, we propose LOCR, a model that integrates location guiding into the transformer architecture during autoregression. We train the model on an original large-scale dataset comprising over 53M text-location pairs from 89K academic document pages, including bounding boxes for words, tables and mathematical symbols. LOCR adeptly handles various formatting elements and generates content in Markdown language. It outperforms all existing methods in our test set constructed from arXiv.LOCR also eliminates repetition in the arXiv dataset, and reduces repetition frequency in OOD documents, from 13.19% to 0.04% for natural science documents. Additionally, LOCR features an interactive OCR mode, facilitating the generation of complex documents through a few location prompts from human.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.314",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Sing it, Narrate it: Quality Musical Lyrics Translation": {
        "type": "INPROCEEDINGS",
        "key": "ye-etal-2024-sing",
        "author": "Ye, Zhuorui and Li, Jinhan and Xu, Rongwu",
        "booktitle": "EMNLP-findings2024",
        "title": "Sing it, Narrate it: Quality Musical Lyrics Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Translating lyrics for musicals presents unique challenges due to the need to ensure high translation quality while adhering to singability requirements such as length and rhyme. Existing song translation approaches often prioritize these singability constraints at the expense of translation quality, which is crucial for musicals. This paper aims to enhance translation quality while maintaining key singability features. Our method consists of three main components. First, we create a dataset to train reward models for the automatic evaluation of translation quality. Second, to enhance both singability and translation quality, we implement a two-stage training process with filtering techniques. Finally, we introduce an inference-time optimization framework for translating entire songs. Extensive experiments, including both automatic and human evaluations, demonstrate significant improvements over baseline methods and validate the effectiveness of each component in our approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.315",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring Automated Keyword Mnemonics Generation with Large Language Models via Overgenerate-and-Rank": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-exploring-automated",
        "author": "Lee, Jaewook and McNichols, Hunter and Lan, Andrew",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring Automated Keyword Mnemonics Generation with Large Language Models via Overgenerate-and-Rank",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we study an under-explored area of language and vocabulary learning: keyword mnemonics, a technique for memorizing vocabulary through memorable associations with a target word via a verbal cue. Typically, creating verbal cues requires extensive human effort and is quite time-consuming, necessitating an automated method that is more scalable. We propose a novel overgenerate-and-rank method via prompting large language models (LLMs) to generate verbal cues and then ranking them according to psycholinguistic measures and takeaways from a pilot user study. To assess cue quality, we conduct both an automated evaluation of imageability and coherence, as well as a human evaluation involving English teachers and learners. Results show that LLM-generated mnemonics are comparable to human-generated ones in terms of imageability, coherence, and perceived usefulness, but there remains plenty of room for improvement due to the diversity in background and preference among language learners.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.316",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Dual-teacher Knowledge Distillation for Low-frequency Word Translation": {
        "type": "INPROCEEDINGS",
        "key": "guo-etal-2024-dual",
        "author": "Guo, Yifan and Zan, Hongying and Xu, Hongfei",
        "booktitle": "EMNLP-findings2024",
        "title": "Dual-teacher Knowledge Distillation for Low-frequency Word Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Neural Machine Translation (NMT) models are trained on parallel corpora with unbalanced word frequency distribution. As a result, NMT models are likely to prefer high-frequency words than low-frequency ones despite low-frequency word may carry the crucial semantic information, which may hamper the translation quality once they are neglected. The objective of this study is to enhance the translation of meaningful but low-frequency words. Our general idea is to optimize the translation of low-frequency words through knowledge distillation. Specifically, we employ a low-frequency teacher model that excels in translating low-frequency words to guide the learning of the student model. To remain the translation quality of high-frequency words, we further introduce a dual-teacher distillation framework, leveraging both the low-frequency and high-frequency teacher models to guide the student model\u2019s training. Our single-teacher distillation method already achieves a +0.64 BLEU improvements over the state-of-the-art method on the WMT 16 English-to-German translation task on the low-frequency test set. While our dual-teacher framework leads to +0.87, +1.24, +0.47, +0.87 and +0.86 BLEU improvements on the IWSLT 14 German-to-English, WMT 16 English-to-German, WMT 15 English-to-Czech, WMT 14 English-to-French and WMT 18 Chinese-to-English tasks respectively compared to the baseline, while maintaining the translation performance of high-frequency words.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.317",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Simple Angle-based Approach for Contrastive Learning of Unsupervised Sentence Representation": {
        "type": "INPROCEEDINGS",
        "key": "jeong-etal-2024-simple-angle",
        "author": "Jeong, Yoo Hyun and Han, Myeongsoo and Chae, Dong-Kyu",
        "booktitle": "EMNLP-findings2024",
        "title": "A Simple Angle-based Approach for Contrastive Learning of Unsupervised Sentence Representation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Contrastive learning has been successfully adopted in VRL (visual representation learning) by constructing effective contrastive pairs. A promising baseline SimCSE has made notable breakthroughs in unsupervised SRL (sentence representation learning) following the success of contrastive learning. However, considering the difference between VRL and SRL, there is still room for designing a novel contrastive framework specially targeted for SRL. We pro- pose a novel angle-based similarity function for contrastive objective. By examining the gra- dient of our contrastive objective, we show that an angle-based similarity function incites better training dynamics on SRL than the off-the-shelf cosine similarity: (1) effectively pulling a posi- tive instance toward an anchor instance in the early stage of training and (2) not excessively repelling a false negative instance during the middle of training. Our experimental results on widely-utilized benchmarks demonstrate the ef- fectiveness and extensibility of our novel angle- based approach. Subsequent analyses establish its improved sentence representation power.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.318",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "kimyeeun-etal-2024-developing",
        "author": "Kim, Yeeun and Choi, Youngrok and Choi, Eunkyung and Choi, JinHwan and Park, Hai Jin and Hwang, Wonseok",
        "booktitle": "EMNLP-findings2024",
        "title": "Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have demonstrated remarkable performance in the legal domain, with GPT-4 even passing the Uniform Bar Exam in the U.S. However their efficacy remains limited for non-standardized tasks and tasks in languages other than English. This underscores the need for careful evaluation of LLMs within each legal system before application.Here, we introduce KBL, a benchmark for assessing the Korean legal language understanding of LLMs, consisting of (1) 7 legal knowledge tasks (510 examples), (2) 4 legal reasoning tasks (288 examples), and (3) the Korean bar exam (4 domains, 53 tasks, 2,510 examples). First two datasets were developed in close collaboration with lawyers to evaluate LLMs in practical scenarios in a certified manner. Furthermore, considering legal practitioners\u2019 frequent use of extensive legal documents for research, we assess LLMs in both a closed book setting, where they rely solely on internal knowledge, and a retrieval-augmented generation (RAG) setting, using a corpus of Korean statutes and precedents. The results indicate substantial room and opportunities for improvement.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.319",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Visual Pivoting Unsupervised Multimodal Machine Translation in Low-Resource Distant Language Pairs": {
        "type": "INPROCEEDINGS",
        "key": "tayir-etal-2024-visual",
        "author": "Tayir, Turghun and Li, Lin and Tao, Xiaohui and Maimaiti, Mieradilijiang and Li, Ming and Liu, Jianquan",
        "booktitle": "EMNLP-findings2024",
        "title": "Visual Pivoting Unsupervised Multimodal Machine Translation in Low-Resource Distant Language Pairs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Unsupervised multimodal machine translation (UMMT) aims to leverage vision information as a pivot between two languages to achieve better performance on low-resource language pairs. However, there is presently a challenge: how to handle alignment between distant language pairs (DLPs) in UMMT. To this end, this paper proposes a visual pivoting UMMT method for DLPs. Specifically, we first construct a dataset containing two DLPs, including English-Uyghur and Chinese-Uyghur. We then apply the visual pivoting method for both to pre-training and fine-tuning, and we observe that the images on the encoder and decoder of UMMT have noticeable effects on DLPs. Finally, we introduce informative multi-granularity image features to facilitate further alignment of the latent space between the two languages. Experimental results show that the proposed method significantly outperforms several baselines on DLPs and close language pairs (CLPs).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.320",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-scalable-fine",
        "author": "Li, Dongyue and Zhang, Ziniu and Wang, Lu and Zhang, Hongyang R.",
        "booktitle": "EMNLP-findings2024",
        "title": "Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We study the problem of fine-tuning a language model (LM) for a target task by optimally using the information from n auxiliary tasks. This problem has broad applications in NLP, such as targeted instruction tuning and data selection in chain-of-thought fine-tuning. The key challenge of this problem is that not all auxiliary tasks are useful to improve the performance of the target task. Thus, choosing the right subset of auxiliary tasks is crucial. Conventional subset selection methods, such as forward &amp; backward selection, are unsuitable for LM fine-tuning because they require repeated training on subsets of auxiliary tasks. This paper introduces a new algorithm to estimate model fine-tuning performances without repeated training. Our algorithm first performs multitask training using the data of all the tasks to obtain a meta initialization. Then, we approximate the model fine-tuning loss of a subset using functional values and gradients from the meta initialization. Empirically, we find that this gradient-based approximation holds with remarkable accuracy for twelve transformer-based LMs. Thus, we can now estimate fine-tuning performances on CPUs within a few seconds. We conduct extensive experiments to validate our approach, delivering a speedup of 30\\times over conventional subset selection while incurring only 1% error of the true fine-tuning performances. In downstream evaluations of instruction tuning and chain-of-thought fine-tuning, our approach improves over prior methods that utilize gradient or representation similarity for subset selection by up to 3.8%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.321",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models": {
        "type": "INPROCEEDINGS",
        "key": "han-etal-2024-context",
        "author": "Han, Pengrui and Song, Peiyang and Yu, Haofei and You, Jiaxuan",
        "booktitle": "EMNLP-findings2024",
        "title": "In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in artificial intelligence have led to the creation of highly capable large language models (LLMs) that can perform tasks in a human-like manner. However, LLMs exhibit only infant-level cognitive abilities in certain areas. One such area is the A-Not-B error, a phenomenon seen in infants where they repeat a previously rewarded behavior despite well-observed changed conditions. This highlights their lack of inhibitory control \u2013 the ability to stop a habitual or impulsive response. In our work, we design a text-based multi-choice QA scenario similar to the A-Not-B experimental settings to systematically test the inhibitory control abilities of LLMs. We found that state-of-the-art LLMs (like Llama3-8b) perform consistently well with in-context learning (ICL) but make errors and show a significant drop of as many as 83.3% in reasoning tasks when the context changes trivially. This suggests that LLMs only have inhibitory control abilities on par with human infants in this regard, often failing to suppress the previously established response pattern during ICL.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.322",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula": {
        "type": "INPROCEEDINGS",
        "key": "lucy-etal-2024-mathfish",
        "author": "Lucy, Li and August, Tal and Wang, Rose E. and Soldaini, Luca and Allison, Courtney and Lo, Kyle",
        "booktitle": "EMNLP-findings2024",
        "title": "MathFish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To ensure that math curriculum is grade-appropriate and aligns with critical skills or concepts in accordance with educational standards, pedagogical experts can spend months carefully reviewing published math problems. Drawing inspiration from this process, our work presents a novel angle for evaluating language models\u2019 (LMs) mathematical abilities, by investigating whether they can discern skills and concepts enabled by math content. We contribute two datasets: one consisting of 385 fine-grained descriptions of K-12 math skills and concepts, or *standards*, from Achieve the Core (*ATC*), and another of 9.9K math problems labeled with these standards (*MathFish*). We develop two tasks for evaluating LMs\u2019 abilities to assess math problems: (1) verifying whether a problem aligns with a given standard, and (2) tagging a problem with all aligned standards. Working with experienced teachers, we find that LMs struggle to tag and verify standards linked to problems, and instead predict labels that are close to ground truth, but differ in subtle ways. We also show that LMs often generate problems that do not fully align with standards described in prompts, suggesting the need for careful scrutiny on use cases involving LMs for generating curricular materials. Finally, we categorize problems in GSM8k using math standards, allowing us to better understand why some problems are more difficult to solve for models than others.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.323",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Multi-Label Text Classification under Label-Dependent Noise: A Label-Specific Denoising Framework": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-enhancing",
        "author": "Xu, Pengyu and Jing, Liping and Yu, Jian",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Multi-Label Text Classification under Label-Dependent Noise: A Label-Specific Denoising Framework",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in noisy multi-label text classification have primarily relied on the class-conditional noise (CCN) assumption, which treats each label independently undergoing label flipping to generate noisy labels. However, in real-world scenarios, noisy labels often exhibit dependencies with true labels. In this study, we validate through hypothesis testing that real-world datasets are unlikely to adhere to the CCN assumption, indicating that label noise is dependent on the labels. To address this, we introduce a label-specific denoising framework designed to counteract label-dependent noise. The framework initially presents a holistic selection metric that evaluates noisy labels by concurrently considering loss information, ranking information, and feature centroid. Subsequently, it identifies and corrects noisy labels individually for each label category in a fine-grained manner. Extensive experiments on benchmark datasets demonstrate the effectiveness of our method under both synthetic and real-world noise conditions, significantly improving performance over existing state-of-the-art models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.324",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Automatic Reconstruction of Ancient Chinese Pronunciations": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-automatic",
        "author": "Huang, Zhige and Jin, Haoan and Wu, Mengyue and Zhu, Kenny Q.",
        "booktitle": "EMNLP-findings2024",
        "title": "Automatic Reconstruction of Ancient Chinese Pronunciations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reconstructing ancient Chinese pronunciation is a challenging task due to the scarcity of phonetic records. Different from historical linguistics\u2019 comparative approaches, we reformulate this problem into a temporal prediction task with masked language models, digitizing existing phonology rules into ACP (Ancient Chinese Phonology) dataset of 70,943 entries for 17,001 Chinese characters. Utilizing this dataset and Chinese character glyph information, our transformer-based model demonstrates superior performance on a series of reconstruction tasks, with or without prior phonological knowledge on the target historical period. Our work significantly advances the digitization and computational reconstruction of ancient Chinese phonology, providing a more complete and temporally contextualized resource for computational linguistics and historical research. The dataset and model training code are publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.325",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-instance",
        "author": "Wang, Zhiqi and He, Shizhu and Liu, Kang and Zhao, Jun",
        "booktitle": "EMNLP-findings2024",
        "title": "Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models perform well on tasks that have undergone fine-tuning of instructions, but their performance on completely unseen tasks is often less than ideal. To overcome the challenge of cross-task generalization, task-level LoRAs combination is proposed, which does not require training a model for new tasks. Instead, it learns the LoRA modules combination weights based on a small number of samples to form the task model. However, task-level LoRAs combination only utilizes a few task modules due to its reliance on the weight enumeration method, and it also ignores the specificity between different instances. Therefore, we proposed an instance-level LoRAs composition for cross-task generalization, which selects appropriate multiple task LoRA modules for each input instance and dynamically determines the composition weights. Our experiments on publicly available datasets show that our method outperforms the typical method, LoraHub, in 16 out of 27 tasks. We release the source code at https://github.com/noname822/iLoraComp.git",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.326",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LongWanjuan: Towards Systematic Measurement for Long Text Quality": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-longwanjuan",
        "author": "Liu, Xiaoran and Lv, Kai and Guo, Qipeng and Yan, Hang and He, Conghui and Qiu, Xipeng and Lin, Dahua",
        "booktitle": "EMNLP-findings2024",
        "title": "LongWanjuan: Towards Systematic Measurement for Long Text Quality",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The quality of training data is crucial for enhancing the long-text capabilities of foundation models. Despite existing efforts to refine data quality through heuristic rules and evaluations based on data diversity and difficulty, there\u2019s a lack of systematic approaches specifically tailored for assessing long texts. Addressing this gap, our work systematically measures the quality of long texts by evaluating three fundamental linguistic dimensions: coherence, cohesion, and complexity. Drawing inspiration from the aforementioned three dimensions, we introduce a suite of metrics designed to evaluate the quality of long texts, encompassing both statistical and pre-trained language model-based ones. Leveraging these metrics, we present LongWanjuan, a bilingual dataset specifically tailored to enhance the training of language models for long-text tasks with over 160B tokens. In LongWanjuan, we categorize long texts into holistic, aggregated, and chaotic types, enabling a detailed analysis of long-text quality. Furthermore, we devise a data mixture recipe that strategically balances different types of long texts within LongWanjuan, leading to significant improvements in model performance on long-text tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.327",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Model for Multi-Domain Translation: Benchmarking and Domain CoT Fine-tuning": {
        "type": "INPROCEEDINGS",
        "key": "hu-etal-2024-large-language",
        "author": "Hu, Tianxiang and Zhang, Pei and Yang, Baosong and Xie, Jun and Wong, Derek F. and Wang, Rui",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Model for Multi-Domain Translation: Benchmarking and Domain CoT Fine-tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Achieving consistent high-quality machine translation (MT) across diverse domains remains a significant challenge, primarily due to the limited and imbalanced parallel training data available in various domains. While large language models (LLMs) have demonstrated impressive general understanding and generation abilities, their potential in multi-domain MT is under-explored. We establish a comprehensive benchmark for multi-domain translation, featuring 25 German\u21d4English and 22 Chinese\u21d4English test sets respectively covering 15 domains. Our evaluation of prominent LLMs reveals a discernible performance gap against traditional MT systems, highlighting domain overfitting and catastrophic forgetting issues after fine-tuning on domain-limited corpora. To mitigate this, we propose a domain Chain of Thought (CoT) fine-tuning technique that utilizes the intrinsic multi-domain intelligence of LLMs to improve translation performance. This method inspires the LLM to perceive domain information from the source text, which then serves as a helpful hint to guide the translation process. Despite being trained on a small dataset of four domains, our CoT fine-tune approach achieves notable enhancements in translation accuracy and domain robustness than traditional fine-tuning, as evidenced by an average 1.53 BLEU score increase in over 20 German\u2192English distinct out-of-domain tests.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.328",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage": {
        "type": "INPROCEEDINGS",
        "key": "lu-etal-2024-triageagent",
        "author": "Lu, Meng and Ho, Brandon and Ren, Dennis and Wang, Xuan",
        "booktitle": "EMNLP-findings2024",
        "title": "TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The global escalation in emergency department patient visits poses significant challenges to efficient clinical management, particularly in clinical triage. Traditionally managed by human professionals, clinical triage is susceptible to substantial variability and high workloads. Although large language models (LLMs) demonstrate promising reasoning and understanding capabilities, directly applying them to clinical triage remains challenging due to the complex and dynamic nature of the clinical triage task. To address these issues, we introduce TriageAgent, a novel heterogeneous multi-agent framework designed to enhance collaborative decision-making in clinical triage. TriageAgent leverages LLMs for role-playing, incorporating self-confidence and early-stopping mechanisms in multi-round discussions to improve document reasoning and classification precision for triage tasks. In addition, TriageAgent employs the medical Emergency Severity Index (ESI) handbook through a retrieval-augmented generation (RAG) approach to provide precise clinical knowledge and integrates both coarse- and fine-grained ESI-level predictions in the decision-making process. Extensive experiments demonstrate that TriageAgent outperforms state-of-the-art LLM-based methods on three clinical triage test sets. Furthermore, we have released the first public benchmark dataset for clinical triage with corresponding ESI levels and human expert performance for comparison.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.329",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Generative Deduplication For Socia Media Data Selection": {
        "type": "INPROCEEDINGS",
        "key": "li-li-2024-generative",
        "author": "Li, Xianming and Li, Jing",
        "booktitle": "EMNLP-findings2024",
        "title": "Generative Deduplication For Socia Media Data Selection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Social media data exhibits severe redundancy caused by its noisy nature. It leads to increased training time and model bias in its processing. To address this issue, we propose a novel Generative Deduplication framework for social media data selection by removing semantically duplicate data. While related work involves data selection in the task-specific training, our model functions as an efficient pre-processing method to universally enhance social media NLP pipelines. Specifically, we train a generative model via self-supervised learning to predict keyword to capture the semantics of noisy social media text for deduplication. Meanwhile, time-dimensional Gaussian noise is added to improve training complexity and avoid learning trivial features. Extensive experiments suggest that our model can better reduce training samples while improving performance than baselines. The results show our model\u2019s potential to broadly advance social media language understanding in effectiveness and efficiency.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.330",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts": {
        "type": "INPROCEEDINGS",
        "key": "levy-etal-2024-gender",
        "author": "Levy, Sharon and Adler, William and Karver, Tahilin Sanchez and Dredze, Mark and Kaufman, Michelle R.",
        "booktitle": "EMNLP-findings2024",
        "title": "Gender Bias in Decision-Making with Large Language Models: A Study of Relationship Conflicts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) acquire beliefs about gender from training data and can therefore generate text with stereotypical gender attitudes. Prior studies have demonstrated model generations favor one gender or exhibit stereotypes about gender, but have not investigated the complex dynamics that can influence model reasoning and decision-making involving gender. We study gender equity within LLMs through a decision-making lens with a new dataset, DeMET Prompts, containing scenarios related to intimate, romantic relationships. We explore nine relationship configurations through name pairs across three name lists (men, women, neutral). We investigate equity in the context of gender roles through numerous lenses: typical and gender-neutral names, with and without model safety enhancements, same and mixed-gender relationships, and egalitarian versus traditional scenarios across various topics. While all models exhibit the same biases (women favored, then those with gender-neutral names, and lastly men), safety guardrails reduce bias. In addition, models tend to circumvent traditional male dominance stereotypes and side with \u201ctraditionally female\u201d individuals more often, suggesting relationships are viewed as a female domain by the models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.331",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evaluating Biases in Context-Dependent Sexual and Reproductive Health Questions": {
        "type": "INPROCEEDINGS",
        "key": "levy-etal-2024-evaluating",
        "author": "Levy, Sharon and Karver, Tahilin Sanchez and Adler, William and Kaufman, Michelle R. and Dredze, Mark",
        "booktitle": "EMNLP-findings2024",
        "title": "Evaluating Biases in Context-Dependent Sexual and Reproductive Health Questions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Chat-based large language models have the opportunity to empower individuals lacking high-quality healthcare access to receive personalized information across a variety of topics. However, users may ask underspecified questions that require additional context for a model to correctly answer. We study how large language model biases are exhibited through these contextual questions in the healthcare domain. To accomplish this, we curate a dataset of sexual and reproductive healthcare questions (ContextSRH) that are dependent on age, sex, and location attributes. We compare models\u2019 outputs with and without demographic context to determine answer alignment among our contextual questions. Our experiments reveal biases in each of these attributes, where young adult female users are favored.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.332",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-Evaluation of Large Language Model based on Glass-box Features": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-self",
        "author": "Huang, Hui and Qu, Yingqi and Liu, Jing and Yang, Muyun and Xu, Bing and Zhao, Tiejun and Lu, Wenpeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-Evaluation of Large Language Model based on Glass-box Features",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The proliferation of open-source Large Language Models (LLMs) underscores the pressing need for evaluation methods. Existing works primarily rely on external evaluators, focusing on training and prompting strategies. However, a crucial aspect \u2013 model-aware glass-box features \u2013 is overlooked. In this study, we explore the utility of glass-box features under the scenario of self-evaluation, namely applying an LLM to evaluate its own output. We investigate various glass-box feature groups and discovered that the softmax distribution serves as a reliable quality indicator for self-evaluation. Experimental results on public benchmarks validate the feasibility of self-evaluation of LLMs using glass-box features.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.333",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "FASTTRACK: Reliable Fact Tracing via Clustering and LLM-Powered Evidence Validation": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-fasttrack",
        "author": "Chen, Si and Kang, Feiyang and Yu, Ning and Jia, Ruoxi",
        "booktitle": "EMNLP-findings2024",
        "title": "FASTTRACK: Reliable Fact Tracing via Clustering and LLM-Powered Evidence Validation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Fact tracing seeks to identify specific training examples that serve as the knowledge source for a given query. Existing approaches to fact tracing rely on assessing the similarity between each training sample and the query along a certain dimension, such as lexical similarity, gradient, or embedding space. However, these methods fall short of effectively distinguishing between samples that are merely relevant and those that actually provide supportive evidence for the information sought by the query. This limitation often results in suboptimal effectiveness. Moreover, these approaches necessitate the examination of the similarity of individual training points for each query, imposing significant computational demands and creating a substantial barrier for practical applications. This paper introduces FASTTRACK, a novel approach that harnesses the capabilities of Large Language Models (LLMs) to validate supportive evidence for queries and at the same time clusters the training database towards a reduced extent for LLMs to trace facts. Our experiments show that FASTTRACK substantially outperforms existing methods in both accuracy and efficiency, achieving more than 100% improvement in F1 score over the state-of-the-art methods while being x33 faster than TracIn.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.334",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PKAD: Pretrained Knowledge is All You Need to Detect and Mitigate Textual Backdoor Attacks": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-pkad",
        "author": "Chen, Yu and Cao, Qi and Zhang, Kaike and Liu, Xuchao and Shen, Huawei",
        "booktitle": "EMNLP-findings2024",
        "title": "PKAD: Pretrained Knowledge is All You Need to Detect and Mitigate Textual Backdoor Attacks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In textual backdoor attacks, attackers insert poisoned samples with triggered inputs and target labels into training datasets to manipulate model behavior, threatening the model\u2019s security and reliability. Current defense methods can generally be categorized into inference-time and training-time ones. The former often requires a part of clean samples to set detection thresholds, which may be hard to obtain in practical application scenarios, while the latter usually requires an additional retraining or unlearning process to get a clean model, significantly increasing training costs. To avoid these drawbacks, we focus on developing a practical defense method before model training without using any clean samples. Our analysis reveals that with the help of a pre-trained language model (PLM), poisoned samples, different from clean ones, exhibit mismatched relationship and shared characteristics. Based on these observations, we further propose a two-stage poison detection strategy solely leveraging insights from PLM before model training. Extensive experiments confirm our approach\u2019s effectiveness, achieving better performance than current leading methods more swiftly. Our code is available at https://github.com/Ascian/PKAD.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.335",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Merely Judging Metaphor is Not Enough: Research on Reasonable Metaphor Detection": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-merely",
        "author": "Chen, Puli and Yang, Cheng and Huang, Qingbao",
        "booktitle": "EMNLP-findings2024",
        "title": "Merely Judging Metaphor is Not Enough: Research on Reasonable Metaphor Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Metaphor, as an advanced form of cognition, is challenging to understand their meaning. Current metaphor detection tasks only provide labels (i.e., metaphor or literal) without interpreting how to understand them. In this paper, we improve the metaphor detection task and explore the reason of metaphor. To the best of our knowledge, we are the first work to reason about metaphor using mainstream Large Language Models (LLMs). Specifically, we utilized ChatGPT3.5 to expand the mainstream datasets in current metaphor detection, including VUA ALL, TroFi, and MOH-X. We input the original sentence, target word, and usage (metaphor or literal) into ChatGPT, guiding it to generate corresponding metaphor reason. Then, we designed supervised baseline experiments (e.g., RoBERTa, GPT-2) and zero-shot experiments with LLMs (e.g., LLaMA3). For the results generated by the above experiments, we provided the case study. We devised four methods that include manual evaluation to evaluate the reason performance of the model, and discussed extensively the advantages and disadvantages of these evaluation methods. Our code is available at https://github.com/yc-cy/Metaphorical-Reasoning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.336",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can we teach language models to gloss endangered languages?": {
        "type": "INPROCEEDINGS",
        "key": "ginn-etal-2024-teach",
        "author": "Ginn, Michael and Hulden, Mans and Palmer, Alexis",
        "booktitle": "EMNLP-findings2024",
        "title": "Can we teach language models to gloss endangered languages?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Interlinear glossed text (IGT) is a popular format in language documentation projects, where each morpheme is labeled with a descriptive annotation. Automating the creation of interlinear glossed text would be desirable to reduce annotator effort and maintain consistency across annotated corpora. Prior research has explored a number of statistical and neural methods for automatically producing IGT. As large language models (LLMs) have showed promising results across multilingual tasks, even for rare, endangered languages, it is natural to wonder whether they can be utilized for the task of generating IGT. We explore whether LLMs can be effective at the task of interlinear glossing with in-context learning, without any traditional training. We propose new approaches for selecting examples to provide in-context, observing that targeted selection can significantly improve performance. We find that LLM-based methods beat standard transformer baselines, despite requiring no training at all. These approaches still underperform state-of-the-art supervised systems for the task, but are highly practical for researchers outside of the NLP community, requiring minimal effort to use.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.337",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On the token distance modeling ability of higher RoPE attention dimension": {
        "type": "INPROCEEDINGS",
        "key": "hong-etal-2024-token",
        "author": "Hong, Xiangyu and Jiang, Che and Qi, Biqing and Meng, Fandong and Yu, Mo and Zhou, Bowen and Zhou, Jie",
        "booktitle": "EMNLP-findings2024",
        "title": "On the token distance modeling ability of higher RoPE attention dimension",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Length extrapolation algorithms based on Rotary position embedding (RoPE) have shown promising results in extending the context length of language models. However, understanding how position embedding can capture longer-range contextual information remains elusive. Based on the intuition that different dimensions correspond to different frequency of changes in RoPE encoding, we conducted a dimension-level analysis to investigate the correlation between a hidden dimension of an attention head and its contribution to capturing long-distance dependencies. Using our correlation metric, we identified a particular type of attention heads, which we named Positional Heads, from various length-extrapolated models. These heads exhibit a strong focus on long-range information interaction and play a pivotal role in long input processing, as evidence by our ablation. We further demonstrate the correlation between the efficiency of length extrapolation and the extension of the high-dimensional attention allocation of these heads. The identification of Positional Heads provides insights for future research in long-text comprehension.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.338",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Byzantine-Resistant Aggregations with Client Embedding": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-enhancing-byzantine",
        "author": "Zhang, Zhiyuan and Zhou, Hao and Meng, Fandong and Zhou, Jie and Sun, Xu",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Byzantine-Resistant Aggregations with Client Embedding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Byzantine-resistant aggregations detect poisonous clients and discard them to ensure that the global model is not poisoned or attacked by malicious clients. However, these aggregations are mainly conducted on the parameter space, and the parameter distances cannot reflect the data distribution divergences between clients. Therefore, existing Byzantine-resistant aggregations cannot defend against backdoor injection by malicious attackers in federated natural language tasks. In this paper, we propose the client embedding for malicious client detection to enhance Byzantine-resistant aggregations. The distances between client embeddings are required to reflect the data distribution divergences of the corresponding clients. Experimental results validate the effectiveness of the proposed client embeddings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.339",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploiting Careful Design of SVM Solution for Aspect-term Sentiment Analysis": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-exploiting",
        "author": "Liu, Hanfeng and Chen, Minping and Zheng, Zhenya and Wen, Zeyi",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploiting Careful Design of SVM Solution for Aspect-term Sentiment Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Aspect-term sentiment analysis (ATSA) identifies fine-grained sentiments towards specific aspects of the text. While pre-trained language models (PLMs) have set the state-of-the-art (SOTA) for ATSA, they are resource-intensive due to their large model sizes, restricting their wide applications to resource-constrained scenarios. Conversely, conventional machine learning methods, such as Support Vector Machines (SVMs), offer the benefit of less resource requirement but have lower predictive accuracy. This paper introduces an innovative pipeline, termed SVM-ATSA, which bridges the gap between the accuracy of SVM-based methods and the efficiency of PLM-based methods. To improve the feature expression of SVMs and better adapt to the ATSA task, SVM-ATSA decomposes the learning problem into multiple view subproblems, and dynamically selects as well as constructs features with reinforcement learning. The experimental results demonstrate that SVM-ATSA surpasses SOTA PLM-based methods in predictive accuracy while maintaining a faster inference speed and significantly reducing the number of model parameters.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.340",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Generate Rules for Realistic Few-Shot Relation Classification: An Encoder-Decoder Approach": {
        "type": "INPROCEEDINGS",
        "key": "singh-blanco-2024-learning",
        "author": "Singh, Mayank and Blanco, Eduardo",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Generate Rules for Realistic Few-Shot Relation Classification: An Encoder-Decoder Approach",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We propose a neuro-symbolic approach for realistic few-shot relation classification via rules. Instead of building neural models to predict relations, we design them to output straightforward rules that can be used to extract relations. The rules are generated using custom T5-style Encoder-Decoder Language Models. Crucially, our rules are fully interpretable and pliable (i.e., humans can easily modify them to boost performance). Through a combination of rules generated by these models along with a very effective, novel baseline, we demonstrate a few-shot relation-classification performance that is comparable to or stronger than the state of the art on the Few-Shot TACRED and NYT29 benchmarks while increasing interpretability and maintaining pliability.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.341",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Plot Twist: Multimodal Models Don\u2019t Comprehend Simple Chart Details": {
        "type": "INPROCEEDINGS",
        "key": "razeghi-etal-2024-plot",
        "author": "Razeghi, Yasaman and Dasgupta, Ishita and Liu, Fangyu and Ramasesh, Vinay Venkatesh and Singh, Sameer",
        "booktitle": "EMNLP-findings2024",
        "title": "Plot Twist: Multimodal Models Don\u2019t Comprehend Simple Chart Details",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advances in multimodal models show remarkable performance in real-world benchmarks for chart and figure understanding like ChartQA that involve interpreting trends, comparing data points, and extracting insights from visuals.In this paper, we investigate the extent to which these models truly comprehend the underlying information in charts by posing direct, elementary questions about simple features such as axes ranges and values to examine their fundamental visual understanding abilities in the context of charts.Our questions are applied to two sets of figures: synthetic and real-world.The empirical evaluation of 5 popular multimodal models on our dataset reveals shortfalls in understanding charts and figures, contrary to what their performance on complex benchmarks might suggest.For instance, Gemini Pro Vision only achieves 57.9% accuracy on our elementary set of questions on real-world plots, while other popular multimodal models showed similar or less performance.This work highlights an important limitation of current multimodal models, and cautions against overly optimistic interpretations of their abilities based on results of canonical evaluations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.342",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "nghiem-daume-iii-2024-hatecot",
        "author": "Nghiem, Huy and Daum\u00e9 Iii, Hal",
        "booktitle": "EMNLP-findings2024",
        "title": "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The widespread use of social media necessitates reliable and efficient detection of offensive content to mitigate harmful effects. Although sophisticated models perform well on individual datasets, they often fail to generalize due to varying definitions and labeling of \u201coffensive content.\u201d In this paper, we introduce HateCOT, an English dataset with over 52,000 samples from diverse sources, featuring explanations generated by GPT-3.5Turbo and curated by humans. We demonstrate that pretraining on HateCOT significantly enhances the performance of open-source Large Language Models on three benchmark datasets for offensive content detection in both zero-shot and few-shot settings, despite differences in domain and task. Additionally, HateCOT facilitates effective K-shot fine-tuning of LLMs with limited data and improves the quality of their explanations, as confirmed by our human evaluation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.343",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Giving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-giving",
        "author": "Liu, Jiapeng and Li, Weijie and Fan, Xiaochao and Deng, Wenjun and Yang, Liang and Li, Yong and Diao, Yufeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Giving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The rapid development of social media has led to an increase in online harassment and offensive speech, posing significant challenges for effective content moderation. Existing automated detection models often exhibit a bias towards predicting offensive speech based on specific vocabulary, which not only compromises model fairness but also potentially exacerbates biases against vulnerable and minority groups. Addressing these issues, this paper proposes a bias self-awareness and data self-iteration framework for mitigating model biases. This framework aims to \u201cgiving control back to models: enabling offensive language detection models to autonomously identify and mitigate biases\u201d through bias self-awareness algorithms and self-iterative data augmentation method. Experimental results demonstrate that the proposed framework effectively reduces the false positive rate of models in both in-distribution and out-of-distribution tests, enhances model accuracy and fairness, and shows promising performance improvements in detecting offensive speech on larger-scale datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.344",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Toolken+: Improving LLM Tool Usage with Reranking and a Reject Option": {
        "type": "INPROCEEDINGS",
        "key": "yakovlev-etal-2024-toolken",
        "author": "Yakovlev, Konstantin and Nikolenko, Sergey and Bout, Andrey",
        "booktitle": "EMNLP-findings2024",
        "title": "Toolken+: Improving LLM Tool Usage with Reranking and a Reject Option",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The recently proposed ToolkenGPT tool learning paradigm demonstrates promising performance but suffers from two major issues: first, it cannot benefit from tool documentation, and second, it often makes mistakes in whether to use a tool at all. We introduce Toolken+ that mitigates the first problem by reranking top-k tools selected by ToolkenGPT and the second problem with a special REJECT option such that the model will generate a vocabulary token if REJECT is ranked first. We demonstrate the effectiveness of Toolken+ on multistep numerical reasoning and tool selection tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.345",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SecureSQL: Evaluating Data Leakage of Large Language Models as Natural Language Interfaces to Databases": {
        "type": "INPROCEEDINGS",
        "key": "song-etal-2024-securesql",
        "author": "Song, Yanqi and Liu, Ruiheng and Chen, Shu and Ren, Qianhao and Zhang, Yu and Yu, Yongqi",
        "booktitle": "EMNLP-findings2024",
        "title": "SecureSQL: Evaluating Data Leakage of Large Language Models as Natural Language Interfaces to Databases",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the widespread application of Large Language Models (LLMs) in Natural Language Interfaces to Databases (NLIDBs), concerns about security issues in NLIDBs have been increasing gradually. However, research on sensitive data leakage in NLIDBs is relatively limited. Therefore, we propose a benchmark to assess the potential of language models to leak sensitive data when generating SQL queries. This benchmark covers 932 samples from 34 different domains, including medical, legal, financial, and political aspects. We evaluate 15 models from six LLM families, and the results show that the model with the best performance has an accuracy of 61.7%, whereas humans achieve an accuracy of 94%. Most models perform close to or even below the level of random selection. We also evaluate two common attack methods, namely prompt injection and inference attacks, as well as a defense method based on chain-of-thoughts (COT) prompting. Experimental results show that both attack methods significantly impact the model, while the defense method based on COT prompting dose not significantly improve accuracy, further highlighting the severity of sensitive data leakage issues in NLIDBs. We hope this research will draw more attention and further study from the researchers on this issue.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.346",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-llama",
        "author": "Chen, Tianxiang and Tan, Zhentao and Gong, Tao and Wu, Yue and Chu, Qi and Liu, Bin and Ye, Jieping and Yu, Nenghai",
        "booktitle": "EMNLP-findings2024",
        "title": "Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As a manner to augment pretrained large language models (LLM), knowledge injection is critical to develop vertical domain large models and has been widely studied. While most current approaches, including parameter-efficient fine-tuning (PEFT) and block expansion methods, uniformly apply knowledge across all LLM layers, it raises the question: are all layers equally crucial for knowledge injection? We embark upon evaluating the importance of each layer to locate the optimal layer range for knowledge injection. Intuitively, more important layers should play more critical roles in knowledge injection and deserve denser injection. We observe performance dips in question-answering benchmarks after the removal or expansion of the shallow layers, and the degradation shrinks as the layer gets deeper, indicating that the shallow layers hold the key to knowledge injection. This insight leads us to propose the S strategy, a post-pretraining strategy of selectively enhancing shallow layers while pruning the less effective deep ones. Based on this strategy, we introduce Llama Slayer 8B. We experimented on the corpus of code &amp; math and demonstrated the effectiveness of our strategy. Further experiments across different LLM, Mistral-7B, and a legal corpus confirmed the approach\u2019s general applicability, underscoring its wide-ranging efficacy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.347",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Entity or Relation Embeddings? An Analysis of Encoding Strategies for Relation Extraction": {
        "type": "INPROCEEDINGS",
        "key": "mtumbuka-schockaert-2024-entity",
        "author": "Mtumbuka, Frank Martin and Schockaert, Steven",
        "booktitle": "EMNLP-findings2024",
        "title": "Entity or Relation Embeddings? An Analysis of Encoding Strategies for Relation Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing approaches to relation extraction obtain relation embeddings by concatenating embeddings of the head and tail entities. Despite the popularity of this approach, we find that such representations mostly capture the types of the entities involved, leading to false positives and confusion between relations that involve entities of the same type. Another possibility is to use a prompt with a [MASK] token to directly learn relation embeddings, but this approach tends to perform poorly. We show that this underperformance comes from the fact that information about entity types is insufficiently captured by the [MASK] embeddings. We therefore propose a simple model, which combines such [MASK] embeddings with entity embeddings. Despite its simplicity, our model consistently outperforms the state-of-the-art across several benchmarks, even when the entity embeddings are obtained from a pre-trained entity typing model. We also experiment with a self-supervised pre-training strategy which further improves the results.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.348",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning": {
        "type": "INPROCEEDINGS",
        "key": "yue-etal-2024-distilling",
        "author": "Yue, Yuanhao and Wang, Chengyu and Huang, Jun and Wang, Peng",
        "booktitle": "EMNLP-findings2024",
        "title": "Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Instruction tuning aims to align large language models (LLMs) with open-domain instructions and human-preferred responses. While several studies have explored autonomous approaches to distilling and annotating instructions from powerful proprietary LLMs, such as ChatGPT, they often neglect the impact of the distributions and characteristics of tasks, together with the varying difficulty of instructions in training sets. This oversight can lead to imbalanced knowledge capabilities and poor generalization powers of student LLMs. To address these challenges, we introduce Task-Aware Curriculum Planning for Instruction Refinement (TAPIR), a multi-round distillation framework that utilizes an oracle LLM to select instructions that are difficult for a student LLM to follow. To balance the student\u2019s capabilities, task distributions in training sets are adjusted with responses automatically refined according to their corresponding tasks. In addition, by incorporating curriculum planning, our approach systematically escalates the difficulty levels of tasks, progressively enhancing the student LLM\u2019s capabilities. We rigorously evaluate TAPIR using several widely recognized benchmarks (such as AlpacaEval 2.0, MT-Bench, etc.) and multiple student LLMs. Empirical results demonstrate that student LLMs, trained with our method and less training data, outperform larger instruction-tuned models and strong distillation baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.350",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On Creating an English-Thai Code-switched Machine Translation in Medical Domain": {
        "type": "INPROCEEDINGS",
        "key": "pengpun-etal-2024-creating",
        "author": "Pengpun, Parinthapat and Tiankanon, Krittamate and Chinkamol, Amrest and Kinchagawat, Jiramet and Chairuengjitjaras, Pitchaya and Supholkhan, Pasit and Aussavavirojekul, Pubordee and Boonnag, Chiraphat and Veerakanjana, Kanyakorn and Phimsiri, Hirunkul and Sae-jia, Boonthicha and Sataudom, Nattawach and Ittichaiwong, Piyalitt and Limkonchotiwat, Peerat",
        "booktitle": "EMNLP-findings2024",
        "title": "On Creating an English-Thai Code-switched Machine Translation in Medical Domain",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Machine translation (MT) in the medical domain plays a pivotal role in enhancing healthcare quality and disseminating medical knowledge. Despite advancements in English-Thai MT technology, common MT approaches often underperform in the medical field due to their inability to precisely translate medical terminologies. Our research prioritizes not merely improving translation accuracy but also maintaining medical terminology in English within the translated text through code-switched (CS) translation. We developed a method to produce CS medical translation data, fine-tuned a CS translation model with this data, and evaluated its performance against strong baselines, such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model demonstrated competitive performance in automatic metrics and was highly favored in human preference evaluations. Our evaluation result also shows that medical professionals significantly prefer CS translations that maintain critical English terms accurately, even if it slightly compromises fluency. Our code and test set are publicly available https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.351",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "lv-etal-2024-coggpt",
        "author": "Lv, Yaojia and Pan, Haojie and Wang, Zekun and Liang, Jiafeng and Liu, Yuanxing and Fu, Ruiji and Liu, Ming and Wang, Zhongyuan and Qin, Bing",
        "booktitle": "EMNLP-findings2024",
        "title": "CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Cognitive dynamics, which refer to the evolution in human cognitive processes, are pivotal to advance human understanding of the world. Recent advancements in large language models (LLMs) highlight their potential for cognitive simulation. However, these LLM-based cognitive studies primarily focus on replicating human cognition in specific contexts, overlooking the inherently dynamic nature of cognition. To bridge this gap, we explore the cognitive dynamics of LLMs and present a corresponding task inspired by longitudinal studies. Toward the task, we develop CogBench, a novel benchmark to assess the cognitive dynamics of LLMs and validate it through participant surveys. We also design two evaluation metrics for CogBench, including Authenticity and Rationality. Recognizing the inherent static nature of LLMs, we further introduce CogGPT for the task, which features an innovative iterative cognitive mechanism to develop lifelong cognitive dynamics. Empirical results demonstrate the superiority of CogGPT over several existing methods, particularly in its ability to facilitate role-specific cognitive dynamics under continuous information flows. We will release the code and data to enable further research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.352",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric": {
        "type": "INPROCEEDINGS",
        "key": "koh-etal-2024-llms",
        "author": "Koh, Hyukhun and Kim, Dohyung and Lee, Minwoo and Jung, Kyomin",
        "booktitle": "EMNLP-findings2024",
        "title": "Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In the pursuit of developing Large Language Models (LLMs) that adhere to societal standards, it is imperative to detect the toxicity in the generated text. The majority of existing toxicity metrics rely on encoder models trained on specific toxicity datasets, which are susceptible to out-of-distribution (OOD) problems and depend on the dataset\u2019s definition of toxicity. In this paper, we introduce a robust metric grounded on LLMs to flexibly measure toxicity according to the given definition. We first analyze the toxicity factors, followed by an examination of the intrinsic toxic attributes of LLMs to ascertain their suitability as evaluators. Finally, we evaluate the performance of our metric with detailed analysis. Our empirical results demonstrate outstanding performance in measuring toxicity within verified factors, improving on conventional metrics by 12 points in the F1 score. Our findings also indicate that upstream toxicity significantly influences downstream metrics, suggesting that LLMs are unsuitable for toxicity evaluations within unverified factors.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.353",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter": {
        "type": "INPROCEEDINGS",
        "key": "maurer-etal-2024-toeing",
        "author": "Maurer, Maximilian and Ceron, Tanise and Pad\u00f3, Sebastian and Lapesa, Gabriella",
        "booktitle": "EMNLP-findings2024",
        "title": "Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Political discourse on Twitter is a moving target: politicians continuously make statements about their positions. It is therefore crucial to track their discourse on social media to understand their ideological positions and goals. However, Twitter data is also challenging to work with since it is ambiguous and often dependent on social context, and consequently, recent work on political positioning has tended to focus strongly on manifestos (parties\u2019 electoral programs) rather than social media.In this paper, we extend recently proposed methods to predict pairwise positional similarities between parties from the manifesto case to the Twitter case, using hashtags as a signal to fine-tune text representations, without the need for manual annotation. We verify the efficacy of fine-tuning and conduct a series of experiments that assess the robustness of our method for low-resource scenarios. We find that our method yields stable positionings reflective of manifesto positionings, both in scenarios with all tweets of candidates across years available and when only smaller subsets from shorter time periods are available. This indicates that it is possible to reliably analyze the relative positioning of actors without the need for manual annotation, even in the noisier context of social media.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.354",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "UniTabNet: Bridging Vision and Language Models for Enhanced Table Structure Recognition": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-unitabnet",
        "author": "Zhang, Zhenrong and Liu, Shuhang and Hu, Pengfei and Ma, Jiefeng and Du, Jun and Zhang, Jianshu and Hu, Yu",
        "booktitle": "EMNLP-findings2024",
        "title": "UniTabNet: Bridging Vision and Language Models for Enhanced Table Structure Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In the digital era, table structure recognition technology is a critical tool for processing and analyzing large volumes of tabular data. Previous methods primarily focus on visual aspects of table structure recovery but often fail to effectively comprehend the textual semantics within tables, particularly for descriptive textual cells. In this paper, we introduce UniTabNet, a novel framework for table structure parsing based on the image-to-text model. UniTabNet employs a \u201cdivide-and-conquer\u201d strategy, utilizing an image-to-text model to decouple table cells and integrating both physical and logical decoders to reconstruct the complete table structure. We further enhance our framework with the Vision Guider, which directs the model\u2019s focus towards pertinent areas, thereby boosting prediction accuracy. Additionally, we introduce the Language Guider to refine the model\u2019s capability to understand textual semantics in table images. Evaluated on prominent table structure datasets such as PubTabNet, PubTables1M, WTW, and iFLYTAB, UniTabNet achieves a new state-of-the-art performance, demonstrating the efficacy of our approach. The code will also be made publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.355",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition": {
        "type": "INPROCEEDINGS",
        "key": "kadaoui-etal-2024-polywer",
        "author": "Kadaoui, Karima and Ali, Maryam Al and Toyin, Hawau Olamide and Mohammed, Ibrahim and Aldarmaki, Hanan",
        "booktitle": "EMNLP-findings2024",
        "title": "PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Code-switching in speech, particularly between languages that use different scripts, can potentially be correctly transcribed in various forms, including different ways of transliteration of the embedded language into the matrix language script. Traditional methods for measuring accuracy, such as Word Error Rate (WER), are too strict to address this challenge. In this paper, we introduce PolyWER, a proposed framework for evaluating speech recognition systems to handle language-mixing. PolyWER accepts transcriptions of code-mixed segments in different forms, including transliterations and translations. We demonstrate the algorithms use cases through detailed examples, and evaluate it against human judgement. To enable the use of this metric, we appended the annotations of a publicly available Arabic-English code-switched dataset with transliterations and translations of code-mixed speech. We also utilize these additional annotations for fine-tuning ASR models and compare their performance using PolyWER. In addition to our main finding on PolyWER\u2019s effectiveness, our experiments show that alternative annotations could be more effective for fine-tuning monolingual ASR models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.356",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations": {
        "type": "INPROCEEDINGS",
        "key": "song-xu-2024-deep",
        "author": "Song, Huacheng and Xu, Hongzhi",
        "booktitle": "EMNLP-findings2024",
        "title": "A Deep Analysis of the Impact of Multiword Expressions and Named Entities on Chinese-English Machine Translations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we present a study on the impact of so-called multiword expressions (MWEs) and multiword named entities (NEs) on the performance of Chinese-English machine translation (MT) systems. Built on an extended version of the data from the WMT22 Metrics Shared Task (with extra labels of 9 types of Chinese MWEs, and 19 types of Chinese multiword NEs) which includes scores and error annotations provided by human experts, we make further extraction of MWE- and NE-related translation errors. By investigating the human evaluation scores and the error rates on each category of MWEs and NEs, we find that: 1) MT systems tend to perform significantly worse on Chinese sentences with most kinds of MWEs and NEs; 2) MWEs and NEs which make up of about twenty percent of tokens, i.e. characters in Chinese, result in one-third of translation errors; 3) for 13 categories of MWEs and NEs, the error rates exceed 50% with the highest to be 84.8%. Based on the results, we emphasize that MWEs and NEs are still a bottleneck issue for MT and special attention to MWEs and NEs should be paid to further improving the performance of MT systems.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.357",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zheng-etal-2024-sca",
        "author": "Zheng, Huanran and Zhu, Wei and Wang, Xiaoling",
        "booktitle": "EMNLP-findings2024",
        "title": "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have achieved impressive performance across various domains, but the limited context window and the expensive computational cost of processing long texts restrict their more comprehensive application. In this paper, we propose Selective Compression Attention (SCA), a general and effective method to expand the context window and reduce memory footprint by compressing the KV cache of LLMs. Specifically, through preliminary experiments, we found that the KV cache contains many similar vectors, resulting in information redundancy, which can be compressed by retaining representative vectors and discarding others. Therefore, SCA continuously selects the most distinctive vectors to keep through a greedy algorithm, reducing information loss during compression. Extensive experiments on various tasks verify the effectiveness of our method. Compared with existing methods, SCA can significantly reduce the impact on model performance under the same compression ratio. Furthermore, the context window of LLMs can be efficiently expanded using SCA without any training, which can even achieve better performance than specially fine-tuned long context models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.358",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "FANTAstic SEquences and Where to Find Them: Faithful and Efficient API Call Generation through State-tracked Constrained Decoding and Reranking": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-fantastic",
        "author": "Wang, Zhuoer and Ribeiro, Leonardo F. R. and Papangelis, Alexandros and Mukherjee, Rohan and Wang, Tzu-Yen and Zhao, Xinyan and Biswas, Arijit and Caverlee, James and Metallinou, Angeliki",
        "booktitle": "EMNLP-findings2024",
        "title": "FANTAstic SEquences and Where to Find Them: Faithful and Efficient API Call Generation through State-tracked Constrained Decoding and Reranking",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "API call generation is the cornerstone of large language models\u2019 tool-using ability that provides access to the larger world. However, existing supervised and in-context learning approaches suffer from high training costs, poor data efficiency, and generated API calls that can be unfaithful to the API documentation and the user\u2019s request. To address these limitations, we propose an output-side optimization approach called FANTASE. Two of the unique contributions of FANTASE are its State-Tracked Constrained Decoding (SCD) and Reranking components. SCD dynamically incorporates appropriate API constraints in the form of Token Search Trie for efficient and guaranteed generation faithfulness with respect to the API documentation. The Reranking component efficiently brings in the supervised signal by leveraging a lightweight model as the discriminator to rerank the beam-searched candidate generations of the large language model. We demonstrate the superior performance of FANTASE in API call generation accuracy, inference efficiency, and context efficiency with DSTC8 and API Bank datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.359",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "mouselinos-etal-2024-beyond",
        "author": "Mouselinos, Spyridon and Michalewski, Henryk and Malinowski, Mateusz",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs\u2019 abilities in constructive geometric problem-solving, \u2013 one of the most fundamental steps in developing human mathematical reasoning, revealing notable challenges in this domain. LLMs exhibit biases in variable names, struggle with 2D spatial relationships and planning, and hallucinate object placements. To this end, we introduce a framework that enhances LLMs\u2019 reasoning potential through a multi-agent system conducting internal dialogue. This work underscores LLMs\u2019 limitations in geometric reasoning and improves their capabilities through self-correction, collaboration, and diverse role specializations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.360",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zeng-etal-2024-adamoe",
        "author": "Zeng, Zihao and Miao, Yibo and Gao, Hongcheng and Zhang, Hao and Deng, Zhijie",
        "booktitle": "EMNLP-findings2024",
        "title": "AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Mixture of experts (MoE) has become the standard for constructing production-level large language models (LLMs) due to its promise to boost model capacity without causing significant overheads. Nevertheless, existing MoE methods usually enforce a constant top-k routing for all tokens, which is arguably restrictive because various tokens (e.g., \u201d\\textlessEOS\\textgreater\u201d vs. \u201capple\u201d) may require various numbers of experts for feature abstraction. Lifting such a constraint can help make the most of limited resources and unleash the potential of the model for downstream tasks. In this sense, we introduce **AdaMoE** to realize token-adaptive routing for MoE, where different tokens are permitted to select a various number of experts. AdaMoE makes minimal modifications to the vanilla MoE with top-k routing\u2014it simply introduces a fixed number of *null experts*, which do not consume any FLOPs, to the expert set and increases the value of k. AdaMoE does not force each token to occupy a fixed number of null experts but ensures the average usage of the null experts with a load-balancing loss, leading to an adaptive number of null/true experts used by each token. AdaMoE exhibits a strong resemblance to MoEs with expert choice routing while allowing for trivial auto-regressive modeling. AdaMoE is easy to implement and can be effectively applied to pre-trained (MoE-)LLMs. Extensive studies show that AdaMoE can reduce average expert load (FLOPs) while achieving superior performance. For example, on the ARC-C dataset, applying our method to fine-tuning Mixtral-8x7B can reduce FLOPs by 14.5% while increasing accuracy by 1.69%.Code is available at [this link](https://github.com/CengZihao/AdaMoE).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.361",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems": {
        "type": "INPROCEEDINGS",
        "key": "kaiser-etal-2024-learning",
        "author": "Kaiser, Magdalena and Ernst, Patrick and Szarvas, Gy\u00f6rgy",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Task-oriented Dialog (ToD) systems have to solve multiple subgoals to accomplish user goals, whereas feedback is often obtained only at the end of the dialog. In this work, we propose SUIT (SUbgoal-aware ITerative Training), an iterative training approach for improving ToD systems. We sample dialogs from the model we aim to improve and determine subgoals that contribute to dialog success using distant supervision to obtain high quality training samples. We show how this data improves supervised fine-tuning or, alternatively, preference learning results. Performance improves when applying these steps over several iterations: SUIT reaches new state-of-the-art performance on a popular ToD benchmark.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.362",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CLEAR: Can Language Models Really Understand Causal Graphs?": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-clear",
        "author": "Chen, Sirui and Xu, Mengying and Wang, Kun and Zeng, Xingyu and Zhao, Rui and Zhao, Shengjie and Lu, Chaochao",
        "booktitle": "EMNLP-findings2024",
        "title": "CLEAR: Can Language Models Really Understand Causal Graphs?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Causal reasoning is a cornerstone of how humans interpret the world. To model and reason about causality, causal graphs offer a concise yet effective solution. Given the impressive advancements in language models, a crucial question arises: can they really understand causal graphs? To this end, we pioneer an investigation into language models\u2019 understanding of causal graphs. Specifically, we develop a framework to define causal graph understanding, by assessing language models\u2019 behaviors through four practical criteria derived from diverse disciplines (e.g., philosophy and psychology). We then develop CLEAR, a novel benchmark that defines three complexity levels and encompasses 20 causal graph-based tasks across these levels. Finally, based on our framework and benchmark, we conduct extensive experiments on six leading language models and summarize five empirical findings. Our results indicate that while language models demonstrate a preliminary understanding of causal graphs, significant potential for improvement remains.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.363",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-promptkd",
        "author": "Kim, Gyeongman and Jang, Doohyuk and Yang, Eunho",
        "booktitle": "EMNLP-findings2024",
        "title": "PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in large language models (LLMs) have raised concerns about inference costs, increasing the need for research into model compression. While knowledge distillation (KD) is a prominent method for this, research on KD for generative language models like LLMs is relatively sparse, and the approach of distilling student-friendly knowledge, which has shown promising performance in KD for classification models, remains unexplored in generative language models. To explore this approach, we propose PromptKD, a simple yet effective method that utilizes prompt tuning - for the first time in KD - to enable generative language models to transfer student-friendly knowledge. Unlike previous works in classification that require fine-tuning the entire teacher model for extracting student-friendly knowledge, PromptKD achieves similar effects by adding a small number of prompt tokens and tuning only the prompt with student guidance. Extensive experiments on instruction-following datasets show that PromptKD achieves state-of-the-art performance while adding only 0.0007% of the teacher\u2019s parameters as prompts. Further analysis suggests that distilling student-friendly knowledge alleviates exposure bias effectively throughout the entire training process, leading to performance enhancements.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.364",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "M2QA: Multi-domain Multilingual Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "englander-etal-2024-m2qa",
        "author": "Engl\u00e4nder, Leon and Sterz, Hannah and Poth, Clifton A. and Pfeiffer, Jonas and Kuznetsov, Ilia and Gurevych, Iryna",
        "booktitle": "EMNLP-findings2024",
        "title": "M2QA: Multi-domain Multilingual Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generalization and robustness to input variation are core desiderata of machine learning research. Language varies along several axes, most importantly, language instance (e.g. French) and domain (e.g. news). While adapting NLP models to new languages within a single domain, or to new domains within a single language, is widely studied, research in joint adaptation is hampered by the lack of evaluation datasets. This prevents the transfer of NLP systems from well-resourced languages and domains to non-dominant language-domain combinations. To address this gap, we introduce M2QA, a multi-domain multilingual question answering benchmark.M2QA includes 13,500 SQuAD 2.0-style question-answer instances in German, Turkish, and Chinese for the domains of product reviews, news, and creative writing. We use M2QA to explore cross-lingual cross-domain performance of fine-tuned models and state-of-the-art LLMs and investigate modular approaches to domain and language adaptation.We witness **1)** considerable performance _variations_ across domain-language combinations within model classes and **2)** considerable performance _drops_ between source and target language-domain combinations across all model sizes. We demonstrate that M2QA is far from solved, and new methods to effectively transfer both linguistic and domain-specific information are necessary.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.365",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unveiling the Invisible: Captioning Videos with Metaphors": {
        "type": "INPROCEEDINGS",
        "key": "rajakumar-kalarani-etal-2024-unveiling",
        "author": "Rajakumar Kalarani, Abisek and Bhattacharyya, Pushpak and Shekhar, Sumit",
        "booktitle": "EMNLP-findings2024",
        "title": "Unveiling the Invisible: Captioning Videos with Metaphors",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Metaphors are a common communication tool used in our day-to-day life. The detection and generation of metaphors in textual form have been studied extensively but metaphors in other forms have been under-explored. Recent studies have shown that Vision-Language (VL) models cannot understand visual metaphors in memes and adverts. As of now, no probing studies have been done that involve complex language phenomena like metaphors with videos. Hence, we introduce a new VL task of describing the metaphors present in the videos in our work. To facilitate this novel task, we construct and release a manually created dataset with 705 videos and 2115 human-written captions, along with a new metric called Average Concept Distance (ACD), to automatically evaluate the creativity of the metaphors generated. We also propose a novel low-resource video metaphor captioning system: GIT-LLaVA, which obtains comparable performance to SoTA video language models on the proposed task. We perform a comprehensive analysis of existing video language models on this task and publish our dataset, models, and benchmark results to enable further research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.366",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?": {
        "type": "INPROCEEDINGS",
        "key": "doostmohammadi-etal-2024-reliable",
        "author": "Doostmohammadi, Ehsan and Holmstr\u00f6m, Oskar and Kuhlmann, Marco",
        "booktitle": "EMNLP-findings2024",
        "title": "How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Work on instruction-tuned Large Language Models (LLMs) has used automatic methods based on text overlap and LLM judgments as cost-effective alternatives to human evaluation. In this paper, we perform a meta-evaluation of such methods and assess their reliability across a broad range of tasks. In evaluating how well automatic methods align with human evaluations, correlation metrics are the most commonly employed method despite their inherent limitations when dealing with ties and different scales. To address these shortcomings, we use Pairwise Accuracy as an alternative to standard correlation measures. We observe that while automatic evaluation methods can approximate human ratings under specific conditions, their validity is highly context-dependent. Specifically, the simple ROUGE-L metric correlates very well with human ratings for short-answer English tasks but is unreliable in free-form generation tasks and cross-lingual scenarios. The effectiveness of the more advanced method of using GPT-4 as a judge diminishes significantly if reference answers are not included in the prompt, which is the scenario where this method has the potential to provide the most value compared to other metrics. Our findings enhance the understanding of how automatic methods should be applied and interpreted when developing and evaluating instruction-tuned LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.367",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "RippleCOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-ripplecot",
        "author": "Zhao, Zihao and Yang, Yuchen and Li, Yijiang and Cao, Yinzhi",
        "booktitle": "EMNLP-findings2024",
        "title": "RippleCOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.368",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Authorship Obfuscation in Multilingual Machine-Generated Text Detection": {
        "type": "INPROCEEDINGS",
        "key": "macko-etal-2024-authorship",
        "author": "Macko, Dominik and Moro, Robert and Uchendu, Adaku and Srba, Ivan and Lucas, Jason S. and Yamashita, Michiharu and Tripto, Nafis Irtiza and Lee, Dongwon and Simko, Jakub and Bielikova, Maria",
        "booktitle": "EMNLP-findings2024",
        "title": "Authorship Obfuscation in Multilingual Machine-Generated Text Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "High-quality text generation capability of latest Large Language Models (LLMs) causes concerns about their misuse (e.g., in massive generation/spread of disinformation). Machine-generated text (MGT) detection is important to cope with such threats. However, it is susceptible to authorship obfuscation (AO) methods, such as paraphrasing, which can cause MGTs to evade detection. So far, this was evaluated only in monolingual settings. Thus, the susceptibility of recently proposed multilingual detectors is still unknown. We fill this gap by comprehensively benchmarking the performance of 10 well-known AO methods, attacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10 \\times 37 \\times 11 = 4,070 combinations). We also evaluate the effect of data augmentation on adversarial robustness using obfuscated texts. The results indicate that all tested AO methods can cause evasion of automated detection in all tested languages, where homoglyph attacks are especially successful. However, some of the AO methods severely damaged the text, making it no longer readable or easily recognizable by humans (e.g., changed language, weird characters).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.369",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Comparing Edge-based and Node-based Methods on a Citation Prediction Task": {
        "type": "INPROCEEDINGS",
        "key": "vickers-church-2024-comparing",
        "author": "Vickers, Peter and Church, Kenneth",
        "booktitle": "EMNLP-findings2024",
        "title": "Comparing Edge-based and Node-based Methods on a Citation Prediction Task",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Citation Prediction, estimating whether paper a cites paper b, is particularly interesting in a forecasting setting where the model is trained on papers published before time t, and evaluated on papers published after h, where h is the forecast horizon. Performance improves with t (larger training sets) and degrades with h (longer forecast horizons). The trade-off between edge-based methods and node-based methods depends on t. Because edges grow faster than nodes, larger training sets favor edge-based methods.We introduce a new forecast-based Citation Prediction benchmark of 3 million papers to quantify these trends.Our benchmark shows that desirable policies for combining edge- and node-based methods depend on h and t.We release our benchmark, evaluation scripts, and embeddings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.370",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DAdEE: Unsupervised Domain Adaptation in Early Exit PLMs": {
        "type": "INPROCEEDINGS",
        "key": "bajpai-hanawal-2024-dadee",
        "author": "Bajpai, Divya Jyoti and Hanawal, Manjesh Kumar",
        "booktitle": "EMNLP-findings2024",
        "title": "DAdEE: Unsupervised Domain Adaptation in Early Exit PLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Pre-trained Language Models (PLMs) exhibit good accuracy and generalization ability across various tasks using self-supervision, but their large size results in high inference latency. Early Exit (EE) strategies handle the issue by allowing the samples to exit from classifiers attached to the intermediary layers, but they do not generalize well, as exit classifiers can be sensitive to domain changes. To address this, we propose Unsupervised Domain Adaptation in EE framework (DAdEE) that employs multi-level adaptation using knowledge distillation. DAdEE utilizes GAN-based adversarial adaptation at each layer to achieve domain-invariant representations, reducing the domain gap between the source and target domain across all layers. The attached exits not only speed up inference but also enhance domain adaptation by reducing catastrophic forgetting and mode collapse, making it more suitable for real-world scenarios. Experiments on tasks such as sentiment analysis, entailment classification, and natural language inference demonstrate that DAdEE consistently outperforms not only early exit methods but also various domain adaptation methods under domain shift scenarios. The anonymized source code is available at https://github.com/Div290/DAdEE.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.371",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LaCo: Large Language Model Pruning via Layer Collapse": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-laco",
        "author": "Yang, Yifei and Cao, Zouying and Zhao, Hai",
        "booktitle": "EMNLP-findings2024",
        "title": "LaCo: Large Language Model Pruning via Layer Collapse",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.372",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Llamipa: An Incremental Discourse Parser": {
        "type": "INPROCEEDINGS",
        "key": "thompson-etal-2024-llamipa",
        "author": "Thompson, Kate and Chaturvedi, Akshay and Hunter, Julie and Asher, Nicholas",
        "booktitle": "EMNLP-findings2024",
        "title": "Llamipa: An Incremental Discourse Parser",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper provides the first discourse parsing experiments with a large language model (LLM) finetuned on corpora annotated in the style of SDRT (Segmented Discourse Representation Theory, Asher (1993), Asher and Lascarides (2003)). The result is a discourse parser, Llamipa (Llama Incremental Parser), that leverages discourse context, leading to substantial performance gains over approaches that use encoder-only models to provide local, context-sensitive representations of discourse units. Furthermore, it is able to process discourse data incrementally, which is essential for the eventual use of discourse information in downstream tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.373",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Nebula: A discourse aware Minecraft Builder": {
        "type": "INPROCEEDINGS",
        "key": "chaturvedi-etal-2024-nebula",
        "author": "Chaturvedi, Akshay and Thompson, Kate and Asher, Nicholas",
        "booktitle": "EMNLP-findings2024",
        "title": "Nebula: A discourse aware Minecraft Builder",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "When engaging in collaborative tasks, humans efficiently exploit the semantic structure of a conversation to optimize verbal and nonverbal interactions. But in recent \u201clanguage to code\u201d or \u201clanguage to action\u201d models, this information is lacking. We show how incorporating the prior discourse and nonlinguistic context of a conversation situated in a nonlinguistic environment can improve the \u201clanguage to action\u201d component of such interactions. We finetune an LLM to predict actions based on prior context; our model, Nebula, doubles the net-action F1 score over the baseline on this task of Jayannavar et al. (2020). We also investigate our model\u2019s ability to construct shapes and understand location descriptions using a synthetic dataset.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.374",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Referring Ability for Biomedical Language Models": {
        "type": "INPROCEEDINGS",
        "key": "jiang-etal-2024-improving",
        "author": "Jiang, Junfeng and Cheng, Fei and Aizawa, Akiko",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Referring Ability for Biomedical Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing auto-regressive large language models (LLMs) are primarily trained using documents from general domains. In the biomedical domain, continual pre-training is a prevalent method for domain adaptation to inject professional knowledge into powerful LLMs that have been pre-trained in general domains. Previous studies typically conduct standard pre-training by randomly packing multiple documents into a long pre-training sequence. Recently, some existing works suggest that enhancing the relatedness of documents within the same pre-training sequence may be advantageous. However, these studies primarily focus on general domains, which cannot be readily applied in the biomedical domain where the distinction of fine-grained topics is harder. Is it possible to further improve the pre-training for biomedical language models (LMs) using exactly the same corpus? In this paper, we explore an improved approach to continual pre-training, which is a prevalent method for domain adaptation, by utilizing information from the citation network in this challenging scenario. Empirical studies demonstrate that our proposed LinkLM data improves both the intra-sample and inter-sample referring abilities of auto-regressive LMs in the biomedical domain, encouraging more profound consideration of task-specific pre-training sequence design for continual pre-training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.375",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CapEEN: Image Captioning with Early Exits and Knowledge Distillation": {
        "type": "INPROCEEDINGS",
        "key": "bajpai-hanawal-2024-capeen",
        "author": "Bajpai, Divya Jyoti and Hanawal, Manjesh Kumar",
        "booktitle": "EMNLP-findings2024",
        "title": "CapEEN: Image Captioning with Early Exits and Knowledge Distillation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Deep neural networks (DNNs) have made significant progress in recognizing visual elements and generating descriptive text in image-captioning tasks. However, their improved performance comes from increased computational burden and inference latency. Early Exit (EE) strategies can be used to enhance their efficiency, but their adaptation presents challenges in image captioning as it requires varying levels of semantic information for accurate predictions. To overcome this, we introduce CapEEN to improve the performance of EE strategies using knowledge distillation. Inference in CapEEN is completed at intermediary layers if prediction confidence exceeds a predefined value learned from the training data. To account for real-world deployments, where target distributions could drift from that of training samples, we introduce a variant A-CapEEN to adapt the thresholds on the fly using Multi-armed bandits framework. Experiments on the MS COCO and Flickr30k datasets show that CapEEN gains speedup of 1.77\\times while maintaining competitive performance compared to the final layer, and A-CapEEN additionally offers robustness against distortions. The source code is available at https://github.com/Div290/CapEEN.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.376",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LumberChunker: Long-Form Narrative Document Segmentation": {
        "type": "INPROCEEDINGS",
        "key": "duarte-etal-2024-lumberchunker",
        "author": "Duarte, Andr\u00e9 V. and Marques, Jo\u00e3o DS and Gra\u00e7a, Miguel and Freire, Miguel and Li, Lei and Oliveira, Arlindo L.",
        "booktitle": "EMNLP-findings2024",
        "title": "LumberChunker: Long-Form Narrative Document Segmentation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Modern NLP tasks increasingly rely on dense retrieval methods to access up-to-date and relevant contextual information. We are motivated by the premise that retrieval benefits from segments that can vary in size such that a content\u2019s semantic independence is better captured. We propose LumberChunker, a method leveraging an LLM to dynamically segment documents, which iteratively prompts the LLM to identify the point within a group of sequential passages where the content begins to shift. To evaluate our method, we introduce GutenQA, a benchmark with 3000 \u201cneedle in a haystack\u201d type of question-answer pairs derived from 100 public domain narrative books available on Project Gutenberg. Our experiments show that LumberChunker not only outperforms the most competitive baseline by 7.37% in retrieval performance (DCG@20) but also that, when integrated into a RAG pipeline, LumberChunker proves to be more effective than other chunking methods and competitive baselines, such as the Gemini 1.5M Pro.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.377",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions": {
        "type": "INPROCEEDINGS",
        "key": "meadows-etal-2024-exploring",
        "author": "Meadows, Jordan and James, Tamsin Emily and Freitas, Andre",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language models (LMs) can hallucinate when performing complex mathematical reasoning. Physics provides a rich domain for assessing their mathematical capabilities, where physical context requires that any symbolic manipulation satisfies complex semantics (e.g., units, tensorial order). In this work, we systematically remove crucial context from prompts to force instances where model inference may be algebraically coherent, yet unphysical. We assess LM capabilities in this domain using a curated dataset encompassing multiple notations and Physics subdomains. Further, we improve zero-shot scores using synthetic in-context examples, and demonstrate non-linear degradation of derivation quality with perturbation strength via the progressive omission of supporting premises. We find that the models\u2019 mathematical reasoning is not physics-informed in this setting, where physical context is predominantly ignored in favour of reverse-engineering solutions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.378",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unlocking Continual Learning Abilities in Language Models": {
        "type": "INPROCEEDINGS",
        "key": "du-etal-2024-unlocking",
        "author": "Du, Wenyu and Cheng, Shuang and Luo, Tongxu and Qiu, Zihan and Huang, Zeyu and Cheung, Ka Chun and Cheng, Reynold and Fu, Jie",
        "booktitle": "EMNLP-findings2024",
        "title": "Unlocking Continual Learning Abilities in Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.379",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On the Rigour of Scientific Writing: Criteria, Analysis, and Insights": {
        "type": "INPROCEEDINGS",
        "key": "james-etal-2024-rigour",
        "author": "James, Joseph and Xiao, Chenghao and Li, Yucheng and Lin, Chenghua",
        "booktitle": "EMNLP-findings2024",
        "title": "On the Rigour of Scientific Writing: Criteria, Analysis, and Insights",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Rigour is crucial for scientific research as it ensures the reproducibility and validity of results and findings. Despite its importance, little work exists on modelling rigour computationally, and there is a lack of analysis on whether these criteria can effectively signal or measure the rigour of scientific papers in practice. In this paper, we introduce a bottom-up, data-driven framework to automatically identify and define rigour criteria and assess their relevance in scientific writing. Our framework includes rigour keyword extraction, detailed rigour definition generation, and salient criteria identification. Furthermore, our framework is domain-agnostic and can be tailored to the evaluation of scientific rigour for different areas, accommodating the distinct salient criteria across fields. We conducted comprehensive experiments based on datasets collected from different domains (e.g. ICLR, ACL) to demonstrate the effectiveness of our framework in modelling rigour. In addition, we analyse linguist patterns of rigour, revealing that framing certainty is crucial for enhancing the perception of scientific rigour, while suggestion certainty and probability uncertainty diminish it.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.380",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MMUTF: Multimodal Multimedia Event Argument Extraction with Unified Template Filling": {
        "type": "INPROCEEDINGS",
        "key": "seeberger-etal-2024-mmutf",
        "author": "Seeberger, Philipp and Wagner, Dominik and Riedhammer, Korbinian",
        "booktitle": "EMNLP-findings2024",
        "title": "MMUTF: Multimodal Multimedia Event Argument Extraction with Unified Template Filling",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the advancement of multimedia technologies, news documents and user-generated content are often represented as multiple modalities, making Multimedia Event Extraction (MEE) an increasingly important challenge. However, recent MEE methods employ weak alignment strategies and data augmentation with simple classification models, which ignore the capabilities of natural language-formulated event templates for the challenging Event Argument Extraction (EAE) task. In this work, we focus on EAE and address this issue by introducing a unified template filling model that connects the textual and visual modalities via textual prompts. This approach enables the exploitation of cross-ontology transfer and the incorporation of event-specific semantics. Experiments on the M2E2 benchmark demonstrate the effectiveness of our approach. Our system surpasses the current SOTA on textual EAE by +7% F1, and performs generally better than the second-best systems for multimedia EAE.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.381",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Not All Preference Pairs Are Created Equal: A Recipe for Annotation-Efficient Iterative Preference Learning": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-preference",
        "author": "Yang, Sen and Cui, Leyang and Cai, Deng and Huang, Xinting and Shi, Shuming and Lam, Wai",
        "booktitle": "EMNLP-findings2024",
        "title": "Not All Preference Pairs Are Created Equal: A Recipe for Annotation-Efficient Iterative Preference Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Iterative preference learning, though yielding superior performances, requires online annotated preference labels. In this work, we study strategies to save annotation budgets while achieving competitive or even better performances for iterative preference learning. Built on intuitions from active learning, we empirically show that annotating those response pairs with small margins is generally better than large or random. Besides, experiments under the multi-iteration scenario suggest allocating more annotation budgets in the earlier iterations rather than later ones.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.382",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Cross-lingual Contextualized Phrase Retrieval": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-cross-lingual",
        "author": "Li, Huayang and Cai, Deng and Qu, Zhi and Cui, Qu and Kamigaito, Hidetaka and Liu, Lemao and Watanabe, Taro",
        "booktitle": "EMNLP-findings2024",
        "title": "Cross-lingual Contextualized Phrase Retrieval",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Phrase-level dense retrieval has shown many appealing characteristics in downstream NLP tasks by leveraging the fine-grained information that phrases offer. In our work, we propose a new task formulation of dense retrieval, cross-lingual contextualized phrase retrieval, which aims to augment cross-lingual applications by addressing polysemy using context information. However, the lack of specific training data and models are the primary challenges to achieve our goal. As a result, we extract pairs of cross-lingual phrases using word alignment information automatically induced from parallel sentences. Subsequently, we train our Cross-lingual Contextualized Phrase Retriever (CCPR) using contrastive learning, which encourages the hidden representations of phrases with similar contexts and semantics to align closely. Comprehensive experiments on both the cross-lingual phrase retrieval task and a downstream task, i.e, machine translation, demonstrate the effectiveness of CCPR. On the phrase retrieval task, CCPR surpasses baselines by a significant margin, achieving a top-1 accuracy that is at least 13 points higher. When utilizing CCPR to augment the large-language-model-based translator, it achieves average gains of 0.7 and 1.5 in BERTScore for translations from X=\\textgreaterEn and vice versa, respectively, on WMT16 dataset. We will release our code and data.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.383",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs": {
        "type": "INPROCEEDINGS",
        "key": "liao-etal-2024-videoinsta",
        "author": "Liao, Ruotong and Erler, Max and Wang, Huiyu and Zhai, Guangyao and Zhang, Gengyuan and Ma, Yunpu and Tresp, Volker",
        "booktitle": "EMNLP-findings2024",
        "title": "VideoINSTA: Zero-shot Long Video Understanding via Informative Spatial-Temporal Reasoning with LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In the video-language domain, recent works in leveraging zero-shot Large Language Model-based reasoning for video understanding have become competitive challengers to previous end-to-end models. However, long video understanding presents unique challenges due to the complexity of reasoning over extended timespans, even for zero-shot LLM-based approaches. The challenge of information redundancy in long videos prompts the question of what specific information is essential for large language models (LLMs) and how to leverage them for complex spatial-temporal reasoning in long-form video analysis. We propose a framework VideoINSTA , i.e. INformative Spatial-TemporAl Reasoning for zero-shot long-form video understanding.VideoINSTA contributes (1) a zero-shot framework for long video understanding using LLMs; (2) an event-based temporalreasoning and content-based spatial reasoning approach for LLMs to reason over spatial-temporal information in videos; (3) a self-reflective information reasoning scheme based on information sufficiency and prediction confidence while balancing temporal factors.Our model significantly improves the state-of-the-art on three long video question-answering benchmarks: EgoSchema, NextQA, and IntentQA, and the open question answering dataset ActivityNetQA. Code is released: https://github.com/mayhugotong/VideoINSTA.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.384",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement": {
        "type": "INPROCEEDINGS",
        "key": "feng-etal-2024-self",
        "author": "Feng, Yunlong and Teng, Dechuan and Xu, Yang and Mu, Honglin and Xu, Xiao and Qin, Libo and Zhu, Qingfu and Che, Wanxiang",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Decompilation transforms compiled code back into a high-level programming language for analysis when source code is unavailable. Previous work has primarily focused on enhancing decompilation performance by increasing the scale of model parameters or training data for pre-training. Based on the characteristics of the decompilation task, we propose two methods: (1) Without fine-tuning, the Self-Constructed Context Decompilation (sc\u00b2dec) method recompiles the LLM\u2019s decompilation results to construct pairs for in-context learning, helping the model improve decompilation performance. (2) Fine-grained Alignment Enhancement (FAE), which meticulously aligns assembly code with source code at the statement level by leveraging debugging information, is employed during the fine-tuning phase to achieve further improvements in decompilation. By integrating these two methods, we achieved a Re-Executability performance improvement of approximately 3.90% on the Decompile-Eval benchmark, establishing a new state-of-the-art performance of 52.41%. The code, data, and models are available at https://github.com/AlongWY/sccdec.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.385",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Efficiently Computing Susceptibility to Context in Language Models": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-efficiently",
        "author": "Liu, Tianyu and Du, Kevin and Sachan, Mrinmaya and Cotterell, Ryan",
        "booktitle": "EMNLP-findings2024",
        "title": "Efficiently Computing Susceptibility to Context in Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "One strength of modern language models is their ability to incorporate information from a user-input context when answering queries. However, they are not equally sensitive to the subtle changes to that context.To quantify this, Du et al. (2024) gives an information-theoretic metric to measure such sensitivity. Their metric, susceptibility, is defined as the degree to which contexts can influence a model\u2019s response to a query at a distributional level.However, exactly computing susceptibility is difficult and, thus, Du et al. (2024) falls back on a Monte Carlo approximation.Due to the large number of samples required, the Monte Carlo approximation is inefficient in practice. As a faster alternative, we propose Fisher susceptibility, an efficient method to estimate the susceptibility based on Fisher information.Empirically, we validate that Fisher susceptibility is comparable to Monte Carlo estimated susceptibility across a diverse set of query domains despite its being 70\\times faster.Exploiting the improved efficiency, we apply Fisher susceptibility to analyze factors affecting the susceptibility of language models.We observe that larger models are as susceptible as smaller ones.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.386",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-esg",
        "author": "Lee, Jaeyoung and Son, Geonyeong and Kim, Misuk",
        "booktitle": "EMNLP-findings2024",
        "title": "ESG-Kor: A Korean Dataset for ESG-related Information Extraction and Practical Use Cases",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the expansion of pre-trained language model usage in recent years, the importance of datasets for performing tasks in specialized domains has significantly increased. Therefore, we have built a Korean dataset called ESG-Kor to automatically extract Environmental, Social, and Governance (ESG) information, which has recently gained importance. ESG-Kor is a dataset consisting of a total of 118,946 sentences that extracted information on each ESG component from Korean companies\u2019 sustainability reports and manually labeled it according to objective rules provided by ESG evaluation agencies. To verify the effectiveness and applicability of the ESG-Kor dataset, classification performance was confirmed using several Korean pre-trained language models, and significant performance was obtained. Additionally, by extending the ESG classification model to documents of small and medium enterprises and extracting information based on ESG key issues and in-depth analysis, we demonstrated potential and practical use cases in the ESG field.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.387",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-wrong",
        "author": "Zhang, Yongheng and Chen, Qiguang and Zhou, Jingxuan and Wang, Peng and Si, Jiasheng and Wang, Jin and Lu, Wenpeng and Qin, Libo",
        "booktitle": "EMNLP-findings2024",
        "title": "Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Chain-of-Thought (CoT) has become a vital technique for enhancing the performance of Large Language Models (LLMs), attracting increasing attention from researchers. One stream of approaches focuses on the iterative enhancement of LLMs by continuously verifying and refining their reasoning outputs for desired quality. Despite its impressive results, this paradigm faces two critical issues: (1) Simple verification methods: The current paradigm relies solely on a single verification method. (2) Wrong Information Ignorance: Traditional paradigms directly ignore wrong information during reasoning and refine the logic paths from scratch each time. To address these challenges, we propose Wrong-of-Thought (WoT), which includes two core modules: (1) Multi-Perspective Verification: A multi-perspective verification method for accurately refining the reasoning process and result, and (2) Wrong Information Utilization: Utilizing wrong information to alert LLMs and reduce the probability of LLMs making same mistakes. Experiments on 8 popular datasets and 5 LLMs demonstrate that WoT surpasses all previous baselines. In addition, WoT exhibits powerful capabilities in difficult computation tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.388",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning Semantic Structure through First-Order-Logic Translation": {
        "type": "INPROCEEDINGS",
        "key": "chaturvedi-asher-2024-learning",
        "author": "Chaturvedi, Akshay and Asher, Nicholas",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning Semantic Structure through First-Order-Logic Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we study whether transformer-based language models can extract predicate argument structure from simple sentences. We firstly show that language models sometimes confuse which predicates apply to which objects. To mitigate this, we explore two tasks: question answering (Q/A), and first order logic (FOL) translation, and two regimes, prompting and finetuning. In FOL translation, we finetune several large language models on synthetic datasets designed to gauge their generalization abilities. For Q/A, we finetune encoder models like BERT and RoBERTa and use prompting for LLMs. The results show that FOL translation for LLMs is better suited to learn predicate argument structure.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.390",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Training Data Recipe to Accelerate A* Search with Language Models": {
        "type": "INPROCEEDINGS",
        "key": "gupta-li-2024-training",
        "author": "Gupta, Devaansh and Li, Boyang",
        "booktitle": "EMNLP-findings2024",
        "title": "A Training Data Recipe to Accelerate A* Search with Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Combining Large Language Models (LLMs) with heuristic search algorithms like A* holds the promise of enhanced LLM reasoning and scalable inference. To accelerate training and reduce computational demands, we investigate the coreset selection problem for the training data of LLM heuristic learning. Few methods to learn the heuristic functions consider the interaction between the search algorithm and the machine learning model. In this work, we empirically disentangle the requirements of A* search algorithm from the requirements of the LLM to generalise on this task. Surprisingly, we find an overlap between their requirements; A* requires more accurate predictions on search nodes near the goal, and LLMs need the same set of nodes for effective generalisation. With these insights, we derive a data-selection distribution for learning LM-based heuristics. On three classical planning domains, maze navigation, Sokoban and sliding tile puzzles, our technique reduces the number of iterations required to find the solutions by up to 15x, with a wall-clock speed-up of search up to 5x. The code has been made available at https://github.com/devaansh100/a_star.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.391",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions": {
        "type": "INPROCEEDINGS",
        "key": "shin-etal-2024-generation",
        "author": "Shin, Donghyeon and Lee, Seungpil and Kovacec, Klea Lena and Kim, Sundong",
        "booktitle": "EMNLP-findings2024",
        "title": "From Generation to Selection: Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As artificial intelligence reasoning abilities gain prominence, generating reliable benchmarks becomes crucial. The Abstract and Reasoning Corpus (ARC) offers challenging problems yet unsolved by AI. While ARC effectively assesses reasoning, its generation-based evaluation overlooks other assessment aspects. Bloom\u2019s Taxonomy suggests evaluating six cognitive stages: Remember, Understand, Apply, Analyze, Evaluate, and Create. To extend ARC\u2019s focus beyond the Create stage, we developed MC-LARC, a multiple-choice format suitable for assessing stages like Understand and Apply in Large Language Models (LLMs). Our evaluation of ChatGPT4V\u2019s analogical reasoning using MC-LARC confirmed that this format supports LLMs\u2019 reasoning capabilities and facilitates evidence analysis. However, we observed LLMs using shortcuts in MC-LARC tasks. To address this, we propose a self-feedback framework where LLMs identify issues and generate improved options. MC-LARC is available at https://mc-larc.github.io/.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.392",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "What\u2019s under the hood: Investigating Automatic Metrics on Meeting Summarization": {
        "type": "INPROCEEDINGS",
        "key": "kirstein-etal-2024-whats",
        "author": "Kirstein, Frederic and Wahle, Jan Philip and Ruas, Terry and Gipp, Bela",
        "booktitle": "EMNLP-findings2024",
        "title": "What\u2019s under the hood: Investigating Automatic Metrics on Meeting Summarization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Meeting summarization has become a critical task considering the increase in online interactions. Despite new techniques being proposed regularly, the evaluation of meeting summarization techniques relies on metrics not tailored to capture meeting-specific errors, leading to ineffective assessment. This paper explores what established automatic metrics capture and the errors they mask by correlating metric scores with human evaluations across a comprehensive error taxonomy. We start by reviewing the literature on English meeting summarization to identify key challenges, such as speaker dynamics and contextual turn-taking, and error types, including missing information and linguistic inaccuracy, concepts previously loosely defined in the field. We then examine the relationship between these challenges and errors using human annotated transcripts and summaries from encoder-decoder-based and autoregressive Transformer models on the QMSum dataset. Experiments reveal that different model architectures respond variably to the challenges, resulting in distinct links between challenges and errors. Current established metrics struggle to capture the observable errors, showing weak to moderate correlations, with a third of the correlations indicating error masking. Only a subset of metrics accurately reacts to specific errors, while most correlations show either unresponsiveness or failure to reflect the error\u2019s impact on summary quality.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.393",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages": {
        "type": "INPROCEEDINGS",
        "key": "schmidt-etal-2024-self",
        "author": "Schmidt, Fabian David and Borchert, Philipp and Vuli\u0107, Ivan and Glava\u0161, Goran",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "LLMs have become a go-to solution not just for text generation, but also for natural language understanding (NLU) tasks. Acquiring extensive knowledge through language modeling on web-scale corpora, they excel on English NLU, yet struggle to extend their NLU capabilities to underrepresented languages. In contrast, machine translation models (MT) produce excellent multilingual representations, resulting in strong translation performance even for low-resource languages. MT encoders, however, lack the knowledge necessary for comprehensive NLU that LLMs obtain through language modeling training on immense corpora. In this work, we get the best both worlds by integrating MT encoders directly into LLM backbones via sample-efficient self-distillation. The resulting MT-LLMs preserve the inherent multilingual representational alignment from the MT encoder, allowing lower-resource languages to tap into the rich knowledge embedded in English-centric LLMs. Merging the MT encoder and LLM in a single model, we mitigate the propagation of translation errors and inference overhead of MT decoding inherent to discrete translation-based cross-lingual transfer (e.g., translate-test). Evaluation spanning three prominent NLU tasks and 127 predominantly low-resource languages renders MT-LLMs highly effective in cross-lingual transfer. MT-LLMs substantially and consistently outperform translation-test based on the same MT model, showing that we truly unlock multilingual language understanding for LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.394",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference": {
        "type": "INPROCEEDINGS",
        "key": "yamaguchi-etal-2024-empirical",
        "author": "Yamaguchi, Atsuki and Villavicencio, Aline and Aletras, Nikolaos",
        "booktitle": "EMNLP-findings2024",
        "title": "An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Language Model Inference",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The development of state-of-the-art generative large language models (LLMs) disproportionately relies on English-centric tokenizers, vocabulary and pre-training data. Despite the fact that some LLMs have multilingual capabilities, recent studies have shown that their inference efficiency deteriorates when generating text in languages other than English. This results in increased inference time and costs. Cross-lingual vocabulary adaptation (CVA) methods have been proposed for adapting models to a target language aiming to improve downstream performance. However, the effectiveness of these methods on increasing inference efficiency of generative LLMs has yet to be explored. In this paper, we perform an empirical study of five CVA methods on four generative LLMs (including monolingual and multilingual models) across four typologically-diverse languages and four natural language understanding tasks. We find that CVA substantially contributes to LLM inference speedups of up to 271.5%. We also show that adapting LLMs that have been pre-trained on more balanced multilingual data results in downstream performance comparable to the original models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.396",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "cheng-etal-2024-autodetect",
        "author": "Cheng, Jiale and Lu, Yida and Gu, Xiaotao and Ke, Pei and Liu, Xiao and Dong, Yuxiao and Wang, Hongning and Tang, Jie and Huang, Minlie",
        "booktitle": "EMNLP-findings2024",
        "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Although Large Language Models (LLMs) are becoming increasingly powerful, they still exhibit significant but subtle weaknesses, such as mistakes in instruction-following or coding tasks.As these unexpected errors could lead to severe consequences in practical deployments, it is crucial to investigate the limitations within LLMs systematically.Traditional benchmarking approaches cannot thoroughly pinpoint specific model deficiencies, while manual inspections are costly and not scalable. In this paper, we introduce a unified framework, AutoDetect, to automatically expose weaknesses in LLMs across various tasks. Inspired by the educational assessment process that measures students\u2019 learning outcomes, AutoDetect consists of three LLM-powered agents: Examiner, Questioner, and Assessor.The collaboration among these three agents is designed to realize comprehensive and in-depth weakness identification. Our framework demonstrates significant success in uncovering flaws, with an identification success rate exceeding 30% in prominent models such as ChatGPT and Claude.More importantly, these identified weaknesses can guide specific model improvements, proving more effective than untargeted data augmentation methods like Self-Instruct. Our approach has led to substantial enhancements in popular LLMs, including the Llama series and Mistral-7b, boosting their performance by over 10% across several benchmarks.Code and data are publicly available at https://github.com/thu-coai/AutoDetect.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.397",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-bapo",
        "author": "Lee, Gihun and Jeong, Minchan and Kim, Yujin and Jung, Hojung and Oh, Jaehoon and Kim, SangMook and Yun, Se-Young",
        "booktitle": "EMNLP-findings2024",
        "title": "BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in Large Language Models Personalization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While learning to align Large Language Models (LLMs) with human preferences has shown remarkable success, aligning these models to meet the diverse user preferences presents further challenges in preserving previous knowledge. This paper examines the impact of personalized preference optimization on LLMs, revealing that the extent of knowledge loss varies significantly with preference heterogeneity. Although previous approaches have utilized the KL constraint between the reference model and the policy model, we observe that they fail to maintain general knowledge and alignment when facing personalized preferences. To this end, we introduce Base-Anchored Preference Optimization (BAPO), a simple yet effective approach that utilizes the initial responses of reference model to mitigate forgetting while accommodating personalized alignment. BAPO effectively adapts to diverse user preferences while minimally affecting global knowledge or general alignment. Our experiments demonstrate the efficacy of BAPO in various setups.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.398",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "kumar-etal-2024-beyond",
        "author": "Kumar, Rishabh and Ghosh, Sabyasachi and Ramakrishnan, Ganesh",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this work, we address the challenge of cross-lingual proper noun recognition in automatic speech recognition (ASR), where proper nouns in an utterance may originate from a language different from the language in which the ASR system is trained. We enhance the performance of end-to-end ASR systems by instructing a large language model (LLM) to correct the ASR model\u2019s predictions. The LLM\u2019s context is augmented with a dictionary of cross-lingual words that are phonetically and graphemically similar to the potentially incorrect proper nouns in the ASR predictions. Our dictionary-based method DiP-ASR (Dictionary-based Prompting for Automatic Speech Recognition) significantly reduces word error rates compared to both the end-to-end ASR baseline and instruction-based prompting of the LLM without the dictionary across cross-lingual proper noun recognition tasks involving three secondary languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.399",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting": {
        "type": "INPROCEEDINGS",
        "key": "naguib-etal-2024-shot",
        "author": "Naguib, Marco and Tannier, Xavier and N\u00e9v\u00e9ol, Aur\u00e9lie",
        "booktitle": "EMNLP-findings2024",
        "title": "Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have become the preferred solution for many natural language processing tasks. In low-resource environments such as specialized domains, their few-shot capabilities are expected to deliver high performance. Named Entity Recognition (NER) is a critical task in information extraction that is not covered in recent LLM benchmarks. There is a need for better understanding the performance of LLMs for NER in a variety of settings including languages other than English. This study aims to evaluate generative LLMs, employed through prompt engineering, for few-shot clinical NER. We compare 13 auto-regressive models using prompting and 16 masked models using fine-tuning on 14 NER datasets covering English, French and Spanish. While prompt-based auto-regressive models achieve competitive F1 for general NER, they are outperformed within the clinical domain by lighter biLSTM-CRF taggers based on masked models. Additionally, masked models exhibit lower environmental impact compared to auto-regressive models. Findings are consistent across the three languages studied, which suggests that LLM prompting is not yet suited for NER production in the clinical domain.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.400",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "STTATTS: Unified Speech-To-Text And Text-To-Speech Model": {
        "type": "INPROCEEDINGS",
        "key": "toyin-etal-2024-sttatts",
        "author": "Toyin, Hawau Olamide and Li, Hao and Aldarmaki, Hanan",
        "booktitle": "EMNLP-findings2024",
        "title": "STTATTS: Unified Speech-To-Text And Text-To-Speech Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Speech recognition and speech synthesis models are typically trained separately, each with its own set of learning objectives, training data, and model parameters, resulting in two distinct large networks. We propose a parameter-efficient approach to learning ASR and TTS jointly via a multi-task learning objective and shared parameters. Our evaluation demonstrates thatthe performance of our multi-task model is comparable to that of individually trained models while significantly savingcomputational and memory costs (~50% reduction in the total number of parameters required for the two tasks combined). We experiment with English as a resource-rich language, and Arabic as a relatively low-resource language due to shortage of TTS data. Our models are trained with publicly available data, and both the training code and model checkpoints are openly available for further research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.401",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "From Text Segmentation to Enhanced Representation Learning: A Novel Approach to Multi-Label Classification for Long Texts": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-text-segmentation",
        "author": "Zhang, Wang and Wang, Xin and Wang, Qian and Deng, Tao and Wu, Xiaoru",
        "booktitle": "EMNLP-findings2024",
        "title": "From Text Segmentation to Enhanced Representation Learning: A Novel Approach to Multi-Label Classification for Long Texts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multi-label text classification (MLTC) is an important task in the field of natural language processing. Most existing models rely on high-quality text representations provided by pre-trained language models (PLMs). They hence face the challenge of input length limitation caused by PLMs, when dealing with long texts. In light of this, we introduce a comprehensive approach to multi-label long text classification. We propose a text segmentation algorithm, which guarantees to produce the optimal segmentation, to address the issue of input length limitation caused by PLMs. We incorporate external knowledge, labels\u2019 co-occurrence relations, and attention mechanisms in representation learning to enhance both text and label representations. Our method\u2019s effectiveness is validated through extensive experiments on various MLTC datasets, unraveling the intricate correlations between texts and labels.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.402",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL": {
        "type": "INPROCEEDINGS",
        "key": "zhong-etal-2024-learning",
        "author": "Zhong, Qihuang and Chen, Kunfeng and Ding, Liang and Liu, Juhua and Du, Bo and Tao, Dacheng",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have shown promising performance in text-to-SQL, which involves translating natural language questions into SQL queries. However, current text-to-SQL LLMs are computationally expensive and challenging to deploy in real-world applications, highlighting the importance of compressing them. To achieve this goal, knowledge distillation (KD) is a common approach, which aims to distill the larger teacher model into a smaller student model. While numerous KD methods for autoregressive LLMs have emerged recently, it is still under-explored whether they work well in complex text-to-SQL scenarios. To this end, we conduct a series of analyses and reveal that these KD methods generally fall short in balancing performance and efficiency. In response to this problem, we propose to improve the KD with imperfect data, namely KID, which effectively boosts the performance without introducing much training budget. The core of KID is to efficiently mitigate the training-inference mismatch by simulating the cascading effect of inference in the imperfect training data. Extensive experiments on 5 text-to-SQL benchmarks show that, KID can not only achieve consistent and significant performance gains (up to +5.83% average score) across all model types and sizes, but also effectively improve the training efficiency.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.403",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-conu",
        "author": "Wang, Zhiyuan and Duan, Jinhao and Cheng, Lu and Zhang, Yue and Wang, Qingni and Shi, Xiaoshuang and Xu, Kaidi and Shen, Heng Tao and Zhu, Xiaofeng",
        "booktitle": "EMNLP-findings2024",
        "title": "ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Uncertainty quantification (UQ) in natural language generation (NLG) tasks remains an open challenge, exacerbated by the closed-source nature of the latest large language models (LLMs). This study investigates applying conformal prediction (CP), which can transform any heuristic uncertainty notion into rigorous prediction sets, to black-box LLMs in open-ended NLG tasks. We introduce a novel uncertainty measure based on self-consistency theory, and then develop a conformal uncertainty criterion by integrating the uncertainty condition aligned with correctness into the CP algorithm. Empirical evaluations indicate that our uncertainty measure outperforms prior state-of-the-art methods. Furthermore, we achieve strict control over the correctness coverage rate utilizing 7 popular LLMs on 4 free-form NLG datasets, spanning general-purpose and medical scenarios. Additionally, the calibrated prediction sets with small size further highlights the efficiency of our method in providing trustworthy guarantees for practical open-ended NLG applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.404",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Irrelevant Alternatives Bias Large Language Model Hiring Decisions": {
        "type": "INPROCEEDINGS",
        "key": "valkanova-yordanov-2024-irrelevant",
        "author": "Valkanova, Kremena and Yordanov, Pencho",
        "booktitle": "EMNLP-findings2024",
        "title": "Irrelevant Alternatives Bias Large Language Model Hiring Decisions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We investigate whether LLMs display a well-known human cognitive bias, the attraction effect, in hiring decisions. The attraction effect occurs when the presence of an inferior candidate makes a superior candidate more appealing, increasing the likelihood of the superior candidate being chosen over a non-dominated competitor. Our study finds consistent and significant evidence of the attraction effect in GPT-3.5 and GPT-4 when they assume the role of a recruiter. Irrelevant attributes of the decoy, such as its gender, further amplify the observed bias. GPT-4 exhibits greater bias variation than GPT-3.5. Our findings remain robust even when warnings against the decoy effect are included and the recruiter role definition is varied.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.405",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PclGPT: A Large Language Model for Patronizing and Condescending Language Detection": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-pclgpt",
        "author": "Wang, Hongbo and LiMingDa, LiMingDa and Lu, Junyu and Xia, Hebin and Yang, Liang and Xu, Bo and Liu, Ruizhu and Lin, Hongfei",
        "booktitle": "EMNLP-findings2024",
        "title": "PclGPT: A Large Language Model for Patronizing and Condescending Language Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Disclaimer: Samples in this paper may be harmful and cause discomfort! Patronizing and condescending language (PCL) is a form of speech directed at vulnerable groups. As an essential branch of toxic language, this type of language exacerbates conflicts and confrontations among Internet communities and detrimentally impacts disadvantaged groups. Traditional pre-trained language models (PLMs) perform poorly in detecting PCL due to its implicit toxicity traits like hypocrisy and false sympathy. With the rise of large language models (LLMs), we can harness their rich emotional semantics to establish a paradigm for exploring implicit toxicity. In this paper, we introduce PclGPT, a comprehensive LLM benchmark designed specifically for PCL. We collect, annotate, and integrate the Pcl-PT/SFT dataset, and then develop a bilingual PclGPT-EN/CN model group through a comprehensive pre-training and supervised fine-tuning staircase process to facilitate implicit toxic detection. Group detection results and fine-grained detection from PclGPT and other models reveal significant variations in the degree of bias in PCL towards different vulnerable groups, necessitating increased societal attention to protect them.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.406",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate": {
        "type": "INPROCEEDINGS",
        "key": "amayuelas-etal-2024-multiagent",
        "author": "Amayuelas, Alfonso and Yang, Xianjun and Antoniades, Antonis and Hua, Wenyue and Pan, Liangming and Wang, William Yang",
        "booktitle": "EMNLP-findings2024",
        "title": "MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have shown exceptional results on current benchmarks when working individually. The advancement in their capabilities, along with a reduction in parameter size and inference times, has facilitated the use of these models as agents, enabling interactions among multiple models to execute complex tasks. Such collaborations offer several advantages, including the use of specialized models (e.g. coding), improved confidence through multiple computations, and enhanced divergent thinking, leading to more diverse outputs. Thus, the collaborative use of language models is expected to grow significantly in the coming years. In this work, we evaluate the behavior of a network of models collaborating through debate under the influence of an adversary. We introduce pertinent metrics to assess the adversary\u2019s effectiveness, focusing on system accuracy and model agreement. Our findings highlight the importance of a model\u2019s persuasive ability in influencing others. Additionally, we explore inference-time methods to generate more compelling arguments and evaluate the potential of prompt-based mitigation as a defensive strategy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.407",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CEAMC: Corpus and Empirical Study of Argument Analysis in Education via LLMs": {
        "type": "INPROCEEDINGS",
        "key": "ren-etal-2024-ceamc",
        "author": "Ren, Yupei and Wu, Hongyi and Long, Zhaoguang and Zhao, Shangqing and Zhou, Xinyi and Yin, Zheqin and Zhuang, Xinlin and Bai, Xiaopeng and Lan, Man",
        "booktitle": "EMNLP-findings2024",
        "title": "CEAMC: Corpus and Empirical Study of Argument Analysis in Education via LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper introduces the Chinese Essay Argument Mining Corpus (CEAMC), a manually annotated dataset designed for argument component classification on multiple levels of granularity. Existing argument component types in education remain simplistic and isolated, failing to encapsulate the complete argument information. Originating from authentic examination settings, CEAMC categorizes argument components into 4 coarse-grained and 10 fine-grained delineations, surpassing previous simple representations to capture the subtle nuances of argumentation in the real world, thus meeting the needs of complex and diverse argumentative scenarios. Our contributions include the development of CEAMC, the establishment of baselines for further research, and a thorough exploration of the performance of Large Language Models (LLMs) on CEAMC. The results indicate that our CEAMC can serve as a challenging benchmark for the development of argument analysis in education.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.408",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "cui-wang-2024-ada",
        "author": "Cui, Wanyun and Wang, Qianle",
        "booktitle": "EMNLP-findings2024",
        "title": "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Instructions augmentation is a crucial step for unleashing the full potential of large language models (LLMs) in downstream tasks. Existing Self-Instruct methods primarily simulate new instructions from a few initial instructions with in-context learning. However, our study identifies a critical flaw in this approach: even with GPT4o, it cannot generate complex instructions of length \\ge 100, which is necessary in complex tasks such as code completion.To address this issue, our key insight is that fine-tuning open source LLMs with only ten examples can produce complex instructions that maintain distributional consistency for complex reasoning tasks. We introduce Ada-Instruct, an adaptive instruction generator developed through fine-tuning. We empirically validated Ada-Instruct\u2019s efficacy across different applications. The results highlight Ada-Instruct\u2019s capacity to generate long, intricate, and distributionally consistent instructions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.409",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LINKAGE: Listwise Ranking among Varied-Quality References for Non-Factoid QA Evaluation via LLMs": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-linkage",
        "author": "Yang, Sihui and Bi, Keping and Cui, Wanqing and Guo, Jiafeng and Cheng, Xueqi",
        "booktitle": "EMNLP-findings2024",
        "title": "LINKAGE: Listwise Ranking among Varied-Quality References for Non-Factoid QA Evaluation via LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Non-Factoid (NF) Question Answering (QA) is challenging to evaluate due to diverse potential answers and no objective criterion. The commonly used automatic evaluation metrics like ROUGE or BERTScore cannot accurately measure semantic similarities or answers from different perspectives. Recently, Large Language Models (LLMs) have been resorted to for NFQA evaluation due to their compelling performance on various NLP tasks. Common approaches include pointwise scoring of each candidate answer and pairwise comparisons between answers. Inspired by the evolution from pointwise to pairwise to listwise in learning-to-rank methods, we propose a novel listwise NFQA evaluation approach, that utilizes LLMs to rank candidate answers in a list of reference answers sorted by descending quality. Moreover, for NF questions that do not have multi-grade or any golden answers, we leverage LLMs to generate the reference answer list of various quality to facilitate the listwise evaluation. Extensive experimental results on three NFQA datasets, i.e., ANTIQUE, the TREC-DL-NF, and WebGLM show that our method has significantly higher correlations with human annotations compared to automatic scores and common pointwise and pairwise approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.410",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-breaking",
        "author": "Chen, Nuo and Zheng, Zinan and Wu, Ning and Gong, Ming and Zhang, Dongmei and Li, Jia",
        "booktitle": "EMNLP-findings2024",
        "title": "Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing research predominantly focuses on developing powerful large language models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we construct the first multilingual math reasoning instruction dataset, **MGSM8KInstruct**, encompassing ten distinct languages, thus addressing the issue of training data scarcity in xMR tasks. Based on the collected dataset, we propose different training strategies to build powerful xMR LLMs, named MathOctopus, notably outperform conventional open-source LLMs and exhibit superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond remarkable results, we unearth several pivotal observations and insights: (1) When extending the rejection sampling strategy to the multilingual context, it proves effective for model performances, albeit limited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT) across multiple languages not only significantly enhances model performance multilingually but also elevates their monolingual performance. This indicates that crafting multilingual corpora can be regarded as a vital strategy for enhancing model performance in a specific language, especially in mathematical reasoning tasks. For instance, MathOctopus-7B improves its counterparts that trained on English from 42.4% to 50.8% on the GSM8K test set.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.411",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SynthEval: Hybrid Behavioral Testing of NLP Models with Synthetic Evaluation": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-syntheval",
        "author": "Zhao, Raoyuan and K\u00f6ksal, Abdullatif and Liu, Yihong and Weissweiler, Leonie and Korhonen, Anna and Schuetze, Hinrich",
        "booktitle": "EMNLP-findings2024",
        "title": "SynthEval: Hybrid Behavioral Testing of NLP Models with Synthetic Evaluation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Traditional benchmarking in NLP typically involves using static, held-out test sets and calculating aggregated statistics based on diverse examples. However, this approach often results in an overestimation of performance and lacks the ability to offer comprehensive, interpretable, and dynamic assessments of NLP models. Recently, works like DynaBench and Checklist have addressed these limitations through behavioral testing of NLP models with test types generated by a multi-step human-annotated pipeline. Unfortunately, manually creating a variety of test types requires significant human labor, thus weakening efficiency. In this work, we propose SynthEval, a hybrid behavioral testing framework that leverages large language models (LLMs) to generate a wide range of test types for a comprehensive evaluation of NLP models. The SynthEval framework first generates sentences via LLMs using controlled generation, and then identifies challenging examples by comparing the predictions made by LLMs with task-specific NLP models. In the last stage, human experts investigate the challenging examples, manually design templates, and identify the types of failures the task-specific models consistently exhibit. We apply SynthEval to two classification tasks and show that our framework is effective in identifying weaknesses of strong models on these tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.412",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish": {
        "type": "INPROCEEDINGS",
        "key": "yuksel-etal-2024-turkishmmlu",
        "author": "Y\u00fcksel, Arda and K\u00f6ksal, Abdullatif and Senel, L\u00fctfi Kerem and Korhonen, Anna and Schuetze, Hinrich",
        "booktitle": "EMNLP-findings2024",
        "title": "TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multiple choice question answering tasks evaluate the reasoning, comprehension, and mathematical abilities of Large Language Models (LLMs). While existing benchmarks employ automatic translation for multilingual evaluation, this approach is error-prone and potentially introduces culturally biased questions, especially in social sciences. We introduce the first multitask, multiple-choice Turkish QA benchmark, TurkishMMLU, to evaluate LLMs\u2019 understanding of the Turkish language. TurkishMMLU includes over 10,000 questions, covering 9 different subjects from Turkish high-school education curricula. These questions are written by curriculum experts, suitable for the high-school curricula in Turkey, covering subjects ranging from natural sciences and math questions to more culturally representative topics such as Turkish Literature and the history of the Turkish Republic. We evaluate over 20 LLMs, including multilingual open-source (e.g., Gemma, Llama, MT5), closed-source (GPT 4o, Claude, Gemini), and Turkish-adapted (e.g., Trendyol) models. We provide an extensive evaluation, including zero-shot and few-shot evaluation of LLMs, chain-of-thought reasoning, and question difficulty analysis along with model performance. We provide an in-depth analysis of the Turkish capabilities and limitations of current LLMs to provide insights for future LLMs for the Turkish language. We publicly release our code for the dataset and evaluation: https://github.com/ArdaYueksel/TurkishMMLU",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.413",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LongForm: Effective Instruction Tuning with Reverse Instructions": {
        "type": "INPROCEEDINGS",
        "key": "koksal-etal-2024-longform",
        "author": "K\u00f6ksal, Abdullatif and Schick, Timo and Korhonen, Anna and Schuetze, Hinrich",
        "booktitle": "EMNLP-findings2024",
        "title": "LongForm: Effective Instruction Tuning with Reverse Instructions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Instruction tuning enables language models to more effectively generalize and better follow user intent. However, obtaining instruction data is costly and challenging. Prior work employs methods such as expensive human annotation, crowd-sourced datasets with alignment issues, and generating noisy examples via LLMs. We introduce the LongForm-C dataset, which is created by reverse instructions. We generate instructions via LLMs for human-written corpus examples using reverse instructions. First we select a diverse set of human-written documents from corpora such as C4 and Wikipedia; then we generate instructions for these documents via LLMs. This approach provides a cheaper and cleaner instruction-tuning dataset with natural output and one suitable for long text generation. Our models outperform 10x larger language models without instruction tuning on tasks such as story/recipe generation and long-form question answering. Moreover, LongForm models outperform prior instruction-tuned models such as FLAN-T5 and Alpaca by a large margin, and improve language understanding capabilities further. We publicly release our data and models: [Anonymized-URL].",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.414",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective on Molecule Graphs": {
        "type": "INPROCEEDINGS",
        "key": "he-etal-2024-explaining",
        "author": "He, Yinhan and Zheng, Zaiyi and Soga, Patrick and Zhu, Yaochen and Dong, Yushun and Li, Jundong",
        "booktitle": "EMNLP-findings2024",
        "title": "Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective on Molecule Graphs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In recent years, Graph Neural Networks (GNNs) have become successful in molecular property prediction tasks such as toxicity analysis. However, due to the black-box nature of GNNs, their outputs can be concerning in high-stakes decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph Counterfactual Explanation (GCE) has emerged as a promising approach to improve GNN transparency. However, current GCE methods usually fail to take domain-specific knowledge into consideration, which can result in outputs that are not easily comprehensible by humans. To address this challenge, we propose a novel GCE method, LLM-GCE, to unleash the power of large language models (LLMs) in explaining GNNs for molecular property prediction. Specifically, we utilize an autoencoder to generate the counterfactual graph topology from a set of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which provides intermediate feedback derived from the generated counterfactuals as an attempt to give more faithful guidance. Extensive experiments demonstrate the superior performance of LLM-GCE. Our code is released on https://github.com/YinhanHe123/new_LLM4GNNExplanation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.415",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Knowledge Mechanisms in Large Language Models: A Survey and Perspective": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-knowledge-mechanisms",
        "author": "Wang, Mengru and Yao, Yunzhi and Xu, Ziwen and Qiao, Shuofei and Deng, Shumin and Wang, Peng and Chen, Xiang and Gu, Jia-Chen and Jiang, Yong and Xie, Pengjun and Huang, Fei and Chen, Huajun and Zhang, Ningyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Knowledge Mechanisms in Large Language Models: A Survey and Perspective",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial for advancing towards trustworthy AGI. This paper reviews knowledge mechanism analysis from a novel taxonomy including knowledge utilization and evolution. Knowledge utilization delves into the mechanism of memorization, comprehension and application, and creation. Knowledge evolution focuses on the dynamic progression of knowledge within individual and group LLMs. Moreover, we discuss what knowledge LLMs have learned, the reasons for the fragility of parametric knowledge, and the potential dark knowledge (hypothesis) that will be challenging to address. We hope this work can help understand knowledge in LLMs and provide insights for future research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.416",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LongHeads: Multi-Head Attention is Secretly a Long Context Processor": {
        "type": "INPROCEEDINGS",
        "key": "lu-etal-2024-longheads",
        "author": "Lu, Yi and Zhou, Xin and He, Wei and Zhao, Jun and Ji, Tao and Gui, Tao and Zhang, Qi and Huang, Xuanjing",
        "booktitle": "EMNLP-findings2024",
        "title": "LongHeads: Multi-Head Attention is Secretly a Long Context Processor",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have achieved impressive performance in numerous domains but often struggle to process lengthy inputs effectively and efficiently due to limited length generalization and attention\u2019s quadratic computational demands. Many sought to mitigate this by restricting the attention window within the pre-trained length. However, these methods introduce new issues such as ignoring the middle context and requiring additional training. To address these problems, we propose LongHeads, a training-free framework that enhances LLM\u2019s long context ability by unlocking multi-head attention\u2019s untapped potential. Instead of allowing each head to attend to the full sentence, which struggles with generalizing to longer sequences due to out-of-distribution (OOD) issues, we allow each head to process in-distribution length by selecting and attending to important context chunks. To this end, we propose a chunk selection strategy that relies on the inherent correlation between the query and the key representations, efficiently distributing context chunks to different heads. In this way, each head ensures it can effectively process attended tokens within the trained length, while different heads in different layers can collectively process longer contexts. LongHeads works efficiently and fits seamlessly with many LLMs that use relative positional encoding. LongHeads achieves 100% accuracy at the 128k length on passkey retrieval task, verifying LongHeads\u2019 efficacy in extending the usable context window for existing models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.417",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Crisis counselor language and perceived genuine concern in crisis conversations": {
        "type": "INPROCEEDINGS",
        "key": "buda-etal-2024-crisis",
        "author": "Buda, Greg and Tripodi, Ignacio J. and Meagher, Margaret and Olson, Elizabeth A.",
        "booktitle": "EMNLP-findings2024",
        "title": "Crisis counselor language and perceived genuine concern in crisis conversations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Although clients\u2019 perceptions of therapist empathy are known to correlate with therapy effectiveness, the specific ways that the therapist\u2019s language use contributes to perceived empathy remain less understood. Natural Language Processing techniques, such as transformer models, permit the quantitative, automated, and scalable analysis of therapists\u2019 verbal behaviors. Here, we present a novel approach to extract linguistic features from text-based crisis intervention transcripts to analyze associations between specific crisis counselor verbal behaviors and perceived genuine concern. Linguistic features associated with higher perceived genuine concern included positive emotional language and affirmations; features associated with lower perceived genuine concern included self-oriented talk and overuse of templates. These findings provide preliminary evidence toward pathways for automating real-time feedback to crisis counselors about clients\u2019 perception of the therapeutic relationship.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.418",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Edit-Constrained Decoding for Sentence Simplification": {
        "type": "INPROCEEDINGS",
        "key": "zetsu-etal-2024-edit",
        "author": "Zetsu, Tatsuya and Arase, Yuki and Kajiwara, Tomoyuki",
        "booktitle": "EMNLP-findings2024",
        "title": "Edit-Constrained Decoding for Sentence Simplification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We propose edit operation based lexically constrained decoding for sentence simplification. In sentence simplification, lexical paraphrasing is one of the primary procedures for rewriting complex sentences into simpler correspondences. While previous studies have confirmed the efficacy of lexically constrained decoding on this task, their constraints can be loose and may lead to sub-optimal generation. We address this problem by designing constraints that replicate the edit operations conducted in simplification and defining stricter satisfaction conditions. Our experiments indicate that the proposed method consistently outperforms the previous studies on three English simplification corpora commonly used in this task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.419",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas": {
        "type": "INPROCEEDINGS",
        "key": "giorgi-etal-2024-modeling",
        "author": "Giorgi, Salvatore and Liu, Tingting and Aich, Ankit and Isman, Kelsey Jane and Sherman, Garrick and Fried, Zachary and Sedoc, Jo\u00e3o and Ungar, Lyle and Curtis, Brenda",
        "booktitle": "EMNLP-findings2024",
        "title": "Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) are increasingly being used in human-centered social scientific tasks, such as data annotation, synthetic data creation, and engaging in dialog. However, these tasks are highly subjective and dependent on human factors, such as one\u2019s environment, attitudes, beliefs, and lived experiences. Thus, it may be the case that employing LLMs (which do not have such human factors) in these tasks results in a lack of variation in data, failing to reflect the diversity of human experiences. In this paper, we examine the role of prompting LLMs with human-like personas and asking the models to answer as if they were a specific human. This is done explicitly, with exact demographics, political beliefs, and lived experiences, or implicitly via names prevalent in specific populations. The LLM personas are then evaluated via (1) subjective annotation task (e.g., detecting toxicity) and (2) a belief generation task, where both tasks are known to vary across human factors. We examine the impact of explicit vs. implicit personas and investigate which human factors LLMs recognize and respond to. Results show that explicit LLM personas show mixed results when reproducing known human biases, but generally fail to demonstrate implicit biases. We conclude that LLMs may capture the statistical patterns of how people speak, but are generally unable to model the complex interactions and subtleties of human perceptions, potentially limiting their effectiveness in social science applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.420",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection": {
        "type": "INPROCEEDINGS",
        "key": "zahid-etal-2024-multi",
        "author": "Zahid, Iqra and Chang, Yue and Madusanka, Tharindu and Sun, Youcheng and Batista-Navarro, Riza",
        "booktitle": "EMNLP-findings2024",
        "title": "Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Modern natural language generation (NLG) systems have led to the development of synthetic human-like open-ended texts, posing concerns as to who the original author of a text is. To address such concerns, we introduce DeB-Ang: the utilisation of a custom DeBERTa model with angular loss and contrastive loss functions for effective class separation in neural text classification tasks. We expand the application of this model on binary machine-generated text detection and multi-class neural authorship attribution. We demonstrate improved performance on many benchmark datasets whereby the accuracy for machine-generated text detection was increased by as much as 38.04% across all datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.421",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Large Language Model Based Sequential Recommender Systems with Pseudo Labels Reconstruction": {
        "type": "INPROCEEDINGS",
        "key": "na-etal-2024-enhancing",
        "author": "Na, Hyunsoo and Gang, Minseok and Ko, Youngrok and Seol, Jinseok and Lee, Sang-goo",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Large Language Model Based Sequential Recommender Systems with Pseudo Labels Reconstruction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) are utilized in various studies, and they also demonstrate a potential to function independently as a recommendation model. Nevertheless, training sequences and text labels modifies LLMs\u2019 pre-trained weights, diminishing their inherent strength in constructing and comprehending natural language sentences. In this study, we propose a reconstruction-based LLM recommendation model (ReLRec) that harnesses the feature extraction capability of LLMs, while preserving LLMs\u2019 sentence generation abilities. We reconstruct the user and item pseudo-labels generated from user reviews, while training on sequential data, aiming to exploit the key features of both users and items. Experimental results demonstrate the efficacy of label reconstruction in sequential recommendation tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.423",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On the Generalization of Training-based ChatGPT Detection Methods": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-generalization",
        "author": "Xu, Han and Ren, Jie and He, Pengfei and Zeng, Shenglai and Cui, Yingqian and Liu, Amy and Liu, Hui and Tang, Jiliang",
        "booktitle": "EMNLP-findings2024",
        "title": "On the Generalization of Training-based ChatGPT Detection Methods",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models, such as ChatGPT, achieve amazing performance on various language processing tasks. However, they can also be exploited for improper purposes such as plagiarism or misinformation dissemination. Thus, there is an urgent need to detect the texts generated by LLMs. One type of most studied methods trains classification models to distinguish LLM texts from human texts. However, existing studies demonstrate the trained models may suffer from distribution shifts (during test), i.e., they are ineffective to predict the generated texts from unseen language tasks or topics which are not collected during training. In this work, we focus on ChatGPT as a representative model, and we conduct a comprehensive investigation on these methods\u2019 generalization behaviors under distribution shift caused by a wide range of factors, including prompts, text lengths, topics, and language tasks. To achieve this goal, we first collect a new dataset with human and ChatGPT texts, and then we conduct extensive studies on the collected dataset. Our studies unveil insightful findings that provide guidance for future methodologies and data collection strategies for LLM detection.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.424",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Private prediction for large-scale synthetic text generation": {
        "type": "INPROCEEDINGS",
        "key": "amin-etal-2024-private",
        "author": "Amin, Kareem and Bie, Alex and Kong, Weiwei and Kurakin, Alexey and Ponomareva, Natalia and Syed, Umar and Terzis, Andreas and Vassilvitskii, Sergei",
        "booktitle": "EMNLP-findings2024",
        "title": "Private prediction for large-scale synthetic text generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We present an approach for generating differentially private synthetic text using large language models (LLMs), via private prediction. In the private prediction framework, we only require the output synthetic data to satisfy differential privacy guarantees. This is in contrast to approaches that train a generative model on potentially sensitive user-supplied source data and seek to ensure the model itself is safe to release.We prompt a pretrained LLM with source data, but ensure that next-token predictions are made with differential privacy guarantees. Previous work in this paradigm reported generating a small number of examples (&lt;10) at reasonable privacy levels, an amount of data that is useful only for downstream in-context learning or prompting. In contrast, we make changes that allow us to generate thousands of high-quality synthetic data points, greatly expanding the set of potential applications. Our improvements come from an improved privacy analysis and a better private selection mechanism, which makes use of the equivalence between the softmax layer for sampling tokens in LLMs and the exponential mechanism. Furthermore, we introduce a novel use of public predictions via the sparse vector technique, in which we do not pay privacy costs for tokens that are predictable without sensitive data; we find this to be particularly effective for structured data.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.425",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Multi-Agent Debate with Sparse Communication Topology": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-improving-multi",
        "author": "Li, Yunxuan and Du, Yibing and Zhang, Jiageng and Hou, Le and Grabowski, Peter and Li, Yeqing and Ie, Eugene",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Multi-Agent Debate with Sparse Communication Topology",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multi-agent debate has proven effective in improving large language models quality for reasoning and factuality tasks. While various role-playing strategies in multi-agent debates have been explored, in terms of the communication among agents, existing approaches adopt a brute force algorithm \u2013 each agent can communicate with all other agents. In this paper, we systematically investigate the effect of communication connectivity in multi-agent systems. Our experiments on GPT and Mistral models reveal that multi-agent debates leveraging sparse communication topology can achieve comparable or superior performance while significantly reducing computational costs. Furthermore, we extend the multi-agent debate framework to multi-modal reasoning and alignment labeling tasks, showcasing its broad applicability and effectiveness. Our findings underscore the importance of communication connectivity on enhancing the efficiency and effectiveness of the \u201csociety of minds\u201d approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.427",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evidence Retrieval for Fact Verification using Multi-stage Reranking": {
        "type": "INPROCEEDINGS",
        "key": "malviya-katsigiannis-2024-evidence",
        "author": "Malviya, Shrikant and Katsigiannis, Stamos",
        "booktitle": "EMNLP-findings2024",
        "title": "Evidence Retrieval for Fact Verification using Multi-stage Reranking",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In the fact verification domain, the accuracy and efficiency of evidence retrieval are paramount. This paper presents a novel approach to enhance the fact verification process through a Multi-stage ReRanking (M-ReRank) paradigm, which addresses the inherent limitations of single-stage evidence extraction. Our methodology leverages the strengths of advanced reranking techniques, including dense retrieval models and list-aware rerankers, to optimise the retrieval and ranking of evidence of both structured and unstructured types. We demonstrate that our approach significantly outperforms previous state-of-the-art models, achieving a recall rate of 93.63% for Wikipedia pages. The proposed system not only improves the retrieval of relevant sentences and table cells but also enhances the overall verification accuracy. Through extensive experimentation on the FEVEROUS dataset, we show that our M-ReRank pipeline achieves substantial improvements in evidence extraction, particularly increasing the recall of sentences by 7.85%, tables by 8.29% and cells by 3% compared to the current state-of-the-art on the development set.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.428",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-multi-step",
        "author": "Wang, Zihan and Li, Yunxuan and Wu, Yuexin and Luo, Liangchen and Hou, Le and Yu, Hongkun and Shang, Jingbo",
        "booktitle": "EMNLP-findings2024",
        "title": "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Process supervision, using a trained verifier to evaluate the intermediate steps generated by a reasoner, has demonstrated significant improvements in multi-step problem solving. In this paper, to avoid the expensive effort of human annotation on the verifier training data, we introduce Model-induced Process Supervision (MiPS), a novel method for automating data curation. MiPS annotates an intermediate step by sampling completions of this solution through the reasoning model, and obtaining an accuracy defined as the proportion of correct completions. Inaccuracies of the reasoner would cause MiPS underestimating the accuracy of intermediate steps, therefore, we suggest and empirically show that verification focusing on high predicted scores of the verifier shall be preferred over that of low predicted scores, contrary to prior observations on human curated data. Our approach significantly improves the performance of PaLM 2 on math and coding tasks (accuracy +0.67% on GSM8K, +4.16% on MATH, +0.92% on MBPP compared with an output supervision trained verifier). Additionally, our study demonstrates that the verifier exhibits strong generalization ability across different reasoning models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.429",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MUSCLE: A Model Update Strategy for Compatible LLM Evolution": {
        "type": "INPROCEEDINGS",
        "key": "echterhoff-etal-2024-muscle",
        "author": "Echterhoff, Jessica Maria and Faghri, Fartash and Vemulapalli, Raviteja and Hu, Ting-Yao and Li, Chun-Liang and Tuzel, Oncel and Pouransari, Hadi",
        "booktitle": "EMNLP-findings2024",
        "title": "MUSCLE: A Model Update Strategy for Compatible LLM Evolution",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are regularly updated to enhance performance, typically through changes in data or architecture. Within the update process, developers often prioritize improving overall performance metrics, paying less attention to maintaining compatibility with earlier model versions. Instance-level degradation (instance regression) of performance from one model version to the next can interfere with a user\u2019s mental model of the capabilities of a particular language model. Users having to adapt their mental model with every update can lead to dissatisfaction, especially when the new model has degraded compared to a prior version for a known use case (model update regression).We find that when pretrained LLM base models are updated, fine-tuned user-facing downstream task adapters experience negative flips \u2013 previously correct instances are now predicted incorrectly. We observe model update regression between different model versions on a diverse set of tasks and models, even when the downstream task training procedures remain identical. We argue for the importance of maintaining model update compatibility during updates, and present evaluation metrics designed specifically for generative tasks, while also being applicable to discriminative tasks. We propose a training strategy to minimize the extent of instance regression in model updates, involving training of a compatibility adapter that can enhance task fine-tuned language models. We show negative flips reduce by up to 40% e.g. when updating Llama 1 to Llama 2 with our proposed method.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.430",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Event-Keyed Summarization": {
        "type": "INPROCEEDINGS",
        "key": "gantt-etal-2024-event",
        "author": "Gantt, William and Martin, Alexander and Kuchmiichuk, Pavlo and White, Aaron Steven",
        "booktitle": "EMNLP-findings2024",
        "title": "Event-Keyed Summarization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We introduce *event-keyed summarization* (EKS), a novel task that marries traditional summarization and document-level event extraction, with the goal of generating a contextualized summary for a specific event, given a document and an extracted event structure. We introduce a dataset for this task, MUCSUM, consisting of summaries of all events in the classic MUC-4 dataset, along with a set of baselines that comprises both pretrained LM standards in the summarization literature, as well as larger frontier models. We show that ablations that reduce EKS to traditional summarization or structure-to-text yield inferior summaries of target events and that MUCSUM is a robust benchmark for this task. Lastly, we conduct a human evaluation of both reference and model summaries, and provide some detailed analysis of the results.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.431",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Effect of Sampling Temperature on Problem Solving in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "renze-2024-effect",
        "author": "Renze, Matthew",
        "booktitle": "EMNLP-findings2024",
        "title": "The Effect of Sampling Temperature on Problem Solving in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this research study, we empirically investigate the effect of sampling temperature on the performance of Large Language Models (LLMs) on various problem-solving tasks. We created a multiple-choice question-and-answer (MCQA) exam by randomly sampling problems from standard LLM benchmarks. Then, we used nine popular LLMs with five prompt-engineering techniques to solve the MCQA problems while increasing the sampling temperature from 0.0 to 1.6. Despite anecdotal reports to the contrary, our empirical results indicate that changes in temperature from 0.0 to 1.0 do not have a statistically significant impact on LLM performance for problem-solving tasks. In addition, these results appear to generalize across LLMs, prompt-engineering techniques, and problem domains. All code, data, and supplemental materials are available on GitHub at: https://github.com/matthewrenze/jhu-llm-temperature",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.432",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents": {
        "type": "INPROCEEDINGS",
        "key": "t-y-s-s-etal-2024-hiculr",
        "author": "T.y.s.s, Santosh and Isaia, Apolline and Hong, Shiyu and Grabmair, Matthias",
        "booktitle": "EMNLP-findings2024",
        "title": "HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Rhetorical Role Labeling (RRL) of legal documents is pivotal for various downstream tasks such as summarization, semantic case search and argument mining. Existing approaches often overlook the varying difficulty levels inherent in legal document discourse styles and rhetorical roles. In this work, we propose HiCuLR, a hierarchical curriculum learning framework for RRL. It nests two curricula: Rhetorical Role-level Curriculum (RC) on the outer layer and Document-level Curriculum (DC) on the inner layer. DC categorizes documents based on their difficulty, utilizing metrics like deviation from a standard discourse structure and exposes the model to them in an easy-to-difficult fashion. RC progressively strengthens the model to discern coarse-to-fine-grained distinctions between rhetorical roles. Our experiments on four RRL datasets demonstrate the efficacy of HiCuLR, highlighting the complementary nature of DC and RC.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.433",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Semi-Supervised Reward Modeling via Iterative Self-Training": {
        "type": "INPROCEEDINGS",
        "key": "he-etal-2024-semi-supervised",
        "author": "He, Yifei and Wang, Haoxiang and Jiang, Ziyan and Papangelis, Alexandros and Zhao, Han",
        "booktitle": "EMNLP-findings2024",
        "title": "Semi-Supervised Reward Modeling via Iterative Self-Training",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reward models (RM) capture the values and preferences of humans and play a central role in Reinforcement Learning with Human Feedback (RLHF) to align pretrained large language models (LLMs). Traditionally, training these models relies on extensive human-annotated preference data, which poses significant challenges in terms of scalability and cost. To overcome these limitations, we propose Semi-Supervised Reward Modeling (SSRM), an approach that enhances RM training using unlabeled data. Given an unlabeled dataset, SSRM involves three key iterative steps: pseudo-labeling unlabeled examples, selecting high-confidence examples through a confidence threshold, and supervised finetuning on the refined dataset. Across extensive experiments on various model configurations, we demonstrate that SSRM significantly improves reward models without incurring additional labeling costs. Notably, SSRM can achieve performance comparable to models trained entirely on labeled data of equivalent volumes. Overall, SSRM substantially reduces the dependency on large volumes of human-annotated data, thereby decreasing the overall cost and time involved in training effective reward models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.434",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Demonstration Selection Strategies for Numerical Time Series Data-to-Text": {
        "type": "INPROCEEDINGS",
        "key": "kawarada-etal-2024-demonstration",
        "author": "Kawarada, Masayuki and Ishigaki, Tatsuya and Topi\u0107, Goran and Takamura, Hiroya",
        "booktitle": "EMNLP-findings2024",
        "title": "Demonstration Selection Strategies for Numerical Time Series Data-to-Text",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Demonstration selection, the process of selecting examples used in prompts, plays a critical role in in-context learning. This paper explores demonstration selection methods for data-to-text tasks that involve numerical time series data as inputs.Previously developed demonstration selection methods primarily focus on textual inputs, often relying on embedding similarities of textual tokens to select similar instances from an example bank. However, this approach may not be suitable for numerical time series data.To address this issue, we propose two novel selection methods: (1) sequence similarity-based selection using various similarity measures, and (2) task-specific knowledge-based selection.From our experiments on two benchmark datasets, we found that our proposed models significantly outperform baseline selections and often surpass fine-tuned models. We also found that scale-invariant similarity measures such as Pearson\u2019s correlation work better than scale-variant measures such as Euclidean distance.Manual evaluation by human judges also confirms that our proposed methods outperform conventional methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.435",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ALIGN-SIM: A Task-Free Test Bed for Evaluating and Interpreting Sentence Embeddings through Semantic Similarity Alignment": {
        "type": "INPROCEEDINGS",
        "key": "mahajan-etal-2024-align",
        "author": "Mahajan, Yash and Bansal, Naman and Blanco, Eduardo and Karmaker, Santu",
        "booktitle": "EMNLP-findings2024",
        "title": "ALIGN-SIM: A Task-Free Test Bed for Evaluating and Interpreting Sentence Embeddings through Semantic Similarity Alignment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Sentence embeddings play a pivotal role in a wide range of NLP tasks, yet evaluating and interpreting these real-valued vectors remains an open challenge to date, especially in a task-free setting. To address this challenge, we introduce a novel task-free test bed for evaluating and interpreting sentence embeddings. Our test bed consists of five semantic similarity alignment criteria, namely, *semantic distinction, synonym replacement, antonym replacement, paraphrasing without negation, and sentence jumbling*. Using these criteria, we examined five classical (e.g., Sentence-BERT, Universal Sentence Encoder (USE), etc.) and eight LLM-induced sentence embedding techniques (e.g., LLaMA2, GPT-3, OLMo, etc.) to test whether their semantic similarity spaces align with what a human mind would naturally expect. Our extensive experiments with 13 different sentence encoders revealed that none of the studied embeddings aligned with all the five semantic similarity alignment criteria. Yet, most encoders performed highly on the SentEval dataset, a popular task-specific benchmark. This finding demonstrates a significant limitation of the current practice in sentence embedding evaluation and associated popular benchmarks, a critical issue that needs careful attention and reassessment by the NLP community. Finally, we conclude the paper by highlighting the utility of the proposed alignment-based test bed for analyzing sentence embeddings in a novel way, especially in a task-free setting.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.436",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chang-etal-2024-bipeft",
        "author": "Chang, Aofei and Wang, Jiaqi and Liu, Han and Bhatia, Parminder and Xiao, Cao and Wang, Ting and Ma, Fenglong",
        "booktitle": "EMNLP-findings2024",
        "title": "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Parameter Efficient Fine-Tuning (PEFT) offers an efficient solution for fine-tuning large pretrained language models for downstream tasks. However, most PEFT strategies are manually designed, often resulting in suboptimal performance. Recent automatic PEFT approaches aim to address this but face challenges such as search space entanglement, inefficiency, and lack of integration between parameter budgets and search processes. To overcome these issues, we introduce a novel Budget-guided Iterative search strategy for automatic PEFT (BIPEFT), significantly enhancing search efficiency. BIPEFT employs a new iterative search strategy to disentangle the binary module and rank dimension search spaces. Additionally, we design early selection strategies based on parameter budgets, accelerating the learning process by gradually removing unimportant modules and fixing rank dimensions. Extensive experiments on public benchmarks demonstrate the superior performance of BIPEFT in achieving efficient and effective PEFT for downstream tasks with a low parameter budget.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.437",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "In-Context Learning with Iterative Demonstration Selection": {
        "type": "INPROCEEDINGS",
        "key": "qin-etal-2024-context",
        "author": "Qin, Chengwei and Zhang, Aston and Chen, Chen and Dagar, Anirudh and Ye, Wenming",
        "booktitle": "EMNLP-findings2024",
        "title": "In-Context Learning with Iterative Demonstration Selection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Spurred by advancements in scale, large language models (LLMs) have demonstrated strong few-shot learning ability via in-context learning (ICL). However, the performance of ICL has been shown to be highly sensitive to the selection of few-shot demonstrations. Selecting the most suitable examples as context remains an ongoing challenge and an open problem. Existing literature has highlighted the importance of selecting examples that are diverse or semantically similar to the test sample while ignoring the fact that the optimal selection dimension, i.e., diversity or similarity, is task-specific. Based on how the test sample is answered, we propose Iterative Demonstration Selection (IDS) to leverage the merits of both dimensions. Using zero-shot chain-of-thought reasoning (Zero-shot-CoT), IDS iteratively selects examples that are diverse but still strongly correlated with the test sample as ICL demonstrations. Specifically, IDS applies Zero-shot-CoT to the test sample before demonstration selection. The output reasoning path is then used to choose demonstrations that are prepended to the test sample for inference. The generated answer is followed by its corresponding reasoning path for extracting a new set of demonstrations in the next iteration. After several iterations, IDS adopts majority voting to obtain the final result. Through extensive experiments on tasks including reasoning, question answering, and topic classification, we demonstrate that IDS can consistently outperform existing ICL demonstration selection methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.438",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On Evaluating Explanation Utility for Human-AI Decision Making in NLP": {
        "type": "INPROCEEDINGS",
        "key": "hashemi-chaleshtori-etal-2024-evaluating",
        "author": "Hashemi Chaleshtori, Fateme and Ghosal, Atreya and Gill, Alexander and Bambroo, Purbid and Marasovic, Ana",
        "booktitle": "EMNLP-findings2024",
        "title": "On Evaluating Explanation Utility for Human-AI Decision Making in NLP",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Is explainability a false promise? This debate has emerged from the insufficient evidence that explanations help people in situations they are introduced for. More human-centered, application-grounded evaluations of explanations are needed to settle this. Yet, with no established guidelines for such studies in NLP, researchers accustomed to standardized proxy evaluations must discover appropriate measurements, tasks, datasets, and sensible models for human-AI teams in their studies. To aid with this, we first review existing metrics suitable for application-grounded evaluation. We then establish criteria to select appropriate datasets, and using them, we find that only 4 out of over 50 datasets available for explainability research in NLP meet them. We then demonstrate the importance of reassessing the state of the art to form and study human-AI teams: teaming people with models for certain tasks might only now start to make sense, and for others, it remains unsound. Finally, we present the exemplar studies of human-AI decision-making for one of the identified tasks \u2014 verifying the correctness of a legal claim given a contract. Our results show that providing AI predictions, with or without explanations, does not cause decision makers to speed up their work without compromising performance. We argue for revisiting the setup of human-AI teams and improving automatic deferral of instances to AI, where explanations could play a useful role.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.439",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unsupervised Hierarchical Topic Modeling via Anchor Word Clustering and Path Guidance": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-unsupervised",
        "author": "Liu, Jiyuan and Chen, Hegang and Zhu, Chunjiang and Rao, Yanghui",
        "booktitle": "EMNLP-findings2024",
        "title": "Unsupervised Hierarchical Topic Modeling via Anchor Word Clustering and Path Guidance",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Hierarchical topic models nowadays tend to capture the relationship between words and topics, often ignoring the role of anchor words that guide text generation. For the first time, we detect and add anchor words to the text generation process in an unsupervised way. Firstly, we adopt a clustering algorithm to adaptively detect anchor words that are highly consistent with every topic, which forms the path of topic \\rightarrow anchor word. Secondly, we add the causal path of anchor word \\rightarrow word to the popular Variational Auto-Encoder (VAE) framework via implicitly using word co-occurrence graphs. We develop the causal path of topic+anchor word \\rightarrow higher-layer topic that aids the expression of topic concepts with anchor words to capture a more semantically tight hierarchical topic structure. Finally, we enhance the model\u2019s representation of the anchor words through a novel contrastive learning. After jointly training the aforementioned constraint objectives, we can produce more coherent and diverse topics with a better hierarchical structure. Extensive experiments on three datasets show that our model outperforms state-of-the-art methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.440",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "GuardEmb: Dynamic Watermark for Safeguarding Large Language Model Embedding Service Against Model Stealing Attack": {
        "type": "INPROCEEDINGS",
        "key": "wang-cheng-2024-guardemb",
        "author": "Wang, Liaoyaqi and Cheng, Minhao",
        "booktitle": "EMNLP-findings2024",
        "title": "GuardEmb: Dynamic Watermark for Safeguarding Large Language Model Embedding Service Against Model Stealing Attack",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language model (LLM) companies provide Embedding as a Service (EaaS) to assist the individual in efficiently dealing with downstream tasks such as text classification and recommendation. However, recent works reveal the risk of the model stealing attack, posing a financial threat to EaaS providers. To protect the copyright of EaaS, we propose GuardEmb, a dynamic embedding watermarking method, striking a balance between enhancing watermark detectability and preserving embedding functionality. Our approach involves selecting special tokens and perturbing embeddings containing these tokens to inject watermarks. Simultaneously, we train a verifier to detect these watermarks. In the event of an attacker attempting to replicate our EaaS for profit, their model inherits our watermarks. For watermark verification, we construct verification texts to query the suspicious EaaS, and the verifier identifies our watermarks within the responses, effectively tracing copyright infringement. Extensive experiments across diverse datasets showcase the high detectability of our watermark method, even in out-of-distribution scenarios, without compromising embedding functionality. Our code is publicly available at https://github.com/Melodramass/Dynamic-Watermark.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.441",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-difficult",
        "author": "Zhao, Sihang and Yuan, Youliang and Tang, Xiaoying and He, Pinjia",
        "booktitle": "EMNLP-findings2024",
        "title": "Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal Large Language Models (MLLMs) demonstrate a strong understanding of the real world and can even handle complex tasks. However, they still fail on some straightforward visual question-answering (VQA) problems. This paper dives deeper into this issue, revealing that models tend to err when answering easy questions (e.g., Yes/No questions) about an image, even though they can correctly describe it.We refer to this model behavior discrepancy between difficult and simple questions as model laziness.To systematically investigate model laziness, we manually construct LazyBench, a benchmark that includes Yes/No, multiple choice, short answer questions, and image description tasks that are related to the same subjects in the images.Based on LazyBench. we observe that laziness widely exists in current advanced MLLMs (e.g., GPT-4o, Gemini-1.5-pro, Claude 3, LLaVA-1.5, LLaVA-1.6, and QWen-VL). We also analyzed the failure cases of LLaVA-1.5-13B on the VQA-v2 benchmark and discovered that about half of these failures are due to the model\u2019s laziness. This further highlights the importance of ensuring that the model fully utilizes its capability.To this end, we conduct a preliminary exploration of how to mitigate laziness and find that chain of thought can effectively avoid this issue. The data can be accessed at https://github.com/Akutagawa1998/LazyBench.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.442",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery": {
        "type": "INPROCEEDINGS",
        "key": "deng-etal-2024-pseudo",
        "author": "Deng, Yimin and Wu, Yuxia and Zhao, Guoshuai and Zhu, Li and Qian, Xueming",
        "booktitle": "EMNLP-findings2024",
        "title": "Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "New intent discovery is a crucial capability for task-oriented dialogue systems. Existing methods focus on transferring in-domain (IND) prior knowledge to out-of-domain (OOD) data through pre-training and clustering stages. They either handle the two processes in a pipeline manner, which exhibits a gap between intent representation and clustering process or use typical contrastive clustering that overlooks the potential supervised signals from the whole data. Besides, they often deal with either open intent discovery or OOD settings individually. To this end, we propose a Pseudo-Label enhanced Prototypical Contrastive Learning (PLPCL) model for uniformed intent discovery. We iteratively utilize pseudo-labels to explore potential positive/negative samples for contrastive learning and bridge the gap between representation and clustering. To enable better knowledge transfer, we design a prototype learning method integrating the supervised and pseudo signals from IND and OOD samples. In addition, our method has been proven effective in two different settings of discovering new intents. Experiments on three benchmark datasets and two task settings demonstrate the effectiveness of our approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.443",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-rolora",
        "author": "Huang, Xijie and Liu, Zechun and Liu, Shih-Yang and Cheng, Kwang-Ting",
        "booktitle": "EMNLP-findings2024",
        "title": "RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Low-Rank Adaptation (LoRA), as a representative Parameter-Efficient Fine-Tuning (PEFT) method, significantly enhances the training efficiency by updating only a small portion of the weights in Large Language Models (LLMs). Recently, weight-only quantization techniques have also been applied to LoRA methods to reduce the memory footprint of fine-tuning. However, applying weight-activation quantization to the LoRA pipeline is under-explored, and we observe substantial performance degradation primarily due to the presence of activation outliers. In this work, we propose RoLoRA, the first LoRA-based scheme to apply rotation for outlier elimination, and then fine-tune rotated outlier-free LLMs for effective weight-activation quantization. Different from previous work tackling the outlier challenges from a post-training perspective, we propose rotation-aware fine-tuning to eliminate and preserve the outlier-free characteristics brought by rotation operations. RoLoRA can improve low-bit LoRA convergence and post-training quantization robustness in weight-activation settings. RoLoRA is evaluated across various LLM series (LLaMA2, LLaMA3, LLaVA-1.5), tasks, and quantization settings, achieving up to 29.5% absolute accuracy gain of 4-bit weight-activation quantized LLaMA2-13B on commonsense reasoning tasks compared to LoRA baseline. We further demonstrate its effectiveness on Large Multimodal Models (LMMs) and prove the compatibility with advanced LoRA variants.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.444",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration": {
        "type": "INPROCEEDINGS",
        "key": "yuan-etal-2024-large",
        "author": "Yuan, Weikang and Cao, Junjie and Jiang, Zhuoren and Kang, Yangyang and Lin, Jun and Song, Kaisong and Lin, Tianqianjin and Yan, Pengwei and Sun, Changlong and Liu, Xiaozhong",
        "booktitle": "EMNLP-findings2024",
        "title": "Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) could struggle to fully understand legal theories and perform complex legal reasoning tasks. In this study, we introduce a challenging task (confusing charge prediction) to better evaluate LLMs\u2019 understanding of legal theories and reasoning capabilities. We also propose a novel framework: Multi-Agent framework for improving complex Legal Reasoning capability (MALR). MALR employs non-parametric learning, encouraging LLMs to automatically decompose complex legal tasks and mimic human learning process to extract insights from legal rules, helping LLMs better understand legal theories and enhance their legal reasoning abilities. Extensive experiments on multiple real-world datasets demonstrate that the proposed framework effectively addresses complex reasoning issues in practical scenarios, paving the way for more reliable applications in the legal domain.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.445",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Retrieval and Reasoning on KGs: Integrate Knowledge Graphs into Large Language Models for Complex Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "ji-etal-2024-retrieval",
        "author": "Ji, Yixin and Wu, Kaixin and Li, Juntao and Chen, Wei and Zhong, Mingjie and Jia, Xu and Zhang, Min",
        "booktitle": "EMNLP-findings2024",
        "title": "Retrieval and Reasoning on KGs: Integrate Knowledge Graphs into Large Language Models for Complex Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite Large Language Models (LLMs) have performed impressively in various Natural Language Processing (NLP) tasks, their inherent hallucination phenomena severely challenge their credibility in complex reasoning. Combining explainable Knowledge Graphs (KGs) with LLMs is a promising path to address this issue. However, structured KGs are difficult to utilize, and how to make LLMs understand and incorporate them is a challenging topic. We thereby reorganize a more efficient structure of KGs, while designing the KG-related instruction tuning and continual pre-training strategies to enable LLMs to learn and internalize this form of representation effectively. Moreover, we construct subgraphs to further enhance the retrieval capabilities of KGs via CoT reasoning. Extensive experiments on two KGQA datasets demonstrate that our model achieves convincing performance compared to strong baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.446",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Insights into LLM Long-Context Failures: When Transformers Know but Don\u2019t Tell": {
        "type": "INPROCEEDINGS",
        "key": "gao-etal-2024-insights",
        "author": "Gao, Muhan and Lu, TaiMing and Yu, Kuai and Byerly, Adam and Khashabi, Daniel",
        "booktitle": "EMNLP-findings2024",
        "title": "Insights into LLM Long-Context Failures: When Transformers Know but Don\u2019t Tell",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) exhibit positional bias, struggling to utilize information from the middle or end of long contexts. Our study explores LLMs\u2019 long-context reasoning by probing their hidden representations. We find that while LLMs encode the position of target information, they often fail to leverage this in generating accurate responses. This reveals a disconnect between information retrieval and utilization, a \u201cknow but don\u2019t tell\u201d phenomenon. We further analyze the relationship between extraction time and final accuracy, offering insights into the underlying mechanics of transformer models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.447",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "E\u00b2CL: Exploration-based Error Correction Learning for Embodied Agents": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-e2cl",
        "author": "Wang, Hanlin and Leong, Chak Tou and Wang, Jian and Li, Wenjie",
        "booktitle": "EMNLP-findings2024",
        "title": "E\u00b2CL: Exploration-based Error Correction Learning for Embodied Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language models are exhibiting increasing capability in knowledge utilization and reasoning. However, when applied as agents in embodied environments, they often suffer from misalignment between their intrinsic knowledge and environmental knowledge, leading to infeasible actions. Traditional environment alignment methods, such as supervised learning on expert trajectories and reinforcement learning, encounter limitations in covering environmental knowledge and achieving efficient convergence, respectively. Inspired by human learning, we propose Exploration-based Error Correction Learning (E\u00b2CL), a novel framework that leverages exploration-induced errors and environmental feedback to enhance environment alignment for embodied agents. E\u00b2CL incorporates teacher-guided and teacher-free explorations to gather environmental feedback and correct erroneous actions. The agent learns to provide feedback and self-correct, thereby enhancing its adaptability to target environments. Extensive experiments in the VirtualHome environment demonstrate that E\u00b2CL-trained agents outperform those trained by baseline methods and exhibit superior self-correction capabilities.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.448",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BERGEN: A Benchmarking Library for Retrieval-Augmented Generation": {
        "type": "INPROCEEDINGS",
        "key": "rau-etal-2024-bergen",
        "author": "Rau, David and D\u00e9jean, Herv\u00e9 and Chirkova, Nadezhda and Formal, Thibault and Wang, Shuai and Clinchant, St\u00e9phane and Nikoulina, Vassilina",
        "booktitle": "EMNLP-findings2024",
        "title": "BERGEN: A Benchmarking Library for Retrieval-Augmented Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-Augmented Generation allows to enhance Large Language Models with external knowledge. In response to the recent popularity of generative LLMs, many RAG approaches have been proposed, which involve an intricate number of different configurations such as evaluation datasets, collections, metrics, retrievers, and LLMs. Inconsistent benchmarking poses a major challenge in comparing approaches and understanding the impact of each component in the pipeline. In this work, we study best practices that lay the groundwork for a systematic evaluation of RAG and present BERGEN, an end-to-end library for reproducible research standardizing RAG experiments. In an extensive study focusing on QA, we benchmark different state-of-the-art retrievers, rerankers, and LLMs. Additionally, we analyze existing RAG metrics and datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.449",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Contextualized Graph Representations for Generating Counter-Narratives against Hate Speech": {
        "type": "INPROCEEDINGS",
        "key": "baez-santamaria-etal-2024-contextualized",
        "author": "Baez Santamaria, Selene and Gomez Adorno, Helena and Markov, Ilia",
        "booktitle": "EMNLP-findings2024",
        "title": "Contextualized Graph Representations for Generating Counter-Narratives against Hate Speech",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Hate speech (HS) is a widely acknowledged societal problem with potentially grave effects on vulnerable individuals and minority groups. Developing counter-narratives (CNs) that confront biases and stereotypes driving hateful narratives is considered an impactful strategy. Current automatic methods focus on isolated utterances to detect and react to hateful content online, often omitting the conversational context where HS naturally occurs. In this work, we explore strategies for the incorporation of conversational history for CN generation, comparing text and graphical representations with varying degrees of context. Overall, automatic and human evaluations show that 1) contextualized representations are comparable to those of isolated utterances, and 2) models based on graph representations outperform text representations, thus opening new research directions for future work.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.450",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Modeling Historical Relevant and Local Frequency Context for Representation-Based Temporal Knowledge Graph Forecasting": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-modeling-historical",
        "author": "Zhang, Shengzhe and Wei, Wei and Huang, Rikui and Xie, Wenfeng and Chen, Dangyang",
        "booktitle": "EMNLP-findings2024",
        "title": "Modeling Historical Relevant and Local Frequency Context for Representation-Based Temporal Knowledge Graph Forecasting",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.451",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Representation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-representation",
        "author": "Li, Ying and Liu, Jianjian and Yu, Zhengtao and Gao, Shengxiang and Huang, Yuxin and Mao, Cunli",
        "booktitle": "EMNLP-findings2024",
        "title": "Representation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the strong representational capabilities of pre-trained language models, dependency parsing in resource-rich languages has seen significant advancements. However, the parsing accuracy drops sharply when the model is transferred to low-resource language due to distribution shifts. To alleviate this issue, we propose a representation alignment and adversarial model to filter out useful knowledge from rich-resource language and ignore useless ones. Our proposed model consists of two components, i.e., an alignment network in the input layer for selecting useful language-specific features and an adversarial network in the encoder layer for augmenting the language-invariant contextualized features. Experiments on the benchmark datasets show that our proposed model outperforms RoBERTa-enhanced strong baseline models by 1.37 LAS and 1.34 UAS. Detailed analysis shows that both alignment and adversarial networks are equally important in alleviating the distribution shifts problem and can complement each other. In addition, the comparative experiments demonstrate that both the alignment and adversarial networks can substantially facilitate extracting and utilizing relevant target language features, thereby increasing the adaptation capability of our proposed model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.452",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "An Instruction Tuning-Based Contrastive Learning Framework for Aspect Sentiment Quad Prediction with Implicit Aspects and Opinions": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-instruction",
        "author": "Zhang, Hao and Cheah, Yu-N and He, Congqing and Yi, Feifan",
        "booktitle": "EMNLP-findings2024",
        "title": "An Instruction Tuning-Based Contrastive Learning Framework for Aspect Sentiment Quad Prediction with Implicit Aspects and Opinions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Aspect sentiment quad prediction (ASQP) is crucial in aspect-based sentiment analysis (ABSA). It involves identifying a text\u2019s aspect,sentiment, opinion, and category. Existing methods have insufficiently explored how to effectively leverage the knowledge of pre-trainedlanguage models (PLMs) to handle implicit aspects and opinions, particularly in combinations such as implicit aspect &amp; explicit opinion, explicit aspect &amp; implicit opinion, and implicit aspect &amp; implicit opinion. We introduce ITSCL, a framework leveraging Instruction Tuning and Supervised Contrastive Learning to improve aspect sentiment quad predictions, especially for implicit aspects and opinions. Implementing this approach presents several challenges. First, designing effective instructions and prompts to optimize the model\u2019s training is difficult. Second, creating sentiment combination vectors with contrastive learning to enhance the model\u2019s discrimination requires further investigation. To address these challenges, ITSCL combines instruction tuning with aligned PLM templates, enabling better knowledge acquisition and identification of implicit sentiments. Additionally, the contrastive learning framework enhances performance by using four fully connected layers to combine sentiments, aspects, opinions, and combinations, maximizing similarity for same-label representationsand minimizing it for different labels. Experimental results show our method significantly outperforms previous methods on benchmark datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.453",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MACAROON: Training Vision-Language Models To Be Your Engaged Partners": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-macaroon",
        "author": "Wu, Shujin and Fung, Yi and Li, Sha and Wan, Yixin and Chang, Kai-Wei and Ji, Heng",
        "booktitle": "EMNLP-findings2024",
        "title": "MACAROON: Training Vision-Language Models To Be Your Engaged Partners",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large vision-language models (LVLMs), while proficient in following instructions and responding to diverse questions, invariably generate detailed responses even when questions are ambiguous or unanswerable, leading to hallucinations and bias issues. Thus, it is essential for LVLMs to proactively engage with humans to ask for clarifications or additional information for better responses. In this study, we aim to shift LVLMs from passive answer providers to proactive engaged partners. We begin by establishing a three-tiered hierarchy for questions of invalid, ambiguous, and personalizable nature to measure the proactive engagement capabilities of LVLMs. Utilizing this hierarchy, we create PIE, (ProactIve Engagement Evaluation) through GPT-4o and human annotators, consisting of 853 questions across six distinct, fine-grained question types that are verified by human annotators and accompanied with well-defined metrics. Our evaluations on indicate poor performance of existing LVLMs, with the best-performing open-weights model only achieving an Aggregate Align Rate (AAR) of 0.28. In response, we introduce MACAROON, self-iMaginAtion for ContrAstive pReference OptimizatiON, which instructs LVLMs to autonomously generate contrastive response pairs for unlabeled questions given the task description and human-crafted criteria. Then, the self-imagined data is formatted for conditional reinforcement learning. Experimental results show MACAROON effectively improves LVLMs\u2019 capabilities to be proactively engaged (0.84 AAR) while maintaining comparable performance on general tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.454",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation": {
        "type": "INPROCEEDINGS",
        "key": "man-etal-2024-icl",
        "author": "Man, Zhibo and Huang, Kaiyu and Zhang, Yujie and Chen, Yuanmeng and Chen, Yufeng and Xu, Jinan",
        "booktitle": "EMNLP-findings2024",
        "title": "ICL: Iterative Continual Learning for Multi-domain Neural Machine Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In a practical scenario, multi-domain neural machine translation (MDNMT) aims to continuously acquire knowledge from new domain data while retaining old knowledge. Previous work separately learns each new domain knowledge based on parameter isolation methods, which effectively capture the new knowledge. However, task-specific parameters lead to isolation between models, which hinders the mutual transfer of knowledge between new domains. Given the scarcity of domain-specific corpora, we consider making full use of the data from multiple new domains. Therefore, our work aims to leverage previously acquired domain knowledge when modeling subsequent domains. To this end, we propose an Iterative Continual Learning (ICL) framework for multi-domain neural machine translation. Specifically, when each new domain arrives, (1) we first build a pluggable incremental learning model, (2) then we design an iterative updating algorithm to continuously update the original model, which can be used flexibly for constructing subsequent domain models. Furthermore, we design a domain knowledge transfer mechanism to enhance the fine-grained domain-specific representation, thereby solving the word ambiguity caused by mixing domain data. Experimental results on the UM-Corpus and OPUS multi-domain datasets show the superior performance of our proposed model compared to representative baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.455",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Mitigating Hallucinations of Large Language Models in Medical Information Extraction via Contrastive Decoding": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-mitigating",
        "author": "Xu, Derong and Zhang, Ziheng and Zhu, Zhihong and Lin, Zhenxi and Liu, Qidong and Wu, Xian and Xu, Tong and Zhao, Xiangyu and Zheng, Yefeng and Chen, Enhong",
        "booktitle": "EMNLP-findings2024",
        "title": "Mitigating Hallucinations of Large Language Models in Medical Information Extraction via Contrastive Decoding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The impressive capabilities of large language models (LLMs) have attracted extensive interests of applying LLMs to medical field. However, the complex nature of clinical environments presents significant hallucination challenges for LLMs, hindering their widespread adoption. In this paper, we address these hallucination issues in the context of Medical Information Extraction (MIE) tasks by introducing ALternate Contrastive Decoding (ALCD). We begin by redefining MIE tasks as an identify-and-classify process. We then separate the identification and classification functions of LLMs by selectively masking the optimization of tokens during fine-tuning. During the inference stage, we alternately contrast output distributions derived from sub-task models. This approach aims to selectively enhance the identification and classification capabilities while minimizing the influence of other inherent abilities in LLMs. Additionally, we propose an alternate adaptive constraint strategy to more effectively adjust the scale and scope of contrastive tokens. Through comprehensive experiments on two different backbones and six diverse medical information extraction tasks, ALCD demonstrates significant improvements in resolving hallucination issues compared to conventional decoding methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.456",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization": {
        "type": "INPROCEEDINGS",
        "key": "pham-etal-2024-neuromax",
        "author": "Pham, Duy-Tung and Nguyen Vu, Thien Trang and Nguyen, Tung and Ngo, Linh Van and Nguyen, Duc Anh and Nguyen, Thien Huu",
        "booktitle": "EMNLP-findings2024",
        "title": "NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advances in neural topic models have concentrated on two primary directions: the integration of the inference network (encoder) with a pre-trained language model (PLM) and the modeling of the relationship between words and topics in the generative model (decoder). However, the use of large PLMs significantly increases inference costs, making them less practical for situations requiring low inference times. Furthermore, it is crucial to simultaneously model the relationships between topics and words as well as the interrelationships among topics themselves. In this work, we propose a novel framework called NeuroMax (**Neur**al T**o**pic Model with **Max**imizing Mutual Information with Pretrained Language Model and Group Topic Regularization) to address these challenges. NeuroMax maximizes the mutual information between the topic representation obtained from the encoder in neural topic models and the representation derived from the PLM. Additionally, NeuroMax employs optimal transport to learn the relationships between topics by analyzing how information is transported among them. Experimental results indicate that NeuroMax reduces inference time, generates more coherent topics and topic groups, and produces more representative document embeddings, thereby enhancing performance on downstream tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.457",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM Self-Correction with DeCRIM: Decompose, Critique, and Refine for Enhanced Following of Instructions with Multiple Constraints": {
        "type": "INPROCEEDINGS",
        "key": "palmeira-ferraz-etal-2024-llm",
        "author": "Palmeira Ferraz, Thomas and Mehta, Kartik and Lin, Yu-Hsiang and Chang, Haw-Shiuan and Oraby, Shereen and Liu, Sijia and Subramanian, Vivek and Chung, Tagyoung and Bansal, Mohit and Peng, Nanyun",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM Self-Correction with DeCRIM: Decompose, Critique, and Refine for Enhanced Following of Instructions with Multiple Constraints",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Instruction following is a key capability for LLMs. However, recent studies have shown that LLMs often struggle with instructions containing multiple constraints (e.g. a request to create a social media post \u201cin a funny tone\u201d with \u201cno hashtag\u201d). Despite this, most evaluations focus solely on synthetic data. To address this, we introduce RealInstruct, the first benchmark designed to evaluate LLMs\u2019 ability to follow real-world multi-constrained instructions by leveraging queries real users asked AI assistants. We also investigate model-based evaluation as a cost-effective alternative to human annotation for this task. Our findings reveal that even the proprietary GPT-4 model fails to meet at least one constraint on over 21% of instructions, highlighting the limitations of state-of-the-art models. To address the performance gap between open-source and proprietary models, we propose the Decompose, Critique and Refine (DeCRIM) self-correction pipeline, which enhances LLMs\u2019 ability to follow constraints. DeCRIM works by decomposing the original instruction into a list of constraints and using a Critic model to decide when and where the LLM\u2019s response needs refinement. Our results show that DeCRIM improves Mistral\u2019s performance by 7.3% on RealInstruct and 8.0% on IFEval even with weak feedback. Moreover, we demonstrate that with strong feedback, open-source LLMs with DeCRIM can outperform GPT-4 on both benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.458",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-learning-plan",
        "author": "Wang, Junjie and Chen, Mingyang and Hu, Binbin and Yang, Dan and Liu, Ziqi and Shen, Yue and Wei, Peng and Zhang, Zhiqiang and Gu, Jinjie and Zhou, Jun and Pan, Jeff Z. and Zhang, Wen and Chen, Huajun",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Improving the performance of large language models (LLMs) in complex question-answering (QA) scenarios has always been a research focal point. Recent studies have attempted to enhance LLMs\u2019 performance by combining step-wise planning with external retrieval. While effective for advanced models like GPT-3.5, smaller LLMs face challenges in decomposing complex questions, necessitating supervised fine-tuning. Previous work has relied on manual annotation and knowledge distillation from teacher LLMs, which are time-consuming and not accurate enough. In this paper, we introduce a novel framework for enhancing LLMs\u2019 planning capabilities by using planning data derived from knowledge graphs (KGs). LLMs fine-tuned with this data have improved planning capabilities, better equipping them to handle complex QA tasks that involve retrieval. Evaluations on multiple datasets, including our newly proposed benchmark, highlight the effectiveness of our framework and the benefits of KG-derived planning data.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.459",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?": {
        "type": "INPROCEEDINGS",
        "key": "bai-etal-2024-compound",
        "author": "Bai, Yinhao and Han, Zhixin and Zhao, Yuhua and Gao, Hang and Zhang, Zhuowei and Wang, Xunzhi and Hu, Mengting",
        "booktitle": "EMNLP-findings2024",
        "title": "Is Compound Aspect-Based Sentiment Analysis Addressed by LLMs?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Aspect-based sentiment analysis (ABSA) aims to predict aspect-based elements from the given text, mainly including four elements, i.e., aspect category, sentiment polarity, aspect term, and opinion term. Extracting pair, triple, or quad of elements is defined as compound ABSA. Due to its challenges and practical applications, such a compound scenario has become an emerging topic. Recently, large language models (LLMs), e.g. ChatGPT and LLaMA, present impressive abilities in tackling various human instructions. In this work, we are particularly curious whether LLMs still possess superior performance in handling compound ABSA tasks. To assess the performance of LLMs, we design a novel framework, called ChatABSA. Concretely, we design two strategies: constrained prompts, to automatically organize the returned predictions; post-processing, to better evaluate the capability of LLMs in recognition of implicit information. The overall evaluation involves 5 compound ABSA tasks and 8 publicly available datasets. We compare LLMs with few-shot supervised baselines and fully supervised baselines, including corresponding state-of-the-art (SOTA) models on each task. Experimental results show that ChatABSA exhibits excellent aspect-based sentiment analysis capabilities and overwhelmingly beats few-shot supervised methods under the same few-shot settings. Surprisingly, it can even outperform fully supervised methods in some cases. However, in most cases, it underperforms fully supervised methods, and there is still a huge gap between its performance and the SOTA method. Moreover, we also conduct more analyses to gain a deeper understanding of its sentiment analysis capabilities.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.460",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multilingual Fine-Grained News Headline Hallucination Detection": {
        "type": "INPROCEEDINGS",
        "key": "shen-etal-2024-multilingual",
        "author": "Shen, Jiaming and Liu, Tianqi and Liu, Jialu and Qin, Zhen and Pavagadhi, Jay and Baumgartner, Simon and Bendersky, Michael",
        "booktitle": "EMNLP-findings2024",
        "title": "Multilingual Fine-Grained News Headline Hallucination Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The popularity of automated news headline generation has surged with advancements in pre-trained language models. However, these models often suffer from the \u201challucination\u201d problem, where the generated headline is not fully supported by its source article. Efforts to address this issue have predominantly focused on English, using over-simplistic classification schemes that overlook nuanced hallucination types. In this study, we introduce the first multilingual, fine-grained news headline hallucination detection dataset that contains over 11 thousand \\textlessarticle, headline\\textgreater pairs in 5 languages, each annotated with detailed hallucination types by experts. We conduct extensive experiments on this dataset under two settings. First, we implement several supervised fine-tuning approaches as preparatory solutions and demonstrate this dataset\u2019s challenges and utilities. Second, we test various large language models\u2019 in-context learning abilities and propose two novel techniques, language-dependent demonstration selection and coarse-to-fine prompting, to boost the few-shot hallucination detection performance in terms of the example-F1 metric. We release this dataset to foster further research in multilingual, fine-grained headline hallucination detection.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.461",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PE: A Poincare Explanation Method for Fast Text Hierarchy Generation": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-pe",
        "author": "Chen, Qian and Li, Dongyang and He, Xiaofeng and Li, Hongzhao and Yi, Hongyu",
        "booktitle": "EMNLP-findings2024",
        "title": "PE: A Poincare Explanation Method for Fast Text Hierarchy Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The black-box nature of deep learning models in NLP hinders their widespread application. The research focus has shifted to Hierarchical Attribution (HA) for its ability to model feature interactions. Recent works model non-contiguous combinations with a time-costly greedy search in Eculidean spaces, neglecting underlying linguistic information in feature representations. In this work, we introduce a novel method, namely Poincare Explanation (PE), for modeling feature interactions with hyperbolic spaces in a time efficient manner.Specifically, we take building text hierarchies as finding spanning trees in hyperbolic spaces. First we project the embeddings into hyperbolic spaces to elicit inherit semantic and syntax hierarchical structures. Then we propose a simple yet effective strategy to calculate Shapley score. Finally we build the the hierarchy with proving the constructing process in the projected space could be viewed as building a minimum spanning tree and introduce a time efficient building algorithm. Experimental results demonstrate the effectiveness of our approach. Our code is available at https://anonymous.4open.science/r/PE-747B.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.462",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Step-level Value Preference Optimization for Mathematical Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-step",
        "author": "Chen, Guoxin and Liao, Minpeng and Li, Chengxi and Fan, Kai",
        "booktitle": "EMNLP-findings2024",
        "title": "Step-level Value Preference Optimization for Mathematical Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Direct Preference Optimization (DPO) using an implicit reward model has proven to be an effective alternative to reinforcement learning from human feedback (RLHF) for fine-tuning preference aligned large language models (LLMs). However, the overall preference annotations of responses do not fully capture the fine-grained quality of model outputs in complex multi-step reasoning tasks, such as mathematical reasoning. To address this limitation, we introduce a novel algorithm called Step-level Value Preference Optimization (SVPO). Our approach employs Monte Carlo Tree Search (MCTS) to automatically annotate step-level preferences for multi-step reasoning. Furthermore, from the perspective of learning-to-rank, we train an explicit value model to replicate the behavior of the implicit reward model, complementing standard preference optimization. This value model enables the LLM to generate higher reward responses with minimal cost during inference. Experimental results demonstrate that our method achieves state-of-the-art performance on both in-domain and out-of-domain mathematical reasoning benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.463",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Benchmarking Situational Awareness of Large Language Models:Comprehensive Benchmark, Evaluation and Analysis": {
        "type": "INPROCEEDINGS",
        "key": "tang-etal-2024-towards",
        "author": "Tang, Guo and Chu, Zheng and Zheng, Wenxiang and Liu, Ming and Qin, Bing",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Benchmarking Situational Awareness of Large Language Models:Comprehensive Benchmark, Evaluation and Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Situational awareness refers to the capacity to perceive and comprehend the present context and anticipate forthcoming events, which plays a critical role in aiding decision-making, anticipating potential issues, and adapting to dynamic circumstances. Nevertheless, the situational awareness capabilities of large language models have not yet been comprehensively assessed. To address this, we propose SA-Bench, a comprehensive benchmark that covers three tiers of situational awareness capabilities, covering environment perception, situation comprehension and future projection. SA-Bench provides a comprehensive evaluation to explore the situational awareness capabilities of LLMs. We conduct extensive experiments on advanced LLMs, including GPT-4, LLaMA3, Qwen1.5, among others. Our experimental results indicate that even SOTA LLMs still exhibit substantial capability gaps compared to humans. In addition, we thoroughly analysis and examine the challenges encountered by LLMs across various tasks, as well as emphasize the deficiencies they confront. We hope SA-Bench will foster research within the field of situational awareness.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.464",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Balancing Visual Context Understanding in Dialogue for Image Retrieval": {
        "type": "INPROCEEDINGS",
        "key": "wei-etal-2024-balancing",
        "author": "Wei, Zhaohui and Liao, Lizi and Du, Xiaoyu and Xiang, Xinguang",
        "booktitle": "EMNLP-findings2024",
        "title": "Balancing Visual Context Understanding in Dialogue for Image Retrieval",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In the realm of dialogue-to-image retrieval, the primary challenge is to fetch images from a pre-compiled database that accurately reflect the intent embedded within the dialogue history. Existing methods often overemphasize inter-modal alignment, neglecting the nuanced nature of conversational context. Dialogue histories are frequently cluttered with redundant information and often lack direct image descriptions, leading to a substantial disconnect between conversational content and visual representation. This study introduces VCU, a novel framework designed to enhance the comprehension of dialogue history and improve cross-modal matching for image retrieval. VCU leverages large language models (LLMs) to perform a two-step extraction process. It generates precise image-related descriptions from dialogues, while also enhancing visual representation by utilizing object-list texts associated with images. Additionally, auxiliary query collections are constructed to balance the matching process, thereby reducing bias in similarity computations. Experimental results demonstrate that VCU significantly outperforms baseline methods in dialogue-to-image retrieval tasks, highlighting its potential for practical application and effectiveness in bridging the gap between dialogue context and visual content.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.465",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations": {
        "type": "INPROCEEDINGS",
        "key": "yu-etal-2024-mechanistic",
        "author": "Yu, Lei and Cao, Meng and Cheung, Jackie CK and Dong, Yue",
        "booktitle": "EMNLP-findings2024",
        "title": "Mechanistic Understanding and Mitigation of Language Model Non-Factual Hallucinations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "State-of-the-art language models (LMs) sometimes generate that misalign with world knowledge. To explore the mechanistic causes of these hallucinations, we create diagnostic datasets with subject-relation queries and adapt interpretability methods to trace hallucinations through internal model representations. We discover two general and distinct mechanistic causes of hallucinations shared across LMs (Llama-2, Pythia, GPT-J): 1) : insufficient subject attribute knowledge in lower layer MLPs, and 2) : failure to select the correct object attribute in upper layer attention heads. We also found these two internal mechanistic causes of hallucinations are reflected in external manifestations. Based on insights from our mechanistic analysis, we propose a novel hallucination mitigation method through targeted restoration of the LM\u2019s internal fact recall pipeline, demonstrating superior performance compared to baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.466",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Study of Implicit Ranking Unfairness in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-study",
        "author": "Xu, Chen and Wang, Wenjie and Li, Yuxin and Pang, Liang and Xu, Jun and Chua, Tat-Seng",
        "booktitle": "EMNLP-findings2024",
        "title": "A Study of Implicit Ranking Unfairness in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, Large Language Models (LLMs) have demonstrated a superior ability to serve as ranking models. However, concerns have arisen as LLMs will exhibit discriminatory ranking behaviors based on users\u2019 sensitive attributes (gender). Worse still, in this paper, we identify a subtler form of discrimination in LLMs, termed implicit ranking unfairness, where LLMs exhibit discriminatory ranking patterns based solely on non-sensitive user profiles, such as user names. Such implicit unfairness is more widespread but less noticeable, threatening the ethical foundation. To comprehensively explore such unfairness, our analysis will focus on three research aspects: (1) We propose an evaluation method to investigate the severity of implicit ranking unfairness. (2) We uncover the reasons for causing such unfairness. (3) To mitigate such unfairness effectively, we utilize a pair-wise regression method to conduct fair-aware data augmentation for LLM fine-tuning. The experiment demonstrates that our method outperforms existing approaches in ranking fairness, achieving this with only a small reduction in accuracy. Lastly, we emphasize the need for the community to identify and mitigate the implicit unfairness, aiming to avert the potential deterioration in the reinforced human-LLMs ecosystem deterioration.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.467",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models": {
        "type": "INPROCEEDINGS",
        "key": "tsvetkov-kipnis-2024-information",
        "author": "Tsvetkov, Alexander and Kipnis, Alon",
        "booktitle": "EMNLP-findings2024",
        "title": "Information Parity: Measuring and Predicting the Multilingual Capabilities of Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are increasingly deployed in user-facing applications worldwide, necessitating handling multiple languages across various tasks. We propose a metric called Information Parity (IP) that can predict an LLM\u2019s capabilities across multiple languages in a task-agnostic manner. IP is well-motivated from an information theoretic perspective: it is associated with the LLM\u2019s efficiency of compressing the text in a given language compared to a reference language. We evaluate IP and other popular metrics such as Tokenization Parity (TP) and Tokenizer Fertility (TF) on several variants of open-sourced LLMs (Llama2, Gemma, Mistral). Among all metrics known to us, IP is better correlated with existing task-specific benchmark scores from the literature and thus better predicts such scores in a certain language. These findings show that IP may be useful for ranking multilingual LLMs\u2019 capabilities regardless of the downstream task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.468",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Better Call SAUL: Fluent and Consistent Language Model Editing with Generation Regularization": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-better",
        "author": "Wang, Mingyang and Lange, Lukas and Adel, Heike and Str\u00f6tgen, Jannik and Schuetze, Hinrich",
        "booktitle": "EMNLP-findings2024",
        "title": "Better Call SAUL: Fluent and Consistent Language Model Editing with Generation Regularization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To ensure large language models contain up-to-date knowledge, they need to be updated regularly. However, model editing is challenging as it might also affect knowledge that is unrelated to the new data. State-of-the-art methods identify parameters associated with specific knowledge and then modify them via direct weight updates. However, these locate-and-edit methods suffer from heavy computational overhead and lack theoretical validation. In contrast, directly fine-tuning the model on requested edits affects the model\u2019s behavior on unrelated knowledge, and significantly damages the model\u2019s generation fluency and consistency. To address these challenges, we propose SAUL, a streamlined model editing method that uses sentence concatenation with augmented random facts for generation regularization. Evaluations on three model editing benchmarks show that is a practical and reliable solution for model editing outperforming state-of-the-art methods while maintaining generation quality and reducing computational overhead.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.469",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Semantic Search Engine for Mathlib4": {
        "type": "INPROCEEDINGS",
        "key": "gao-etal-2024-semantic-search",
        "author": "Gao, Guoxiong and Ju, Haocheng and Jiang, Jiedong and Qin, Zihan and Dong, Bin",
        "booktitle": "EMNLP-findings2024",
        "title": "A Semantic Search Engine for Mathlib4",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The interactive theorem prover Lean enables the verification of formal mathematical proofs and is backed by an expanding community. Central to this ecosystem is its mathematical library, mathlib4, which lays the groundwork for the formalization of an expanding range of mathematical theories. However, searching for theorems in mathlib4 can be challenging. To successfully search in mathlib4, users often need to be familiar with its naming conventions or documentation strings. Therefore, creating a semantic search engine that can be used easily by individuals with varying familiarity with mathlib4 is very important. In this paper, we present a semantic search engine for mathlib4 that accepts informal queries and finds the relevant theorems. We also establish a benchmark for assessing the performance of various search engines for mathlib4.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.470",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs": {
        "type": "INPROCEEDINGS",
        "key": "mousavi-etal-2024-dyknow",
        "author": "Mousavi, Seyed Mahed and Alghisi, Simone and Riccardi, Giuseppe",
        "booktitle": "EMNLP-findings2024",
        "title": "DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "LLMs acquire knowledge from massive data snapshots collected at different timestamps. Their knowledge is then commonly evaluated using static benchmarks. However, factual knowledge is generally subject to time-sensitive changes, and static benchmarks cannot address those cases. We present an approach to dynamically evaluate the knowledge in LLMs and their time-sensitiveness against Wikidata, a publicly available up-to-date knowledge graph. We evaluate the time-sensitive knowledge in twenty-four private and open-source LLMs, as well as the effectiveness of four editing methods in updating the outdated facts. Our results show that 1) outdatedness is a critical problem across state-of-the-art LLMs; 2) LLMs output inconsistent answers when prompted with slight variations of the question prompt; and 3) the performance of the state-of-the-art knowledge editing algorithms is very limited, as they can not reduce the cases of outdatedness and output inconsistency.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.471",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue": {
        "type": "INPROCEEDINGS",
        "key": "du-etal-2024-rewarding",
        "author": "Du, Huifang and Li, Shuqin and Wu, Minghao and Feng, Xuejing and Li, Yuan-Fang and Wang, Haofen",
        "booktitle": "EMNLP-findings2024",
        "title": "Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reinforcement learning (RL) is a powerful approach to enhance task-oriented dialogue (TOD) systems. However, existing RL methods tend to mainly focus on generation tasks, such as dialogue policy learning (DPL) or response generation (RG), while neglecting dialogue state tracking (DST) for understanding. This narrow focus limits the systems to achieve globally optimal performance by overlooking the interdependence between understanding and generation. Additionally, RL methods face challenges with sparse and delayed rewards, which complicates training and optimization. To address these issues, we extend RL into both understanding and generation tasks by introducing step-by-step rewards throughout the token generation. The understanding reward increases as more slots are correctly filled in DST, while the generation reward grows with the accurate inclusion of user requests. Our approach provides a balanced optimization aligned with task completion. Experimental results demonstrate that our approach effectively enhances the performance of TOD systems and achieves new state-of-the-art results on three widely used datasets, including MultiWOZ2.0, MultiWOZ2.1, and In-Car. Our approach also shows superior few-shot ability in low-resource settings compared to current models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.472",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues": {
        "type": "INPROCEEDINGS",
        "key": "hua-etal-2024-assistive",
        "author": "Hua, Yuncheng and Qu, Lizhen and Haf, Reza",
        "booktitle": "EMNLP-findings2024",
        "title": "Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We develop assistive agents based on Large Language Models (LLMs) that aid interlocutors in business negotiations.Specifically, we simulate business negotiations by letting two LLM-based agents engage in role play. A third LLM acts as a remediator agent to rewrite utterances violating norms for improving negotiation outcomes.We introduce a simple tuning-free and label-free In-Context Learning (ICL) method to identify high-quality ICL exemplars for the remediator, where we propose a novel select criteria, called value impact, to measure the quality of the negotiation outcomes. We provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different negotiation topics. We have released our source code and the generated dataset at: https://github.com/tk1363704/SADAS.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.473",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-hollmwood",
        "author": "Chen, Jing and Zhu, Xinyu and Yang, Cheng and Shi, Chufan and Xi, Yadong and Zhang, Yuxiang and Wang, Junjie and Pu, Jiashu and Feng, Tian and Yang, Yujiu and Zhang, Rongsheng",
        "booktitle": "EMNLP-findings2024",
        "title": "HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generative AI has demonstrated unprecedented creativity in the field of computer vision, yet such phenomena have not been observed in natural language processing. In particular, large language models (LLMs) can hardly produce written works at the level of human experts due to the extremely high complexity of literature writing. In this paper, we present HoLLMwood, an automated framework for unleashing the creativity of LLMs and exploring their potential in screenwriting, which is a highly demanding task. Mimicking the human creative process, we assign LLMs to different roles involved in the real-world scenario. In addition to the common practice of treating LLMs as Writer, we also apply LLMs as Editor, who is responsible for providing feedback and revision advice to Writer. Besides, to enrich the characters and deepen the plots, we introduce a role-playing mechanism and adopt LLMs as Actors that can communicate and interact with each other. Evaluations on automatically generated screenplays show that HoLLMwood substantially outperforms strong baselines in terms of coherence, relevance, interestingness and overall quality.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.474",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Advancing Cross-Lingual Entity Alignment with Large Language Models: Tailored Sample Segmentation and Zero-Shot Prompts": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-advancing",
        "author": "Yang, Linyan and Cheng, Jingwei and Zhang, Fu",
        "booktitle": "EMNLP-findings2024",
        "title": "Advancing Cross-Lingual Entity Alignment with Large Language Models: Tailored Sample Segmentation and Zero-Shot Prompts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In recent years, the advent of large language models (LLMs) like GPT and Llama has significantly influenced numerous domains, particularly in advancing natural language processing (NLP) capabilities. LLMs have shown remarkable performance in NLP tasks such as relation extraction (RE) and knowledge graph completion (KGC), enhancing activities related to knowledge graphs. As a result, there is a growing interest in integrating LLMs into cross-lingual entity alignment (EA) task, which aims to identify equivalent entities across various knowledge graphs, thereby improving the performance of current baselines. However, employing LLMs for entity alignment poses challenges in efficiently handling large-scale data, generating suitable data samples, and adapting prompts for the EA task. To tackle these challenges, we propose Seg-Align, an innovative framework that integrating distance feature extraction, sample **Seg**mentation, and zero-shot prompts. Through extensive experiments on two widely used cross-lingual benchmark datasets, we have not only demonstrated the effectiveness of our proposed sample segmentation algorithm but also highlighted the state-of-the-art performance of Seg-Align. Code is available at https://github.com/yangxiaoxiaoly/Seg-Align.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.475",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction": {
        "type": "INPROCEEDINGS",
        "key": "hua-etal-2024-causal",
        "author": "Hua, Yuncheng and Huang, Yujin and Huang, Shuo and Feng, Tao and Qu, Lizhen and Bain, Christopher and Bassed, Richard and Haf, Reza",
        "booktitle": "EMNLP-findings2024",
        "title": "Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper tackles the task of emotion-cause pair extraction in the unsupervised domain adaptation setting.The problem is challenging as the distributions of the events causing emotions in target domains are dramatically different than those in source domains, despite the distributions of emotional expressions between domains are overlapped. Inspired by causal discovery,we propose a novel deep latent model in the variational autoencoder (VAE) framework, which not only captures the underlying latent structures of data but also utilizes the easily transferable knowledge of emotions as the bridge to link the distributions of events in different domains. To facilitate knowledge transfer across domains, we also propose a novel variational posterior regularization technique to disentangle the latent representations of emotions from those of events in order to mitigate the damage caused by the spurious correlations related to the events in source domains. Through extensive experiments, we demonstrate that our model outperforms the strongest baseline by approximately 11.05% on a Chinese benchmark and 2.45% on a English benchmark in terms of weighted-average F1 score. We have released our source code and the generated dataset publicly at: https://github.com/tk1363704/CAREL-VAE.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.476",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation": {
        "type": "INPROCEEDINGS",
        "key": "park-etal-2024-large",
        "author": "Park, Jae-Woo and Park, Seong-Jin and Won, Hyun-Sik and Kim, Kang-Min",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in educational platforms have emphasized the importance of personalized education. Accurately estimating question difficulty based on the ability of the student group is essential for personalized question recommendations. Several studies have focused on predicting question difficulty using student question-solving records or textual information about the questions. However, these approaches require a large amount of student question-solving records and fail to account for the subjective difficulties perceived by different student groups. To address these limitations, we propose the LLaSA framework that utilizes large language models to represent students at various levels. Our proposed method, LLaSA and the zero-shot LLaSA, can estimate question difficulty both with and without students\u2019 question-solving records. In evaluations on the DBE-KT22 and ASSISTMents 2005\u20132006 benchmarks, the zero-shot LLaSA demonstrated a performance comparable to those of strong baseline models even without any training. When evaluated using the classification method, LLaSA outperformed the baseline models, achieving state-of-the-art performance. In addition, the zero-shot LLaSA showed a high correlation with the regressed IRT curve when compared to question difficulty derived from students\u2019 question-solving records, highlighting its potential for real-world applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.477",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models Without Preference Data": {
        "type": "INPROCEEDINGS",
        "key": "xia-etal-2024-inverse",
        "author": "Xia, Han and Gao, Songyang and Ge, Qiming and Xi, Zhiheng and Zhang, Qi and Huang, Xuanjing",
        "booktitle": "EMNLP-findings2024",
        "title": "Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models Without Preference Data",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has proven effective in aligning large language models with human intentions, yet it often relies on complex methodologies like Proximal Policy Optimization (PPO) that require extensive hyper-parameter tuning and present challenges in sample efficiency and stability. In this paper, we introduce Inverse-Q*, an innovative framework that transcends traditional RL methods by optimizing token-level reinforcement learning without the need for additional reward or value models. Inverse-Q* leverages direct preference optimization techniques but extends them by estimating the conditionally optimal policy directly from the model\u2019s responses, facilitating more granular and flexible policy shaping. Our approach reduces reliance on human annotation and external supervision, making it especially suitable for low-resource settings. We present extensive experimental results demonstrating that Inverse-Q* not only matches but potentially exceeds the effectiveness of PPO in terms of convergence speed and the alignment of model responses with human preferences. Our findings suggest that Inverse-Q* offers a practical and robust alternative to conventional RLHF approaches, paving the way for more efficient and adaptable model training approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.478",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Activation Scaling for Steering and Interpreting Language Models": {
        "type": "INPROCEEDINGS",
        "key": "stoehr-etal-2024-activation",
        "author": "Stoehr, Niklas and Du, Kevin and Sn\u00e6bjarnarson, V\u00e9steinn and West, Robert and Cotterell, Ryan and Schein, Aaron",
        "booktitle": "EMNLP-findings2024",
        "title": "Activation Scaling for Steering and Interpreting Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Given the prompt \u201cRome is in\u201d, can we steer a language model to flip its prediction of an incorrect token \u201cFrance\u201d to a correct token \u201cItaly\u201d by only multiplying a few relevant activation vectors with scalars? We argue that successfully intervening on a model is a prerequisite for interpreting its internal workings. Concretely, we establish a three-term objective: a successful intervention should flip the correct with the wrong token and vice versa (effectiveness), and leave other tokens unaffected (faithfulness), all while being sparse (minimality). Using gradient-based optimization, this objective lets us learn (and later evaluate) a specific kind of efficient and interpretable intervention: activation scaling only modifies the signed magnitude of activation vectors to strengthen, weaken, or reverse the steering directions already encoded in the model. On synthetic tasks, this intervention performs comparably with steering vectors in terms of effectiveness and faithfulness, but is much more minimal allowing us to pinpoint interpretable model components. We evaluate activation scaling from different angles, compare performance on different datasets, and make activation scalars a learnable function of the activation vectors themselves to generalize to varying-length prompts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.479",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "shaik-etal-2024-lara",
        "author": "Shaik, Zuhair Hasan and Hegde, Pradyoth and Bannulmath, Prashant and T, Deepak K.",
        "booktitle": "EMNLP-findings2024",
        "title": "LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Integrating speech and text capabilities into large language models (LLMs) is a challenging task and we present Large Rank Adaptation (LaRA) for effective cross-modal integration of speech and text in the LLM framework. Unlike conventional LoRA, our method requires significantly larger ranks comparable to the pretrained weights to accommodate the complexities of speech-text cross-modality learning. The approach utilizes HuBERT to convert speech into discrete tokens and fine-tunes the pretrained LLM to adapt to cross-modal inputs and outputs. The work employs a Hi-Fi GAN vocoder to synthesize speech waveforms from the generated speech units. The initial studies use the Librispeech corpus to teach the model the relationships between speech and text, and Daily Talk, which involves dialog conversations, to adapt for interaction. The proposed work demonstrates adaptation for spoken and text conversations. However, the proposed framework can be easily extended to other cross-modal applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.480",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "pourreza-rafiei-2024-dts",
        "author": "Pourreza, Mohammadreza and Rafiei, Davood",
        "booktitle": "EMNLP-findings2024",
        "title": "DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Leading models for the text-to-SQL task heavily rely on proprietary Large Language Models (LLMs), posing concerns over data privacy. Closing the performance gap between small open-source models and large proprietary models is crucial to mitigate this reliance. To this end, we introduce a novel two-stage fine-tuning approach that decomposes the task into two simpler tasks. Through comprehensive evaluation on three large cross-domain datasets and two small LLMs, we show that this approach improves execution accuracy by 3 to 7 percent, effectively aligning the performance of open-source models with their proprietary counterparts. Our proposed method has achieved 60.31% execution accuracy on Bird hold-out test set, which is the highest performance among methods using 7B parameter models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.481",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MedINST: Meta Dataset of Biomedical Instructions": {
        "type": "INPROCEEDINGS",
        "key": "han-etal-2024-medinst",
        "author": "Han, Wenhan and Fang, Meng and Zhang, Zihan and Yin, Yu and Song, Zirui and Chen, Ling and Pechenizkiy, Mykola and Chen, Qingyu",
        "booktitle": "EMNLP-findings2024",
        "title": "MedINST: Meta Dataset of Biomedical Instructions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The integration of large language model (LLM) techniques in the field of medical analysis has brought about significant advancements, yet the scarcity of large, diverse, and well-annotated datasets remains a major challenge. Medical data and tasks, which vary in format, size, and other parameters, require extensive preprocessing and standardization for effective use in training LLMs. To address these challenges, we introduce MedINST, the Meta Dataset of Biomedical Instructions, a novel multi-domain, multi-task instructional meta-dataset. MedINST comprises 133 biomedical NLP tasks and over 7 million training samples, making it the most comprehensive biomedical instruction dataset to date. Using MedINST as the meta dataset, we curate MedINST32, a challenging benchmark with different task difficulties aiming to evaluate LLMs\u2019 generalization ability. We fine-tune several LLMs on MedINST and evaluate on MedINST32, showcasing enhanced cross-task generalization.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.482",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PropTest: Automatic Property Testing for Improved Visual Programming": {
        "type": "INPROCEEDINGS",
        "key": "koo-etal-2024-proptest",
        "author": "Koo, Jaywon and Yang, Ziyan and Cascante-Bonilla, Paola and Ray, Baishakhi and Ordonez, Vicente",
        "booktitle": "EMNLP-findings2024",
        "title": "PropTest: Automatic Property Testing for Improved Visual Programming",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Visual Programming has recently emerged as an alternative to end-to-end black-box visual reasoning models. This type of method leverages Large Language Models (LLMs) to generate the source code for an executable computer program that solves a given problem. This strategy has the advantage of offering an interpretable reasoning path and does not require finetuning a model with task-specific data. We propose PropTest, a general strategy that improves visual programming by further using an LLM to generate code that tests for visual properties in an initial round of proposed solutions. Our method generates tests for data-type consistency, output syntax, and semantic properties. PropTest achieves comparable results to state-of-the-art methods while using publicly available LLMs. This is demonstrated across different benchmarks on visual question answering and referring expression comprehension. Particularly, PropTest improves ViperGPT by obtaining 46.1% accuracy (+6.0%) on GQA using Llama3-8B and 59.5% (+8.1%) on RefCOCO+ using CodeLlama-34B.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.483",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers": {
        "type": "INPROCEEDINGS",
        "key": "xue-etal-2024-badfair",
        "author": "Xue, Jiaqi and Lou, Qian and Zheng, Mengxin",
        "booktitle": "EMNLP-findings2024",
        "title": "BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Although many works have been developed to improve the fairness of deep learning models, their resilience against malicious attacks\u2014particularly the growing threat of backdoor attacks\u2014has not been thoroughly explored.Attacking fairness is crucial because compromised models can introduce biased outcomes, undermining trust and amplifying inequalities in sensitive applications like hiring, healthcare, and law enforcement. This highlights the urgent need to understand how fairness mechanisms can be exploited and to develop defenses that ensure both fairness and robustness. We introduce *BadFair*, a novel backdoored fairness attack methodology. BadFair stealthily crafts a model that operates with accuracy and fairness under regular conditions but, when activated by certain triggers, discriminates and produces incorrect results for specific groups. This type of attack is particularly stealthy and dangerous, as it circumvents existing fairness detection methods, maintaining an appearance of fairness in normal use. Our findings reveal that BadFair achieves a more than 85% attack success rate in attacks aimed at target groups on average while only incurring a minimal accuracy loss. Moreover, it consistently exhibits a significant discrimination score, distinguishing between pre-defined target and non-target attacked groups across various datasets and models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.484",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models\u2019 Capability in Reproducing Academic Charts": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-gpt",
        "author": "Zhang, Zhehao and Ma, Weicheng and Vosoughi, Soroush",
        "booktitle": "EMNLP-findings2024",
        "title": "Is GPT-4V (ision) All You Need for Automating Academic Data Visualization? Exploring Vision-Language Models\u2019 Capability in Reproducing Academic Charts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While effective data visualization is crucial to present complex information in academic research, its creation demands significant expertise in both data management and graphic design. We explore the potential of using Vision-Language Models (VLMs) in automating the creation of data visualizations by generating code templates from existing charts. As the first work to systematically investigate this task, we first introduce AcademiaChart, a dataset comprising 2525 high-resolution data visualization figures with captions from a variety of AI conferences, extracted directly from source codes. We then conduct large-scale experiments with six state-of-the-art (SOTA) VLMs, including both closed-source and open-source models. Our findings reveal that SOTA closed-source VLMs can indeed be helpful in reproducing charts. On the contrary, open-source ones are only effective at reproducing much simpler charts but struggle with more complex ones. Interestingly, the application of Chain-of-Thought (CoT) prompting significantly enhances the performance of the most advanced model, GPT-4-V, while it does not work as well for other models. These results underscore the potential of VLMs in data visualization while also highlighting critical areas that need improvement for broader application.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.485",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Financial Forecasting from Textual and Tabular Time Series": {
        "type": "INPROCEEDINGS",
        "key": "koval-etal-2024-financial",
        "author": "Koval, Ross and Andrews, Nicholas and Yan, Xifeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Financial Forecasting from Textual and Tabular Time Series",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "There is a variety of multimodal data pertinent to public companies, spanning from accounting statements, macroeconomic statistics, earnings conference calls, and financial reports. These diverse modalities capture the state of firms from a variety of different perspectives but requires complex interactions to reconcile in the formation of accurate financial predictions. The commonality between these different modalities is that they all represent a time series, typically observed for a particular firm at a quarterly horizon, providing the ability to model trends and variations of company data over time. However, the time series of these diverse modalities contains varying temporal and cross-channel patterns that are challenging to model without the appropriate inductive biases. In this work, we design a novel multimodal time series prediction task that includes numerical financial results, macroeconomic states, and long financial documents to predict next quarter\u2019s company earnings relative to analyst expectations. We explore a variety of approaches for this novel setting, establish strong unimodal baselines, and propose a multimodal model that exhibits state-of-the-art performance on this unique task. We demonstrate that each modality contains unique information and that the best performing model requires careful fusion of the different modalities in a multi-stage training approach. To better understand model behavior, we conduct a variety of probing experiments, reveal insights into the value of different modalities, and demonstrate the practical utility of our proposed method in a simulated trading setting.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.486",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA": {
        "type": "INPROCEEDINGS",
        "key": "xing-etal-2024-learning",
        "author": "Xing, Xiaoying and Xiong, Peixi and Fan, Lei and Li, Yunxuan and Wu, Ying",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Ask Denotative and Connotative Questions for Knowledge-based VQA",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have attracted increasing attention due to its prominent performance on various tasks. Recent works seek to leverage LLMs on knowledge-based visual question answering (VQA) tasks which require common sense knowledge to answer the question about an image, since LLMs have obtained rich knowledge from large-scale training. Several methods have proposed to leverage frozen LLMs by converting visual information to textual prompts. However, how to efficiently exploit the knowledge of LLMs and bridge the disconnects between visual information and language models remain open problems. In this paper, we propose to let LLMs learn to ask (L2A) informative questions to collect essential visual information. We introduce the concepts of denotation and connotation to promote image and question understanding and provide a clear guidance with respect to the objective of question generation. In this way, the model can better capture the associations between different concepts, as well as efficiently collect both explicit information and implicit relevant information that contribute to the final answer. The experiments demonstrate that our proposed method achieves consistent performance on various knowledge-based VQA datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.487",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-contor",
        "author": "Li, Na and Bailleux, Thomas and Bouraoui, Zied and Schockaert, Steven",
        "booktitle": "EMNLP-findings2024",
        "title": "CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We consider the problem of finding plausible rules that are missing from a given ontology. A number of strategies for this problem have already been considered in the literature. Little is known about the relative performance of these strategies, however, as they have thus far been evaluated on different ontologies. Moreover, existing evaluations have focused on distinguishing held-out ontology rules from randomly corrupted ones, which often makes the task unrealistically easy and leads to the presence of incorrectly labelled negative examples. To address these concerns, we introduce a benchmark with manually annotated hard negatives and use this benchmark to evaluate ontology completion models. In addition to previously proposed models, we test the effectiveness of several approaches that have not yet been considered for this task, including LLMs and simple but effective hybrid strategies.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.488",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout": {
        "type": "INPROCEEDINGS",
        "key": "lee-lim-2024-towards",
        "author": "Lee, Changhun and Lim, Chiehyeon",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Pareto-Efficient RLHF: Paying Attention to a Few High-Reward Samples with Reward Dropout",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, leveraging reinforcement learning (RL) to fine-tune language models (LMs), known as reinforcement learning from human feedback (RLHF), has become an important research topic. However, there is still a lack of theoretical understanding of how RLHF works, the conditions under which it succeeds or fails, and whether it guarantees optimization of both likelihood \u03b2(\u00b7) and reward R(\u00b7) objectives. To address these issues, we consider RLHF as a bi-objective problem that has the nature of a Pareto optimization, present a Pareto improvement condition that is necessary to obtain Pareto-efficient policies, and propose a simple yet powerful method named reward dropout that guarantees a Pareto improvement. To demonstrate the performance of reward dropout, two benchmark datasets commonly used in text style transfer tasks were utilized in our study: sentiment and topic datasets sourced from Yelp and AG_News, respectively. Our experiments highlight that paying attention to a few samples with higher rewards leads to greater Pareto improvements regardless of model size. We also demonstrate that the effect of reward dropout is generalizable and most effective with non-pretrained target models, saving the effort of pretraining.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.489",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Weak-to-Strong Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-weak",
        "author": "Yang, Yuqing and Ma, Yan and Liu, Pengfei",
        "booktitle": "EMNLP-findings2024",
        "title": "Weak-to-Strong Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "When large language models (LLMs) surpass human capabilities, supervising them effectively becomes difficult. Weak-to-strong learning, where a less capable model enhances a stronger one, proves valuable in this context. Yet, the efficacy of this paradigm for complex reasoning tasks is still unexplored. In this paper, we introduce a progressive weak-to-strong reasoning framework that enables the strong model to autonomously refine its training data, maximizing the use of weak signals and unlocking its latent abilities. This framework begins with supervised fine-tuning on a selective small but high-quality dataset, followed by preference optimization on contrastive samples identified by the strong model itself. Experiments on the GSM8K and MATH datasets verify that our method can effectively improve the reasoning capabilities of Llama2-70b using three separate weak models. This work paves the way for a more scalable and sophisticated strategy to enhance AI reasoning powers. All relevant code and resources are available in https://github.com/GAIR-NLP/weak-to-strong-reasoning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.490",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-fine",
        "author": "Li, Xianzhi and Zmigrod, Ran and Ma, Zhiqiang and Liu, Xiaomo and Zhu, Xiaodan",
        "booktitle": "EMNLP-findings2024",
        "title": "Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language models are capable of memorizing detailed patterns and information, leading to a double-edged effect: they achieve impressive modeling performance on downstream tasks with the stored knowledge but also raise significant privacy concerns. Traditional differential privacy based training approaches offer robust safeguards by employing a uniform noise distribution across all parameters. However, this overlooks the distinct sensitivities and contributions of individual parameters in privacy protection and often results in suboptimal models. To address these limitations, we propose ANADP, a novel algorithm that adaptively allocates additive noise based on the importance of model parameters. We demonstrate that ANADP narrows the performance gap between regular fine-tuning and traditional DP fine-tuning on a series of datasets while maintaining the required privacy constraints.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.491",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Mystery of Compositional Generalization in Graph-based Generative Commonsense Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "fu-frank-2024-mystery",
        "author": "Fu, Xiyan and Frank, Anette",
        "booktitle": "EMNLP-findings2024",
        "title": "The Mystery of Compositional Generalization in Graph-based Generative Commonsense Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While LLMs have emerged as performant architectures for reasoning tasks, their compositional generalization capabilities have been questioned. In this work, we introduce a Compositional Generalization Challenge for Graph-based Commonsense Reasoning (CGGC) that goes beyond previous evaluations that are based on sequences or tree structures \u2013 and instead involves a reasoning graph: It requires models to generate a natural sentence based on given concepts and a corresponding reasoning graph, where the presented graph involves a previously unseen combination of relation types. To master this challenge, models need to learn how to reason over relation tupels within the graph, and how to compose them when conceptualizing a verbalization. We evaluate seven well-known LLMs using in-context learning and find that performant LLMs still struggle in compositional generalization. We investigate potential causes of this gap by analyzing the structures of reasoning graphs, and find that different structures present varying levels of difficulty for compositional generalization. Arranging the order of demonstrations according to the structures\u2019 difficulty shows that organizing samples in an easy-to-hard schema enhances the compositional generalization ability of LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.492",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AutoHallusion: Automatic Generation of Hallucination Benchmarks for Vision-Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-autohallusion",
        "author": "Wu, Xiyang and Guan, Tianrui and Li, Dianqi and Huang, Shuaiyi and Liu, Xiaoyu and Wang, Xijun and Xian, Ruiqi and Shrivastava, Abhinav and Huang, Furong and Boyd-Graber, Jordan Lee and Zhou, Tianyi and Manocha, Dinesh",
        "booktitle": "EMNLP-findings2024",
        "title": "AutoHallusion: Automatic Generation of Hallucination Benchmarks for Vision-Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large vision-language models (LVLMs) are prone to hallucinations, where certain contextual cues in an image can trigger the language module to produce overconfident and incorrect reasoning about abnormal or hypothetical objects. While some benchmarks have been developed to investigate LVLM hallucinations, they often rely on hand-crafted corner cases whose failure patterns may not generalize well. Additionally, fine-tuning on these examples could undermine their validity. To address this, we aim to scale up the number of cases through an automated approach, reducing human bias in crafting such corner cases. This motivates the development of AutoHallusion, the first automated benchmark generation approach that employs several key strategies to create a diverse range of hallucination examples. Our generated visual-question pairs pose significant challenges to LVLMs, requiring them to overcome contextual biases and distractions to arrive at correct answers. AutoHallusion enables us to create new benchmarks at the minimum cost and thus overcomes the fragility of hand-crafted benchmarks. It also reveals common failure patterns and reasons, providing key insights to detect, avoid, or control hallucinations. Comprehensive evaluations of top-tier LVLMs, e.g., GPT-4V(ision), Gemini Pro Vision, Claude 3, and LLaVA-1.5, show a 97.7% and 98.7% success rate of hallucination induction on synthetic and real-world datasets of AutoHallusion, paving the way for a long battle against hallucinations. The codebase and data can be accessed at https://github.com/wuxiyang1996/AutoHallusion",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.493",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MetaKP: On-Demand Keyphrase Generation": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-metakp",
        "author": "Wu, Di and Shen, Xiaoxian and Chang, Kai-Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "MetaKP: On-Demand Keyphrase Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Traditional keyphrase prediction methods predict a single set of keyphrases per document, failing to cater to the diverse needs of users and downstream applications. To bridge the gap, we introduce on-demand keyphrase generation, a novel paradigm that requires keyphrases that conform to specific high-level goals or intents. For this task, we present MetaKP, a large-scale benchmark comprising four datasets, 7500 documents, and 3760 goals across news and biomedical domains with human-annotated keyphrases. Leveraging MetaKP, we design both supervised and unsupervised methods, including a multi-task fine-tuning approach and a self-consistency prompting method with large language models. The results highlight the challenges of supervised fine-tuning, whose performance is not robust to distribution shifts. By contrast, the proposed self-consistency prompting approach greatly improves the performance of large language models, enabling GPT-4o to achieve 0.548 SemF1, surpassing the performance of a fully fine-tuned BART-base model. Finally, we demonstrate the potential of our method to serve as a general NLP infrastructure, exemplified by its application in epidemic event detection from social media.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.494",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PSST: A Benchmark for Evaluation-driven Text Public-Speaking Style Transfer": {
        "type": "INPROCEEDINGS",
        "key": "sun-etal-2024-psst",
        "author": "Sun, Huashan and Wu, Yixiao and Yang, Yizhe and Li, Yinghao and Li, Jiawei and Ye, Yuhao and Gao, Yang",
        "booktitle": "EMNLP-findings2024",
        "title": "PSST: A Benchmark for Evaluation-driven Text Public-Speaking Style Transfer",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language style is necessary for AI systems to accurately understand and generate diverse human language. However, previous text style transfer primarily focused on sentence-level data-driven approaches, limiting exploration of potential problems in large language models (LLMs) and the ability to meet complex application needs. To overcome these limitations, we introduce a novel task called Public-Speaking Style Transfer (PSST), which aims to simulate humans to transform passage-level, official texts into a public-speaking style. Grounded in the analysis of real-world data from a linguistic perspective, we decompose public-speaking style into key sub-styles to pose challenges and quantify the style modeling capability of LLMs. For such intricate text style transfer, we further propose a fine-grained evaluation framework to analyze the characteristics and identify the problems of stylized texts. Comprehensive experiments suggest that current LLMs struggle to generate public speaking texts that align with human preferences, primarily due to excessive stylization and loss of semantic information. We will release our data, code, and model upon acceptance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.495",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation": {
        "type": "INPROCEEDINGS",
        "key": "fang-etal-2024-trace",
        "author": "Fang, Jinyuan and Meng, Zaiqiao and MacDonald, Craig",
        "booktitle": "EMNLP-findings2024",
        "title": "TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-augmented generation (RAG) offers an effective approach for addressing question answering (QA) tasks. However, the imperfections of the retrievers in RAG models often result in the retrieval of irrelevant information, which could introduce noise and degrade the performance, especially when handling multi-hop questions that require multiple steps of reasoning. To enhance the multi-hop reasoning ability of RAG models, we propose TRACE. TRACE constructs knowledge-grounded reasoning chains, which are a series of logically connected knowledge triples, to identify and integrate supporting evidence from the retrieved documents for answering questions. Specifically, TRACE employs a KG Generator to create a knowledge graph (KG) from the retrieved documents, and then uses a novel Autoregressive Reasoning Chain Constructor to build reasoning chains. Experimental results on three multi-hop QA datasets show that TRACE achieves an average performance improvement of up to 14.03% compared to using all the retrieved documents. Moreover, the results indicate that using reasoning chains as context, rather than the entire documents, is often sufficient to correctly answer questions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.496",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enable Fast Sampling for Seq2Seq Text Diffusion": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-enable",
        "author": "Liu, Pan and Tian, Xiaohua and Lin, Zhouhan",
        "booktitle": "EMNLP-findings2024",
        "title": "Enable Fast Sampling for Seq2Seq Text Diffusion",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Diffusion models exhibit promising capacity for generating high-quality text. However, owing to the curved nature of generation path, they necessitate traversing numerous steps to guarantee the text quality. In this paper, we propose an efficient model FMSeq, which utilizes flow matching to straighten the generation path, thereby enabling fast sampling for diffusion-based seq2seq text generation. Specifically, we construct transport flow only on the target sequences to adapt the diffusion-based model with flow matching. Furthermore, we explore different settings and identify target-parameterization, self-conditioning and time-difference as three effective techniques to improve the generation quality under a few steps. Experiments on four popular tasks demonstrate that FMSeq generates texts of comparable quality to the SOTA diffusion-based DiffuSeq in just 10 steps, achieving a 200-fold speedup.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.497",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AlignSum: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference": {
        "type": "INPROCEEDINGS",
        "key": "han-etal-2024-alignsum",
        "author": "Han, Yang and Wang, Yiming and Wang, Rui and Chen, Lu and Yu, Kai",
        "booktitle": "EMNLP-findings2024",
        "title": "AlignSum: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Text summarization tasks commonly employ Pre-trained Language Models (PLMs) to fit diverse standard datasets. While these PLMs excel in automatic evaluations, they frequently underperform in human evaluations, indicating a deviation between their generated summaries and human summarization preferences. This discrepancy is likely due to the low quality of fine-tuning datasets and the limited availability of high-quality human-annotated data that reflect true human preference. To address this challenge, we introduce a novel human summarization preference alignment framework AlignSum. This framework consists of three parts: Firstly, we construct a Data Pymarid with extractive, abstractive, and human-annotated summary data. Secondly, we conduct the Gaussian Resampling to remove summaries with extreme lengths. Finally, we implement the two-stage hierarchical fine-tuning with Data Pymarid after Gaussian Resampling. We apply AlignSum to PLMs on the human-annotated CNN/DailyMail and BBC XSum datasets. Experiments show that with AlignSum, PLMs like BART-Large surpass 175B GPT-3 in both automatic and human evaluations. This demonstrates that AlignSum significantly enhances the alignment of language models with human summarization preferences.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.498",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CHIRON: Rich Character Representations in Long-Form Narratives": {
        "type": "INPROCEEDINGS",
        "key": "gurung-lapata-2024-chiron",
        "author": "Gurung, Alexander and Lapata, Mirella",
        "booktitle": "EMNLP-findings2024",
        "title": "CHIRON: Rich Character Representations in Long-Form Narratives",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Characters are integral to long-form narratives, but are poorly understood by existing story analysis and generation systems. While prior work has simplified characters via graph-based methods and brief character descriptions, we aim to better tackle the problem of representing complex characters by taking inspiration from advice given to professional writers. We propose CHIRON, a new \u2018character sheet\u2019 based representation that organizes and filters textual information about characters. We construct CHIRON sheets in two steps: a Generation Module that prompts an LLM for character information via question-answering and a Validation Module that uses automated reasoning and a domain-specific entailment model to eliminate false facts about a character. We validate CHIRON via the downstream task of masked-character prediction, where our experiments show CHIRON is better and more flexible than comparable summary-based baselines. We also show that metrics derived from CHIRON can be used to automatically infer character-centricity in stories, and that these metrics align with human judgments.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.499",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Refiner: Restructure Retrieved Content Efficiently to Advance Question-Answering Capabilities": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-refiner",
        "author": "Li, Zhonghao and Hu, Xuming and Liu, Aiwei and Zheng, Kening and Huang, Sirui and Xiong, Hui",
        "booktitle": "EMNLP-findings2024",
        "title": "Refiner: Restructure Retrieved Content Efficiently to Advance Question-Answering Capabilities",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.500",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "jiang-etal-2024-infrared",
        "author": "Jiang, Shixin and Chen, Zerui and Liang, Jiafeng and Zhao, Yanyan and Liu, Ming and Qin, Bing",
        "booktitle": "EMNLP-findings2024",
        "title": "Infrared-LLaVA: Enhancing Understanding of Infrared Images in Multi-Modal Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Expanding the understanding capabilities of multi-modal large language models (MLLMs) for infrared modality is a challenge due to the single-modality nature and limited amount of training data. Existing methods typically construct a uniform embedding space for cross-modal alignment and leverage abundant visual image data to indirectly understand infrared images. However, they ignore the supervisory signals of infrared-modality-specific attributes, which may lead to biased understanding of infrared images. To address this issue, we propose a debating multi-agent generation system which transfers knowledge from visible images to generate infrared image-text pairs and infrared instruction data. Moreover, we construct an infrared question-answering benchmark based on common infrared tasks. Experimental results from incremental fine-tuning on existing models and our Infrared-LLaVA-7B trained from scratch on infrared data demonstrate the effectiveness of the generated data and the feasibility of the generation approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.501",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LPZero: Language Model Zero-cost Proxy Search from Zero": {
        "type": "INPROCEEDINGS",
        "key": "dong-etal-2024-lpzero",
        "author": "Dong, Peijie and Li, Lujun and Liu, Xiang and Tang, Zhenheng and Liu, Xuebo and Wang, Qiang and Chu, Xiaowen",
        "booktitle": "EMNLP-findings2024",
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite the outstanding performance, Neural Architecture Search (NAS) is criticized for massive computation. Recently, Zero-shot NAS has emerged as a promising approach by exploiting Zero-cost (ZC) proxies, which markedly reduce computational demands. Despite this, existing ZC proxies heavily rely on expert knowledge and incur significant trial-and-error costs. Particularly in NLP tasks, most existing ZC proxies fail to surpass the performance of the naive baseline. To address these challenges, we introduce a novel framework, LPZero, which is the first to automatically design zero-cost (ZC) proxies for various tasks, achieving higher ranking consistency than human-designed proxies. Specifically, we model the ZC proxy as a symbolic equation and incorporate a unified proxy search space that encompasses existing ZC proxies, which are composed of a predefined set of mathematical symbols. To heuristically search for the best ZC proxy, LPZero incorporates genetic programming to find the optimal symbolic composition. We propose a Predictive-Pruning Strategy (PPS), which preemptively eliminates unpromising proxies, thereby mitigating the risk of proxy degradation. Extensive experiments on FlexiBERT, GPT-2, and LLaMA-7B demonstrate LPZero\u2019s superior ranking ability and performance on downstream tasks compared to current approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.502",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "meng-etal-2024-traffic",
        "author": "Meng, Rui and Liu, Ye and Tu, Lifu and He, Daqing and Zhou, Yingbo and Yavuz, Semih",
        "booktitle": "EMNLP-findings2024",
        "title": "Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Phrases are fundamental linguistic units through which humans convey semantics. This study critically examines the capacity of API-based large language models (LLMs) to comprehend phrase semantics, utilizing three human-annotated datasets. We assess the performance of LLMs in executing phrase semantic reasoning tasks guided by natural language instructions and explore the impact of common prompting techniques, including few-shot demonstrations and Chain-of-Thought reasoning. Our findings reveal that LLMs greatly outperform traditional embedding methods across the datasets; however, they do not show a significant advantage over fine-tuned methods. The effectiveness of advanced prompting strategies shows variability. We conduct detailed error analyses to interpret the limitations faced by LLMs in comprehending phrase semantics. Code and data can be found at https://github.com/memray/llm_phrase_semantics/.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.503",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-far",
        "author": "Huang, Heyan and Li, Yinghao and Sun, Huashan and Bai, Yu and Gao, Yang",
        "booktitle": "EMNLP-findings2024",
        "title": "How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent studies have demonstrated that In-Context Learning (ICL), through the use of specific demonstrations, can align Large Language Models (LLMs) with human preferences known as In-Context Alignment (ICA), indicating that models can comprehend human instructions without requiring parameter adjustments. However, the exploration of the mechanism and applicability of ICA remains limited. In this paper, we begin by dividing the context text used in ICA into three categories: format, system prompt, and example. Through ablation experiments, we investigate the effectiveness of each part in enabling ICA to function effectively. We then examine how variants in these parts impact the model\u2019s alignment performance. Our findings indicate that the example part is crucial for enhancing the model\u2019s alignment capabilities, with changes in examples significantly affecting alignment performance. We also conduct a comprehensive evaluation of ICA\u2019s zero-shot capabilities in various alignment tasks. The results indicate that compared to parameter fine-tuning methods, ICA demonstrates superior performance in knowledge-based tasks and tool-use tasks. However, it still exhibits certain limitations in areas such as multi-turn dialogues and instruction following. Source codes and scripts are available at https://github.com/li-aolong/how-far-can-ica-go.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.504",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Variational Language Concepts for Interpreting Foundation Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-variational",
        "author": "Wang, Hengyi and Tan, Shiwei and Hong, Zhiqing and Zhang, Desheng and Wang, Hao",
        "booktitle": "EMNLP-findings2024",
        "title": "Variational Language Concepts for Interpreting Foundation Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Foundation Language Models (FLMs) such as BERT and its variants have achieved remarkable success in natural language processing. To date, the interpretability of FLMs has primarily relied on the attention weights in their self-attention layers. However, these attention weights only provide word-level interpretations, failing to capture higher-level structures, and are therefore lacking in readability and intuitiveness. To address this challenge, we first provide a formal definition of *conceptual interpretation* and then propose a variational Bayesian framework, dubbed VAriational Language Concept (VALC), to go beyond word-level interpretations and provide concept-level interpretations. Our theoretical analysis shows that our VALC finds the optimal language concepts to interpret FLM predictions. Empirical results on several real-world datasets show that our method can successfully provide conceptual interpretation for FLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.505",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga Dataset and Its Challenging Tasks": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-exploring-capability",
        "author": "Yang, Qi and Zeng, Jingjie and Yang, Liang and Yang, Zhihao and Lin, Hongfei",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga Dataset and Its Challenging Tasks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Yonkoma Manga, characterized by its four-panel structure, presents unique challenges due to its rich contextual information and strong sequential features. To address the limitations of current multimodal large language models (MLLMs) in understanding this type of data, we create a novel dataset named YManga from the Internet. After filtering out low-quality content, we collect a dataset of 1,015 yonkoma strips, containing 10,150 human annotations. We then define three challenging tasks for this dataset: panel sequence detection, generation of the author\u2019s creative intention, and description generation for masked panels. These tasks progressively introduce the complexity of understanding and utilizing such image-text data. To the best of our knowledge, YManga is the first dataset specifically designed for yonkoma manga strips understanding. Extensive experiments conducted on this dataset reveal significant challenges faced by current multimodal large language models. Our results show a substantial performance gap between models and humans across all three tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.506",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TWBias: A Benchmark for Assessing Social Bias in Traditional Chinese Large Language Models through a Taiwan Cultural Lens": {
        "type": "INPROCEEDINGS",
        "key": "hsieh-etal-2024-twbias",
        "author": "Hsieh, Hsin-Yi and Huang, Shih-Cheng and Tsai, Richard Tzong-Han",
        "booktitle": "EMNLP-findings2024",
        "title": "TWBias: A Benchmark for Assessing Social Bias in Traditional Chinese Large Language Models through a Taiwan Cultural Lens",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.507",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unlocking the Potential of Model Merging for Low-Resource Languages": {
        "type": "INPROCEEDINGS",
        "key": "tao-etal-2024-unlocking",
        "author": "Tao, Mingxu and Zhang, Chen and Huang, Quzhe and Ma, Tianyao and Huang, Songfang and Zhao, Dongyan and Feng, Yansong",
        "booktitle": "EMNLP-findings2024",
        "title": "Unlocking the Potential of Model Merging for Low-Resource Languages",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Adapting large language models (LLMs) to new languages typically involves continual pre-training (CT) followed by supervised fine-tuning (SFT). However, this CT-then-SFT approach struggles with limited data in the context of low-resource languages, failing to balance language modeling and task-solving capabilities. We thus propose a new model merging solution as an alternative for low-resource languages, combining models with distinct capabilities into a single model without additional training. We use model merging to develop task-solving LLMs for low-resource languages without SFT data in the target languages. Our experiments based on Llama-2-7B demonstrate that model merging effectively endows LLMs for low-resource languages with task-solving abilities, outperforming CT-then-SFT in scenarios with extremely scarce data. Observing performance saturation in model merging with increasingly more training tokens, we further analyze the merging process and introduce a slack variable to the model merging algorithm to mitigate the loss of important parameters, thereby enhancing model performance. We hope that model merging can benefit more human languages suffering from data scarcity with its higher data efficiency.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.508",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness": {
        "type": "INPROCEEDINGS",
        "key": "yao-etal-2024-pure",
        "author": "Yao, Wenjin and Wang, Yidong and Yu, Zhuohao and Xie, Rui and Zhang, Shikun and Ye, Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Aligning large language models (LLMs) with human values and preferences is a significant challenge. Training-based methods, such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO), require substantial resources and are impractical for API-based LLMs. Post-processing methods decouple alignment from training but may incur high multiple-time inference costs or rely on less knowledgeable lightweight models for response refinement. In this paper, we propose a new LLM alignment paradigm from the perspective of pre-processing. By reformulating risky queries into highly relevant yet harmless ones before feeding them into LLMs, our method eliminates the high costs of training base LLMs, efficiently applies to both open-source and proprietary LLMs, and achieves a promising balance of harmlessness and helpfulness. For example, with Vicuna-7B as the LLM to align, it enhances helpfulness by 28.52% over DPO while maintaining comparable harmlessness levels. When applied to Gemini-1.5-pro, it increased harmlessness and helpfulness by 7.04% and 29.37%, respectively.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.509",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-mmedagent",
        "author": "Li, Binxu and Yan, Tiankai and Pan, Yuanting and Luo, Jie and Ji, Ruiyang and Ding, Jiayuan and Xu, Zhe and Liu, Shilong and Dong, Haoyu and Lin, Zihao and Wang, Yixin",
        "booktitle": "EMNLP-findings2024",
        "title": "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit limited generality and often fall short when compared to specialized models. Recently, LLM-based agents have been developed to address these challenges by selecting appropriate specialized models as tools based on user inputs. However, such advancements have not been extensively explored within the medical domain. To bridge this gap, this paper introduces the first agent explicitly designed for the medical field, named Multi-modal Medical Agent (MMedAgent). We curate an instruction-tuning dataset comprising six medical tools solving seven tasks across five modalities, enabling the agent to choose the most suitable tools for a given task. Comprehensive experiments demonstrate that MMedAgent achieves superior performance across a variety of medical tasks compared to state-of-the-art open-source methods and even the closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in updating and integrating new medical tools.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.510",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SALMON: A Structure-Aware Language Model with logicality and densification strategy for Temporal Knowledge Graph Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-salmon",
        "author": "Zhang, Fu and Lin, Jinghao and Cheng, Jingwei",
        "booktitle": "EMNLP-findings2024",
        "title": "SALMON: A Structure-Aware Language Model with logicality and densification strategy for Temporal Knowledge Graph Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Temporal knowledge graph reasoning (TKGR) is a crucial task that involves reasoning at known timestamps to complete the future facts and has attracted more and more attention in recent years. The current TKGR models are mainly based on graph neural networks or tensor decomposition techniques. Few works in TKGR focus on pre-trained language models (PLMs) which have powerful sequence modeling capabilities to capture the temporal associations between facts. In this paper, we propose a model SALMON: a Structure-Aware Language Model with logicality and densification strategy. Specifically, we design a PLM-based framework with a structure-aware layer inside to jointly capture the temporal evolving pattern and structural information in TKGs. To further enhance the model\u2019s ability to infer causal associations of facts, we propose a logical judging module, which can guide the model to prioritize learning the most relevant evolving information of logical causal associations in TKGs during the training process. Moreover, we propose a densification strategy based on large language models, through a carefully crafted Chain of Thought prompt, to dig out some knowledge necessary for reasoning about fact associations, thereby making the model perform better. Extensive experimental results demonstrate the superiority of our model over the state-of-the-art baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.511",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping": {
        "type": "INPROCEEDINGS",
        "key": "zhu-etal-2024-multilingual-contrastive",
        "author": "Zhu, Wenhao and Liu, Sizhe and Huang, Shujian and She, Shuaijie and Wendler, Chris and Chen, Jiajun",
        "booktitle": "EMNLP-findings2024",
        "title": "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Decoding by contrasting layers (DoLa), is designed to improve the generation quality of large language models (LLMs) by contrasting the prediction probabilities between an early exit output (amateur logits) and the final output (expert logits).However, we find that this approach does not work well on non-English tasks.Inspired by previous interpretability work on language transition during the model\u2019s forward pass, we discover that this issue arises from a language mismatch between early exit output and final output.In this work, we propose an improved contrastive decoding algorithm that is effective for diverse languages beyond English.To obtain more helpful amateur logits, we devise two strategies to skip a set of bottom, language-agnostic layers based on our preliminary analysis.Experimental results on multilingual reasoning benchmarks demonstrate that our proposed method outperforms previous contrastive decoding baselines and substantially improves LLM\u2019s chain-of-thought reasoning accuracy across 11 languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.512",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "ma-etal-2024-potential",
        "author": "Ma, Bolei and Wang, Xinpeng and Hu, Tiancheng and Haensch, Anna-Carolina and Hedderich, Michael A. and Plank, Barbara and Kreuter, Frauke",
        "booktitle": "EMNLP-findings2024",
        "title": "The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advances in Large Language Models (LLMs) have sparked wide interest in validating and comprehending the human-like cognitive-behavioral traits LLMs may capture and convey. These cognitive-behavioral traits include typically Attitudes, Opinions, Values (AOVs). However, measuring AOVs embedded within LLMs remains opaque, and different evaluation methods may yield different results. This has led to a lack of clarity on how different studies are related to each other and how they can be interpreted. This paper aims to bridge this gap by providing a comprehensive overview of recent works on the evaluation of AOVs in LLMs. Moreover, we survey related approaches in different stages of the evaluation pipeline in these works. By doing so, we address the potential and challenges with respect to understanding the model, human-AI alignment, and downstream application in social sciences. Finally, we provide practical insights into evaluation methods, model enhancement, and interdisciplinary collaboration, thereby contributing to the evolving landscape of evaluating AOVs in LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.513",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Low-Resource Machine Translation through the Lens of Personalized Federated Learning": {
        "type": "INPROCEEDINGS",
        "key": "moskvoretskii-etal-2024-low",
        "author": "Moskvoretskii, Viktor and Tupitsa, Nazarii and Biemann, Chris and Horv\u00e1th, Samuel and Gorbunov, Eduard and Nikishina, Irina",
        "booktitle": "EMNLP-findings2024",
        "title": "Low-Resource Machine Translation through the Lens of Personalized Federated Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We present a new approach called MeritOpt based on the Personalized Federated Learning algorithm MeritFed that can be applied to Natural Language Tasks with heterogeneous data. We evaluate it on the Low-Resource Machine Translation task, using the datasets of South East Asian and Finno-Ugric languages. In addition to its effectiveness, MeritOpt is also highly interpretable, as it can be applied to track the impact of each language used for training. Our analysis reveals that target dataset size affects weight distribution across auxiliary languages, that unrelated languages do not interfere with the training, and auxiliary optimizer parameters have minimal impact. Our approach is easy to apply with a few lines of code, and we provide scripts for reproducing the experiments (https://github.com/VityaVitalich/MeritOpt).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.514",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can Language Models Recognize Convincing Arguments?": {
        "type": "INPROCEEDINGS",
        "key": "rescala-etal-2024-language",
        "author": "Rescala, Paula and Ribeiro, Manoel Horta and Hu, Tiancheng and West, Robert",
        "booktitle": "EMNLP-findings2024",
        "title": "Can Language Models Recognize Convincing Arguments?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The capabilities of large language models (LLMs) have raised concerns about their potential to create and propagate convincing narratives. Here, we study their performance in detecting convincing arguments to gain insights into LLMs\u2019 persuasive capabilities without directly engaging in experimentation with humans. We extend a dataset by Durmus and Cardie (2018) with debates, votes, and user traits and propose tasks measuring LLMs\u2019 ability to (1) distinguish between strong and weak arguments, (2) predict stances based on beliefs and demographic characteristics, and (3) determine the appeal of an argument to an individual based on their traits. We show that LLMs perform on par with humans in these tasks and that combining predictions from different LLMs yields significant performance gains, surpassing human performance. The data and code released with this paper contribute to the crucial effort of continuously evaluating and monitoring LLMs\u2019 capabilities and potential impact. (https://go.epfl.ch/persuasion-llm)",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.515",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature": {
        "type": "INPROCEEDINGS",
        "key": "katz-etal-2024-knowledge",
        "author": "Katz, Uri and Levy, Mosh and Goldberg, Yoav",
        "booktitle": "EMNLP-findings2024",
        "title": "Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The exponential growth of scientific literature necessitates advanced tools for effective knowledge exploration. We present Knowledge Navigator, a system designed to enhance exploratory search abilities by organizing and structuring the retrieved documents from broad topical queries into a navigable, two-level hierarchy of named and descriptive scientific topics and subtopics. This structured organization provides an overall view of the research themes in a domain, while also enabling iterative search and deeper knowledge discovery within specific subtopics by allowing users to refine their focus and retrieve additional relevant documents. Knowledge Navigator combines LLM capabilities with cluster-based methods to enable an effective browsing method. We demonstrate our approach\u2019s effectiveness through automatic and manual evaluations on two novel benchmarks, CLUSTREC-COVID and SCITOC Our code, prompts, and benchmarks are made publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.516",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Scalable and Domain-General Abstractive Proposition Segmentation": {
        "type": "INPROCEEDINGS",
        "key": "hosseini-etal-2024-scalable",
        "author": "Hosseini, Mohammad Javad and Gao, Yang and Baumg\u00e4rtner, Tim and Fabrikant, Alex and Amplayo, Reinald Kim",
        "booktitle": "EMNLP-findings2024",
        "title": "Scalable and Domain-General Abstractive Proposition Segmentation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Segmenting text into fine-grained units of meaning is important to a wide range of NLP applications. The default approach of segmenting text into sentences is often insufficient, especially since sentences are usually complex enough to include multiple units of meaning that merit separate treatment in the downstream task. We focus on the task of abstractive proposition segmentation (APS): transforming text into simple, self-contained, well-formed sentences. Several recent works have demonstrated the utility of proposition segmentation with few-shot prompted LLMs for downstream tasks such as retrieval-augmented grounding and fact verification. However, this approach does not scale to large amounts of text and may not always extract all the facts from the input text.In this paper, we first introduce evaluation metrics for the task to measure several dimensions of quality.We then propose a scalable, yet accurate, proposition segmentation model. We model proposition segmentation as a supervised task by training LLMs on existing annotated datasets and show that training yields significantly improved results. We further show that by using the fine-tuned LLMs (Gemini Pro and Gemini Ultra) as teachers for annotating large amounts of multi-domain synthetic distillation data, we can train smaller student models (Gemma 1 2B and 7B) with results similar to the teacher LLMs. We then demonstrate that our technique leads to effective domain generalization, by annotating data in two domains outside the original training data and evaluating on them. Finally, as a key contribution of the paper, we share an easy-to-use API for NLP practitioners to use.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.517",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention": {
        "type": "INPROCEEDINGS",
        "key": "lu-etal-2024-hit",
        "author": "Lu, Wenxuan and Jiang, Songhao and Yijing, Wang and Zang, Tianning",
        "booktitle": "EMNLP-findings2024",
        "title": "Hit the Nail on the Head: Parameter-Efficient Multi-task Tuning via Human Language Intervention",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Parameter-Efficient Fine-Tuning (PEFT) on small Pre-trained Language Models (PLMs) has emerged as a promising approach to enhance their multi-tasking capabilities. Prevalent methods simultaneously train additional modules (i.e., one task-shared module and multiple task-specific modules) for adapting PLMs to downstream tasks. However, their adaptability to new tasks is constrained, as the task-specific modules independently adapt to each task, overlooking the potential for knowledge transfer across tasks. In this paper, we propose a novel multi-task learning framework, Inspirational Pointer (IP), that enables the transfer of prior knowledge across tasks through human language intervention. Specifically, we attach task descriptions to the input samples, which are then mapped to corresponding task embeddings. Based on those embeddings, we adapt PLMs for downstream tasks. Similar tasks share akin descriptions, allowing new task samples close to similar trained tasks in the task embedding space, hitting the memory about trained tasks of the model. Our experiments on the T5 model demonstrate performance improvements of our method in multi-task learning and few-shot transfer learning. Further, we implemented the IP in decoder-only models including GPT2 and large language models (LLMs), and the results show that IP enhances the capabilities of decoder-only models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.518",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-linked",
        "author": "Li, Jiachun and Cao, Pengfei and Wang, Chenhao and Jin, Zhuoran and Chen, Yubo and Liu, Kang and Jiang, Xiaojian and Xu, Jiexin and Zhao, Jun",
        "booktitle": "EMNLP-findings2024",
        "title": "LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) sometimes demonstrate poor performance on knowledge-intensive tasks, commonsense reasoning is one of them. Researchers typically address these issues by retrieving related knowledge from knowledge graphs or employing self-enhancement methods to elicit knowledge in LLMs. However, noisy knowledge and invalid reasoning issues hamper their ability to answer questions accurately. To this end, we propose a novel method named eliciting, filtering and integrating knowledge in large language model (LINKED). In it, we design a reward model to filter out the noisy knowledge and take the marginal consistent reasoning module to reduce invalid reasoning. With our comprehensive experiments on two complex commonsense reasoning benchmarks, our method outperforms SOTA baselines (up to 9.0% improvement of accuracy). Besides, to measure the positive and negative impact of the injected knowledge, we propose a new metric called effectiveness-preservation score for the knowledge enhancement works. Finally, through extensive experiments, we conduct an in-depth analysis and find many meaningful conclusions about LLMs in commonsense reasoning tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.519",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-beyond-agreement",
        "author": "Wang, Yupei and Hu, Renfen and Zhao, Zhe",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While current Automated Essay Scoring (AES) methods demonstrate high scoring agreement with human raters, their decision-making mechanisms are not fully understood. Our proposed method, using counterfactual intervention assisted by Large Language Models (LLMs), reveals that BERT-like models primarily focus on sentence-level features, whereas LLMs such as GPT-3.5, GPT-4 and Llama-3 are sensitive to conventions &amp; accuracy, language complexity, and organization, indicating a more comprehensive rationale alignment with scoring rubrics. Moreover, LLMs can discern counterfactual interventions when giving feedback on essays. Our approach improves understanding of neural AES methods and can also apply to other domains seeking transparency in model-driven decisions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.520",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-ts",
        "author": "Zhang, Chen and Tang, Chengguang and Chong, Dading and Shi, Ke and Tang, Guohua and Jiang, Feng and Li, Haizhou",
        "booktitle": "EMNLP-findings2024",
        "title": "TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Mainstream approaches to aligning large language models (LLMs) heavily rely on human preference data, particularly when models require periodic updates. The standard process for iterative alignment of LLMs involves collecting new human feedback for each update. However, the data collection process is costly and challenging to scale. To address this issue, we introduce the \u201cTS-Align\u201d framework, which fine-tunes a policy model using pairwise feedback data automatically mined from its outputs. This automatic mining process is efficiently accomplished through the collaboration between a large-scale teacher model and a small-scale student model. The policy fine-tuning process can be iteratively repeated using on-policy generations within our proposed teacher-student collaborative framework. Through extensive experiments, we demonstrate that our final aligned policy outperforms the base policy model with an average win rate of 69.7% across seven conversational or instruction-following datasets. Furthermore, we show that the ranking capability of the teacher is effectively distilled into the student through our pipeline, resulting in a small-scale yet effective reward model for policy model alignment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.521",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Datasets for Multilingual Answer Sentence Selection": {
        "type": "INPROCEEDINGS",
        "key": "gabburo-etal-2024-datasets",
        "author": "Gabburo, Matteo and Campese, Stefano and Agostini, Federico and Moschitti, Alessandro",
        "booktitle": "EMNLP-findings2024",
        "title": "Datasets for Multilingual Answer Sentence Selection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Answer Sentence Selection (AS2) is a critical task for designing effective retrieval-based Question Answering (QA) systems. Most advancements in AS2 focus on English due to the scarcity of annotated datasets for other languages. This lack of resources prevents the training of effective AS2 models in different languages, creating a performance gap between QA systems in English and other locales. In this paper, we introduce new high-quality datasets for AS2 in five European languages (French, German, Italian, Portuguese, and Spanish), obtained through supervised Automatic Machine Translation (AMT) of existing English AS2 datasets such as ASNQ, WikiQA, and TREC-QA using a Large Language Model (LLM). We evaluated our approach and the quality of the translated datasets through multiple experiments with different Transformer architectures. The results indicate that our datasets are pivotal in producing robust and powerful multilingual AS2 models, significantly contributing to closing the performance gap between English and other languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.522",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Active Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-active",
        "author": "Li, Dongyuan and Zhang, Ying and Wang, Zhen and Tan, Shiyin and Kosugi, Satoshi and Okumura, Manabu",
        "booktitle": "EMNLP-findings2024",
        "title": "Active Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "For abstractive text summarization, laborious data annotation and time-consuming model training become two high walls, hindering its further progress. Active Learning, selecting a few informative instances for annotation and model training, sheds light on solving these issues. However, only few active learning-based studies focus on abstractive text summarization and suffer from low stability, effectiveness, and efficiency. To solve the problems, we propose a novel LLM-determined curriculum active learning framework. Firstly, we design a prompt to ask large language models to rate the difficulty of instances, which guides the model to train on from easier to harder instances. Secondly, we design a novel active learning strategy, i.e., Certainty Gain Maximization, enabling to select instances whose distribution aligns well with the overall distribution. Experiments show our method can improve stability, effectiveness, and efficiency of abstractive text summarization backbones.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.523",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-question",
        "author": "Zhang, Yu and Chen, Kehai and Bai, Xuefeng and Kang, Zhao and Guo, Quanjiang and Zhang, Min",
        "booktitle": "EMNLP-findings2024",
        "title": "Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Knowledge graph question answering (KGQA) involves answering natural language questions by leveraging structured information stored in a knowledge graph. Typically, KGQA initially retrieve a targeted subgraph from a large-scale knowledge graph, which serves as the basis for reasoning models to address queries. However, the retrieved subgraph inevitably brings distraction information for knowledge utilization, impeding the model\u2019s ability to perform accurate reasoning. To address this issue, we propose a Question-guided Knowledge Graph Re-scoring method (Q-KGR) to eliminate noisy pathways for the input question, thereby focusing specifically on pertinent factual knowledge.Moreover, we introduce Knowformer, a parameter-efficient method for injecting the re-scored knowledge graph into large language models to enhance their ability to perform factual reasoning.Extensive experiments on multiple KGQA benchmarks demonstrate the superiority of our method over existing systems.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.524",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Achieving Stronger Generation via Simple Contrastive Tuning": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-achieving",
        "author": "Wang, Zhimeng and Wang, Pinzheng and Li, Juntao and Chen, Yibin and Zhang, Min",
        "booktitle": "EMNLP-findings2024",
        "title": "Achieving Stronger Generation via Simple Contrastive Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Instruction tuning is widely used to unlock the abilities of Large Language Models (LLMs) in following human instructions, resulting in substantial performance improvements across various downstream tasks.Furthermore, contrastive decoding methods are employed to enhance instruction-tuned models. To further explore the potential of contrastive decoding, we introduce the Contrastive Tuning and Decoding (CTD) framework, which enhances model performance without requiring additional data or significant computational resources.When performing Contrastive Tuning, we optimize a correction model by targeting discrepancies between the original outputs and labels. During Contrastive Decoding, the correction model adjusts the logits of the SFT model using the same input to ensure better adherence to instructions.With the lightweight CTD framework, we refine the behavior of instruction-tuned models, improving their performance on the challenging SUPNATINST dataset with unfamiliar data distributions across various models and prompt formats.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.525",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling": {
        "type": "INPROCEEDINGS",
        "key": "gwak-etal-2024-forecasting",
        "author": "Gwak, Daehoon and Park, Junwoo and Park, Minho and Park, ChaeHun and Lee, Hyunchan and Choi, Edward and Choo, Jaegul",
        "booktitle": "EMNLP-findings2024",
        "title": "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Predicting future international events from textual information, such as news articles, has tremendous potential for applications in global policy, strategic decision-making, and geopolitics. However, existing datasets available for this task are often limited in quality, hindering the progress of related research. In this paper, we introduce a novel dataset designed to address these limitations by leveraging the advanced reasoning capabilities of large-language models (LLMs). Our dataset features high-quality scoring labels generated through advanced prompt modeling and rigorously validated by domain experts in political science. We showcase the quality and utility of our dataset for real-world event prediction tasks, demonstrating its effectiveness through extensive experiments and analysis. Furthermore, we publicly release our dataset along with the full automation source code for data collection, labeling, and benchmarking, aiming to support and advance research in text-based event prediction.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.526",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "QPaug: Question and Passage Augmentation for Open-Domain Question Answering of LLMs": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-qpaug",
        "author": "Kim, Minsang and Park, Cheoneum and Baek, Seung Jun",
        "booktitle": "EMNLP-findings2024",
        "title": "QPaug: Question and Passage Augmentation for Open-Domain Question Answering of LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-augmented generation (RAG) has received much attention for Open-domain question-answering (ODQA) tasks as a means to compensate for the parametric knowledge of large language models (LLMs). While previous approaches focused on processing retrieved passages to remove irrelevant context, they still rely heavily on the quality of retrieved passages which can degrade if the question is ambiguous or complex. In this paper, we propose a simple yet efficient method called question and passage augmentation (QPaug) via LLMs for open-domain QA. QPaug first decomposes the original questions into multiple-step sub-questions. By augmenting the original question with detailed sub-questions and planning, we are able to make the query more specific on what needs to be retrieved, improving the retrieval performance. In addition, to compensate for the case where the retrieved passages contain distracting information or divided opinions, we augment the retrieved passages with self-generated passages by LLMs to guide the answer extraction. Experimental results show that QPaug outperforms the previous state-of-the-art and achieves significant performance gain over existing RAG methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.527",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ICON: Improving Inter-Report Consistency in Radiology Report Generation via Lesion-aware Mixup Augmentation": {
        "type": "INPROCEEDINGS",
        "key": "hou-etal-2024-icon",
        "author": "Hou, Wenjun and Cheng, Yi and Xu, Kaishuai and Hu, Yan and Li, Wenjie and Liu, Jiang",
        "booktitle": "EMNLP-findings2024",
        "title": "ICON: Improving Inter-Report Consistency in Radiology Report Generation via Lesion-aware Mixup Augmentation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Previous research on radiology report generation has made significant progress in terms of increasing the clinical accuracy of generated reports. In this paper, we emphasize another crucial quality that it should possess, i.e., inter-report consistency, which refers to the capability of generating consistent reports for semantically equivalent radiographs. This quality is even of greater significance than the overall report accuracy in terms of ensuring the system\u2019s credibility, as a system prone to providing conflicting results would severely erode users\u2019 trust. Regrettably, existing approaches struggle to maintain inter-report consistency, exhibiting biases towards common patterns and susceptibility to lesion variants. To address this issue, we propose ICON, which improves the inter-report consistency of radiology report generation. Aiming to enhance the system\u2019s ability to capture similarities in semantically equivalent lesions, our approach first involves extracting lesions from input images and examining their characteristics. Then, we introduce a lesion-aware mixup technique to ensure that the representations of the semantically equivalent lesions align with the same attributes, achieved through a linear combination during the training phase. Extensive experiments on three publicly available chest X-ray datasets verify the effectiveness of our approach, both in terms of improving the consistency and accuracy of the generated reports.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.528",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-diahalu",
        "author": "Chen, Kedi and Chen, Qin and Zhou, Jie and Yishen, He and He, Liang",
        "booktitle": "EMNLP-findings2024",
        "title": "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Though large language models (LLMs) achieve significant success in recent years, the hallucination issue remains a challenge, and numerous benchmarks are proposed for hallucination detection. Nevertheless, some of these benchmarks are not naturally generated by LLMs but are intentionally induced. Also, many merely focus on the factuality hallucination while ignoring the faithfulness hallucination. Additionally, although dialogue pattern is more widely utilized in the era of LLMs, current benchmarks only concentrate on sentence-level and passage-level hallucination. In this study, we propose DiaHalu, the first dedicated dialogue-level hallucination evaluation benchmark for LLMs to our knowledge. Initially, we integrate the collected topics into system prompts and facilitate a dialogue between two LLMs. Subsequently, we manually modify the contents that do not adhere to human language conventions and then have LLMs re-generate, simulating authentic human-machine interaction scenarios. Finally, professional scholars annotate all the samples in the dataset. DiaHalu covers four common multi-turn dialogue domains and five hallucination subtypes, extended from factuality and faithfulness hallucination. Experiments through some well-known LLMs and detection methods on the dataset show that DiaHalu is a challenging benchmark, holding significant value for further research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.529",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "mo-hu-2024-expertease",
        "author": "Mo, Kaijie and Hu, Renfen",
        "booktitle": "EMNLP-findings2024",
        "title": "ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Text simplification is crucial for making texts more accessible, yet current research primarily focuses on sentence-level simplification, neglecting document-level simplification and the different reading levels of target audiences. To bridge these gaps, we introduce ExpertEase, a multi-agent framework for grade-specific document simplification using Large Language Models (LLMs). ExpertEase simulates real-world text simplification by introducing expert, teacher, and student agents that cooperate on the task and rely on external tools for calibration. Experiments demonstrate that this multi-agent approach significantly enhances LLMs\u2019 ability to simplify reading materials for diverse audiences. Furthermore, we evaluate the performance of LLMs varying in size and type, and compare LLM-generated texts with human-authored ones, highlighting their potential in educational resource development and guiding future research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.530",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Inference-Time Decontamination: Reusing Leaked Benchmarks for Large Language Model Evaluation": {
        "type": "INPROCEEDINGS",
        "key": "zhu-etal-2024-inference",
        "author": "Zhu, Qin and Cheng, Qinyuan and Peng, Runyu and Li, Xiaonan and Peng, Ru and Liu, Tengxiao and Qiu, Xipeng and Huang, Xuanjing",
        "booktitle": "EMNLP-findings2024",
        "title": "Inference-Time Decontamination: Reusing Leaked Benchmarks for Large Language Model Evaluation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The training process of large language models (LLMs) often involves varying degrees of test data contamination. Although current LLMs are achieving increasingly better performance on various benchmarks, their performance in practical applications does not always match their benchmark results. Leakage of benchmarks can prevent the accurate assessment of LLMs\u2019 true performance. However, constructing new benchmarks is costly, labor-intensive and still carries the risk of leakage. Therefore, in this paper, we ask the question Can we reuse these leaked benchmarks for LLM evaluation? We propose Inference-Time Decontamination (ITD) to address this issue by detecting and rewriting leaked samples without altering their difficulties. ITD can mitigate performance inflation caused by memorizing leaked benchmarks. Our proof-of-concept experiments demonstrate that ITD reduces inflated accuracy by 22.9% on GSM8K and 19.0% on MMLU. On MMLU, using Inference-time Decontamination can lead to a decrease in the results of Phi3 and Mistral by 6.7% and 3.6% respectively. We hope that ITD can provide more truthful evaluation results for large language models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.532",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech": {
        "type": "INPROCEEDINGS",
        "key": "bak-etal-2024-multiverse",
        "author": "Bak, Taejun and Eom, Youngsik and Choi, SeungJae and Joo, Young-Sun",
        "booktitle": "EMNLP-findings2024",
        "title": "MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Text-to-speech (TTS) systems that scale up the amount of training data have achieved significant improvements in zero-shot speech synthesis. However, these systems have certain limitations: they require a large amount of training data, which increases costs, and often overlook prosody similarity. To address these issues, we propose MultiVerse, a zero-shot multi-task TTS system that is able to perform TTS or speech style transfer in zero-shot and cross-lingual conditions. MultiVerse requires much less training data than traditional data-driven approaches. To ensure zero-shot performance even with limited data, we leverage source-filter theory-based disentanglement, utilizing the prompt for modeling filter-related and source-related representations. Additionally, to further enhance prosody similarity, we adopt a prosody modeling approach combining prompt-based autoregressive and non-autoregressive methods. Evaluations demonstrate the remarkable zero-shot multi-task TTS performance of MultiVerse and show that MultiVerse not only achieves zero-shot TTS performance comparable to data-driven TTS systems with much less data, but also significantly outperforms other zero-shot TTS systems trained with the same small amount of data. In particular, our novel prosody modeling technique significantly contributes to MultiVerse\u2019s ability to generate speech with high prosody similarity to the given prompts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.533",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "RoBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies": {
        "type": "INPROCEEDINGS",
        "key": "aftar-etal-2024-robert2vectm",
        "author": "Aftar, Sania and Gagliardelli, Luca and Ganadi, Amina El and Ruozzi, Federico and Bergamaschi, Sonia",
        "booktitle": "EMNLP-findings2024",
        "title": "RoBERT2VecTM: A Novel Approach for Topic Extraction in Islamic Studies",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Investigating \u201cHadith\u201d texts, crucial for theological studies and Islamic jurisprudence, presents challenges due to the linguistic complexity of Arabic, such as its complex morphology. In this paper, we propose an innovative approach to address the challenges of topic modeling in Hadith studies by utilizing the Contextualized Topic Model (CTM). Our study introduces RoBERT2VecTM, a novel neural-based approach that combines the RoBERTa transformer model with Doc2Vec, specifically targeting the semantic analysis of \u201cMatn\u201d (the actual content). The methodology outperforms many traditional state-of-the-art NLP models by generating more coherent and diverse Arabic topics. The diversity of the generated topics allows for further categorization, deepening the understanding of discussed concepts. Notably, our research highlights the critical impact of lemmatization and stopwords in enhancing topic modeling. This breakthrough marks a significant stride in applying NLP to non-Latin languages and opens new avenues for the nuanced analysis of complex religious texts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.534",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Are ELECTRA\u2019s Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity": {
        "type": "INPROCEEDINGS",
        "key": "rep-etal-2024-electras",
        "author": "Rep, Ivan and Duki\u0107, David and \u0160najder, Jan",
        "booktitle": "EMNLP-findings2024",
        "title": "Are ELECTRA\u2019s Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While BERT produces high-quality sentence embeddings, its pre-training computational cost is a significant drawback. In contrast, ELECTRA provides a cost-effective pre-training objective and downstream task performance improvements, but worse sentence embeddings. The community tacitly stopped utilizing ELECTRA\u2019s sentence embeddings for semantic textual similarity (STS). We notice a significant drop in performance for the ELECTRA discriminator\u2019s last layer in comparison to prior layers. We explore this drop and propose a way to repair the embeddings using a novel truncated model fine-tuning (TMFT) method. TMFT improves the Spearman correlation coefficient by over 8 points while increasing parameter efficiency on the STS Benchmark. We extend our analysis to various model sizes, languages, and two other tasks. Further, we discover the surprising efficacy of ELECTRA\u2019s generator model, which performs on par with BERT, using significantly fewer parameters and a substantially smaller embedding size. Finally, we observe boosts by combining TMFT with word similarity or domain adaptive pre-training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.535",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DetectiveNN: Imitating Human Emotional Reasoning with a Recall-Detect-Predict Framework for Emotion Recognition in Conversations": {
        "type": "INPROCEEDINGS",
        "key": "hong-etal-2024-detectivenn",
        "author": "Hong, Simin and Sun, Jun and Li, Taihao",
        "booktitle": "EMNLP-findings2024",
        "title": "DetectiveNN: Imitating Human Emotional Reasoning with a Recall-Detect-Predict Framework for Emotion Recognition in Conversations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Emotion Recognition in conversations (ERC) involves an internal cognitive process that interprets emotional cues by using a collection of past emotional experiences. However, many existing methods struggle to decipher emotional cues in dialogues since they are insufficient in understanding the rich historical emotional context. In this work, we introduce an innovative Detective Network (DetectiveNN), a novel model that is grounded in the cognitive theory of emotion and utilizes a \u201crecall-detect-predict\u201d framework to imitate human emotional reasoning. This process begins by \u2018recalling\u2019 past interactions of a specific speaker to collect emotional cues. It then \u2018detects\u2019 relevant emotional patterns by interpreting these cues in the context of the ongoing conversation. Finally, it \u2018predicts\u2019 the speaker\u2019s current emotional state. Tested on three benchmark datasets, our approach significantly outperforms existing methods. This highlights the advantages of incorporating cognitive factors into deep learning for ERC, enhancing task efficacy and prediction accuracy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.536",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs": {
        "type": "INPROCEEDINGS",
        "key": "bazaga-etal-2024-hyperbert",
        "author": "Bazaga, Adri\u00e1n and Lio, Pietro and Micklem, Gos",
        "booktitle": "EMNLP-findings2024",
        "title": "HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Hypergraphs are characterized by complex topological structure, representing higher-order interactions among multiple entities through hyperedges. Lately, hypergraph-based deep learning methods to learn informative data representations for the problem of node classification on text-attributed hypergraphs have garnered increasing research attention. However, existing methods struggle to simultaneously capture the full extent of hypergraph structural information and the rich linguistic attributes inherent in the nodes attributes, which largely hampers their effectiveness and generalizability. To overcome these challenges, we explore ways to further augment a pretrained BERT model with specialized hypergraph-aware layers for the task of node classification. Such layers introduce higher-order structural inductive bias into the language model, thus improving the model\u2019s capacity to harness both higher-order context information from the hypergraph structure and semantic information present in text. In this paper, we propose a new architecture, HyperBERT, a mixed text-hypergraph model which simultaneously models hypergraph relational structure while maintaining the high-quality text encoding capabilities of a pre-trained BERT. Notably, HyperBERT presents results that achieve a new state-of-the-art on five challenging text-attributed hypergraph node classification benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.537",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On Diversified Preferences of Large Language Model Alignment": {
        "type": "INPROCEEDINGS",
        "key": "zeng-etal-2024-diversified",
        "author": "Zeng, Dun and Dai, Yong and Cheng, Pengyu and Wang, Longyue and Hu, Tianhao and Chen, Wanshun and Du, Nan and Xu, Zenglin",
        "booktitle": "EMNLP-findings2024",
        "title": "On Diversified Preferences of Large Language Model Alignment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Aligning large language models (LLMs) with human preferences has been recognized as the key to improving LLMs\u2019 interaction quality. However, in this pluralistic world, human preferences can be diversified due to annotators\u2019 different tastes, which hinders the effectiveness of LLM alignment methods. This paper presents the first quantitative analysis of the experimental scaling law for reward models with varying sizes, from 1.3 billion to 7 billion parameters, trained with human feedback exhibiting diverse preferences. Our analysis reveals that the impact of diversified human preferences depends on both model size and data size. Larger models with sufficient capacity mitigate the negative effects of diverse preferences, while smaller models struggle to accommodate them. To mitigate the impact of diverse preferences, we introduce a new metric, Expected Calibration Error (ECE), to evaluate RMs and show their obvious positive correlation with the alignment performance of LLMs. Furthermore, we propose a Multi-Objective Reward learning method (MORE) to enhance the calibration performance of RMs on shared preferences. Through experiments on four models and five human preference datasets, we find the calibration error can be adopted as a key metric for evaluating RMs and MORE can obtain superior alignment performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.538",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-loraexit",
        "author": "Liu, Jiacheng and Tang, Peng and Hou, Xiaofeng and Li, Chao and Heng, Pheng-Ann",
        "booktitle": "EMNLP-findings2024",
        "title": "LoRAExit: Empowering Dynamic Modulation of LLMs in Resource-limited Settings using Low-rank Adapters",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have exhibited remarkable performance across various natural language processing tasks. However, deploying LLMs on resource-limited settings remains a challenge. While early-exit techniques offer an effective approach, they often require compromised training methods that result in sub-optimal performance. On the other hand, multi-model methods achieve improved results but suffer from significant inference latency and memory consumption. In this paper, we propose LoRAExit, a novel dynamic inference architecture that leverages low-rank adaptors for efficient deployment of LLMs. LoRAExit decouples the training of multiple exit interfaces, enabling the separate optimization of each exit, thereby fundamentally addressing the performance issues of early-exit networks. Moreover, we introduce a superior-exit guided distillation method that effectively utilizes models of different sizes, thereby further enhancing the performance of early exits. Experimental results demonstrate that LoRAExit significantly improves LLM performance when deployed on resource-limited settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.539",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-improving-diversity",
        "author": "Zhang, Tianhui and Peng, Bei and Bollegala, Danushka",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generative Commonsense Reasoning (GCR) requires a model to reason about a situation using commonsense knowledge, while generating coherent sentences. Although the quality of the generated sentences is crucial, the diversity of the generation is equally important because it reflects the model\u2019s ability to use a range of commonsense knowledge facts. Large Language Models (LLMs) have shown proficiency in enhancing the generation quality across various tasks through in-context learning (ICL) using given examples without the need for any fine-tuning. However, the diversity aspect in LLM outputs has not been systematically studied before. To address this, we propose a simple method that diversifies the LLM generations, while preserving their quality. Experimental results on three benchmark GCR datasets show that our method achieves an ideal balance between the quality and diversity. Moreover, the sentences generated by our proposed method can be used as training data to improve diversity in existing commonsense generators.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.540",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code": {
        "type": "INPROCEEDINGS",
        "key": "guan-etal-2024-codeip",
        "author": "Guan, Batu and Wan, Yao and Bi, Zhangqian and Wang, Zheng and Zhang, Hongyu and Zhou, Pan and Sun, Lichao",
        "booktitle": "EMNLP-findings2024",
        "title": "CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have achieved remarkable progress in code generation. It now becomes crucial to identify whether the code is AI-generated and to determine the specific model used, particularly for purposes such as protecting Intellectual Property (IP) in industry and preventing cheating in programming exercises. To this end, several attempts have been made to insert watermarks into machine-generated code. However, existing approaches are limited to inserting only a single bit of information. In this paper, we introduce CodeIP, a novel multi-bit watermarking technique that embeds additional information to preserve crucial provenance details, such as the vendor ID of an LLM, thereby safeguarding the IPs of LLMs in code generation. Furthermore, to ensure the syntactical correctness of the generated code, we propose constraining the sampling process for predicting the next token by training a type predictor. Experiments conducted on a real-world dataset across five programming languages demonstrate the effectiveness of CodeIP in watermarking LLMs for code generation while maintaining the syntactical correctness of code.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.541",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "StablePT : Towards Stable Prompting for Few-shot Learning via Input Separation": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-stablept",
        "author": "Liu, Xiaoming and Liu, Chen and Zhang, Zhaohan and Li, Chengzhengxu and Wang, Longtian and Lan, Yu and Shen, Chao",
        "booktitle": "EMNLP-findings2024",
        "title": "StablePT : Towards Stable Prompting for Few-shot Learning via Input Separation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models have shown their ability to become effective few-shot learners with prompting, revoluting the paradigm of learning with data scarcity. However, this approach largely depends on the quality of prompt initialization and always exhibits large variability among different runs. Such property makes prompt tuning highly unreliable and vulnerable to poorly constructed prompts, which limits its extension to more real-world applications. To tackle this issue, we propose to treat the hard prompt and soft prompt as separate inputs to mitigate noise brought by the prompt initialization. Furthermore, we optimize soft prompts with contrastive learning for utilizing class-aware information in the training process to maintain model performance. Experimental results demonstrate that StablePT outperforms state-of-the-art methods by 6.97% in accuracy and reduces the standard deviation by 1.92 on average. Furthermore, extensive experiments underscore its robustness and stability across 8 datasets covering various tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.542",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Natural Evolution-based Dual-Level Aggregation for Temporal Knowledge Graph Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-natural",
        "author": "Chen, Bin and Xiao, Chunjing and Zhou, Fan",
        "booktitle": "EMNLP-findings2024",
        "title": "Natural Evolution-based Dual-Level Aggregation for Temporal Knowledge Graph Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Temporal knowledge graph (TKG) reasoning aims to predict missing facts based on a given history. Most of the existing methods unifiedly model the evolution process of different events and ignore their inherent asynchronous characteristics, resulting in suboptimal performance. To tackle this challenge, we propose a Natural Evolution-based Dual-level Aggregation framework (NEDA) for TKG reasoning. Specifically, we design a natural division strategy to group TKGs into different patches according to the occurrence of a given target entity. Then, we present a dual-level aggregation scheme to extract local representations from information within patches and then aggregate these representations with adaptive weights as the final entity representations. By assigning varying weights to different patches, this aggregation scheme can incorporate the asynchronous characteristics of event evolution for representation computation, thus enhancing prediction performance. Extensive experiments demonstrate the significant improvement of our proposed model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.543",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Creative and Context-Aware Translation of East Asian Idioms with GPT-4": {
        "type": "INPROCEEDINGS",
        "key": "tang-etal-2024-creative",
        "author": "Tang, Kenan and Song, Peiyang and Qin, Yao and Yan, Xifeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Creative and Context-Aware Translation of East Asian Idioms with GPT-4",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As a type of figurative language, an East Asian idiom condenses rich cultural background into only a few characters. Translating such idioms is challenging for human translators, who often resort to choosing a context-aware translation from an existing list of candidates. However, compiling a dictionary of candidate translations demands much time and creativity even for expert translators. To alleviate such burden, we evaluate if GPT-4 can help generate high-quality translations. Based on automatic evaluations of faithfulness and creativity, we first identify Pareto-optimal prompting strategies that can outperform translation engines from Google and DeepL. Then, at a low cost, our context-aware translations can achieve far more high-quality translations per idiom than the human baseline. We open-source all code and data to facilitate further research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.544",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions": {
        "type": "INPROCEEDINGS",
        "key": "borah-mihalcea-2024-towards",
        "author": "Borah, Angana and Mihalcea, Rada",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain insights into various societal aspects, it is essential to mitigate these biases. To that end, our study investigates the presence of implicit gender biases in multi-agent LLM interactions and proposes two strategies to mitigate these biases. We begin by creating a dataset of scenarios where implicit gender biases might arise, and subsequently develop a metric to assess the presence of biases. Our empirical analysis reveals that LLMs generate outputs characterized by strong implicit bias associations (\\geq \\approx 50% of the time). Furthermore, these biases tend to escalate following multi-agent interactions. To mitigate them, we propose two strategies: self-reflection with in-context examples (ICE); and supervised fine-tuning. Our research demonstrates that both methods effectively mitigate implicit biases, with the ensemble of fine-tuning and self-reflection proving to be the most successful.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.545",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring Hint Generation Approaches for Open-Domain Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "mozafari-etal-2024-exploring",
        "author": "Mozafari, Jamshid and Abdallah, Abdelrahman and Piryani, Bhawna and Jatowt, Adam",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring Hint Generation Approaches for Open-Domain Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automatic Question Answering (QA) systems rely on contextual information to provide accurate answers. Commonly, contexts are prepared through either retrieval-based or generation-based methods. The former involves retrieving relevant documents from a corpus like Wikipedia, whereas the latter uses generative models such as Large Language Models (LLMs) to generate the context. In this paper, we introduce a novel context preparation approach called HINTQA, which employs Automatic Hint Generation (HG) techniques. Unlike traditional methods, HINTQA prompts LLMs to produce hints about potential answers for the question rather than generating relevant context. We evaluate our approach across three QA datasets including TriviaQA, Natural Questions, and Web Questions, examining how the number and order of hints impact performance. Our findings show that the HINTQA surpasses both retrieval-based and generation-based approaches. We demonstrate that hints enhance the accuracy of answers more than retrieved and generated contexts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.546",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Do LLMs Think Fast and Slow? A Causal Study on Sentiment Analysis": {
        "type": "INPROCEEDINGS",
        "key": "lyu-etal-2024-llms",
        "author": "Lyu, Zhiheng and Jin, Zhijing and Gonzalez Adauto, Fernando and Mihalcea, Rada and Sch\u00f6lkopf, Bernhard and Sachan, Mrinmaya",
        "booktitle": "EMNLP-findings2024",
        "title": "Do LLMs Think Fast and Slow? A Causal Study on Sentiment Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Sentiment analysis (SA) aims to identify the sentiment expressed in a piece of text, often in the form of a review. Assuming a review and the sentiment associated with it, in this paper we formulate SA as a combination of two tasks: (1) a causal discovery task that distinguishes whether a review \u201cprimes\u201d the sentiment (Causal Hypothesis C1), or the sentiment \u201cprimes\u201d the review (Causal Hypothesis C2); and (2) the traditional prediction task to model the sentiment using the review as input. Using the peak-end rule in psychology, we classify a sample as C1 if its overall sentiment score approximates an average of all the sentence-level sentiments in the review, and as C2 if the overall sentiment score approximates an average of the peak and end sentiments. For the prediction task, we use the discovered causal mechanisms behind the samples to improve the performance of LLMs by proposing causal prompts that give the models an inductive bias of the underlying causal graph, leading to substantial improvements by up to 32.13 F1 points on zero-shot five-class SA.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.547",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PEDANTS: Cheap but Effective and Interpretable Answer Equivalence": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-pedants",
        "author": "Li, Zongxia and Mondal, Ishani and Nghiem, Huy and Liang, Yijun and Boyd-Graber, Jordan Lee",
        "booktitle": "EMNLP-findings2024",
        "title": "PEDANTS: Cheap but Effective and Interpretable Answer Equivalence",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Question answering (QA) can only make progress if we know if an answer is correct, but current answer correctness (AC) metrics struggle with verbose, free-form answers from large language models (LLMs). There are two challenges with current short-form QA evaluations: a lack of diverse styles of evaluation data and an over-reliance on expensive and slow LLMs. LLM-based scorers correlate better with humans, but this expensive task has only been tested on limited QA datasets. We rectify these issues by providing rubrics and datasets for evaluating machine QA adopted from the Trivia community. We also propose an efficient, and interpretable QA evaluation that is more stable than an exact match and neural methods (BERTScore).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.548",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation": {
        "type": "INPROCEEDINGS",
        "key": "he-etal-2024-agentscourt",
        "author": "He, Zhitao and Cao, Pengfei and Wang, Chenhao and Jin, Zhuoran and Chen, Yubo and Xu, Jiexin and Li, Huaijun and Liu, Kang and Zhao, Jun",
        "booktitle": "EMNLP-findings2024",
        "title": "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the development of deep learning, natural language processing technology has effectively improved the efficiency of various aspects of the traditional judicial industry. However, most current efforts focus on tasks within individual judicial stages, making it difficult to handle complex tasks that span multiple stages. As the autonomous agents powered by large language models are becoming increasingly smart and able to make complex decisions in real-world settings, offering new insights for judicial intelligence. In this paper, (1) we propose a novel multi-agent framework, AgentsCourt, for judicial decision-making. Our framework follows the classic court trial process, consisting of court debate simulation, legal resources retrieval and decision-making refinement to simulate the decision-making of judge. (2) we introduce SimuCourt, a judicial benchmark that encompasses 420 Chinese judgment documents, spanning the three most common types of judicial cases. Furthermore, to support this task, we construct a large-scale legal knowledge base, Legal-KB, with multi-resource legal knowledge. (3) Extensive experiments show that our framework outperforms the existing advanced methods in various aspects, especially in generating legal articles, where our model achieves significant improvements of 8.6% and 9.1% F1 score in the first and second instance settings, respectively.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.549",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "hsueh-etal-2024-editing",
        "author": "Hsueh, Cheng-Hsun and Huang, Paul Kuo-Ming and Lin, Tzu-Han and Liao, Che Wei and Fang, Hung-Chieh and Huang, Chao-Wei and Chen, Yun-Nung",
        "booktitle": "EMNLP-findings2024",
        "title": "Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Knowledge editing is a rising technique for efficiently updating factual knowledge in large language models (LLMs) with minimal alteration of parameters. However, recent studies have identified side effects, such as knowledge distortion and the deterioration of general abilities, that have emerged after editing. Despite these findings, evaluating the pitfalls of knowledge editing often relies on inconsistent metrics and benchmarks, lacking a uniform standard. In response, this survey presents a comprehensive study of these side effects, providing a unified perspective on the challenges of knowledge editing in LLMs by conducting experiments with consistent metrics and benchmarks. Additionally, we review related works and outline potential research directions to address these limitations. Our survey highlights the limitations of current knowledge editing methods, emphasizing the need for a deeper understanding of the inner knowledge structures of LLMs and improved knowledge editing methods. To foster future research, we have released the complementary materials publicly (https://github.com/MiuLab/EditLLM-Survey).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.550",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving LLM Attributions with Randomized Path-Integration": {
        "type": "INPROCEEDINGS",
        "key": "barkan-etal-2024-improving",
        "author": "Barkan, Oren and Elisha, Yehonatan and Toib, Yonatan and Weill, Jonathan and Koenigstein, Noam",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving LLM Attributions with Randomized Path-Integration",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We present Randomized Path-Integration (RPI) - a path-integration method for explaining language models via randomization of the integration path over the attention information in the model. RPI employs integration on internal attention scores and their gradients along a randomized path, which is dynamically established between a baseline representation and the attention scores of the model. The inherent randomness in the integration path originates from modeling the baseline representation as a randomly drawn tensor from a Gaussian diffusion process. As a consequence, RPI generates diverse baselines, yielding a set of candidate attribution maps. This set facilitates the selection of the most effective attribution map based on the specific metric at hand. We present an extensive evaluation, encompassing 11 explanation methods and 5 language models, including the Llama2 and Mistral models. Our results demonstrate that RPI outperforms latest state-of-the-art methods across 4 datasets and 5 evaluation metrics.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.551",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "VeriScore: Evaluating the factuality of verifiable claims in long-form text generation": {
        "type": "INPROCEEDINGS",
        "key": "song-etal-2024-veriscore",
        "author": "Song, Yixiao and Kim, Yekyung and Iyyer, Mohit",
        "booktitle": "EMNLP-findings2024",
        "title": "VeriScore: Evaluating the factuality of verifiable claims in long-form text generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing metrics for evaluating the factuality of long-form text, such as FACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input text into \u201catomic claims\u201d and verify each against a knowledge base like Wikipedia. These metrics are not suitable for most generation tasks because they assume that every claim is verifiable (i.e., can plausibly be proven true or false). We address this issue with VERISCORE,1 a metric for evaluating factuality in diverse long-form generation tasks that contain both verifiable and unverifiable content. VERISCORE can be effectively implemented with either closed or fine-tuned open-weight language models. Human evaluation confirms that VERISCORE\u2019s extracted claims are more sensible than those from competing methods across eight different long-form tasks. We use VERISCORE to evaluate generations from 16 different models across multiple long-form tasks and find that while GPT-4o is the best-performing model overall, open-weight models such as Mixtral-8\\times22 are closing the gap. We show that an LM\u2019s VERISCORE on one task (e.g., biography generation) does not necessarily correlate to its VERISCORE on a different task (e.g., long-form QA), highlighting the need for expanding factuality evaluation across tasks with varying fact density.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.552",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging": {
        "type": "INPROCEEDINGS",
        "key": "kargupta-etal-2024-instruct",
        "author": "Kargupta, Priyanka and Agarwal, Ishika and Tur, Dilek Hakkani and Han, Jiawei",
        "booktitle": "EMNLP-findings2024",
        "title": "Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Socratic questioning is an effective teaching strategy, encouraging critical thinking and problem-solving. The conversational capabilities of large language models (LLMs) show great potential for providing scalable, real-time student guidance. However, current LLMs often give away solutions directly, making them ineffective instructors. We tackle this issue in the code debugging domain with TreeInstruct, an Instructor agent guided by a novel state space-based planning algorithm. TreeInstruct asks probing questions to help students independently identify and resolve errors. It estimates a student\u2019s conceptual and syntactical knowledge to dynamically construct a question tree based on their responses and current knowledge state, effectively addressing both independent and dependent mistakes concurrently in a multi-turn interaction setting. In addition to using an existing single-bug debugging benchmark, we construct a more challenging multi-bug dataset of 150 coding problems, incorrect solutions, and bug fixes\u2013 all carefully constructed and annotated by experts. Extensive evaluation shows TreeInstruct\u2019s state-of-the-art performance on both datasets, proving it to be a more effective instructor than baselines. Furthermore, a real-world case study with five students of varying skill levels further demonstrates TreeInstruct\u2019s ability to guide students to debug their code efficiently with minimal turns and highly Socratic questioning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.553",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Tutor-ICL: Guiding Large Language Models for Improved In-Context Learning Performance": {
        "type": "INPROCEEDINGS",
        "key": "cho-etal-2024-tutor",
        "author": "Cho, Ikhyun and Kwon, Gaeul and Hockenmaier, Julia",
        "booktitle": "EMNLP-findings2024",
        "title": "Tutor-ICL: Guiding Large Language Models for Improved In-Context Learning Performance",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "There has been a growing body of work focusing on the in-context learning (ICL) abilities of large language models (LLMs). However, it is an open question how effective ICL can be. This paper presents Tutor-ICL, a simple prompting method for classification tasks inspired by how effective instructors might engage their students in learning a task. Specifically, we propose presenting exemplar answers in a *comparative format* rather than the traditional single-answer format. We also show that including the test instance before the exemplars can improve performance, making it easier for LLMs to focus on relevant exemplars. Lastly, we include a summarization step before attempting the test, following a common human practice. Experiments on various classification tasks, conducted across both decoder-only LLMs (Llama 2, 3) and encoder-decoder LLMs (Flan-T5-XL, XXL), show that Tutor-ICL consistently boosts performance, achieving up to a 13.76% increase in accuracy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.554",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy": {
        "type": "INPROCEEDINGS",
        "key": "nguyen-etal-2024-taking",
        "author": "Nguyen, Vivian and Jung, Sang Min and Lee, Lillian and Hull, Thomas D. and Danescu-Niculescu-Mizil, Cristian",
        "booktitle": "EMNLP-findings2024",
        "title": "Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Mental-health therapy involves a complex conversation flow in which patients and therapists continuously negotiate what should be talked about next. For example, therapists might try to shift the conversation\u2019s direction to keep the therapeutic process on track and avoid stagnation, or patients might push the discussion towards issues they want to focus on.How do such patient and therapist redirections relate to the development and quality of their relationship? To answer this question, we introduce a probabilistic measure of the extent to which a certain utterance immediately redirects the flow of the conversation, accounting for both the intention and the actual realization of such a change. We apply this new measure to characterize the development of patient- therapist relationships over multiple sessions in a very large, widely-used online therapy platform. Our analysis reveals that (1) patient control of the conversation\u2019s direction generally increases relative to that of the therapist as their relationship progresses; and (2) patients who have less control in the first few sessions are significantly more likely to eventually express dissatisfaction with their therapist and terminate the relationship.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.555",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM Explainability via Attributive Masking Learning": {
        "type": "INPROCEEDINGS",
        "key": "barkan-etal-2024-llm",
        "author": "Barkan, Oren and Toib, Yonatan and Elisha, Yehonatan and Weill, Jonathan and Koenigstein, Noam",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM Explainability via Attributive Masking Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we introduce Attributive Masking Learning (AML), a method designed for explaining language model predictions by learning input masks. AML trains an attribution model to identify influential tokens in the input for a given language model\u2019s prediction. The central concept of AML is to train an auxiliary attribution model to simultaneously 1) mask as much input data as possible while ensuring that the language model\u2019s prediction closely aligns with its prediction on the original input, and 2) ensure a significant change in the model\u2019s prediction when applying the inverse (complement) of the same mask to the input. This dual-masking approach further enables the optimization of the explanation w.r.t. the metric of interest. We demonstrate the effectiveness of AML on both encoder-based and decoder-based language models, showcasing its superiority over a variety of state-of-the-art explanation methods on multiple benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.556",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "How Entangled is Factuality and Deception in German?": {
        "type": "INPROCEEDINGS",
        "key": "velutharambath-etal-2024-entangled",
        "author": "Velutharambath, Aswathy and Wuehrl, Amelie and Klinger, Roman",
        "booktitle": "EMNLP-findings2024",
        "title": "How Entangled is Factuality and Deception in German?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The statement \u201cThe earth is flat\u201d is factually inaccurate, but if someone truly believes and argues in its favor, it is not deceptive. Research on deception detection and fact checking often conflates factual accuracy with the truthfulness of statements. This assumption makes it difficult to (a) study subtle distinctions and interactions between the two and (b) gauge their effects on downstream tasks. The belief-based deception framework disentangles these properties by defining texts as deceptive when there is a mismatch between what people say and what they truly believe. In this study, we assess if presumed patterns of deception generalize to German language texts. We test the effectiveness of computational models in detecting deception using an established corpus of belief-based argumentation. Finally, we gauge the impact of deception on the downstream task of fact checking and explore if this property confounds verification models. Surprisingly, our analysis finds no correlation with established cues of deception. Previous work claimed that computational models can outperform humans in deception detection accuracy, however, our experiments show that both traditional and state-of-the-art models struggle with the task, performing no better than random guessing. For fact checking, we find that natural language inference-based verification performs worse on non-factual and deceptive content, while prompting large language models for the same task is less sensitive to these properties.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.557",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation": {
        "type": "INPROCEEDINGS",
        "key": "iana-etal-2024-train",
        "author": "Iana, Andreea and Glava\u0161, Goran and Paulheim, Heiko",
        "booktitle": "EMNLP-findings2024",
        "title": "Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent neural news recommenders (NNRs) extend content-based recommendation (1) by aligning additional aspects (e.g., topic, sentiment) between candidate news and user history or (2) by diversifying recommendations w.r.t. these aspects. This customization is achieved by \u201dhardcoding\u201d additional constraints into the NNR\u2019s architecture and/or training objectives: any change in the desired recommendation behavior thus requires retraining the model with a modified objective. This impedes widespread adoption of multi-aspect news recommenders. In this work, we introduce MANNeR, a modular framework for multi-aspect neural news recommendation that supports on-the-fly customization over individual aspects at inference time. With metric-based learning as its backbone, MANNeR learns aspect-specialized news encoders and then flexibly and linearly combines the resulting aspect-specific similarity scores into different ranking functions, alleviating the need for ranking function-specific retraining of the model. Extensive experimental results show that MANNeR consistently outperforms state-of-the-art NNRs on both standard content-based recommendation and single- and multi-aspect customization. Lastly, we validate that MANNeR\u2019s aspect-customization module is robust to language and domain transfer.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.558",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A LLM-based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation": {
        "type": "INPROCEEDINGS",
        "key": "zubiaga-etal-2024-llm",
        "author": "Zubiaga, Irune and Soroa, Aitor and Agerri, Rodrigo",
        "booktitle": "EMNLP-findings2024",
        "title": "A LLM-based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper proposes a novel approach to evaluate Counter Narrative (CN) generation using a Large Language Model (LLM) as an evaluator. We show that traditional automatic metrics correlate poorly with human judgements and fail to capture the nuanced relationship between generated CNs and human perception. To alleviate this, we introduce a model ranking pipeline based on pairwise comparisons of generated CNs from different models, organized in a tournament-style format. The proposed evaluation method achieves a high correlation with human preference, with a \u03c1 score of 0.88. As an additional contribution, we leverage LLMs as zero-shot CN generators and provide a comparative analysis of chat, instruct, and base models, exploring their respective strengths and limitations. Through meticulous evaluation, including fine-tuning experiments, we elucidate the differences in performance and responsiveness to domain-specific data. We conclude that chat-aligned models in zero-shot are the best option for carrying out the task, provided they do not refuse to generate an answer due to security concerns.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.559",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Survey on Open Information Extraction from Rule-based Model to Large Language Model": {
        "type": "INPROCEEDINGS",
        "key": "pai-etal-2024-survey",
        "author": "Pai, Liu and Gao, Wenyang and Dong, Wenjie and Ai, Lin and Gong, Ziwei and Huang, Songfang and Zongsheng, Li and Hoque, Ehsan and Hirschberg, Julia and Zhang, Yue",
        "booktitle": "EMNLP-findings2024",
        "title": "A Survey on Open Information Extraction from Rule-based Model to Large Language Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Open Information Extraction (OpenIE) represents a crucial NLP task aimed at deriving structured information from unstructured text, unrestricted by relation type or domain. This survey paper provides an overview of OpenIE technologies spanning from 2007 to 2024, emphasizing a chronological perspective absent in prior surveys. It examines the evolution of task settings in OpenIE to align with the advances in recent technologies. The paper categorizes OpenIE approaches into rule-based, neural, and pre-trained large language models, discussing each within a chronological framework. Additionally, it highlights prevalent datasets and evaluation metrics currently in use. Building on this extensive review, this paper systematically reviews the evolution of task settings, data, evaluation metrics, and methodologies in the era of large language models, highlighting their mutual influence, comparing their capabilities, and examining their implications for open challenges and future research directions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.560",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Tool Retrieval with Iterative Feedback from Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-enhancing-tool",
        "author": "Xu, Qiancheng and Li, Yongqi and Xia, Heming and Li, Wenjie",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Tool Retrieval with Iterative Feedback from Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Tool learning aims to enhance and expand large language models\u2019 (LLMs) capabilities with external tools, which has gained significant attention recently. Current methods have shown that LLMs can effectively handle a certain amount of tools through in-context learning or fine-tuning. However, in real-world scenarios, the number of tools is typically extensive and irregularly updated, emphasizing the necessity for a dedicated tool retrieval component. Tool retrieval is nontrivial due to the following challenges: 1) complex user instructions and tool descriptions; 2) misalignment between tool retrieval and tool usage models. To address the above issues, we propose to enhance tool retrieval with iterative feedback from the large language model. Specifically, we prompt the tool usage model, i.e., the LLM, to provide feedback for the tool retriever model in multi-round, which could progressively improve the tool retriever\u2019s understanding of instructions and tools and reduce the gap between the two standalone components. We build a unified and comprehensive benchmark to evaluate tool retrieval models. The extensive experiments indicate that our proposed approach achieves advanced performance in both in-domain evaluation and out-of-domain evaluation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.561",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Detecting Temporal Ambiguity in Questions": {
        "type": "INPROCEEDINGS",
        "key": "piryani-etal-2024-detecting",
        "author": "Piryani, Bhawna and Abdallah, Abdelrahman and Mozafari, Jamshid and Jatowt, Adam",
        "booktitle": "EMNLP-findings2024",
        "title": "Detecting Temporal Ambiguity in Questions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Detecting and answering ambiguous questions has been a challenging task in open-domain question answering. Ambiguous questions have different answers depending on their interpretation and can take diverse forms. Temporally ambiguous questions are one of the most common types of such questions. In this paper, we introduce TEMPAMBIQA, a manually annotated temporally ambiguous QA dataset consisting of 8,162 open-domain questions derived from existing datasets. Our annotations focus on capturing temporal ambiguity to study the task of detecting temporally ambiguous questions. We propose a novel approach by using diverse search strategies based on disambiguate versions of the questions. We also introduce and test non-search, competitive baselines for detecting temporal ambiguity using zero-shot and few-shot approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.562",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation": {
        "type": "INPROCEEDINGS",
        "key": "azizi-etal-2024-lamda",
        "author": "Azizi, Seyedarmin and Kundu, Souvik and Pedram, Massoud",
        "booktitle": "EMNLP-findings2024",
        "title": "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Low-rank adaptation (LoRA) has become the default approach to fine-tune large language models (LLMs) due to its significant reduction in trainable parameters. However, trainable parameter demand for LoRA increases with increasing model embedding dimensions, leading to high compute costs. Additionally, its backward updates require storing high-dimensional intermediate activations and optimizer states, demanding high peak GPU memory. In this paper, we introduce _LaMDA_, a novel approach to fine-tuning large language models, which leverages low-dimensional adaptation to achieve significant reductions in trainable parameters and peak GPU memory footprint. LaMDA freezes a first projection matrix (PMA) in the adaptation path while introducing a low-dimensional trainable square matrix, resulting in substantial reductions in trainable parameters and peak GPU memory usage. LaMDA gradually freezes a second projection matrix (PMB) during the early fine-tuning stages, reducing the compute cost associated with weight updates to enhance parameter efficiency further.We also present an enhancement, LaMDA++, incorporating a \u201clite-weight\u201d adaptive rank allocation for the LoRA path via normalized spectrum analysis of pre-trained model weights. We evaluate LaMDA/LaMDA++ across various tasks, including natural language understanding with the GLUE benchmark, text summarization, natural language generation, and complex reasoning on different LLMs.Results show that LaMDA matches or surpasses the performance of existing alternatives while requiring up to **17.7\\times** fewer parameter updates and up to **1.32\\times** lower peak GPU memory usage during fine-tuning. Code will be publicly available at https://github.com/ArminAzizi98/LaMDA.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.563",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "benkirane-etal-2024-machine",
        "author": "Benkirane, Kenza and Gongas, Laura and Pelles, Shahar and Fuchs, Naomi and Darmon, Joshua and Stenetorp, Pontus and Adelani, David Ifeoluwa and S\u00e1nchez, Eduardo",
        "booktitle": "EMNLP-findings2024",
        "title": "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in massively multilingual machine translation systems have significantly enhanced translation accuracy; however, even the best performing systems still generate hallucinations, severely impacting user trust. Detecting hallucinations in Machine Translation (MT) remains a critical challenge, particularly since existing methods excel with High-Resource Languages (HRLs) but exhibit substantial limitations when applied to Low-Resource Languages (LRLs). This paper evaluates sentence-level hallucination detection approaches using Large Language Models (LLMs) and semantic similarity within massively multilingual embeddings. Our study spans 16 language directions, covering HRLs, LRLs, with diverse scripts. We find that the choice of model is essential for performance. On average, for HRLs, Llama3-70B outperforms the previous state of the art by as much as 0.16 MCC (Matthews Correlation Coefficient). However, for LRLs we observe that Claude Sonnet outperforms other LLMs on average by 0.03 MCC. The key takeaway from our study is that LLMs can achieve performance comparable or even better than previously proposed models, despite not being explicitly trained for any machine translation task. However, their advantage is less significant for LRLs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.564",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Navigating Hallucinations for Reasoning of Unintentional Activities": {
        "type": "INPROCEEDINGS",
        "key": "grover-etal-2024-navigating",
        "author": "Grover, Shresth and Vineet, Vibhav and Rawat, Yogesh S.",
        "booktitle": "EMNLP-findings2024",
        "title": "Navigating Hallucinations for Reasoning of Unintentional Activities",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this work we present a novel task of understanding unintentional human activities in videos. We formalize this problem as a reasoning task under zero-shot scenario, where given a video of an unintentional activity we want to know why it transitioned from intentional to unintentional. We first evaluate the effectiveness of current state-of-the-art Large Multimodal Models on this reasoning task and observe that they suffer from hallucination. We further propose a novel prompting technique, termed as Dream of Thoughts (DoT), which allows the model to navigate through hallucinated thoughts to achieve better reasoning. To evaluate the performance on this task, we also introduce three different specialized metrics designed to quantify the models reasoning capability. We perform our experiments on three datasets, OOPs, UCF-Crimes, and ReUAct, and our findings show that DOT prompting technique is able to outperform standard prompting, while minimizing hallucinations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.565",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Pruning Foundation Models for High Accuracy without Retraining": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-pruning",
        "author": "Zhao, Pu and Sun, Fei and Shen, Xuan and Yu, Pinrui and Kong, Zhenglun and Wang, Yanzhi and Lin, Xue",
        "booktitle": "EMNLP-findings2024",
        "title": "Pruning Foundation Models for High Accuracy without Retraining",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite the superior performance, it is challenging to deploy large language models (LLMs) due to their massive parameters and computations. While pruning is a promising technique to reduce model size and accelerate the inference, the traditional pruning techniques can hardly be applied for LLMs as they need to finetune the model on the full dataset with multiple epochs consuming massive data and hardware resources. To deal with this problem, post-training pruning methods are proposed to prune LLMs in one-shot without retraining. However, their accuracy after pruning may suffer from certain performance degradation due to the lack of retraining with massive data. To address this issue, in this paper, we first formulate the post-training problem for layer-wise LLM compression to simultaneously prune multiple weights in LLMs. Next, we provide an optimal solution for this problem and design our post-training pruning algorithm for both unstructured and semi-structured sparsity. Our extensive experiments demonstrate the superior performance of the proposed methods in comparison to SOTA baselines across various LLM families including transformer-based LLMs and Mamba-based LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.566",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-pixels",
        "author": "Li, Yu and Hazarika, Devamanyu and Jin, Di and Hirschberg, Julia and Liu, Yang",
        "booktitle": "EMNLP-findings2024",
        "title": "From Pixels to Personas: Investigating and Modeling Self-Anthropomorphism in Human-Robot Dialogues",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Self-anthropomorphism in robots manifests itself through their display of human-like characteristics in dialogue, such as expressing preferences and emotions. Our study systematically analyzes self-anthropomorphic expression within various dialogue datasets, outlining the contrasts between self-anthropomorphic and non-self-anthropomorphic responses in dialogue systems. We show significant differences in these two types of responses and propose transitioning from one type to the other. We also introduce Pix2Persona, a novel dataset aimed at developing ethical and engaging AI systems in various embodiments. This dataset preserves the original dialogues from existing corpora and enhances them with paired responses: self-anthropomorphic and non-self-anthropomorphic for each original bot response. Our work not only uncovers a new category of bot responses that were previously under-explored but also lays the groundwork for future studies about dynamically adjusting self-anthropomorphism levels in AI systems to align with ethical standards and user expectations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.567",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking": {
        "type": "INPROCEEDINGS",
        "key": "cavusoglu-etal-2024-disgem",
        "author": "\u00c7avu\u015fo\u011flu, Devrim and \u015een, Se\u00e7il and Sert, Ula\u015f",
        "booktitle": "EMNLP-findings2024",
        "title": "DisGeM: Distractor Generation for Multiple Choice Questions with Span Masking",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in Natural Language Processing (NLP) have impacted numerous sub-fields such as natural language generation, natural language inference, question answering, and more. However, in the field of question generation, the creation of distractors for multiple-choice questions (MCQ) remains a challenging task. In this work, we present a simple, generic framework for distractor generation using readily available Pre-trained Language Models (PLMs). Unlike previous methods, our framework relies solely on pre-trained language models and does not require additional training on specific datasets. Building upon previous research, we introduce a two-stage framework consisting of candidate generation and candidate selection. Our proposed distractor generation framework outperforms previous methods without the need for training or fine-tuning. Human evaluations confirm that our approach produces more effective and engaging distractors. The related codebase is publicly available at https://github.com/obss/disgem.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.568",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-chatglm",
        "author": "Xu, Yifan and Liu, Xiao and Liu, Xinghan and Hou, Zhenyu and Li, Yueyan and Zhang, Xiaohan and Wang, Zihan and Zeng, Aohan and Du, Zhengxiao and Wenyi, Zhao and Tang, Jie and Dong, Yuxiao",
        "booktitle": "EMNLP-findings2024",
        "title": "ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have shown excellent mastering of human language but still struggle in real-world applications that require mathematical problem-solving. While many strategies and datasets to enhance LLMs\u2019 mathematics are developed, it remains a challenge to simultaneously maintain and improve both language and mathematical capabilities in deployed LLM systems. In this work, we tailor the Self-Critique pipeline, which addresses the challenge in the feedback learning stage of LLM alignment. We first train a general Math-Critique model from the LLM itself to provide feedback signals. Then, we sequentially employ rejective fine-tuning and direct preference optimization over the LLM\u2019s own generations for data collection. Based on ChatGLM3-32B, we conduct experiments on both academic and our newly created challenging dataset, MathUserEval. Results show that our pipeline significantly enhances the LLM\u2019s mathematical problem-solving while still improving its language ability, outperforming LLMs that could be two times larger. Related techniques have been deployed to ChatGLM, an online serving LLM. Related evaluation datasets and scripts are released at https://github.com/THUDM/ChatGLM-Math.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.569",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MobileQuant: Mobile-friendly Quantization for On-device Language Models": {
        "type": "INPROCEEDINGS",
        "key": "tan-etal-2024-mobilequant",
        "author": "Tan, Fuwen and Lee, Royson and Dudziak, \u0141ukasz and Hu, Shell Xu and Bhattacharya, Sourav and Hospedales, Timothy and Tzimiropoulos, Georgios and Martinez, Brais",
        "booktitle": "EMNLP-findings2024",
        "title": "MobileQuant: Mobile-friendly Quantization for On-device Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have revolutionized language processing, delivering outstanding results across multiple applications. However, deploying LLMs on edge devices poses several challenges with respect to memory, energy, and compute costs, limiting their widespread use in devices such as mobile phones. A promising solution is to reduce the number of bits used to represent weights and activations. While existing works have found partial success at quantizing LLMs to lower bitwidths, e.g. 4-bit weights, quantizing activations beyond 16 bits often leads to large computational overheads due to poor on-device quantization support, or a considerable accuracy drop. Yet, 8-bit activations are very attractive for on-device deployment as they would enable LLMs to fully exploit mobile-friendly hardware, e.g. Neural Processing Units (NPUs). In this work, we make a first attempt to facilitate the on-device deployment of LLMs using integer-only quantization. We first investigate the limitations of existing quantization methods for on-device deployment, with a special focus on activation quantization. We then address these limitations by introducing a simple post-training quantization method, named MobileQuant, that extends previous weight equivalent transformation works by jointly optimizing the weight transformation and activation range parameters in an end-to-end manner. MobileQuant demonstrates superior capabilities over existing methods by 1) achieving near-lossless quantization on a wide range of LLM benchmarks, 2) reducing latency and energy consumption by 20%-50% compared to current on-device quantization strategies, 3) requiring limited compute budget, 4) being compatible with mobile-friendly compute units, e.g. NPU.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.570",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Do *they* mean \u2018us\u2019? Interpreting Referring Expression variation under Intergroup Bias": {
        "type": "INPROCEEDINGS",
        "key": "govindarajan-etal-2024-mean",
        "author": "Govindarajan, Venkata S. and Zang, Matianyu and Mahowald, Kyle and Beaver, David and Li, Junyi Jessy",
        "booktitle": "EMNLP-findings2024",
        "title": "Do *they* mean \u2018us\u2019? Interpreting Referring Expression variation under Intergroup Bias",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The variations between in-group and out-group speech (intergroup bias) are subtle and could underlie many social phenomena like stereotype perpetuation and implicit bias. In this paper, we model intergroup bias as a tagging task on English sports comments from forums dedicated to fandom for NFL teams. We curate a dataset of over 6 million game-time comments from opposing perspectives (the teams in the game), each comment grounded in a non-linguistic description of the events that precipitated these comments (live win probabilities for each team). Expert and crowd annotations justify modeling the bias through tagging of implicit and explicit referring expressions and reveal the rich, contextual understanding of language and the world required for this task. For large-scale analysis of intergroup variation, we use LLMs for automated tagging, and discover that LLMs occasionally perform better when prompted with linguistic descriptions of the win probability at the time of the comment, rather than numerical probability. Further, large-scale tagging of comments using LLMs uncovers linear variations in the form of referent across win probabilities that distinguish in-group and out-group utterances.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.571",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Survey on Detection of LLMs-Generated Content": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-survey",
        "author": "Yang, Xianjun and Pan, Liangming and Zhao, Xuandong and Chen, Haifeng and Petzold, Linda Ruth and Wang, William Yang and Cheng, Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "A Survey on Detection of LLMs-Generated Content",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The burgeoning capabilities of advanced large language models (LLMs) such as ChatGPT have led to an increase in synthetic content generation with implications across a variety of sectors, including media, cybersecurity, public discourse, and education. As such, the ability to detect LLMs-generated content has become of paramount importance. We aim to provide a detailed overview of existing detection strategies and benchmarks, scrutinizing their differences and identifying key challenges and prospects in the field, advocating for more adaptable and robust models to enhance detection accuracy. We also posit the necessity for a multi-faceted approach to defend against various attacks to counter the rapidly advancing capabilities of LLMs. To the best of our knowledge, this work is the first comprehensive survey on the detection in the era of LLMs. We hope it will provide a broad understanding of the current landscape of LLMs-generated content detection, and we have maintained a website to consistently update the latest research as a guiding reference for researchers and practitioners.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.572",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can LLMs Reason in the Wild with Programs?": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-llms",
        "author": "Yang, Yuan and Xiong, Siheng and Payani, Ali and Shareghi, Ehsan and Fekri, Faramarz",
        "booktitle": "EMNLP-findings2024",
        "title": "Can LLMs Reason in the Wild with Programs?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have shown superior capability to solve reasoning problems with programs. While being a promising direction, most of such frameworks are trained and evaluated in settings with a prior knowledge of task requirements. However, as LLMs become more capable, it is necessary to assess their reasoning abilities in more realistic scenarios where many real-world problems are open-ended with ambiguous scope, and often require multiple formalisms to solve. To investigate this, we introduce the task of reasoning in the wild, where an LLM is tasked to solve a reasoning problem of unknown type by identifying the sub-problems and their corresponding formalisms, and writing a program to solve each sub-problem, guided by a tactic. We create a large tactic-guided trajectory dataset containing detailed solutions to a diverse set of reasoning problems, ranging from well-defined single-form reasoning (e.g., math, logic), to ambiguous and hybrid ones (e.g., commonsense, combined math and logic). This allows us to test various aspects of LLMs reasoning at the fine-grained level such as the selection and execution of tactics, and the tendency to take undesired shortcuts. In experiments, we highlight that existing LLMs fail significantly on problems with ambiguous and mixed scope, revealing critical limitations and overfitting issues (e.g. accuracy on GSM8K drops by at least 50%). We further show the potential of finetuning a local LLM on the tactic-guided trajectories in achieving better performance. Project repo is available at https://github.com/gblackout/Reason-in-the-Wild.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.573",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can Textual Unlearning Solve Cross-Modality Safety Alignment?": {
        "type": "INPROCEEDINGS",
        "key": "chakraborty-etal-2024-textual",
        "author": "Chakraborty, Trishna and Shayegani, Erfan and Cai, Zikui and Abu-Ghazaleh, Nael B. and Asif, M. Salman and Dong, Yue and Roy-Chowdhury, Amit and Song, Chengyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Can Textual Unlearning Solve Cross-Modality Safety Alignment?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent studies reveal that integrating new modalities into large language models (LLMs), such as vision-language models (VLMs), creates a new attack surface that bypasses existing safety training techniques like supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). While further SFT and RLHF-based safety training can be conducted in multi-modal settings, collecting multi-modal training datasets poses a significant challenge. Inspired by the structural design of recent multi-modal models, where all input modalities are ultimately fused into the language space, we explore whether unlearning solely in the textual domain can be effective for cross-modality safety alignment. Our empirical evaluation across seven datasets demonstrates promising transferability \u2014 textual unlearning in VLMs significantly reduces the Attack Success Rate (ASR) to less than 8% and in some cases, even as low as nearly 2% for both text-based and vision-text-based attacks, alongside preserving the utility. Moreover, our experiments show that unlearning with a multi-modal dataset offers no potential benefits but incurs significantly increased computational demands.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.574",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "VDebugger: Harnessing Execution Feedback for Debugging Visual Programs": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-vdebugger",
        "author": "Wu, Xueqing and Lin, Zongyu and Zhao, Songyan and Wu, Te-Lin and Lu, Pan and Peng, Nanyun and Chang, Kai-Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "VDebugger: Harnessing Execution Feedback for Debugging Visual Programs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Visual programs are executable code generated by large language models to address visual reasoning problems. They decompose complex questions into multiple reasoning steps and invoke specialized models for each step to solve the problems. However, these programs are prone to logic errors, with our preliminary evaluation showing that 58% of the total errors are caused by program logic errors. Debugging complex visual programs remains a major bottleneck for visual reasoning. To address this, we introduce **VDebugger**, a novel critic-refiner framework trained to localize and debug visual programs by tracking execution step by step. VDebugger identifies and corrects program errors leveraging detailed execution feedback, improving interpretability and accuracy. The training data is generated through an automated pipeline that injects errors into correct visual programs using a novel mask-best decoding technique. Evaluations on six datasets demonstrate VDebugger\u2019s effectiveness, showing performance improvements of up to 3.2% in downstream task accuracy. Further studies show VDebugger\u2019s ability to generalize to unseen tasks, bringing a notable improvement of 2.3% on the unseen COVR task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.575",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Monotonic Paraphrasing Improves Generalization of Language Model Prompting": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-monotonic",
        "author": "Liu, Qin and Wang, Fei and Xu, Nan and Yan, Tianyi Lorena and Meng, Tao and Chen, Muhao",
        "booktitle": "EMNLP-findings2024",
        "title": "Monotonic Paraphrasing Improves Generalization of Language Model Prompting",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Performance of large language models (LLMs) may vary with different prompts or instructions of even the same task. One commonly recognized factor for this phenomenon is the model\u2019s familiarity with the given prompt or instruction, which is typically estimated by its perplexity. However, finding the prompt with the lowest perplexity is challenging, given the enormous space of possible prompting phrases. In this paper, we propose monotonic paraphrasing (MonoPara), an end-to-end decoding strategy that paraphrases given prompts or instructions into their lower perplexity counterparts based on an ensemble of a paraphrase LM for prompt (or instruction) rewriting, and a target LM (i.e. the prompt or instruction executor) that constrains the generation for lower perplexity. The ensemble decoding process can efficiently paraphrase the original prompt without altering its semantic meaning, while monotonically decrease the perplexity of each generation as calculated by the target LM. We explore in detail both greedy and search-based decoding as two alternative decoding schemes of MonoPara. Notably, MonoPara does not require any training and can monotonically lower the perplexity of the paraphrased prompt or instruction, leading to improved performance of zero-shot LM prompting as evaluated on a wide selection of tasks. In addition, MonoPara is also shown to effectively improve LMs\u2019 generalization on perturbed and unseen task instructions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.576",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization": {
        "type": "INPROCEEDINGS",
        "key": "jafari-etal-2024-morl",
        "author": "Jafari, Yasaman and Mekala, Dheeraj and Yu, Rose and Berg-Kirkpatrick, Taylor",
        "booktitle": "EMNLP-findings2024",
        "title": "MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "RL-based techniques can be employed to search for prompts that, when fed into a target language model, maximize a set of user-specified reward functions. However, in many target applications, the natural reward functions are in tension with one another \u2013 for example, content preservation vs. style matching in style transfer tasks. Current techniques focus on maximizing the average of reward functions, which does not necessarily lead to prompts that achieve balance across rewards \u2013 an issue that has been well-studied in the multi-objective and robust optimization literature. In this paper, we conduct an empirical comparison of several existing multi-objective optimization techniques adapted to this new setting: RL-based discrete prompt optimization. We compare two methods optimizing the volume of the Pareto reward surface and one method that chooses an update direction that benefits all rewards simultaneously. We evaluate performance on two NLP tasks: style transfer and machine translation, each using three competing reward functions. Our experiments demonstrate that multi-objective methods that directly optimize the volume of the Pareto reward surface perform better and achieve a better balance of all rewards than those that attempt to find monotonic update directions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.577",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries": {
        "type": "INPROCEEDINGS",
        "key": "fang-etal-2024-understanding",
        "author": "Fang, Biaoyan and Dai, Xiang and Karimi, Sarvnaz",
        "booktitle": "EMNLP-findings2024",
        "title": "Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generating plain biomedical summaries with Large Language Models (LLMs) can enhance the accessibility of biomedical knowledge to the public. However, how faithful the generated summaries are remains an open yet critical question. To address this, we propose FaReBio, a benchmark dataset with expert-annotated Faithfulness and Reasoning on plain Biomedical Summaries. This dataset consists of 175 plain summaries ($,445 sentences) generated by seven different LLMs, paired with source articles. Using our dataset, we identify the performance gap of LLMs in generating faithful plain biomedical summaries and observe a negative correlation between abstractiveness and faithfulness. We also show that current faithfulness evaluation metrics do not work well in the biomedical domain and confirm the over-confident tendency of LLMs as faithfulness evaluators. To better understand the faithfulness judgements, we further benchmark LLMs in retrieving supporting evidence and show the gap of LLMs in reasoning faithfulness evaluation at different abstractiveness levels. Going beyond the binary faithfulness labels, coupled with the annotation of supporting sentences, our dataset could further contribute to the understanding of faithfulness evaluation and reasoning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.578",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy": {
        "type": "INPROCEEDINGS",
        "key": "dumitru-etal-2024-change",
        "author": "Dumitru, Razvan-Gabriel and Clotan, Paul Ioan and Yadav, Vikas and Peteleaza, Darius and Surdeanu, Mihai",
        "booktitle": "EMNLP-findings2024",
        "title": "Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper introduces a novel model compression approach through dynamic layer-specific pruning in Large Language Models (LLMs), enhancing the traditional methodology established by SliceGPT. By transitioning from constant to dynamic slicing, our method leverages the newly proposed Layer Redundancy (LR) score, which assesses how much change each layer changes its input by measuring the cosine similarity of the input to the output of the layer. We use this score to prune parts of individual layers based on redundancy in such a way that the average pruned percentage for all layers is a fixed value. We conducted extensive experiments using models like Llama3-8B and Mistral-7B on multiple datasets, evaluating different slicing bases and percentages to determine optimal configurations that balance efficiency and performance. Our findings show that our dynamic slicing approach not only maintains but, in many cases, enhances model performance compared to the baseline established by constant slicing methods. For instance, in several settings, we see performance improvements of up to 5% over the SliceGPT baseline.Additionally, a perplexity decrease by as much as 7% was observed across multiple benchmarks, validating the effectiveness of our method. The code, model weights, and datasets are open-sourced at - https://github.com/RazvanDu/DynamicSlicing",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.579",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Pruning Multilingual Large Language Models for Multilingual Inference": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-pruning",
        "author": "Kim, Hwichan and Suzuki, Jun and Hirasawa, Tosho and Komachi, Mamoru",
        "booktitle": "EMNLP-findings2024",
        "title": "Pruning Multilingual Large Language Models for Multilingual Inference",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multilingual large language models (MLLMs), trained on multilingual balanced data, demonstrate better zero-shot learning performance in non-English languages compared to large language models trained on English-dominant data. However, the disparity in performance between English and non-English languages remains a challenge yet to be fully addressed. This study introduces a promising direction for enhancing non-English performance through a specialized pruning approach. Specifically, we prune MLLMs using bilingual sentence pairs from English and other languages and empirically demonstrate that this pruning strategy can enhance the MLLMs\u2019 performance in non-English language.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.580",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Video Discourse Parsing and Its Application to Multimodal Summarization: A Dataset and Baseline Approaches": {
        "type": "INPROCEEDINGS",
        "key": "hirao-etal-2024-video",
        "author": "Hirao, Tsutomu and Kobayashi, Naoki and Kamigaito, Hidetaka and Okumura, Manabu and Kimura, Akisato",
        "booktitle": "EMNLP-findings2024",
        "title": "Video Discourse Parsing and Its Application to Multimodal Summarization: A Dataset and Baseline Approaches",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper tackles a new task: discourse parsing for videos, inspired by text discourse parsing based on Rhetorical Structure Theory (RST). The task aims to construct an RST tree for a video to represent its storyline and illustrate the event relationships. We first construct a benchmark dataset by identifying events with their time spans, providing corresponding captions, and constructing RST trees with events as leaves. We then evaluate baseline approaches to video RST parsing: the \u2018parsing after captioning\u2019 framework and parsing via visual features. The results show that a parser using gold captions performed the best, while parsers relying on generated captions performed the worst; a parser using visual features provided intermediate performance. However, we observed that parsing via visual features could be improved by pre-training it with video captioning designed to produce a coherent video story. Furthermore, we demonstrated that RST trees obtained from videos contribute to multimodal summarization consisting of keyframes with texts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.581",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-length",
        "author": "Zhao, Liang and Feng, Xiachong and Feng, Xiaocheng and Zhong, Weihong and Xu, Dongliang and Yang, Qing and Liu, Hongtao and Qin, Bing and Liu, Ting",
        "booktitle": "EMNLP-findings2024",
        "title": "Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Built upon the Transformer, large language models (LLMs) have captured worldwide attention due to their remarkable abilities. Nevertheless, all Transformer-based models including LLMs suffer from a preset length limit and can hardly generalize from short training sequences to longer inference ones, namely, they can not perform **length extrapolation** to handle long sequences. Thus, numerous methods have emerged to enhance the length extrapolation of Transformers. Despite the great research efforts, a systematic survey is still lacking. To fill this gap, we delve into these advances in a unified notation from the perspective of positional encoding (PE), as it has been considered the primary factor on length extrapolation. Specifically, we begin with extrapolatable PEs that have dominated this research field. Then, we dive into extrapolation methods based on them, covering position interpolation and randomized position methods. Finally, several challenges and future directions in this area are highlighted. Through this survey, We aim to enable the reader to gain a deep understanding of existing methods and provide stimuli for future research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.582",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "VPL: Visual Proxy Learning Framework for Zero-Shot Medical Image Diagnosis": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-vpl",
        "author": "Liu, Jiaxiang and Hu, Tianxiang and Xiong, Huimin and Du, Jiawei and Feng, Yang and Wu, Jian and Zhou, Joey Tianyi and Liu, Zuozhu",
        "booktitle": "EMNLP-findings2024",
        "title": "VPL: Visual Proxy Learning Framework for Zero-Shot Medical Image Diagnosis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Vision-language models like CLIP, utilizing class proxies derived from class name text features, have shown a notable capability in zero-shot medical image diagnosis which is vital in scenarios with limited disease databases or labeled samples. However, insufficient medical text precision and the modal disparity between text and vision spaces pose challenges for such paradigm. We show analytically and experimentally that enriching medical texts with detailed descriptions can markedly enhance the diagnosis performance, with the granularity and phrasing of these enhancements having a crucial impact on CLIP\u2019s understanding of medical images; and learning proxies within the vision domain can effectively circumvent the modal gap issue. Based on our analysis, we propose a medical visual proxy learning framework comprising two key components: a text refinement module that create high quality medical text descriptions, and a stable Sinkhorn algorithm for an efficient generation of pseudo labels which further guide the visual proxy learning. Our method elevates the Vanilla CLIP inference by supplying meticulously crafted clues to leverage CLIP\u2019s existing interpretive power and using the feature of refined texts to bridge the vision-text gap. The effectiveness and robustness of our method are clearly demonstrated through extensive experiments. Notably, our method outperforms the state-of-the-art zero-shot medical image diagnosis by a significant margin, ranging from 1.69% to 15.31% on five datasets covering various diseases, confirming its immense potential in zero-shot diagnosis across diverse medical applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.583",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Word-Conditioned 3D American Sign Language Motion Generation": {
        "type": "INPROCEEDINGS",
        "key": "dong-etal-2024-word",
        "author": "Dong, Lu and Wang, Xiao and Nwogu, Ifeoma",
        "booktitle": "EMNLP-findings2024",
        "title": "Word-Conditioned 3D American Sign Language Motion Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Sign words are the building blocks of any sign language. In this work, we present wSignGen, a word-conditioned 3D American Sign Language (ASL) generation model dedicated to synthesizing realistic and grammatically accurate motion sequences for sign words. Our approach leverages a transformer-based diffusion model, trained on a curated dataset of 3D motion meshes from word-level ASL videos. By integrating CLIP, wSignGen offers two advantages: image-based generation, which is particularly useful for children learning sign language but not yet able to read, and the ability to generalize to unseen synonyms. Experiments demonstrate that wSignGen significantly outperforms the baseline model in the task of sign word generation. Moreover, human evaluation experiments show that wSignGen can generate high-quality, grammatically correct ASL signs effectively conveyed through 3D avatars.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.584",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TrustAgent: Towards Safe and Trustworthy LLM-based Agents": {
        "type": "INPROCEEDINGS",
        "key": "hua-etal-2024-trustagent",
        "author": "Hua, Wenyue and Yang, Xianjun and Jin, Mingyu and Li, Zelong and Cheng, Wei and Tang, Ruixiang and Zhang, Yongfeng",
        "booktitle": "EMNLP-findings2024",
        "title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The rise of LLM-based agents shows great potential to revolutionize task planning, capturing significant attention. Given that these agents will be integrated into high-stake domains, ensuring their reliability and safety is crucial. This paper presents an Agent-Constitution-based agent framework, TrustAgent, with a particular focus on improving the LLM-based agent safety. The proposed framework ensures strict adherence to the Agent Constitution through three strategic components: pre-planning strategy which injects safety knowledge to the model before plan generation, in-planning strategy which enhances safety during plan generation, and post-planning strategy which ensures safety by post-planning inspection. Our experimental results demonstrate that the proposed framework can effectively enhance an LLM agent\u2019s safety across multiple domains by identifying and mitigating potential dangers during the planning. Further analysis reveals that the framework not only improves safety but also enhances the helpfulness of the agent. Additionally, we highlight the importance of the LLM reasoning ability in adhering to the Constitution. This paper sheds light on how to ensure the safe integration of LLM-based agents into human-centric environments. Data and code are available at https://anonymous.4open.science/r/TrustAgent-06DC.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.585",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity": {
        "type": "INPROCEEDINGS",
        "key": "subramanyam-etal-2024-enabling",
        "author": "Subramanyam, Prasanna Lakkur and Chou, Jeng-Yu and Nam, Kevin K. and Levine, Brian",
        "booktitle": "EMNLP-findings2024",
        "title": "Enabling Cross-Platform Comparison of Online Communities Using Content and Opinion Similarity",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the continuous growth of online communities, understanding their similarities and dissimilarities is more crucial than ever for enhancing digital interactions, maintaining healthy interactions, and improving content recommendation and moderation systems. In this work, we present two novel techniques: BOTS for finding similarity between online communities based on their opinion, and Emb-PSR for finding similarity in the content they post. To facilitate finding the similarity based on opinion, we model the opinions on online communities using upvotes and downvotes as an indicator for community approval. Our results demonstrate that BOTS and Emb-PSR outperform existing techniques at their individual tasks while also being flexible enough to allow for cross-platform comparison of online communities. We demonstrate this novel cross-platform capability by comparing GAB with various subreddits.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.586",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CNEQ: Incorporating numbers into Knowledge Graph Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "peng-etal-2024-cneq",
        "author": "Peng, Xianshu and Wei, Wei and Xu, Kaihe and Chen, Dangyang",
        "booktitle": "EMNLP-findings2024",
        "title": "CNEQ: Incorporating numbers into Knowledge Graph Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Complex logical reasoning over knowledge graphs lies at the heart of many semantic downstream applications and thus has been extensively explored in recent years. However, nearly all of them overlook the rich semantics of numerical entities (e.g., magnitude, unit, and distribution) and are simply treated as common entities, or even directly removed. It may severely hinder the performance of answering queries involving numerical comparison or numerical computation. To address this issue, we propose the Complex Number and Entity Query model (CNEQ), which comprises a Number-Entity Predictor and an Entity Filter. The Number-Entity Predictor can independently learn the structural and semantic features of entities and numerical values, thereby enabling better prediction of entities as well as numerical values. The Entity Filter can compare or calculate numerical values to filter out entities that meet certain numerical constraints. To evaluate our model, we generated a variety of multi-hop complex logical queries including numerical values on three widely-used Knowledge Graphs: FB15K, DB15K, and YAGO15K. Experimental results demonstrate that CNEQ achieves state-of-the-art results.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.587",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "StraGo: Harnessing Strategic Guidance for Prompt Optimization": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-strago",
        "author": "Wu, Yurong and Gao, Yan and Zhu, Bin Benjamin and Zhou, Zineng and Sun, Xiaodi and Yang, Sheng and Lou, Jian-Guang and Ding, Zhiming and Yang, Linjun",
        "booktitle": "EMNLP-findings2024",
        "title": "StraGo: Harnessing Strategic Guidance for Prompt Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prompt engineering is pivotal for harnessing the capabilities of large language models (LLMs) across diverse applications. While existing prompt optimization methods improve prompt effectiveness, they often lead to prompt drifting, wherein newly generated prompts canadversely impact previously successful cases while addressing failures. Furthermore, these methods tend to rely heavily on LLMs\u2019 intrinsic capabilities for prompt optimization tasks. In this paper, we introduce STRAGO (StrategicGuided Optimization), a novel approach designed to mitigate prompt drifting by leveraging insights from both successful and failed cases to identify critical factors for achieving optimization objectives. STRAGO employs a how-to-do methodology, integrating in-context learning to formulate specific, actionable strategies that provide detailed, step-by-step guidance for prompt optimization. Extensive experiments conducted across a range of tasks, including reasoning, natural language understanding, domain-specific knowledge, and industrial applications, demonstrate STRAGO\u2019s superior performance. It establishes a new stateof-the-art in prompt optimization, showcasing its ability to deliver stable and effective prompt improvements.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.588",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Plan by Updating Natural Language": {
        "type": "INPROCEEDINGS",
        "key": "guo-etal-2024-learning",
        "author": "Guo, Yiduo and Liang, Yaobo and Wu, Chenfei and Wu, Wenshan and Zhao, Dongyan and Duan, Nan",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Plan by Updating Natural Language",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have shown remarkable performance in various basic natural language tasks. For completing the complex task, we still need a plan for the task to guide LLMs to generate the specific solutions step by step. LLMs can directly generate task plans, but these plans may still contain factual errors or are incomplete. A high-quality task plan contains correct step-by-step solutions for solving all situations and behavioral instructions for avoiding mistakes. To obtain it, we propose the Learning to Plan method, which involves two phases: (1) In the first learning task plan phase, it iteratively updates the task plan with new step-by-step solutions and behavioral instructions, which are obtained by prompting LLMs to derive from training error feedback. (2) In the subsequent test phase, the LLM uses the learned task plan to guide the inference of LLM on the test set. We demonstrate the effectiveness of our method on the five different reasoning type tasks (8 datasets). Further, our analysis experiment shows that the task plan learned by one LLM can directly guide another LLM to improve its performance, which reveals a new transfer learning paradigm.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.589",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "C-ICL: Contrastive In-context Learning for Information Extraction": {
        "type": "INPROCEEDINGS",
        "key": "mo-etal-2024-c",
        "author": "Mo, Ying and Liu, Jiahao and Yang, Jian and Wang, Qifan and Zhang, Shun and Wang, Jingang and Li, Zhoujun",
        "booktitle": "EMNLP-findings2024",
        "title": "C-ICL: Contrastive In-context Learning for Information Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "There has been increasing interest in exploring the capabilities of advanced large language models (LLMs) in the field of information extraction (IE), specifically focusing on tasks related to named entity recognition (NER) and relation extraction (RE). Although researchers are exploring the use of few-shot information extraction through in-context learning with LLMs, they tend to focus only on using correct or positive examples for demonstration, neglecting the potential value of incorporating incorrect or negative examples into the learning process. In this paper, we present C-ICL, a novel few-shot technique that leverages both correct and incorrect sample constructions to create in-context learning demonstrations. This approach enhances the ability of LLMs to extract entities and relations by utilizing prompts that incorporate not only the positive samples but also the reasoning behind them. This method allows for the identification and correction of potential interface errors. Specifically, our proposed method taps into the inherent contextual information and valuable information in hard negative samples and the nearest positive neighbors to the test and then applies the in-context learning demonstrations based on LLMs. Our experiments on various datasets indicate that C-ICL outperforms previous few-shot in-context learning methods, delivering substantial enhancements in performance across a broad spectrum of related tasks. These improvements are noteworthy, showcasing the versatility of our approach in miscellaneous scenarios.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.590",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On the Similarity of Circuits across Languages: a Case Study on the Subject-verb Agreement Task": {
        "type": "INPROCEEDINGS",
        "key": "ferrando-costa-jussa-2024-similarity",
        "author": "Ferrando, Javier and Costa-juss\u00e0, Marta R.",
        "booktitle": "EMNLP-findings2024",
        "title": "On the Similarity of Circuits across Languages: a Case Study on the Subject-verb Agreement Task",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Several algorithms implemented by language models have recently been successfully reversed-engineered. However, these findings have been concentrated on specific tasks and models, leaving it unclear how universal circuits are across different settings. In this paper, we study the circuits implemented by Gemma 2B for solving the subject-verb agreement task across two different languages, English and Spanish. We discover that both circuits are highly consistent, being mainly driven by a particular attention head writing a \u2018subject number\u2019 signal to the last residual stream, which is read by a small set of neurons in the final MLPs. Notably, this subject number signal is represented as a direction in the residual stream space, and is language-independent. Finally, we demonstrate this direction has a causal effect on the model predictions, effectively flipping the Spanish predicted verb number by intervening with the direction found in English.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.591",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can LLM be a Personalized Judge?": {
        "type": "INPROCEEDINGS",
        "key": "dong-etal-2024-llm",
        "author": "Dong, Yijiang River and Hu, Tiancheng and Collier, Nigel",
        "booktitle": "EMNLP-findings2024",
        "title": "Can LLM be a Personalized Judge?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As large language models (LLMs) gain widespread adoption, ensuring they cater to diverse user needs has become increasingly important. While many researchers have studied LLM personalization and role-playing, they primarily use LLM-as-a-Judge for evaluation without thoroughly examining its validity. This paper investigates the reliability of LLM-as-a-Personalized-Judge\u2014asking LLMs to judge user preferences based on persona. Our results suggest that LLM-as-a-Personalized-Judge is less reliable for personalization than previously believed, showing low agreement with human ground truth. We observed that the personas provided to the LLM often have limited predictive power for the tasks, leading us to introduce verbal uncertainty estimation. We find that powerful LLMs are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating LLM personalization. Our human annotation reveals that third-person crowd worker evaluations of personalized preferences are even worse than LLM predictions, highlighting the challenges of evaluating LLM personalization.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.592",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Who\u2019s Who: Large Language Models Meet Knowledge Conflicts in Practice": {
        "type": "INPROCEEDINGS",
        "key": "pham-etal-2024-whos",
        "author": "Pham, Quang Hieu and Ngo, Hoang and Luu, Anh Tuan and Nguyen, Dat Quoc",
        "booktitle": "EMNLP-findings2024",
        "title": "Who\u2019s Who: Large Language Models Meet Knowledge Conflicts in Practice",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-augmented generation (RAG) methods are viable solutions for addressing the static memory limits of pre-trained language models. Nevertheless, encountering conflicting sources of information within the retrieval context is an inevitable practical challenge. In such situations, the language models are recommended to transparently inform users about the conflicts rather than autonomously deciding what to present based on their inherent biases. To analyze how current large language models (LLMs) align with our recommendation, we introduce WhoQA, a public benchmark dataset to examine model\u2019s behavior in knowledge conflict situations. We induce conflicts by asking about a common property among entities having the same name, resulting in questions with up to 8 distinctive answers. WhoQA evaluation set includes 5K questions across 13 Wikidata property types and 150K Wikipedia entities. Our experiments show that despite the simplicity of WhoQA questions, knowledge conflicts significantly degrades LLMs\u2019 performance in RAG settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.593",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unleashing the Potentials of Likelihood Composition for Multi-modal Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-unleashing",
        "author": "Zhao, Shitian and Zhang, Renrui and Luo, Xu and Wang, Yan and Zhang, Shanghang and Gao, Peng",
        "booktitle": "EMNLP-findings2024",
        "title": "Unleashing the Potentials of Likelihood Composition for Multi-modal Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Model fusing has always been an important topic, especially in an era where large language models (LLM) and multi-modal language models (MLM) with different architectures, parameter sizes and training pipelines, are being created all the time. In this work, we propose a post-hoc framework, aiming at fusing heterogeneous models off-the-shell, which we call likelihood composition, and the basic idea is to compose multiple models\u2019 likelihood distribution when doing a multi-choice visual-question-answering task. Here the core concept, likelihood, is actually the log-probability of the candidate answer. In likelihood composition, we introduce some basic operations: debias, highlight, majority-vote and ensemble. By combining (composing) these basic elements, we get the mixed composition methods: mix-composition. Through conducting comprehensive experiments on 9 VQA datasets and 10 MLMs, we prove the effectiveness of mix-composition compared with simple ensemble or majority-vote methods. In this framework, people can propose new basic composition methods and combine them to get the new mixed composition methods. We hope our proposed likelihood composition can provide a new perspective of fusing heterogeneous models and inspire the exploration under this framework.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.594",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Automated Peer Reviewing in Paper SEA: Standardization, Evaluation, and Analysis": {
        "type": "INPROCEEDINGS",
        "key": "yu-etal-2024-automated",
        "author": "Yu, Jianxiang and Ding, Zichen and Tan, Jiaqi and Luo, Kangyang and Weng, Zhenmin and Gong, Chenghua and Zeng, Long and Cui, RenJing and Han, Chengcheng and Sun, Qiushi and Wu, Zhiyong and Lan, Yunshi and Li, Xiang",
        "booktitle": "EMNLP-findings2024",
        "title": "Automated Peer Reviewing in Paper SEA: Standardization, Evaluation, and Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In recent years, the rapid increase in scientific papers has overwhelmed traditional review mechanisms, resulting in varying quality of publications. Although existing methods have explored the capabilities of Large Language Models (LLMs) for automated scientific reviewing, their generated contents are often generic or partial. To address the issues above, we introduce an automated paper reviewing framework SEA. It comprises of three modules: Standardization, Evaluation, and Analysis, which are represented by models SEA-S, SEA-E, and SEA-A, respectively. Initially, SEA-S distills data standardization capabilities of GPT-4 for integrating multiple reviews for a paper. Then, SEA-E utilizes standardized data for fine-tuning, enabling it to generate constructive reviews. Finally, SEA-A introduces a new evaluation metric called mismatch score to assess the consistency between paper contents and reviews. Moreover, we design a self-correction strategy to enhance the consistency. Extensive experimental results on datasets collected from eight venues show that SEA can generate valuable insights for authors to improve their papers.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.595",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Knowledge-based Consistency Testing of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "rajan-etal-2024-knowledge",
        "author": "Rajan, Sai Sathiesh and Soremekun, Ezekiel and Chattopadhyay, Sudipta",
        "booktitle": "EMNLP-findings2024",
        "title": "Knowledge-based Consistency Testing of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this work, we systematically expose and measure the inconsistency and knowledge gaps of Large Language Models (LLMs). Specifically, we propose an automated testing framework (called KONTEST) which leverages a knowledge graph to construct test cases. KONTEST probes and measures the inconsistencies in the LLM\u2019s knowledge of the world via a combination of semantically-equivalent queries and test oracles (metamorphic or ontological oracle). KONTEST further mitigates knowledge gaps via a weighted LLM model ensemble. Using four state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that KONTEST generates 19.2% error inducing inputs (1917 errors from 9979 test inputs). It also reveals a 16.5% knowledge gap across all tested LLMs. A mitigation method informed by KONTEST\u2019s test suite reduces LLM knowledge gap by 32.48%. Our ablation study further shows that GPT3.5 is not suitable for knowledge-based consistency testing because it is only 60%-68% effective in knowledge construction.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.596",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes": {
        "type": "INPROCEEDINGS",
        "key": "cao-etal-2024-presto",
        "author": "Cao, He and Shao, Yanjun and Liu, Zhiyuan and Liu, Zijing and Tang, Xiangru and Yao, Yuan and Li, Yu",
        "booktitle": "EMNLP-findings2024",
        "title": "PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal Large Language Models (MLLMs) have seen growing adoption across various scientific disciplines. These advancements encourage the investigation of molecule-text modeling within synthetic chemistry, a field dedicated to designing and conducting chemical reactions to synthesize new compounds with desired properties and applications. Current approaches, however, often neglect the critical role of multi-molecule graph interaction in understanding chemical reactions, leading to suboptimal performance in synthetic chemistry tasks. This study introduces PRESTO (Progressive Pretraining Enhances Synthetic Chemistry Outcomes), a new framework that bridges the molecule-text modality gap by integrating a comprehensive benchmark of pretraining strategies and dataset configurations. It progressively improves multimodal LLMs through cross-modal alignment and multi-graph understanding. Our extensive experiments demonstrate that PRESTO offers competitive results in downstream synthetic chemistry tasks. The code can be found at https://github.com/IDEA-XL/PRESTO.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.597",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Query Routing for Homogeneous Tools: An Instantiation in the RAG Scenario": {
        "type": "INPROCEEDINGS",
        "key": "mu-etal-2024-query",
        "author": "Mu, Feiteng and Jiang, Yong and Zhang, Liwen and Liuchu, Liuchu and Li, Wenjie and Xie, Pengjun and Huang, Fei",
        "booktitle": "EMNLP-findings2024",
        "title": "Query Routing for Homogeneous Tools: An Instantiation in the RAG Scenario",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Current research on tool learning primarily focuses on selecting the most effective tool from a wide array of options, often overlooking cost-effectiveness, a crucial factor in human problem-solving. In this paper, we address query routing for homogeneous tools by predicting both their performance and the associated cost required to accomplish a given task. We then assign queries to the optimal tools in a cost-effective manner. Our experimental results demonstrate that our method achieves higher performance at a lower cost compared to strong baseline approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.598",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-mobilevlm",
        "author": "Wu, Qinzhuo and Xu, Weikai and Liu, Wei and Tan, Tao and Liujianfeng, Liujian and Li, Ang and Luan, Jian and Wang, Bin and Shang, Shuo",
        "booktitle": "EMNLP-findings2024",
        "title": "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, mobile AI agents based on VLMs have been gaining increasing attention. These works typically utilize VLM as a foundation, fine-tuning it with instruction-based mobile datasets. However, these VLMs are typically pre-trained on general-domain data, which often results in a lack of fundamental capabilities specific to the mobile domain. Therefore, they may struggle to recognize specific UI elements and understand intra-UI fine-grained information. In addition, the current fine-tuning task focuses on interacting with the most relevant element for the given instruction. These fine-tuned VLMs may still ignore the relationships between UI pages, neglect the roles of elements in page transitions and lack inter-UI understanding. To address issues, we propose a VLM called MobileVLM, which includes two additional pre-training stages to enhance both intra- and inter-UI understanding. We defined four UI-based pre-training tasks, enabling the model to better perceive fine-grained elements and capture page transition actions. To address the lack of mobile pre-training data, we built a large Chinese mobile dataset Mobile3M from scratch, which contains 3 million UI pages, and real-world transition actions, forming a directed graph structure. Experimental results show MobileVLM excels on both our test set and public mobile benchmarks, outperforming existing VLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.599",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Schema-Driven Information Extraction from Heterogeneous Tables": {
        "type": "INPROCEEDINGS",
        "key": "bai-etal-2024-schema",
        "author": "Bai, Fan and Kang, Junmo and Stanovsky, Gabriel and Freitag, Dayne and Dredze, Mark and Ritter, Alan",
        "booktitle": "EMNLP-findings2024",
        "title": "Schema-Driven Information Extraction from Heterogeneous Tables",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we explore the question of whether large language models can support cost-efficient information extraction from tables. We introduce schema-driven information extraction, a new task that transforms tabular data into structured records following a human-authored schema. To assess various LLM\u2019s capabilities on this task, we present a benchmark comprised of tables from four diverse domains: machine learning papers, chemistry literature, material science journals, and webpages. We use this collection of annotated tables to evaluate the ability of open-source and API-based language models to extract information from tables covering diverse domains and data formats. Our experiments demonstrate that surprisingly competitive performance can be achieved without requiring task-specific pipelines or labels, achieving F1 scores ranging from 74.2 to 96.1, while maintaining cost efficiency. Moreover, through detailed ablation studies and analyses, we investigate the factors contributing to model success and validate the practicality of distilling compact models to reduce API reliance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.600",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-one",
        "author": "Huang, Wenhao and He, Qianyu and Li, Zhixu and Liang, Jiaqing and Xiao, Yanghua",
        "booktitle": "EMNLP-findings2024",
        "title": "Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Definition bias is a negative phenomenon that can mislead models. However, definition bias in information extraction appears not only across datasets from different domains but also within datasets sharing the same domain. We identify two types of definition bias in IE: bias among information extraction datasets and bias between information extraction datasets and instruction tuning datasets. To systematically investigate definition bias, we conduct three probing experiments to quantitatively analyze it and discover the limitations of unified information extraction and large language models in solving definition bias. To mitigate definition bias in information extraction, we propose a multi-stage framework consisting of definition bias measurement, bias-aware fine-tuning, and task-specific bias mitigation. Experimental results demonstrate the effectiveness of our framework in addressing definition bias.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.601",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning": {
        "type": "INPROCEEDINGS",
        "key": "zou-etal-2024-promptintern",
        "author": "Zou, Jiaru and Zhou, Mengyu and Li, Tao and Han, Shi and Zhang, Dongmei",
        "booktitle": "EMNLP-findings2024",
        "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advances in fine-tuning large language models (LLMs) have greatly enhanced their usage in domain-specific tasks. Despite the success, fine-tuning continues to rely on repeated and lengthy prompts, which escalate computational expenses, require more resources, and lead to slower inference. In this paper, we present a novel approach, PromptIntern, which internalizes prompt knowledge during model fine-tuning to achieve efficient inference and save costs. Instead of compressing the prompts for a vanilla model, PromptIntern aims to embed the recurrent prompt directly into the model parameters. We design a fine-tuning pipeline that includes instruction template compression, few-shot example absorption, and a progressive internalization strategy, effectively diminishing the need for intricate prompts during inference. Comprehensive experiments on challenging NL2Code tasks demonstrate that our method reduces input tokens by more than 90%, accelerates inference by 4.2 times, and reduces monetary inference costs by 88.3%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.602",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "sui-etal-2024-tap4llm",
        "author": "Sui, Yuan and Zou, Jiaru and Zhou, Mengyu and He, Xinyi and Du, Lun and Han, Shi and Zhang, Dongmei",
        "booktitle": "EMNLP-findings2024",
        "title": "TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Table reasoning tasks have shown remarkable progress with the development of large language models (LLMs), which involve interpreting and drawing conclusions from tabular data based on natural language (NL) questions. Existing solutions mainly tested on smaller tables face scalability issues and struggle with complex queries due to incomplete or dispersed data across different table sections. To alleviate these challenges, we propose TAP4LLM as a versatile pre-processor suite for leveraging LLMs in table-based tasks effectively. It covers several distinct components: (1) table sampling to decompose large tables into manageable sub-tables based on query semantics, (2) table augmentation to enhance tables with additional knowledge from external sources or models, and (3) table packing &amp; serialization to convert tables into various formats suitable for LLMs\u2019 understanding. In each module, we design and compare several common methods for usage in various scenarios, aiming to shed light on the best practices for leveraging LLMs for table-reasoning tasks. Our experiments show that our method improves LLMs\u2019 reasoning capabilities in various tabular tasks and enhances the interaction between LLMs and tabular data by employing effective pre-processing.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.603",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "joaquin-etal-2024-in2core",
        "author": "Joaquin, Ayrton San and Wang, Bin and Liu, Zhengyuan and Muller, Philippe and Asher, Nicholas and Lim, Brian and Chen, Nancy F.",
        "booktitle": "EMNLP-findings2024",
        "title": "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite advancements, fine-tuning Large Language Models (LLMs) remains costly due to the extensive parameter count and substantial data requirements for model generalization. Accessibility to computing resources remains a barrier for the open-source community. To address this challenge, we propose the In2Core algorithm, which selects a coreset by analyzing the correlation between training and evaluation samples with a trained model. Notably, we assess the model\u2019s internal gradients to estimate this relationship, aiming to rank the contribution of each training point. To enhance efficiency, we propose an optimization to compute influence functions with a reduced number of layers while achieving similar accuracy. By applying our algorithm to instruction fine-tuning data of LLMs, we can achieve similar performance with just 50% of the training data. Meantime, using influence functions to analyze model coverage to certain testing samples could provide a reliable and interpretable signal on the training set\u2019s coverage of those test points.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.604",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "huang-hadfi-2024-personality",
        "author": "Huang, Yin Jou and Hadfi, Rafik",
        "booktitle": "EMNLP-findings2024",
        "title": "How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Psychological evidence reveals the influence of personality traits on decision-making. For instance, agreeableness is generally associated with positive outcomes in negotiations, whereas neuroticism is often linked to less favorable outcomes. This paper introduces a simulation framework centered on large language model (LLM) agents endowed with synthesized personality traits. The agents negotiate within bargaining domains and possess customizable personalities and objectives. The experimental results show that the behavioral tendencies of LLM-based simulations can reproduce behavioral patterns observed in human negotiations. The contribution is twofold. First, we propose a simulation methodology that investigates the alignment between the linguistic and economic capabilities of LLM agents. Secondly, we offer empirical insights into the strategic impacts of Big Five personality traits on the outcomes of bilateral negotiations. We also provide an in-depth analysis based on simulated bargaining dialogues to reveal intriguing behaviors, including deceitful and compromising behaviors.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.605",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation": {
        "type": "INPROCEEDINGS",
        "key": "shimomoto-etal-2024-introducing",
        "author": "Shimomoto, Erica Kido and Marrese-Taylor, Edison and Kobayashi, Ichiro and Takamura, Hiroya and Miyao, Yusuke",
        "booktitle": "EMNLP-findings2024",
        "title": "Introducing Spatial Information and a Novel Evaluation Scheme for Open-Domain Live Commentary Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper focuses on the task of open-domain live commentary generation. Compared to domain-specific work in this task, this setting proved particularly challenging due to the absence of domain-specific features. Aiming to bridge this gap, we integrate spatial information by proposing an utterance generation model with a novel spatial graph that is flexible to deal with the open-domain characteristics of the commentaries and significantly improves performance. Furthermore, we propose a novel evaluation scheme, more suitable for live commentary generation, that uses LLMs to automatically check whether generated utterances address essential aspects of the video via the answerability of questions extracted directly from the videos using LVLMs. Our results suggest that using a combination of our answerability score and a standard machine translation metric is likely a more reliable way to evaluate the performance in this task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.606",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation": {
        "type": "INPROCEEDINGS",
        "key": "he-etal-2024-retrieving",
        "author": "He, Bolei and Chen, Nuo and He, Xinran and Yan, Lingyong and Wei, Zhenkai and Luo, Jinchang and Ling, Zhen-Hua",
        "booktitle": "EMNLP-findings2024",
        "title": "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent Retrieval Augmented Generation (RAG) aims to enhance Large Language Models (LLMs) by incorporating extensive knowledge retrieved from external sources. However, such approach encounters some challenges: Firstly, the original queries may not be suitable for precise retrieval, resulting in erroneous contextual knowledge; Secondly, the language model can easily generate inconsistent answer with external references due to their knowledge boundary limitation. To address these issues, we propose the chain-of-verification (CoV-RAG) to enhance the external retrieval correctness and internal generation consistency. Specifically, we integrate the verification module into the RAG, engaging in scoring, judgment, and rewriting. To correct external retrieval errors, CoV-RAG retrieves new knowledge using a revised query. To correct internal generation errors, we unify QA and verification tasks with a Chain-of-Thought (CoT) reasoning during training. Our comprehensive experiments across various LLMs demonstrate the effectiveness and adaptability compared with other strong baselines. Especially, our CoV-RAG can significantly surpass the state-of-the-art baselines using different LLM backbones.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.607",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Detecting Machine-Generated Long-Form Content with Latent-Space Variables": {
        "type": "INPROCEEDINGS",
        "key": "tian-etal-2024-detecting",
        "author": "Tian, Yufei and Pan, Zeyu and Peng, Nanyun",
        "booktitle": "EMNLP-findings2024",
        "title": "Detecting Machine-Generated Long-Form Content with Latent-Space Variables",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The increasing capability of large language models (LLMs) to generate fluent long-form texts is presenting new challenges in distinguishing these outputs from those of humans. Existing zero-shot detectors that primarily focus on token-level distributions are vulnerable to real-world domain shift including different decoding strategies, variations in prompts, and attacks. We propose a more robust method that incorporates abstract elements\u2014such as topic or event transitions\u2014as key deciding factors, by training a latent-space model on sequences of events or topics derived from human-written texts. On three different domains, machine generations which are originally inseparable from humans\u2019 on the token level can be better distinguished with our latent-space model, leading to a 31% improvement over strong baselines such as DetectGPT. Our analysis further reveals that unlike humans, modern LLMs such as GPT-4 selecting event triggers and transitions differently, and inherent disparity regardless of the generation configurations adopted in real-time.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.608",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Match Representations is Better for End-to-End Task-Oriented Dialog System": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-learning",
        "author": "Xu, Wanshi and Cheng, Xuxin and Zhu, Zhihong and Chen, Zhanpeng and Zou, Yuexian",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Match Representations is Better for End-to-End Task-Oriented Dialog System",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Due to the rapid development with pre-trained language models, fully end-to-end Task-Oriented Dialogue (TOD) systems exhibit superior performance. How to achieve the ability to efficiently retrieve entities in cross-domain large-scale databases is a key issue. Most existing end-to-end Task-Oriented Dialogue systems suffer from the following problems: The ability to handle erroneous but easily confused entities needs to be improved; Matching information between contexts and entities is not captured, leading to weak modeling of domain-invariant and interpretable features, making it difficult to generalize to unseen domains. In this paper, we propose a method for knowledge retrieval driven by matching representations. The approach consists of a matching signal extractor for extracting matching representations between contexts and entities that have generic conceptual features and hence domain invariant properties, and an Attribute Filter for filtering irrelevant information to facilitate the re-selection of entities. Experiments on three standard benchmarks at the dialogue level and on large knowledge bases show that our retriever performs knowledge retrieval more efficiently than existing approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.609",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-shieldlm",
        "author": "Zhang, Zhexin and Lu, Yida and Ma, Jingyuan and Zhang, Di and Li, Rui and Ke, Pei and Sun, Hao and Sha, Lei and Sui, Zhifang and Wang, Hongning and Huang, Minlie",
        "booktitle": "EMNLP-findings2024",
        "title": "ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The safety of Large Language Models (LLMs) has gained increasing attention in recent years, but there still lacks a comprehensive approach for detecting safety issues within LLMs\u2019 responses in an aligned, customizable and explainable manner. In this paper, we propose ShieldLM, an LLM-based safety detector, which aligns with common safety standards, supports customizable detection rules, and provides explanations for its decisions. To train ShieldLM, we compile a large bilingual dataset comprising 14,387 query-response pairs, annotating the safety of responses based on various safety standards. Through extensive experiments, we demonstrate that ShieldLM surpasses strong baselines across four test sets, showcasing remarkable customizability and explainability. Besides performing well on standard detection datasets, ShieldLM has also been shown to be effective as a safety evaluator for advanced LLMs. ShieldLM is released at https://github.com/thu-coai/ShieldLM to support accurate and explainable safety detection under various safety standards.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.610",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BiasDora: Exploring Hidden Biased Associations in Vision-Language Models": {
        "type": "INPROCEEDINGS",
        "key": "raj-etal-2024-biasdora",
        "author": "Raj, Chahat and Mukherjee, Anjishnu and Caliskan, Aylin and Anastasopoulos, Antonios and Zhu, Ziwei",
        "booktitle": "EMNLP-findings2024",
        "title": "BiasDora: Exploring Hidden Biased Associations in Vision-Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing works examining Vision-Language Models (VLMs) for social biases predominantly focus on a limited set of documented bias associations, such as gender-profession or race-crime. This narrow scope often overlooks a vast range of unexamined implicit associations, restricting the identification and, hence, mitigation of such biases. We address this gap by probing VLMs to (1) uncover hidden, implicit associations across 9 bias dimensions. We systematically explore diverse input and output modalities and (2) demonstrate how biased associations vary in their negativity, toxicity, and extremity. Our work (3) identifies subtle and extreme biases that are typically not recognized by existing methodologies. We make the **D**ataset **o**f **r**etrieved **a**ssociations (**Dora**) publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.611",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MoE-I\u00b2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-moe",
        "author": "Yang, Cheng and Sui, Yang and Xiao, Jinqi and Huang, Lingyi and Gong, Yu and Duan, Yuanlin and Jia, Wenqi and Yin, Miao and Cheng, Yu and Yuan, Bo",
        "booktitle": "EMNLP-findings2024",
        "title": "MoE-I\u00b2: Compressing Mixture of Experts Models through Inter-Expert Pruning and Intra-Expert Low-Rank Decomposition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The emergence of Mixture of Experts (MoE) LLMs has significantly advanced the development of language models. Compared to traditional LLMs, MoE LLMs outperform traditional LLMs by achieving higher performance with considerably fewer activated parameters. Despite this efficiency, their enormous parameter size still leads to high deployment costs. In this paper, we introduce a two-stage compression method tailored for MoE to reduce the model size and decrease the computational cost. First, in the inter-expert pruning stage, we analyze the importance of each layer and propose the Layer-wise Genetic Search and Block-wise KT-Reception Field with the non-uniform pruning ratio to prune the individual expert. Second, in the intra-expert decomposition stage, we apply the low-rank decomposition to further compress the parameters within the remaining experts. Extensive experiments on Qwen1.5-MoE-A2.7B, Deepseek-V2-Lite, and Mixtral-8\\times7B, demonstrate that our proposed methods can both reduce the model size and enhance inference efficiency while maintaining performance in various zero-shot tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.612",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multimodal Misinformation Detection by Learning from Synthetic Data with Multimodal LLMs": {
        "type": "INPROCEEDINGS",
        "key": "zeng-etal-2024-multimodal",
        "author": "Zeng, Fengzhu and Li, Wenqian and Gao, Wei and Pang, Yan",
        "booktitle": "EMNLP-findings2024",
        "title": "Multimodal Misinformation Detection by Learning from Synthetic Data with Multimodal LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Detecting multimodal misinformation, especially in the form of image-text pairs, is crucial. Obtaining large-scale, high-quality real-world fact-checking datasets for training detectors is costly, leading researchers to use synthetic datasets generated by AI technologies. However, the generalizability of detectors trained on synthetic data to real-world scenarios remains unclear due to the distribution gap. To address this, we propose learning from synthetic data for detecting real-world multimodal misinformation through two model-agnostic data selection methods that match synthetic and real-world data distributions. Experiments show that our method enhances the performance of a small MLLM (13B) on real-world fact-checking datasets, enabling it to even surpass GPT-4V.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.613",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring Design Choices for Building Language-Specific LLMs": {
        "type": "INPROCEEDINGS",
        "key": "tejaswi-etal-2024-exploring",
        "author": "Tejaswi, Atula and Gupta, Nilesh and Choi, Eunsol",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring Design Choices for Building Language-Specific LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite rapid progress in large language models (LLMs), their performance on a vast majority of languages remains unsatisfactory. In this paper, we study building language-specific LLMs by adapting monolingual and multilingual LLMs. We conduct systematic experiments on how design choices (base model selection, vocabulary extension, and continued pretraining) impact the adapted LLM, both in terms of efficiency (how many tokens are needed to encode the same amount of information) and end task performance. We find that (1) the initial performance of LLM does not always correlate with the final performance after the adaptation. Adapting an English-centric models can yield better results than adapting multilingual models despite their worse initial performance on low-resource languages. (2) Efficiency can easily improved with simple vocabulary extension and continued pretraining in most LLMs we study, and (3) The optimal adaptation method (choice of the base model, new vocabulary size, training data, initialization strategy) is highly language-dependent, and the simplest embedding initialization works well across various experimental settings. Together, our work lays foundations on efficiently building language-specific LLMs by adapting existing LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.614",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Promoting Data and Model Privacy in Federated Learning through Quantized LoRA": {
        "type": "INPROCEEDINGS",
        "key": "jianhao-etal-2024-promoting",
        "author": "JianHao, Zhu and Lv, Changze and Wang, Xiaohua and Wu, Muling and Liu, Wenhao and Li, Tianlong and Ling, Zixuan and Zhang, Cenyuan and Zheng, Xiaoqing and Huang, Xuanjing",
        "booktitle": "EMNLP-findings2024",
        "title": "Promoting Data and Model Privacy in Federated Learning through Quantized LoRA",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Conventional federated learning primarily aims to secure the privacy of data distributed across multiple edge devices, with the global model dispatched to edge devices for parameter updates during the learning process. However, the development of large language models (LLMs) requires substantial data and computational resources, rendering them valuable intellectual properties for their developers and owners. To establish a mechanism that protects both data and model privacy in a federated learning context, we introduce a method that just needs to distribute a quantized version of the model\u2019s parameters during training. This method enables accurate gradient estimations for parameter updates while preventing clients from accessing a model whose performance is comparable to the centrally hosted one. Moreover, we combine this quantization strategy with LoRA, a popular and parameter-efficient fine-tuning method, to significantly reduce communication costs in federated learning. The proposed framework, named FedLPP, successfully ensures both data and model privacy in the federated learning context. Additionally, the learned central model exhibits good generalization and can be trained in a resource-efficient manner.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.615",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-intended",
        "author": "Kim, Jongho and Stora\u00ef, Romain and Hwang, Seung-won",
        "booktitle": "EMNLP-findings2024",
        "title": "Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this study, we investigate the potential of language models (LMs) in aiding patients experiencing anomia, a difficulty identifying the names of items. Identifying the intended target item from patient\u2019s circumlocution involves the two challenges of term failure and error. (1) The terms relevant to identifying the item remain unseen. (2) What makes the challenge unique is inherent perturbed terms by semantic paraphasia, which are not exactly related to the target item, hindering the identification process. To address each, we propose robustifying the model from semantically paraphasic errors and enhancing the model with unseen terms with gradient-based selective augmentation (GradSelect). Specifically, the gradient value controls augmented data quality amid semantic errors, while the gradient variance guides the inclusion of unseen but relevant terms. Due to limited domain-specific datasets, we evaluate the model on the Tip of the Tongue dataset as an intermediary task and then apply our findings to real patient data from AphasiaBank. Our results demonstrate strong performance against baselines, aiding anomia patients by addressing the outlined challenges.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.616",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Fine-tuning Smaller Language Models for Question Answering over Financial Documents": {
        "type": "INPROCEEDINGS",
        "key": "phogat-etal-2024-fine",
        "author": "Phogat, Karmvir Singh and Puranam, Sai Akhil and Dasaratha, Sridhar and Harsha, Chetan and Ramakrishna, Shashishekar",
        "booktitle": "EMNLP-findings2024",
        "title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain, focusing on the challenge of answering questions that require multi-hop numerical reasoning over financial texts. We assess the performance of several smaller models that have been fine-tuned to generate programs that encode the required financial reasoning and calculations. Our findings demonstrate that these fine-tuned smaller models approach the performance of the teacher model.To provide a granular analysis of model performance, we propose an approach to investigate the specific student model capabilities that are enhanced by fine-tuning. Our empirical analysis indicates that fine-tuning refines the student models ability to express and apply the required financial concepts along with adapting the entity extraction for the specific data format. In addition, we hypothesize and demonstrate that comparable financial reasoning capability can be induced using relatively smaller datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.617",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs.": {
        "type": "INPROCEEDINGS",
        "key": "christophe-etal-2024-beyond",
        "author": "Christophe, Clement and Raha, Tathagata and Maslenkova, Svetlana and Salman, Muhammad Umar and Kanithi, Praveenkumar and Pimentel, Marco AF and Khan, Shadab",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs.",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have demonstrated significant potential in revolutionizing clinical applications. In this study, we investigate the efficacy of four techniques in adapting LLMs for clinical use-cases: continuous pretraining, instruct fine-tuning, NEFTune, and prompt engineering. We employ these methods on Mistral 7B and Mixtral 8x7B models, leveraging a large-scale clinical pretraining dataset of 50 billion tokens and an instruct fine-tuning dataset of 500 million tokens. Our evaluation across various clinical tasks reveals nuanced insights. While continuous pretraining beyond 250 billion tokens yields marginal improvements, instruct fine-tuning emerges as a more influential factor. Notably, NEFTune, designed primarily to enhance generation quality, surprisingly demonstrates additional gains on our benchmark. These findings underscore the importance of tailoring fine-tuning strategies and exploring innovative techniques to optimize LLM performance in the clinical domain.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.618",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation": {
        "type": "INPROCEEDINGS",
        "key": "liao-etal-2024-medcare",
        "author": "Liao, Yusheng and Jiang, Shuyang and Chen, Zhe and Wang, Yu and Wang, Yanfeng",
        "booktitle": "EMNLP-findings2024",
        "title": "MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have shown substantial progress in natural language understanding and generation, proving valuable especially in the medical field. Despite advancements, challenges persist due to the complexity and diversity inherent in medical tasks, which can be categorized as knowledge-intensive tasks and alignment-required tasks. Previous approaches either ignore the latter task or focus on a minority of tasks and hence lose generalization. To address these drawbacks, we propose a progressive fine-tuning pipeline. This pipeline employs a and a to encode diverse knowledge in the first stage and filter out detrimental information. In the second stage, we drop the to avoid the interference of suboptimal representation and leverage an additional alignment module optimized towards an orthogonal direction to the knowledge space to mitigate knowledge forgetting. Based on this two-stage paradigm, we proposed a Medical LLM through decoupling Clinical Alignment and Knowledge Aggregation (), which is designed to achieve promising performance on over 20 medical tasks, as well as results on specific medical alignment tasks. Various model sizes of (1.8B, 7B, 14B) all demonstrate significant improvements over existing models with similar model sizes. Our code and datasets are available at https://github.com/BlueZeros/MedCare.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.619",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-interpretable",
        "author": "Wang, Haoxiang and Xiong, Wei and Xie, Tengyang and Zhao, Han and Zhang, Tong",
        "booktitle": "EMNLP-findings2024",
        "title": "Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as the primary method for aligning large language models (LLMs) with human preferences. The RLHF process typically starts by training a reward model (RM) using human preference data. Conventional RMs are trained on pairwise responses to the same user request, with relative ratings indicating which response humans prefer. The trained RM serves as a proxy for human preferences. However, due to the black-box nature of RMs, their outputs lack interpretability, as humans cannot intuitively understand why an RM thinks a response is good or not. As RMs act as human preference proxies, it is desirable for them to be human-interpretable to ensure that their internal decision processes are consistent with human preferences and to prevent reward hacking in LLM alignment. To build RMs with interpretable preferences, we propose a two-stage approach: i) train an Absolute-Rating Multi-Objective Reward Model (ArmoRM) with multi-dimensional absolute-rating data, each dimension corresponding to a human-interpretable objective (e.g., honesty, verbosity, safety); ii) employ a Mixture-of-Experts (MoE) strategy with a gating network that automatically selects the most suitable reward objectives based on the context. We efficiently trained an ArmoRM with Llama-3 8B and a gating network consisting of a shallow MLP on top of the ArmoRM. Our trained model, ArmoRM-Llama3-8B, obtains state-of-the-art performance on RewardBench, a benchmark evaluating RMs for language modeling. Notably, the performance of our model surpasses the LLM-as-a-judge method with GPT-4 judges by a margin, and approaches the performance of the much larger Nemotron-4 340B reward model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.620",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-code",
        "author": "Zhang, Sheng and Li, Hui and Ji, Rongrong",
        "booktitle": "EMNLP-findings2024",
        "title": "Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Code pre-trained language models (CPLMs) have received great attention since they can benefit various tasks that facilitate software development and maintenance. However, CPLMs are trained on massive open-source code, raising concerns about potential data infringement. This paper launches the study of detecting unauthorized code use in CPLMs, i.e., Code Membership Inference (CMI) task. We design a framework Buzzer for different settings of CMI. Buzzer deploys several inference techniques, including signal extraction from pre-training tasks, hard-to-learn sample calibration and weighted inference, to identify code membership status accurately. Extensive experiments show that CMI can be achieved with high accuracy using Buzzer. Hence, Buzzer can serve as a CMI tool and help protect intellectual property rights. The implementation of Buzzer is available at: https://github.com/KDEGroup/Buzzer",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.621",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning When to Retrieve, What to Rewrite, and How to Respond in Conversational QA": {
        "type": "INPROCEEDINGS",
        "key": "roy-etal-2024-learning",
        "author": "Roy, Nirmal and Ribeiro, Leonardo F. R. and Blloshmi, Rexhina and Small, Kevin",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning When to Retrieve, What to Rewrite, and How to Respond in Conversational QA",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Augmenting Large Language Models (LLMs) with information retrieval capabilities (i.e., Retrieval-Augmented Generation (RAG)) has proven beneficial for knowledge-intensive tasks. However, understanding users\u2019 contextual search intent when generating responses is an understudied topic for conversational question answering (QA). This conversational extension leads to additional concerns when compared to single-turn QA as it is more challenging for systems to comprehend conversational context and manage retrieved passages over multiple turns. In this work, we propose a method for enabling LLMs to decide when to retrieve in RAG settings given a conversational context. When retrieval is deemed necessary, the LLM then rewrites the conversation for passage retrieval and judges the relevance of returned passages before response generation. Operationally, we build on the single-turn SELF-RAG framework (Asai et al., 2023) and propose SELF-multi-RAG for conversational settings. SELF-multi-RAG demonstrates improved capabilities over single-turn variants with respect to retrieving relevant passages (by using summarized conversational context) and assessing the quality of generated responses. Experiments on three conversational QA datasets validate the enhanced response generation capabilities of SELF-multi-RAG with improvements of ~13% measured by human annotation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.622",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-beyond-natural",
        "author": "Chen, Weize and Yuan, Chenfei and Yuan, Jiarui and Su, Yusheng and Qian, Chen and Yang, Cheng and Xie, Ruobing and Liu, Zhiyuan and Sun, Maosong",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Natural language (NL) has long been the predominant format for human cognition and communication, and by extension, has been similarly pivotal in the development and application of Large Language Models (LLMs). Yet, besides NL, LLMs have seen various non-NL formats during pre-training, such as code and logical expression. NL\u2019s status as the optimal format for LLMs, particularly in single-LLM reasoning and multi-agent communication, has not been thoroughly examined. In this work, we challenge the default use of NL by exploring the utility of non-NL formats in these contexts. We show that allowing LLMs to autonomously select the most suitable format before reasoning or communicating leads to a 3.3 to 5.7% improvement in reasoning efficiency for different LLMs, and up to a 72.7% reduction in token usage in multi-agent communication, all while maintaining communicative effectiveness. Our comprehensive analysis further reveals that LLMs can devise a format from limited task instructions and that the devised format is effectively transferable across different LLMs. Intriguingly, the structured communication format decided by LLMs exhibits notable parallels with established agent communication languages, suggesting a natural evolution towards efficient, structured communication in agent communication. Our code will be released to facilitate further exploration.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.623",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Use Tools via Cooperative and Interactive Agents": {
        "type": "INPROCEEDINGS",
        "key": "shi-etal-2024-learning",
        "author": "Shi, Zhengliang and Gao, Shen and Chen, Xiuyi and Feng, Yue and Yan, Lingyong and Shi, Haibo and Yin, Dawei and Ren, Pengjie and Verberne, Suzan and Ren, Zhaochun",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Use Tools via Cooperative and Interactive Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Tool learning empowers large language models (LLMs) as agents to use external tools and extend their utility. Existing methods employ one single LLM-based agent to iteratively select and execute tools, thereafter incorporating execution results into the next action prediction. Despite their progress, these methods suffer from performance degradation when addressing practical tasks due to: (1) the pre-defined pipeline with restricted flexibility to calibrate incorrect actions, and (2) the struggle to adapt a general LLM-based agent to perform a variety of specialized actions. To mitigate these problems, we propose ConAgents, a Cooperative and interactive Agents framework, which coordinates three specialized agents for tool selection, tool execution, and action calibration separately. ConAgents introduces two communication protocols to enable the flexible cooperation of agents. To effectively generalize the ConAgents into open-source models, we also propose specialized action distillation, enhancing their ability to perform specialized actions in our framework. Our extensive experiments on three datasets show that the LLMs, when equipped with the ConAgents, outperform baselines with substantial improvement (i.e., up to 14% higher success rate).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.624",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "STARD: A Chinese Statute Retrieval Dataset Derived from Real-life Queries by Non-professionals": {
        "type": "INPROCEEDINGS",
        "key": "su-etal-2024-stard",
        "author": "Su, Weihang and Hu, Yiran and Xie, Anzhe and Ai, Qingyao and Bing, Quezi and Zheng, Ning and Liu, Yun and Shen, Weixing and Liu, Yiqun",
        "booktitle": "EMNLP-findings2024",
        "title": "STARD: A Chinese Statute Retrieval Dataset Derived from Real-life Queries by Non-professionals",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Statute retrieval aims to find relevant statutory articles for specific queries. This process is the basis of a wide range of legal applications such as legal advice, automated judicial decisions, legal document drafting, etc. Existing statute retrieval benchmarks emphasize formal and professional queries from sources like bar exams and legal case documents, thereby neglecting non-professional queries from the general public, which often lack precise legal terminology and references. To address this gap, we introduce the STAtute Retrieval Dataset (STARD), a Chinese dataset comprising 1,543 query cases collected from real-world legal consultations and 55,348 candidate statutory articles. Unlike existing statute retrieval datasets, which primarily focus on professional legal queries, STARD captures the complexity and diversity of real queries from the general public. Through a comprehensive evaluation of various retrieval baselines, we reveal that existing retrieval approaches all fall short of these real queries issued by non-professional users. The best method only achieves a Recall@100 of 0.907, suggesting the necessity for further exploration and additional research in this area.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.625",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-thinking",
        "author": "Kim, Junho and Yeonju, Kim and Ro, Yong Man",
        "booktitle": "EMNLP-findings2024",
        "title": "What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper presents a way of enhancing the reliability of Large Multi-modal Models (LMMs) in addressing hallucination, where the models generate cross-modal inconsistent responses. Without additional training, we propose Counterfactual Inception, a novel method that implants counterfactual thinking into LMMs using self-generated counterfactual keywords. Our method is grounded in the concept of counterfactual thinking, a cognitive process where human considers alternative realities, enabling more extensive context exploration. Bridging the human cognition mechanism into LMMs, we aim for the models to engage with and generate responses that span a wider contextual scene understanding, mitigating hallucinatory outputs. We further introduce Plausibility Verification Process (PVP), a simple yet robust keyword constraint that effectively filters out sub-optimal keywords to enable the consistent triggering of counterfactual thinking in the model responses. Comprehensive analyses across various LMMs, including both open-source and proprietary models, corroborate that counterfactual thinking significantly reduces hallucination and helps to broaden contextual understanding based on true visual clues.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.626",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-melt",
        "author": "Kim, Junho and Kim, Yeachan and Park, Jun-Hyung and Oh, Yerim and Kim, Suho and Lee, SangKeun",
        "booktitle": "EMNLP-findings2024",
        "title": "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We introduce a novel continued pre-training method, MELT (MatEriaLs-aware continued pre-Training), specifically designed to efficiently adapt the pre-trained language models (PLMs) for materials science. Unlike previous adaptation strategies that solely focus on constructing domain-specific corpus, MELT comprehensively considers both the corpus and the training strategy, given that materials science corpus has distinct characteristics from other domains. To this end, we first construct a comprehensive materials knowledge base from the scientific corpus by building semantic graphs. Leveraging this extracted knowledge, we integrate a curriculum into the adaptation process that begins with familiar and generalized concepts and progressively moves toward more specialized terms. We conduct extensive experiments across diverse benchmarks to verify the effectiveness and generality of MELT. A comprehensive evaluation convincingly supports the strength of MELT, demonstrating superior performance compared to existing continued pre-training methods. In-depth analysis also shows that MELT enables PLMs to effectively represent materials entities compared to the existing adaptation methods, thereby highlighting its broad applicability across a wide spectrum of materials science.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.627",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PDF-to-Tree: Parsing PDF Text Blocks into a Tree": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-pdf",
        "author": "Zhang, Yue and Zhang, Zhihao and Lai, Wenbin and Zhang, Chong and Gui, Tao and Zhang, Qi and Huang, Xuanjing",
        "booktitle": "EMNLP-findings2024",
        "title": "PDF-to-Tree: Parsing PDF Text Blocks into a Tree",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In many PDF documents, the reading order of text blocks is missing, which can hinder machine understanding of the document\u2019s content.Existing works try to extract one universal reading order for a PDF file.However, applications, like Retrieval Augmented Generation (RAG), require breaking long articles into sections and subsections for better indexing.For this reason, this paper introduces a new task and dataset, PDF-to-Tree, which organizes the text blocks of a PDF into a tree structure.Since a PDF may contain thousands of text blocks, far exceeding the number of words in a sentence, this paper proposes a transition-based parser that uses a greedy strategy to build the tree structure.Compared to parser for plain text, we also use multi-modal features to encode the parser state.Experiments show that our approach achieves an accuracy of 93.93%, surpassing the performance of baseline methods by an improvement of 6.72%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.628",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes": {
        "type": "INPROCEEDINGS",
        "key": "bandyopadhyay-etal-2024-seeing",
        "author": "Bandyopadhyay, Dibyanayan and Hasanuzzaman, Mohammed and Ekbal, Asif",
        "booktitle": "EMNLP-findings2024",
        "title": "Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Detecting offensive memes is crucial, yet standard deep neural network systems often remain opaque. Various input attribution-based methods attempt to interpret their behavior, but they face challenges with implicitly offensive memes and non-causal attributions. To address these issues, we propose a framework based on a Structural Causal Model (SCM). In this framework, VisualBERT is trained to predict the class of an input meme based on both meme input and causal concepts, allowing for transparent interpretation. Our qualitative evaluation demonstrates the framework\u2019s effectiveness in understanding model behavior, particularly in determining whether the model was right due to the right reason, and in identifying reasons behind misclassification. Additionally, quantitative analysis assesses the significance of proposed modelling choices, such as de-confounding, adversarial learning, and dynamic routing, and compares them with input attribution methods. Surprisingly, we find that input attribution methods do not guarantee causality within our framework, raising questions about their reliability in safety-critical applications. The project page is at: https://newcodevelop.github.io/causality_adventure/",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.629",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models": {
        "type": "INPROCEEDINGS",
        "key": "choi-etal-2024-cross",
        "author": "Choi, Minseok and Min, Kyunghyun and Choo, Jaegul",
        "booktitle": "EMNLP-findings2024",
        "title": "Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Pretrained language models memorize vast amounts of information, including private and copyrighted data, raising significant safety concerns. Retraining these models after excluding sensitive data is prohibitively expensive, making machine unlearning a viable, cost-effective alternative. Previous research has focused on machine unlearning for monolingual models, but we find that unlearning in one language does not necessarily transfer to others. This vulnerability makes models susceptible to low-resource language attacks, where sensitive information remains accessible in less dominant languages. This paper presents a pioneering approach to machine unlearning for multilingual language models, selectively erasing information across different languages while maintaining overall performance. Specifically, our method employs an adaptive unlearning scheme that assigns language-dependent weights to address different language performances of multilingual language models. Empirical results demonstrate the effectiveness of our framework compared to existing unlearning baselines, setting a new standard for secure and adaptable multilingual language models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.630",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages": {
        "type": "INPROCEEDINGS",
        "key": "lu-etal-2024-llamax",
        "author": "Lu, Yinquan and Zhu, Wenhao and Li, Lei and Qiao, Yu and Yuan, Fei",
        "booktitle": "EMNLP-findings2024",
        "title": "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) demonstrate remarkable translation capabilities in high-resource language tasks, yet their performance in low-resource languages is hindered by insufficient multilingual data during pre-training. To address this, we conduct extensive multilingual continual pre-training on the LLaMA series models, enabling translation support across more than 100 languages. Through a comprehensive analysis of training strategies, such as vocabulary expansion and data augmentation, we develop LLaMAX. Remarkably, without sacrificing its generalization ability, LLaMAX achieves significantly higher translation performance compared to existing open-source LLMs (by more than 10 spBLEU points) and performs on-par with specialized translation model (M2M-100-12B) on the Flores-101 benchmark. Extensive experiments indicate that LLaMAX can serve as a robust multilingual foundation model. The code and the models are publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.631",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Emotion-Cause Pair Extraction in Conversations via Center Event Detection and Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-enhancing-emotion",
        "author": "Wang, Botao and Tang, Keke and Zhu, Peican",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Emotion-Cause Pair Extraction in Conversations via Center Event Detection and Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Emotion-Cause Pair Extraction in Conversations (ECPEC) aims to identify emotion utterances and their corresponding cause utterances in unannotated conversations, this task that has garnered increasing attention recently. Previous methods often apply Emotion-Cause Pair Extraction (ECPE) task models, treating the entire conversation as a whole for contextual interaction. However, statistical analysis shows that the number of emotion-cause pairs in ECPEC conversation data far exceeds that in ECPE datasets, leading to interference among multiple events within a conversation and causing noise to propagate between different events. To address this issue, we propose a novel CEnter eveNT-guided framEwoRk (CENTER). This model introduces a Center Event Detection task to construct a center event-aware graph that captures the unique representations of different event regions. Additionally, mimicking human reasoning processes, we build a center event reasoning graph and use graph neural network to facilitate the flow of information between utterance pairs, thereby uncovering the relationships between emotions and their causes. Experimental results demonstrate that our approach achieves state-of-the-art performance across three benchmark datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.632",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Light-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models": {
        "type": "INPROCEEDINGS",
        "key": "han-etal-2024-light",
        "author": "Han, Xu and Jin, Linghao and Ma, Xuezhe and Liu, Xiaofeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Light-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Fine-tuning pre-trained Vision-Language Models (VLMs) has shown remarkable capabilities in medical image and textual depiction synergy. Nevertheless, many pre-training datasets are restricted by patient privacy concerns, potentially containing noise that can adversely affect downstream performance. Moreover, the growing reliance on multi-modal generation exacerbates this issue because of its susceptibility to adversarial attacks. To investigate how VLMs trained on adversarial noisy data perform on downstream medical tasks, we first craft noisy upstream datasets using multi-modal adversarial attacks. Through our comprehensive analysis, we unveil that moderate noise enhances model robustness and transferability, but increasing noise levels negatively impact downstream task performance. To mitigate this issue, we propose rectify adversarial noise (RAN) framework, a recipe designed to effectively defend adversarial attacks and rectify the influence of upstream noise during fine-tuning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.633",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages": {
        "type": "INPROCEEDINGS",
        "key": "deoghare-etal-2024-together",
        "author": "Deoghare, Sourabh Dattatray and Kanojia, Diptesh and Bhattacharyya, Pushpak",
        "booktitle": "EMNLP-findings2024",
        "title": "Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This exploratory study investigates the potential of multilingual Automatic Post-Editing (APE) systems to enhance the quality of machine translations for low-resource Indo-Aryan languages. Focusing on two closely related language pairs, English-Marathi and English-Hindi, we exploit the linguistic similarities to develop a robust multilingual APE model. To facilitate cross-linguistic transfer, we generate synthetic Hindi-Marathi and Marathi-Hindi APE triplets. Additionally, we incorporate a Quality Estimation (QE)-APE multi-task learning framework. While the experimental results underline the complementary nature of APE and QE, we also observe that QE-APE multitask learning facilitates effective domain adaptation. Our experiments demonstrate that the multilingual APE models outperform their corresponding English-Hindi and English-Marathi single-pair models by 2.5 and 2.39 TER points, respectively, with further notable improvements over the multilingual APE model observed through multi-task learning (+1.29 and +1.44 TER points), data augmentation (+0.53 and +0.45 TER points) and domain adaptation (+0.35 and +0.45 TER points). We release the synthetic data, code, and models accrued during this study publicly for further research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.634",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CERT-ED: Certifiably Robust Text Classification for Edit Distance": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-cert",
        "author": "Huang, Zhuoqun and Marchant, Neil G. and Ohrimenko, Olga and Rubinstein, Benjamin I. P.",
        "booktitle": "EMNLP-findings2024",
        "title": "CERT-ED: Certifiably Robust Text Classification for Edit Distance",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the growing integration of AI in daily life, ensuring the robustness of systems to inference-time attacks is crucial. Among the approaches for certifying robustness to such adversarial examples, randomized smoothing has emerged as highly promising due to its nature as a wrapper around arbitrary black-box models. Previous work on randomized smoothing in natural language processing has primarily focused on specific subsets of edit distance operations, such as synonym substitution or word insertion, without exploring the certification of all edit operations. In this paper, we adapt Randomized Deletion (Huang et al., 2023) and propose, CERTified Edit Distance defense (CERT-ED) for natural language classification. Through comprehensive experiments, we demonstrate that CERT-ED outperforms the existing Hamming distance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of both accuracy and the cardinality of the certificate. By covering various threat models, including 5 direct and 5 transfer attacks, our method improves empirical robustness in 38 out of 50 settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.635",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "he-etal-2024-complex",
        "author": "He, Qianyu and Zeng, Jie and He, Qianxi and Liang, Jiaqing and Xiao, Yanghua",
        "booktitle": "EMNLP-findings2024",
        "title": "From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "It is imperative for Large language models (LLMs) to follow instructions with elaborate requirements (i.e. Complex Instructions Following). Yet, it remains under-explored how to enhance the ability of LLMs to follow complex instructions with multiple constraints. To bridge the gap, we initially study what training data is effective in enhancing complex constraints following abilities. We found that training LLMs with instructions containing multiple constraints enhances their understanding of complex instructions, especially those with lower complexity levels. Additionally, we further propose methods addressing how to obtain and utilize the effective training data. Finally, we conduct extensive experiments to prove the effectiveness of our methods in terms of overall performance and training efficiency. We also demonstrate that our methods improve models\u2019 ability to follow instructions generally and generalize effectively across out-of-domain, in domain, and adversarial settings, while maintaining general capabilities.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.637",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents": {
        "type": "INPROCEEDINGS",
        "key": "xiao-etal-2024-flowbench",
        "author": "Xiao, Ruixuan and Ma, Wentao and Wang, Ke and Wu, Yuchuan and Zhao, Junbo and Wang, Haobo and Huang, Fei and Li, Yongbin",
        "booktitle": "EMNLP-findings2024",
        "title": "FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "LLM-based agents have emerged as promising tools, which are crafted to fulfill complex tasks by iterative planning and action. However, these agents are susceptible to undesired planning hallucinations when lacking specific knowledge for expertise-intensive tasks. To address this, preliminary attempts are made to enhance planning reliability by incorporating external workflow-related knowledge. Despite the promise, such infused knowledge is mostly disorganized and diverse in formats, lacking rigorous formalization and comprehensive comparisons. Motivated by this, we formalize different formats of workflow knowledge and present FlowBench, the first benchmark for workflow-guided planning. FlowBench covers 51 different scenarios from 6 domains, with knowledge presented in diverse formats. To assess different LLMs on FlowBench, we design a multi-tiered evaluation framework. We evaluate the efficacy of workflow knowledge across multiple formats, and the results indicate that current LLM agents need considerable improvements for satisfactory planning. We hope that our challenging benchmark can pave the way for future agent planning research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.638",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Mental Disorder Classification via Temporal Representation of Text": {
        "type": "INPROCEEDINGS",
        "key": "kumar-etal-2024-mental",
        "author": "Kumar, Raja and Maharaj, Kishan and Saxena, Ashita and Bhattacharyya, Pushpak",
        "booktitle": "EMNLP-findings2024",
        "title": "Mental Disorder Classification via Temporal Representation of Text",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Mental disorders pose a global challenge, aggravated by the shortage of qualified mental health professionals. Mental disorder prediction from social media posts by current LLMs is challenging due to the complexities of sequential text data and the limited context length of language models. Current language model-based approaches split a single data instance into multiple chunks to compensate for limited context size. The predictive model is then applied to each chunk individually, and the most voted output is selected as the final prediction. This results in the loss of inter-post dependencies and important time variant information, leading to poor performance. We propose a novel framework which first compresses the large sequence of chronologically ordered social media posts into a series of numbers. We then use this time variant representation for mental disorder classification. We demonstrate the generalization capabilities of our framework by outperforming the current SOTA in three different mental conditions: depression, self-harm, and anorexia, by an absolute improvement of 5% in the F1 score. We also investigate the situation when current data instances fall within the context length of language models and present empirical results highlighting the importance of temporal properties of textual data. Furthermore, we utilize the proposed framework for a cross-domain study, exploring commonalities across disorders and the possibility of inter-domain data usage.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.639",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-beyond-single",
        "author": "Chen, Yiming and Yue, Xianghu and Gao, Xiaoxue and Zhang, Chen and D\u2019Haro, Luis Fernando and Tan, Robby T. and Li, Haizhou",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Various audio-LLMs (ALLMs) have been explored recently for tackling different audio tasks simultaneously using a single, unified model. While existing evaluations of ALLMs primarily focus on single-audio tasks, real-world applications often involve processing multiple audio streams simultaneously. To bridge this gap, we propose the first multi-audio evaluation (MAE) benchmark that consists of 20 datasets from 11 multi-audio tasks encompassing both speech and sound scenarios. Comprehensive experiments on MAE demonstrate that the existing ALLMs, while being powerful in comprehending primary audio elements in individual audio inputs, struggling to handle multi-audio scenarios. To this end, we propose a novel multi-audio-LLM (MALLM) to capture audio context among multiple similar audios using discriminative learning on our proposed synthetic data. The results demonstrate that the proposed MALLM outperforms all baselines and achieves high data efficiency using synthetic data without requiring human annotations. The proposed MALLM opens the door for ALLMs towards multi-audio processing era and brings us closer to replicating human auditory capabilities in machines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.640",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multimodal Procedural Planning via Dual Text-Image Prompting": {
        "type": "INPROCEEDINGS",
        "key": "lu-etal-2024-multimodal",
        "author": "Lu, Yujie and Lu, Pan and Chen, Zhiyu and Zhu, Wanrong and Wang, Xin Eric and Wang, William Yang",
        "booktitle": "EMNLP-findings2024",
        "title": "Multimodal Procedural Planning via Dual Text-Image Prompting",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Embodied agents have achieved prominent performance in following human instructions to complete tasks. However, the potential of providing instructions informed by texts and images to assist humans in completing tasks remains underexplored. To uncover this capability, we present the multimodal procedural planning (MPP) task, in which models are given a high-level goal and generate plans of paired text-image steps, providing more complementary and informative guidance than unimodal plans. The key challenges of MPP are to ensure the informativeness, temporal coherence,and accuracy of plans across modalities. To tackle this, we propose Text-Image Prompting (TIP), a dual-modality prompting method that jointly leverages zero-shot reasoning ability in large language models (LLMs) and compelling text-to-image generation ability from diffusion-based models. TIP improves the interaction in the dual modalities using Text-to-Image Bridge and Image-to-Text Bridge, allowing LLMs to guide the textual-grounded image plan generation and leveraging the descriptions of image plans to ground the textual plan reversely. To address the lack of relevant datasets, we collect WIKIPLAN and RECIPEPLAN as a testbed for MPP. Our results show compelling human preferences and automatic scores against unimodal and multimodal baselines on WIKIPLAN and RECIPEPLAN in terms of informativeness, temporal coherence, and plan accuracy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.641",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Functionality learning through specification instructions": {
        "type": "INPROCEEDINGS",
        "key": "luz-de-araujo-roth-2024-functionality",
        "author": "Luz De Araujo, Pedro Henrique and Roth, Benjamin",
        "booktitle": "EMNLP-findings2024",
        "title": "Functionality learning through specification instructions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Test suites assess natural language processing models\u2019 performance on specific functionalities: cases of interest involving model robustness, fairness, or particular linguistic capabilities. This paper introduces specification instructions: text descriptions specifying fine-grained task-specific behaviors. For each functionality in a suite, we generate an instruction that describes it. We combine the specification instructions to create specification-augmented prompts, which we feed to language models pre-trained on natural instruction data.We conduct experiments to measure how optimizing for some functionalities may negatively impact functionalities that are not covered by the specification set. Our analyses across four tasks and models of diverse sizes and families show that smaller models struggle to follow specification instructions. However, larger models (\\textgreater 3B params.) can benefit from specifications and\u2014surprisingly\u2014even generalize certain desirable behaviors across functionalities.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.642",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DictDis: Dictionary Constrained Disambiguation for Improved NMT": {
        "type": "INPROCEEDINGS",
        "key": "maheshwari-etal-2024-dictdis",
        "author": "Maheshwari, Ayush and Jyothi, Preethi and Ramakrishnan, Ganesh",
        "booktitle": "EMNLP-findings2024",
        "title": "DictDis: Dictionary Constrained Disambiguation for Improved NMT",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Domain-specific neural machine translation (NMT) systems (, in educational applications) are socially significant with the potential to help make information accessible to a diverse set of users in multilingual societies. Such NMT systems should be lexically constrained and draw from domain-specific dictionaries. Dictionaries could present multiple candidate translations for a source word/phrase due to the polysemous nature of words. The onus is then on the NMT model to choose the contextually most appropriate candidate. Prior work has largely ignored this problem and focused on the single candidate constraint setting wherein the target word or phrase is replaced by a single constraint. In this work, we present DictDis, a lexically constrained NMT system that disambiguates between multiple candidate translations derived from dictionaries. We achieve this by augmenting training data with multiple dictionary candidates to actively encourage disambiguation during training by implicitly aligning multiple candidate constraints. We demonstrate the utility of DictDis via extensive experiments on English-Hindi, English-German, and English-French datasets across a variety of domains including regulatory, finance, engineering, health and standard benchmark test datasets. In comparison with existing approaches for lexically constrained and unconstrained NMT, we demonstrate superior performance for the copy constraint and disambiguation-related measures on all domains, while also obtaining improved fluency of up to 2-3 BLEU points on some domains. We also release our test set consisting of 4K English-Hindi sentences in multiple domains.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.643",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Fighting Randomness with Randomness: Mitigating Optimisation Instability of Fine-Tuning using Delayed Ensemble and Noisy Interpolation": {
        "type": "INPROCEEDINGS",
        "key": "pecher-etal-2024-fighting",
        "author": "Pecher, Branislav and Cegin, Jan and Belanec, Robert and Simko, Jakub and Srba, Ivan and Bielikova, Maria",
        "booktitle": "EMNLP-findings2024",
        "title": "Fighting Randomness with Randomness: Mitigating Optimisation Instability of Fine-Tuning using Delayed Ensemble and Noisy Interpolation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While fine-tuning of pre-trained language models generally helps to overcome the lack of labelled training samples, it also displays model performance instability. This instability mainly originates from randomness in initialisation or data shuffling. To address this, researchers either modify the training process or augment the available samples, which typically results in increased computational costs. We propose a new mitigation strategy, called **Delayed Ensemble with Noisy Interpolation (DENI)**, that leverages the strengths of ensembling, noise regularisation and model interpolation, while retaining computational efficiency. We compare DENI with 9 representative mitigation strategies across 3 models, 4 tuning strategies and 7 text classification datasets. We show that: 1) DENI outperforms the best performing mitigation strategy (Ensemble), while using only a fraction of its cost; 2) the mitigation strategies are beneficial for parameter-efficient fine-tuning (PEFT) methods, outperforming full fine-tuning in specific cases; and 3) combining DENI with data augmentation often leads to even more effective instability mitigation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.644",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Rethinking Code Refinement: Learning to Judge Code Efficiency": {
        "type": "INPROCEEDINGS",
        "key": "seo-etal-2024-rethinking",
        "author": "Seo, Minju and Baek, Jinheon and Hwang, Sung Ju",
        "booktitle": "EMNLP-findings2024",
        "title": "Rethinking Code Refinement: Learning to Judge Code Efficiency",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in understanding and generating codes. Due to these capabilities, many recent methods are proposed to automatically refine the codes with LLMs. However, we should rethink that the refined codes (from LLMs and even humans) are not always more efficient than their original versions. On the other hand, running two different versions of codes and comparing them every time is not ideal and time-consuming. Therefore, in this work, we propose a novel method based on the code language model that is trained to judge the efficiency between two different codes (generated across humans and machines) by either classifying the superior one or predicting the relative improvement. We validate our method on multiple programming languages with multiple refinement steps, demonstrating that the proposed method can effectively distinguish between more and less efficient versions of code.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.645",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability": {
        "type": "INPROCEEDINGS",
        "key": "chung-etal-2024-selection",
        "author": "Chung, Tsz Ting and Cui, Leyang and Liu, Lemao and Huang, Xinting and Shi, Shuming and Yeung, Dit-Yan",
        "booktitle": "EMNLP-findings2024",
        "title": "Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in a wide range of natural language processing tasks when leveraging in-context learning. To mitigate the additional computational and financial costs associated with in-context learning, several prompt compression methods have been proposed to compress the in-context learning prompts. Despite their success, these methods face challenges with transferability due to model-specific compression, or rely on external training data, such as GPT-4. In this paper, we investigate the ability of LLMs to develop a unified compression method that discretizes uninformative tokens, utilizing a self-supervised pre-training technique. By introducing a small number of parameters during the continual pre-training, the proposed Selection-p produces a probability for each input token, indicating whether to preserve or discard it. Experiments show Selection-p achieves state-of-the-art performance across numerous classification tasks, achieving compression rates of up to 10 times while experiencing only a marginal 0.8% decrease in performance. Moreover, it exhibits superior transferability to different models compared to prior work. Additionally, we further analyze how Selection-p helps maintain performance on in-context learning with long contexts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.646",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities": {
        "type": "INPROCEEDINGS",
        "key": "bi-etal-2024-adaptive",
        "author": "Bi, Baolong and Liu, Shenghua and Wang, Yiwei and Mei, Lingrui and Gao, Hongcheng and Xu, Yilong and Cheng, Xueqi",
        "booktitle": "EMNLP-findings2024",
        "title": "Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The parametric knowledge memorized by large language models (LLMs) becomes outdated quickly. In-context editing (ICE) is currently the most effective method for updating the knowledge of LLMs. Recent advancements involve enhancing ICE by modifying the decoding strategy, obviating the need for altering internal model structures or adjusting external prompts.However, this enhancement operates across the entire sequence generation, encompassing a plethora of non-critical tokens.In this work, we introduce **A**daptive **T**oken **Bias**er (ATBias), a new decoding technique designed to enhance ICE.It focuses on the tokens that are mostly related to knowledge during decoding, biasing their logits by matching key entities related to new and parametric knowledge.Experimental results show that ATBias significantly enhances ICE performance, achieving up to a 32.3% improvement over state-of-the-art ICE methods while incurring only half the latency.ATBias not only improves the knowledge editing capabilities of ICE but can also be widely applied to LLMs with negligible cost.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.647",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Factual Consistency of News Summarization by Contrastive Preference Optimization": {
        "type": "INPROCEEDINGS",
        "key": "feng-etal-2024-improving-factual",
        "author": "Feng, Huawen and Fan, Yan and Liu, Xiong and Lin, Ting-En and Yao, Zekun and Wu, Yuchuan and Huang, Fei and Li, Yongbin and Ma, Qianli",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Factual Consistency of News Summarization by Contrastive Preference Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite the recent progress in news summarization made by large language models (LLMs), they often generate summaries that are factually inconsistent with original articles, known as \u201challucinations\u201d in text generation. Unlike previous small models (e.g., BART, T5), current LLMs make fewer silly mistakes but more sophisticated ones, such as imposing cause and effect, adding false details, overgeneralizing, etc. These hallucinations are challenging to detect through traditional methods, which poses great challenges for improving the factual consistency of text summarization. In this paper, we propose Contrastive Preference Optimization (CPO) to disentangle the LLMs\u2019 propensities to generate faithful and fake content. Furthermore, we adopt a probing-based specific training method to improve their capacity of distinguishing two types of propensities. In this way, LLMs can execute the instructions more accurately and have enhanced perception of hallucinations. Experimental results show that CPO significantly improves the reliability of summarization based on LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.648",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding": {
        "type": "INPROCEEDINGS",
        "key": "suglia-etal-2024-alanavlm",
        "author": "Suglia, Alessandro and Greco, Claudio and Baker, Katie and Part, Jose L. and Papaioannou, Ioannis and Eshghi, Arash and Konstas, Ioannis and Lemon, Oliver",
        "booktitle": "EMNLP-findings2024",
        "title": "AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "AI personal assistants deployed via robots or wearables require embodied understanding to collaborate with humans effectively. However, current Vision-Language Models (VLMs) primarily focus on third-person view videos, neglecting the richness of egocentric perceptual experience. To address this gap, we propose three key contributions. First, we introduce the Egocentric Video Understanding Dataset (EVUD) for training VLMs on video captioning and question answering tasks specific to egocentric videos. Second, we present , a 7B parameter VLM trained using parameter-efficient methods on EVUD. Finally, we evaluate \u2018s capabilities on OpenEQA, a challenging benchmark for embodied video question answering. Our model achieves state-of-the-art performance, outperforming open-source models including strong Socratic models using GPT-4 as a planner by 3.6%.Additionally, we outperform Claude 3 and Gemini Pro Vision 1.0 and showcase competitive results compared to Gemini Pro 1.5 and GPT-4V, even surpassing the latter in spatial reasoning. This research paves the way for building efficient VLMs that can be deployed in robots or wearables, leveraging embodied video understanding to collaborate seamlessly with humans in everyday tasks, contributing to the advancement of next-generation Embodied AI.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.649",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias": {
        "type": "INPROCEEDINGS",
        "key": "koo-etal-2024-platform",
        "author": "Koo, Minseo and Kim, Doeun and Han, Sungwon and Park, Sungkyu Shaun",
        "booktitle": "EMNLP-findings2024",
        "title": "Platform-Invariant Topic Modeling via Contrastive Learning to Mitigate Platform-Induced Bias",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Cross-platform topic dissemination is one of the research subjects that delved into media analysis; sometimes it fails to grasp the authentic topics due to platform-induced biases, which may be caused by aggregating documents from multiple platforms and running them on an existing topic model. This work deals with the impact of unique platform characteristics on the performance of topic models and proposes a new approach to enhance the effectiveness of topic modeling. The data utilized in this study consisted of a total of 1.5 million posts collected using the keyword \u201dChatGPT\u201d on the three social media platforms. The devised model reduces platform influence in topic models by developing a platform-invariant contrastive learning algorithm and removing platform-specific jargon word sets. The proposed approach was thoroughly validated through quantitative and qualitative experiments alongside standard and state-of-the-art topic models and showed its supremacy. This method can mitigate biases arising from platform influences when modeling topics from texts collected across various platforms.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.650",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MAVEN-FACT: A Large-scale Event Factuality Detection Dataset": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-maven",
        "author": "Li, Chunyang and Peng, Hao and Wang, Xiaozhi and Qi, Yunjia and Hou, Lei and Xu, Bin and Li, Juanzi",
        "booktitle": "EMNLP-findings2024",
        "title": "MAVEN-FACT: A Large-scale Event Factuality Detection Dataset",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Event Factuality Detection (EFD) task determines the factuality of textual events, i.e., classifying whether an event is a fact, possibility, or impossibility, which is essential for faithfully understanding and utilizing event knowledge. However, due to the lack of high-quality large-scale data, event factuality detection is under-explored in event understanding research, which limits the development of EFD community. To address these issues and provide faithful event understanding, we introduce MAVEN-FACT, a large-scale and high-quality EFD dataset based on the MAVEN dataset. MAVEN-FACT includes factuality annotations of 112,276 events, making it the largest EFD dataset. Extensive experiments demonstrate that MAVEN-FACT is challenging for both conventional fine-tuned models and large language models (LLMs). Thanks to the comprehensive annotations of event arguments and relations in MAVEN, MAVEN-FACT also supports some further analyses and we find that adopting event arguments and relations helps in event factuality detection for fine-tuned models but does not benefit LLMs. Furthermore, we preliminarily study an application case of event factuality detection and find it helps in mitigating event-related hallucination in LLMs. We will release our dataset and codes to facilitate further research on event factuality detection.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.651",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft": {
        "type": "INPROCEEDINGS",
        "key": "ch-etal-2024-retrieval",
        "author": "Ch, Kranti and Hakimov, Sherzod and Schlangen, David",
        "booktitle": "EMNLP-findings2024",
        "title": "Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In the Minecraft Collaborative Building Task, two players collaborate: an Architect (A) provides instructions to a Builder (B) to assemble a specified structure using 3D blocks. In this work, we investigate the use of large language models (LLMs) to predict the sequence of actions taken by the Builder. Leveraging LLMs\u2019 in-context learning abilities, we use few-shot prompting techniques, that significantly improve performance over baseline methods. Additionally, we present a detailed analysis of the gaps in performance for future work.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.652",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis": {
        "type": "INPROCEEDINGS",
        "key": "seo-etal-2024-make",
        "author": "Seo, Yongsik and Song, Sungwon and Heo, Ryang and Kim, Jieyong and Lee, Dongha",
        "booktitle": "EMNLP-findings2024",
        "title": "Make Compound Sentences Simple to Analyze: Learning to Split Sentences for Aspect-based Sentiment Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In the domain of Aspect-Based Sentiment Analysis (ABSA), generative methods have shown promising results and achieved substantial advancements. However, despite these advancements, the tasks of extracting sentiment quadruplets, which capture the nuanced sentiment expressions within a sentence, remain significant challenges. In particular, compound sentences can potentially contain multiple quadruplets, making the extraction task increasingly difficult as sentence complexity grows. To address this issue, we are focusing on simplifying sentence structures to facilitate the easier recognition of these elements and crafting a model that integrates seamlessly with various ABSA tasks. In this paper, we propose Aspect Term Oriented Sentence Splitter (ATOSS), which simplifies compound sentence into simpler and clearer forms, thereby clarifying their structure and intent. As a plug-and-play module, this approach retains the parameters of the ABSA model while making it easier to identify essential intent within input sentences. Extensive experimental results show that utilizing ATOSS outperforms existing methods in both ASQP and ACOS tasks, which are the primary tasks for extracting sentiment quadruplets",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.653",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement": {
        "type": "INPROCEEDINGS",
        "key": "ying-etal-2024-llms",
        "author": "Ying, Jiahao and Lin, Mingbao and Cao, Yixin and Tang, Wei and Wang, Bo and Sun, Qianru and Huang, Xuanjing and Yan, Shuicheng",
        "booktitle": "EMNLP-findings2024",
        "title": "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper introduces the innovative \u201cLLMs-as-Instructors\u201d framework, which leverages the advanced Large Language Models (LLMs) to autonomously enhance the training of smaller target models. Inspired by the theory of \u201cLearning from Errors\u201d, this framework employs an instructor LLM to meticulously analyze the specific errors within a target model, facilitating targeted and efficient training cycles. Within this framework, we implement two strategies: \u201cLearning from Error,\u201d which focuses solely on incorrect responses to tailor training data, and \u201cLearning from Error by Contrast,\u201d which uses contrastive learning to analyze both correct and incorrect responses for a deeper understanding of errors. Our empirical studies, conducted with several open-source models, demonstrate significant improvements across multiple benchmarks, including mathematical reasoning, coding abilities, and factual knowledge. Notably, the refined Llama-3-8b-Instruction has outperformed ChatGPT, illustrating the effectiveness of our approach. By leveraging the strengths of both strategies, we have attained a more balanced performance improvement on both in-domain and out-of-domain benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.654",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ITER: Iterative Transformer-based Entity Recognition and Relation Extraction": {
        "type": "INPROCEEDINGS",
        "key": "hennen-etal-2024-iter",
        "author": "Hennen, Moritz and Babl, Florian and Geierhos, Michaela",
        "booktitle": "EMNLP-findings2024",
        "title": "ITER: Iterative Transformer-based Entity Recognition and Relation Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "When extracting structured information from text, recognizing entities and extracting relationships are essential. Recent advances in both tasks generate a structured representation of the information in an autoregressive manner, a time-consuming and computationally expensive approach. This naturally raises the question of whether autoregressive methods are necessary in order to achieve comparable results. In this work, we propose ITER, an efficient encoder-based relation extraction model, that performs the task in three parallelizable steps, greatly accelerating a recent language modeling approach: ITER achieves an inference throughput of over 600 samples per second for a large model on a single consumer-grade GPU. Furthermore, we achieve state-of-the-art results on the relation extraction datasets ADE and ACE05, and demonstrate competitive performance for both named entity recognition with GENIA and CoNLL03, and for relation extraction with SciERC and CoNLL04.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.655",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval": {
        "type": "INPROCEEDINGS",
        "key": "furumai-etal-2024-zero",
        "author": "Furumai, Kazuaki and Legaspi, Roberto and Romero, Julio Cesar Vizcarra and Yamazaki, Yudai and Nishimura, Yasutaka and Semnani, Sina and Ikeda, Kazushi and Shi, Weiyan and Lam, Monica",
        "booktitle": "EMNLP-findings2024",
        "title": "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Persuasion plays a pivotal role in a wide range of applications from health intervention to the promotion of social good. Persuasive chatbots employed responsibly for social good can be an enabler of positive individual and social change. Existing methods rely on fine-tuning persuasive chatbots with task-specific training data which is costly, if not infeasible, to collect. Furthermore, they employ only a handful of pre-defined persuasion strategies. We propose PersuaBot, a zero-shot chatbot based on Large Language Models (LLMs) that is factual and more persuasive by leveraging many more nuanced strategies. PersuaBot uses an LLM to first generate a natural responses, from which the strategies used are extracted. To combat hallucination of LLMs, Persuabot replace any unsubstantiated claims in the response with retrieved facts supporting the extracted strategies. We applied our chatbot, PersuaBot, to three significantly different domains needing persuasion skills: donation solicitation, recommendations, and health intervention. Our experiments on simulated and human conversations show that our zero-shot approach is more persuasive than prior work, while achieving factual accuracy surpassing state-of-the-art knowledge-oriented chatbots.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.656",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Logits Reranking via Semantic Labels for Hard Samples in Text Classification": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-logits",
        "author": "Huang, Peijie and Huang, Junbao and Xu, Yuhong and Li, Weizhen and Xiao, Xisheng",
        "booktitle": "EMNLP-findings2024",
        "title": "Logits Reranking via Semantic Labels for Hard Samples in Text Classification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Pre-trained Language Models (PLMs) have achieved significant success in text classification. However, they still face challenges with hard samples, which refer to instances where the model exhibits diminished confidence in distinguishing new samples. Existing research has addressed related issues, but often overlooks the semantic information inherent in the labels, treating them merely as one-hot vectors. In this paper, we propose Logits Reranking via Semantic Labels (LRSL), a model-agnostic post-processing method that leverages label semantics and auto detection of hard samples to improve classification accuracy. LRSL automatically identifies hard samples, which are then jointly processed by MLP-based and Similarity-based approaches. Applied only during inference, LRSL operates solely on classification logits, reranking them based on semantic similarities without interfering with the model\u2019s training process. The experiments demonstrate the effectiveness of our method, showing significant improvements across different PLMs. Our codes are publicly available at https://github.com/SIGSDSscau/LRSL.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.657",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Scaling Laws for Fact Memorization of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "lu-etal-2024-scaling",
        "author": "Lu, Xingyu and Li, Xiaonan and Cheng, Qinyuan and Ding, Kai and Huang, Xuanjing and Qiu, Xipeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Scaling Laws for Fact Memorization of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Fact knowledge memorization is crucial for Large Language Models (LLM) to generate factual and reliable responses. However, the behaviors of LLM fact memorization remain under-explored. In this paper, we analyze the scaling laws for LLM\u2019s fact knowledge and LLMs\u2019 behaviors of memorizing different types of facts. We find that LLMs\u2019 fact knowledge capacity has a linear and negative exponential law relationship with model size and training epochs, respectively. Estimated by the built scaling law, memorizing the whole Wikidata\u2019s facts requires training an LLM with 1000B non-embed parameters for 100 epochs, suggesting that using LLMs to memorize all public facts is almost implausible for a general pre-training setting. Meanwhile, we find that LLMs can generalize on unseen fact knowledge and its scaling law is similar to general pre-training. Additionally, we analyze the compatibility and preference of LLMs\u2019 fact memorization. For compatibility, we find LLMs struggle with memorizing redundant facts in a unified way. Only when correlated facts have the same direction and structure, the LLM can compatibly memorize them. This shows the inefficiency of LLM memorization for redundant facts. For preference, the LLM pays more attention to memorizing more frequent and difficult facts, and the subsequent facts can overwrite prior facts\u2019 memorization, which significantly hinders low-frequency facts memorization. Our findings reveal the capacity and characteristics of LLMs\u2019 fact knowledge learning, which provide directions for LLMs\u2019 fact knowledge augmentation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.658",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Leveraging Web-Crawled Data for High-Quality Fine-Tuning": {
        "type": "INPROCEEDINGS",
        "key": "zhou-etal-2024-leveraging",
        "author": "Zhou, Jing and Jiang, Chenglin and Shen, Wei and Zhou, Xiao and He, Xiaonan",
        "booktitle": "EMNLP-findings2024",
        "title": "Leveraging Web-Crawled Data for High-Quality Fine-Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Most large language models are fine-tuned using either expensive human-annotated data or GPT-4 generated data which cannot guarantee performance in certain domains. We argue that although the web-crawled data often has formatting errors causing semantic inaccuracies, it can still serve as a valuable source for high-quality supervised fine-tuning in specific domains without relying on advanced models like GPT-4. To this end, we create a paired training dataset automatically by aligning web-crawled data with a smaller set of high-quality data. By training a language model on this dataset, we can convert web data with irregular formats into high-quality ones. Our experiments show that training with the model-transformed data yields better results, surpassing training with only high-quality data by an average score of 9.4% in Chinese math problems. Additionally, our 7B model outperforms several open-source models larger than 32B and surpasses well-known closed-source models such as GPT-3.5, highlighting the efficacy of our approach. We have released our code at https://github.com/zhouj8553/Web_to_SFT.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.660",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs": {
        "type": "INPROCEEDINGS",
        "key": "cheng-etal-2024-optimize",
        "author": "Cheng, Wenhua and Zhang, Weiwei and Shen, Haihao and Cai, Yiyang and He, Xin and Kaokao, Lv and Liu, Yi",
        "booktitle": "EMNLP-findings2024",
        "title": "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have demonstrated exceptional proficiency in language-related tasks, but their deployment poses significant challenges due to substantial memory and storage requirements. Weight-only quantization has emerged as a promising solution to address these challenges. Previous research suggests that fine-tuning through up and down rounding can enhance performance. In this study, we introduce SignRound, a method that utilizes signed gradient descent (SignSGD) to optimize rounding values and weight clipping within just 200 steps. SignRound integrates the advantages of Quantization-Aware Training (QAT) and Post-Training Quantization (PTQ), achieving exceptional results across 2 to 4 bits while maintaining low tuning costs and avoiding additional inference overhead. For example, SignRound achieves absolute average accuracy improvements ranging from 6.91% to 33.22% at 2 bits, as measured by the average zero-shot accuracy across 11 tasks. It also demonstrates strong generalization to recent models, achieving near-lossless 4-bit quantization in most scenarios. The source code will be made publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.662",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Using LLMs to simulate students\u2019 responses to exam questions": {
        "type": "INPROCEEDINGS",
        "key": "benedetto-etal-2024-using",
        "author": "Benedetto, Luca and Aradelli, Giovanni and Donvito, Antonia and Lucchetti, Alberto and Cappelli, Andrea and Buttery, Paula",
        "booktitle": "EMNLP-findings2024",
        "title": "Using LLMs to simulate students\u2019 responses to exam questions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Previous research leveraged Large Language Models (LLMs) in numerous ways in the educational domain. Here, we show that they can be used to answer exam questions simulating students of different skill levels and share a prompt, engineered for GPT-3.5, that enables the simulation of varying student skill levels on questions from different educational domains. We evaluate the proposed prompt on three publicly available datasets (one from science exams and two from English reading comprehension exams) and three LLMs (two versions of GPT-3.5 and one of GPT-4), and show that it is robust to different educational domains and capable of generalising to data unseen during the prompt engineering phase. We also show that, being engineered for a specific version of GPT-3.5, the prompt does not generalise well to different LLMs, stressing the need for prompt engineering for each model in practical applications. Lastly, we find that there is not a direct correlation between the quality of the rationales obtained with chain-of-thought prompting and the accuracy in the student simulation task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.663",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HSDreport: Heart Sound Diagnosis with Echocardiography Reports": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-hsdreport",
        "author": "Zhao, Zihan and Wang, Pingjie and Zhao, Liudan and Yang, Yuchen and Zhang, Ya and Sun, Kun and Sun, Xin and Zhou, Xin and Wang, Yu and Wang, Yanfeng",
        "booktitle": "EMNLP-findings2024",
        "title": "HSDreport: Heart Sound Diagnosis with Echocardiography Reports",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Heart sound auscultation holds significant importance in the diagnosis of congenital heart disease. However, existing methods for Heart Sound Diagnosis (HSD) tasks are predominantly limited to a few fixed categories, framing the HSD task as a rigid classification problem that does not fully align with medical practice and offers only limited information to physicians. Besides, such methods do not utilize echocardiography reports, the gold standard in the diagnosis of related diseases. To tackle this challenge, we introduce HSDreport, a new benchmark for HSD, which mandates the direct utilization of heart sounds obtained from auscultation to predict echocardiography reports. This benchmark aims to merge the convenience of auscultation with the comprehensive nature of echocardiography reports. First, we collect a new dataset for this benchmark, comprising 2,275 heart sound samples along with their corresponding reports. Subsequently, we develop a knowledge-aware query-based transformer to handle this task. The intent is to leverage the capabilities of medically pre-trained models and the internal knowledge of large language models (LLMs) to address the task\u2019s inherent complexity and variability, thereby enhancing the robustness and scientific validity of the method. Furthermore, our experimental results indicate that our method significantly outperforms traditional HSD approaches and existing multimodal LLMs in detecting key abnormalities in heart sounds.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.664",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement": {
        "type": "INPROCEEDINGS",
        "key": "chang-etal-2024-repairing",
        "author": "Chang, Zhiyuan and Li, Mingyang and Wang, Junjie and Liu, Yi and Wang, Qing and Liu, Yang",
        "booktitle": "EMNLP-findings2024",
        "title": "Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Text-to-Image Diffusion Models (T2I DMs) have garnered significant attention for their ability to generate high-quality images from textual descriptions.However, these models often produce images that do not fully align with the input prompts, resulting in semantic inconsistencies.The most prominent issue among these semantic inconsistencies is catastrophic-neglect, where the images generated by T2I DMs miss key objects mentioned in the prompt.We first conduct an empirical study on this issue, exploring the prevalence of catastrophic-neglect, potential mitigation strategies with feature enhancement, and the insights gained.Guided by the empirical findings, we propose an automated repair approach named Patcher to address catastrophic-neglect in T2I DMs.Specifically, Patcher first determines whether there are any neglected objects in the prompt, and then applies attention-guided feature enhancement to these neglected objects, resulting in a repaired prompt.Experimental results on three versions of Stable Diffusion demonstrate that Patcher effectively repairs the issue of catastrophic-neglect, achieving 10.1%-16.3% higher Correct Rate in image generation compared to baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.665",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing": {
        "type": "INPROCEEDINGS",
        "key": "yeo-etal-2024-visual",
        "author": "Yeo, Jeonghun and Han, Seunghee and Kim, Minsu and Ro, Yong Man",
        "booktitle": "EMNLP-findings2024",
        "title": "Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In visual speech processing, context modeling capability is one of the most important requirements due to the ambiguous nature of lip movements. For example, homophenes, words that share identical lip movements but produce different sounds, can be distinguished by considering the context. In this paper, we propose a novel framework, namely Visual Speech Processing incorporated with LLMs (VSP-LLM), to maximize the context modeling ability by bringing the overwhelming power of LLMs. Specifically, VSP-LLM is designed to perform multi-tasks of visual speech recognition and translation, where the given instructions control the type of task. The input video is mapped to the input latent space of an LLM by employing a self-supervised visual speech model. Focused on the fact that there is redundant information in input frames, we propose a novel deduplication method that reduces the embedded visual features by employing visual speech units. Through the proposed deduplication and low rank adaptation, VSP-LLM can be trained in a computationally efficient manner. In the translation dataset, the MuAViC benchmark, we demonstrate that VSP-LLM trained on just 30 hours of labeled data can more effectively translate compared to the recent model trained with 433 hours of data.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.666",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MDCR: A Dataset for Multi-Document Conditional Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-mdcr",
        "author": "Chen, Peter Baile and Zhang, Yi and Liu, Chunwei and Gupta, Sejal and Kim, Yoon and Cafarella, Mike",
        "booktitle": "EMNLP-findings2024",
        "title": "MDCR: A Dataset for Multi-Document Conditional Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The same real-life questions posed to different individuals may lead to different answers based on their unique situations. For instance, whether a student is eligible for a scholarship depends on eligibility conditions, such as major or degree required. ConditionalQA was proposed to evaluate models\u2019 capability of reading a document and answering eligibility questions, considering *unmentioned* conditions. However, it is limited to questions on single documents, neglecting harder cases that may require *cross-document reasoning* and *optimization*, for example, \u201cWhat is the maximum number of scholarships attainable?\u201d Such questions over multiple documents are not only more challenging due to more context to understand, but also because the model has to (1) explore all possible combinations of unmentioned conditions and (2) understand the relationship between conditions across documents, to reason about the optimal outcome. To evaluate models\u2019 capability of answering such questions, we propose a new dataset MDCR, which can reflect real-world challenges and serve as a new test bed for complex conditional reasoning that requires optimization. We evaluate this dataset using the most recent LLMs and demonstrate their limitations in solving this task. We believe this dataset will facilitate future research in answering optimization questions with unknown conditions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.667",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-will",
        "author": "Kim, Kyusik and Jeon, Hyeonseok and Ryu, Jeongwoo and Suh, Bongwon",
        "booktitle": "EMNLP-findings2024",
        "title": "Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated their ability to simulate human-like decision-making, yet the impact of psychological pressures on their decision-making processes remains underexplored. To understand how psychological pressures influence decision-making in LLMs, we tested LLMs on various high-level tasks, using both explicit and implicit pressure prompts. Moreover, we examined LLM responses under different personas to compare with human behavior under pressure. Our findings show that pressures significantly affect LLMs\u2019 decision-making, varying across tasks and models. Persona-based analysis suggests some models exhibit human-like sensitivity to pressure, though with some variability. Furthermore, by analyzing both the responses and reasoning patterns, we identified the values LLMs prioritize under specific social pressures. These insights deepen our understanding of LLM behavior and demonstrate the potential for more realistic social simulation experiments.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.668",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Zero-shot Commonsense Reasoning over Machine Imagination": {
        "type": "INPROCEEDINGS",
        "key": "park-etal-2024-zero",
        "author": "Park, Hyuntae and Kim, Yeachan and Park, Jun-Hyung and Lee, SangKeun",
        "booktitle": "EMNLP-findings2024",
        "title": "Zero-shot Commonsense Reasoning over Machine Imagination",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent approaches to zero-shot commonsense reasoning have enabled Pre-trained Language Models (PLMs) to learn a broad range of commonsense knowledge without being tailored to specific situations. However, they often suffer from human reporting bias inherent in textual commonsense knowledge, leading to discrepancies in understanding between PLMs and humans. In this work, we aim to bridge this gap by introducing an additional information channel to PLMs. We propose Imagine (Machine Imagination-based Reasoning), a novel zero-shot commonsense reasoning framework designed to complement textual inputs with visual signals derived from machine-generated images. To achieve this, we enhance PLMs with imagination capabilities by incorporating an image generator into the reasoning process. To guide PLMs in effectively leveraging machine imagination, we create a synthetic pre-training dataset that simulates visual question-answering. Our extensive experiments on diverse reasoning benchmarks and analysis show that Imagine outperforms existing methods by a large margin, highlighting the strength of machine imagination in mitigating reporting bias and enhancing generalization capabilities.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.669",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Framework of Knowledge Graph-Enhanced Large Language Model Based on Question Decomposition and Atomic Retrieval": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-framework",
        "author": "Li, Yading and Song, Dandan and Zhou, Changzhi and Tian, Yuhang and Wang, Hao and Yang, Ziyi and Zhang, Shuhao",
        "booktitle": "EMNLP-findings2024",
        "title": "A Framework of Knowledge Graph-Enhanced Large Language Model Based on Question Decomposition and Atomic Retrieval",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Knowledge graphs (KGs) can provide explainable reasoning for large language models (LLMs), alleviating their hallucination problem. Knowledge graph question answering (KGQA) is a typical benchmark to evaluate the methods enhancing LLMs with KG. Previous methods on KG-enhanced LLM for KGQA either enhance LLMs with KG retrieval in a single round or perform multi-hop KG reasoning in multiple rounds with LLMs. Both of them conduct retrieving and reasoning based solely on the whole original question, without any processing to the question. To tackle this limitation, we propose a framework of KG-enhanced LLM based on question decomposition and atomic retrieval, called KELDaR. We introduce question decomposition tree as the framework for LLM reasoning. This approach extracts the implicit information of reasoning steps within complex questions, serving as a guide to facilitate atomic retrieval on KG targeting the atomic-level simple questions at leaves of the tree. Additionally, we design strategies for atomic retrieval, which extract and retrieve question-relevant KG subgraphs to assist the few-shot LLM in answering atomic-level questions. Experiments on KGQA datasets demonstrate that our framework outperforms existing reasoning-based baselines. And in a low-cost setting without additional training or fine-tuning, our framework achieves competitive or superior results compared to most existing training-based baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.670",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Vanessa: Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis": {
        "type": "INPROCEEDINGS",
        "key": "xiao-etal-2024-vanessa",
        "author": "Xiao, Luwei and Mao, Rui and Zhang, Xulang and He, Liang and Cambria, Erik",
        "booktitle": "EMNLP-findings2024",
        "title": "Vanessa: Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prevailing research concentrates on superficial features or descriptions of images, revealing a significant gap in the systematic exploration of their connotative and aesthetic attributes. Furthermore, the use of cross-modal relation detection modules to eliminate noise from comprehensive image representations leads to the omission of subtle contextual information. In this paper, we present a Visual Connotation and Aesthetic Attributes Understanding Network (Vanessa) for Multimodal Aspect-based Sentiment Analysis. Concretely, Vanessa incorporates a Multi-Aesthetic Attributes Aggregation (MA3) module that models intra- and inter-dependencies among bi-modal representations as well as emotion-laden aesthetic attributes. Moreover, we devise a self-supervised contrastive learning framework to explore the pairwise relevance between images and text via the Gaussian distribution of their CLIP scores. By dynamically clustering and merging multi-modal tokens, Vanessa effectively captures both implicit and explicit sentimental cues. Extensive experiments on widely adopted two benchmarks verify Vanessa\u2019s effectiveness.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.671",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Consistent Document-level Relation Extraction via Counterfactuals": {
        "type": "INPROCEEDINGS",
        "key": "modarressi-etal-2024-consistent",
        "author": "Modarressi, Ali and K\u00f6ksal, Abdullatif and Schuetze, Hinrich",
        "booktitle": "EMNLP-findings2024",
        "title": "Consistent Document-level Relation Extraction via Counterfactuals",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Many datasets have been developed to train and evaluate document-level relation extraction (RE) models. Most of these are constructed using real-world data. It has been shown that RE models trained on real-world data suffer from factual biases. To evaluate and address this issue, we present CovEReD, a counterfactual data generation approach for document-level relation extraction datasets using entity replacement. We first demonstrate that models trained on factual data exhibit inconsistent behavior: while they accurately extract triples from factual data, they fail to extract the same triples after counterfactual modification. This inconsistency suggests that models trained on factual data rely on spurious signals such as specific entities and external knowledge \u2013 rather than on context \u2013 to extract triples. We show that by generating document-level counterfactual data with CovEReD and training models on them, consistency is maintained with minimal impact on RE performance. We release our CovEReD pipeline as well as Re-DocRED-CF, a dataset of counterfactual RE documents, to assist in evaluating and addressing inconsistency in document-level RE.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.672",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants": {
        "type": "INPROCEEDINGS",
        "key": "jia-etal-2024-enhancing",
        "author": "Jia, Lichen and Wu, Chenggang and Tang, Bowen and Zhang, Peihua and Jiang, Zihan and Yang, Yang and Liu, Ning and Zhang, Jingfeng and Wang, Zhe",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Compared to identifying binary versions of the same function under different compilation options, existing Learning-Based Binary Code Similarity Detection (LB-BCSD) methods exhibit lower accuracy in recognizing functions with the same functionality but different implementations. To address this issue, we introduces an adversarial attack method called FuncFooler, which focuses on perturbing critical code to generate multiple variants of the same function. These variants are then used to retrain the model to enhance its robustness. Current adversarial attacks against LB-BCSD mainly draw inspiration from the FGSM (Fast Gradient Sign Method) method in the image domain, which involves generating adversarial bytes and appending them to the end of the executable file. However, this approach has a significant drawback: the appended bytes do not affect the actual code of the executable file, thus failing to create diverse code variants. To overcome this limitation, we proposes a gradient-guided adversarial attack method based on critical code\u2014FuncFooler. This method designs a series of strategies to perturb the code while preserving the program\u2019s semantics. Specifically, we first utilizes gradient information to locate critical nodes in the control flow graph. Then, fine-grained perturbations are applied to these nodes, including control flow, data flow, and internal node perturbations, to obtain adversarial samples. The experimental results show that the application of the FuncFooler method can increase the accuracy of the latest LB-BCSD model by 5%-7%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.673",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Ask the experts: sourcing a high-quality nutrition counseling dataset through Human-AI collaboration": {
        "type": "INPROCEEDINGS",
        "key": "balloccu-etal-2024-ask",
        "author": "Balloccu, Simone and Reiter, Ehud and Li, Karen Jia-Hui and Sargsyan, Rafael and Kumar, Vivek and Reforgiato, Diego and Riboni, Daniele and Dusek, Ondrej",
        "booktitle": "EMNLP-findings2024",
        "title": "Ask the experts: sourcing a high-quality nutrition counseling dataset through Human-AI collaboration",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are being employed by end-users for various tasks, including sensitive ones such as health counseling, disregarding potential safety concerns. It is thus necessary to understand how adequately LLMs perform in such domains. We conduct a case study on ChatGPT in nutrition counseling, a popular use-case where the model supports a user with their dietary struggles. We crowd-source real-world diet-related struggles, then work with nutrition experts to generate supportive text using ChatGPT. Finally, experts evaluate the safety and text quality of ChatGPT\u2019s output. The result is the HAI-coaching dataset, containing ~2.4K crowdsourced dietary struggles and ~97K corresponding ChatGPT-generated and expert-annotated supportive texts. We analyse ChatGPT\u2019s performance, discovering potentially harmful behaviours, especially for sensitive topics like mental health. Finally, we use HAI-coaching to test open LLMs on various downstream tasks, showing that even the latest models struggle to achieve good performance. HAI-coaching is available at https://github.com/uccollab/hai-coaching/",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.674",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HealthAlignSumm : Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues": {
        "type": "INPROCEEDINGS",
        "key": "ghosh-etal-2024-healthalignsumm",
        "author": "Ghosh, Akash and Acharya, Arkadeep and Saha, Sriparna and Pandey, Gaurav and Raghu, Dinesh and Sinha, Setu",
        "booktitle": "EMNLP-findings2024",
        "title": "HealthAlignSumm : Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As generative AI progresses, collaboration be-tween doctors and AI scientists is leading to thedevelopment of personalized models to stream-line healthcare tasks and improve productivity.Summarizing doctor-patient dialogues has be-come important, helping doctors understandconversations faster and improving patient care.While previous research has mostly focused ontext data, incorporating visual cues from pa-tient interactions allows doctors to gain deeperinsights into medical conditions. Most of thisresearch has centered on English datasets, butreal-world conversations often mix languagesfor better communication. To address the lackof resources for multimodal summarization ofcode-mixed dialogues in healthcare, we devel-oped the MCDH dataset. Additionally, we cre-ated HealthAlignSumm, a new model that in-tegrates visual components with the BART ar-chitecture. This represents a key advancementin multimodal fusion, applied within both theencoder and decoder of the BART model. Ourwork is the first to use alignment techniques,including state-of-the-art algorithms like DirectPreference Optimization, on encoder-decodermodels with synthetic datasets for multimodalsummarization. Through extensive experi-ments, we demonstrated the superior perfor-mance of HealthAlignSumm across severalmetrics validated by both automated assess-ments and human evaluations. The datasetMCDH and our proposed model HealthAlign-Summ will be available in this GitHub accounthttps://github.com/AkashGhosh/HealthAlignSumm-Utilizing-Alignment-for-Multimodal-Summarization-of-Code-Mixed-Healthcare-DialoguesDisclaimer: This work involves medical im-agery based on the subject matter of the topic.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.675",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Revisiting the Impact of Pursuing Modularity for Code Generation": {
        "type": "INPROCEEDINGS",
        "key": "kang-etal-2024-revisiting",
        "author": "Kang, Deokyeong and Seo, KiJung and Kim, Taeuk",
        "booktitle": "EMNLP-findings2024",
        "title": "Revisiting the Impact of Pursuing Modularity for Code Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Modular programming, which aims to construct the final program by integrating smaller, independent building blocks, has been regarded as a desirable practice in software development. However, with the rise of recent code generation agents built upon large language models (LLMs), a question emerges: is this traditional practice equally effective for these new tools? In this work, we assess the impact of modularity in code generation by introducing a novel metric for its quantitative measurement. Surprisingly, unlike conventional wisdom on the topic, we find that modularity is not a core factor for improving the performance of code generation models. We also explore potential explanations for why LLMs do not exhibit a preference for modular code compared to non-modular code.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.676",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-decoding",
        "author": "Huang, Chenyang and Zhou, Hao and Jen, Cameron and Zheng, Kangjie and Zaiane, Osmar and Mou, Lili",
        "booktitle": "EMNLP-findings2024",
        "title": "A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Length-control summarization aims to condense long texts into a short one within a certain length limit. Previous approaches often use autoregressive (AR) models and treat the length requirement as a soft constraint, which may not always be satisfied. In this study, we propose a novel length-control decoding algorithm based on the directed acyclic Transformer (DAT). Our approach allows for multiple plausible sequence fragments and predicts a path to connect them. In addition, we propose a Sequence Maximum a Posteriori (Seq-MAP) decoding algorithm that marginalizes different possible paths and finds the most probable summary satisfying the length budget. Our algorithm is based on beam search, which further facilitates a reranker for performance improvement. Experimental results on the Gigaword dataset demonstrate our state-of-the-art performance for length-control summarization.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.677",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "R\u00b2AG: Incorporating Retrieval Information into Retrieval Augmented Generation": {
        "type": "INPROCEEDINGS",
        "key": "ye-etal-2024-r2ag",
        "author": "Ye, Fuda and Li, Shuangyin and Zhang, Yongqi and Chen, Lei",
        "booktitle": "EMNLP-findings2024",
        "title": "R\u00b2AG: Incorporating Retrieval Information into Retrieval Augmented Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval augmented generation (RAG) has been applied in many scenarios to augment large language models (LLMs) with external documents provided by retrievers. However, a semantic gap exists between LLMs and retrievers due to differences in their training objectives and architectures. This misalignment forces LLMs to passively accept the documents provided by the retrievers, leading to incomprehension in the generation process, where the LLMs are burdened with the task of distinguishing these documents using their inherent knowledge. This paper proposes R\u00b2AG, a novel enhanced RAG framework to fill this gap by incorporating **R**etrieval information into **R**etrieval **A**ugmented **G**eneration. Specifically, R\u00b2AG utilizes the nuanced features from the retrievers and employs a R\u00b2-Former to capture retrieval information. Then, a retrieval-aware prompting strategy is designed to integrate retrieval information into LLMs\u2019 generation. Notably, R\u00b2AG suits low-source scenarios where LLMs and retrievers are frozen. Extensive experiments across five datasets validate the effectiveness, robustness, and efficiency of R\u00b2AG. Our analysis reveals that retrieval information serves as an anchor to aid LLMs in the generation process, thereby filling the semantic gap.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.678",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition": {
        "type": "INPROCEEDINGS",
        "key": "surikuchi-etal-2024-yet",
        "author": "Surikuchi, Aditya Kaushik and Fern\u00e1ndez, Raquel and Pezzelle, Sandro",
        "booktitle": "EMNLP-findings2024",
        "title": "Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Visual storytelling consists in generating a natural language story given a temporally ordered sequence of images. This task is not only challenging for models, but also very difficult to evaluate with automatic metrics since there is no consensus about what makes a story \u2018good\u2019. In this paper, we introduce a novel method that measures story quality in terms of human likeness regarding three key aspects highlighted in previous work: visual grounding, coherence, and repetitiveness. We then use this method to evaluate the stories generated by several models, showing that the foundation model LLaVA obtains the best result, but only slightly so compared to TAPM, a 50-times smaller visual storytelling model. Upgrading the visual and language components of TAPM results in a model that yields competitive performance with a relatively low number of parameters. Finally, we carry out a human evaluation study, whose results suggest that a \u2018good\u2019 story may require more than a human-like level of visual grounding, coherence, and repetition.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.679",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing": {
        "type": "INPROCEEDINGS",
        "key": "knuples-etal-2024-gender",
        "author": "Knuple\u0161, Urban and Falenska, Agnieszka and Mileti\u0107, Filip",
        "booktitle": "EMNLP-findings2024",
        "title": "Gender Identity in Pretrained Language Models: An Inclusive Approach to Data Creation and Probing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Pretrained language models (PLMs) have been shown to encode binary gender information of text authors, raising the risk of skewed representations and downstream harms. This effect is yet to be examined for transgender and non-binary identities, whose frequent marginalization may exacerbate harmful system behaviors. Addressing this gap, we first create TRANsCRIPT, a corpus of YouTube transcripts from transgender, cisgender, and non-binary speakers. Using this dataset, we probe various PLMs to assess if they encode the gender identity information, examining both frozen and fine-tuned representations as well as representations for inputs with author-specific words removed. Our findings reveal that PLM representations encode information for all gender identities but to different extents. The divergence is most pronounced for cis women and non-binary individuals, underscoring the critical need for gender-inclusive approaches to NLP systems.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.680",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "\u201cVorbe\\textcommabelowsti Rom\u00e2ne\\textcommabelowste?\u201d A Recipe to Train Powerful Romanian LLMs with English Instructions": {
        "type": "INPROCEEDINGS",
        "key": "masala-etal-2024-vorbesti",
        "author": "Masala, Mihai and Ilie-Ablachim, Denis and Dima, Alexandru and Corlatescu, Dragos Georgian and Zavelca, Miruna-Andreea and Olaru, Ovio and Terian, Simina-Maria and Terian, Andrei and Leordeanu, Marius and Velicu, Horia and Popescu, Marius and Dascalu, Mihai and Rebedea, Traian",
        "booktitle": "EMNLP-findings2024",
        "title": "\u201cVorbe\\textcommabelowsti Rom\u00e2ne\\textcommabelowste?\u201d A Recipe to Train Powerful Romanian LLMs with English Instructions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In recent years, Large Language Models (LLMs) have achieved almost human-like performance on various tasks. While some LLMs have been trained on multilingual data, most of the training data is in English; hence, their performance in English greatly exceeds other languages. To our knowledge, we are the first to collect and translate a large collection of texts, instructions, and benchmarks and train, evaluate, and release open-source LLMs tailored for Romanian. We evaluate our methods on four different categories, including academic benchmarks, MT-Bench (manually translated), and a professionally built historical, cultural, and social benchmark adapted to Romanian. We argue for the usefulness and high performance of RoLLMs by obtaining state-of-the-art results across the board. We publicly release all resources (i.e., data, training and evaluation code, models) with the goal of supporting and encouraging research on Romanian LLMs while concurrently creating a generalizable recipe adequate for other low or less-resourced languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.681",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Generalized Measures of Anticipation and Responsivity in Online Language Processing": {
        "type": "INPROCEEDINGS",
        "key": "giulianelli-etal-2024-generalized",
        "author": "Giulianelli, Mario and Opedal, Andreas and Cotterell, Ryan",
        "booktitle": "EMNLP-findings2024",
        "title": "Generalized Measures of Anticipation and Responsivity in Online Language Processing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We introduce a generalization of classic information-theoretic measures of predictive uncertainty in online language processing, based on the simulation of expected continuations of incremental linguistic contexts. Our framework provides a formal definition of anticipatory and responsive measures, and it equips experimenters with the tools to define new, more expressive measures beyond standard next-symbol entropy and surprisal. While extracting these standard quantities from language models is convenient, we demonstrate that using Monte Carlo simulation to estimate alternative responsive and anticipatory measures pays off empirically: New special cases of our generalized formula exhibit enhanced predictive power compared to surprisal for human cloze completion probability as well as ELAN, LAN, and N400 amplitudes, and greater complementarity with surprisal in predicting reading times.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.682",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-towards-effective",
        "author": "Lee, Huije and Song, Hoyun and Shin, Jisu and Cho, Sukmin and Han, SeungYoon and Park, Jong C.",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Trolling in online communities typically involves disruptive behaviors such as provoking anger and manipulating discussions, leading to a polarized atmosphere and emotional distress. Robust moderation is essential for mitigating these negative impacts and maintaining a healthy and constructive community atmosphere. However, effectively addressing trolls is difficult because their behaviors vary widely and require different response strategies (RSs) to counter them. This diversity makes it challenging to choose an appropriate RS for each specific situation.To address this challenge, our research investigates whether humans have preferred strategies tailored to different types of trolling behaviors.Our findings reveal a correlation between the types of trolling encountered and the preferred RS. In this paper, we introduce a methodology for generating counter-responses to trolls by recommending appropriate RSs, supported by a dataset aligning these strategies with human preferences across various troll contexts. The experimental results demonstrate that our proposed approach guides constructive discussion and reduces the negative effects of trolls, thereby enhancing the online community environment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.683",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs": {
        "type": "INPROCEEDINGS",
        "key": "mendonca-etal-2024-soda",
        "author": "Mendon\u00e7a, John and Trancoso, Isabel and Lavie, Alon",
        "booktitle": "EMNLP-findings2024",
        "title": "Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Although human evaluation remains the gold standard for open-domain dialogue evaluation, the growing popularity of automated evaluation using Large Language Models (LLMs) has also extended to dialogue. However, most frameworks leverage benchmarks that assess older chatbots on aspects such as fluency and relevance, which are not reflective of the challenges associated with contemporary models. In fact, a qualitative analysis on Soda. (Kim et al., 2023), a GPT-3.5 generated dialogue dataset, suggests that current chatbots may exhibit several recurring issues related to coherence and commonsense knowledge, but generally produce highly fluent and relevant responses.Noting the aforementioned limitations, this paper introduces Soda-Eval, an annotated dataset based on Soda that covers over 120K turn-level assessments across 10K dialogues, where the annotations were generated by GPT-4. Using Soda-Eval as a benchmark, we then study the performance of several open-access instruction-tuned LLMs, finding that dialogue evaluation remains challenging. Fine-tuning these models improves performance over few-shot inferences, both in terms of correlation and explanation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.684",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models": {
        "type": "INPROCEEDINGS",
        "key": "sahoo-etal-2024-comprehensive",
        "author": "Sahoo, Pranab and Meharia, Prabhash and Ghosh, Akash and Saha, Sriparna and Jain, Vinija and Chadha, Aman",
        "booktitle": "EMNLP-findings2024",
        "title": "A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The rapid advancement of foundation models (FMs) across language, image, audio, and video domains has shown remarkable capabilities in diverse tasks. However, the proliferation of FMs brings forth a critical challenge: the potential to generate hallucinated outputs, particularly in high-stakes applications. The tendency of foundation models to produce hallucinated content arguably represents the biggest hindrance to their widespread adoption in real-world scenarios, especially in domains where reliability and accuracy are paramount. This survey paper presents a comprehensive overview of recent developments that aim to identify and mitigate the problem of hallucination in FMs, spanning text, image, video, and audio modalities. By synthesizing recent advancements in detecting and mitigating hallucination across various modalities, the paper aims to provide valuable insights for researchers, developers, and practitioners. Essentially, it establishes a clear framework encompassing definition, taxonomy, and detection strategies for addressing hallucination in multimodal foundation models, laying the foundation for future research and development in this pivotal area.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.685",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Predicting generalization performance with correctness discriminators": {
        "type": "INPROCEEDINGS",
        "key": "yao-koller-2024-predicting",
        "author": "Yao, Yuekun and Koller, Alexander",
        "booktitle": "EMNLP-findings2024",
        "title": "Predicting generalization performance with correctness discriminators",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The ability to predict an NLP model\u2019s accuracy on unseen, potentially out-of-distribution data is a prerequisite for trustworthiness. We present a novel model that establishes upper and lower bounds on the accuracy, without requiring gold labels for the unseen data. We achieve this by training a *discriminator* which predicts whether the output of a given sequence-to-sequence model is correct or not. We show across a variety of tagging, parsing, and semantic parsing tasks that the gold accuracy is reliably between the predicted upper and lower bounds, and that these bounds are remarkably close together.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.686",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhu-etal-2024-fastmem",
        "author": "Zhu, Junyi and Liu, Shuochen and Yu, Yu and Tang, Bo and Yan, Yibo and Li, Zhiyu and Xiong, Feiyu and Xu, Tong and Blaschko, Matthew B.",
        "booktitle": "EMNLP-findings2024",
        "title": "FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) excel in generating coherent text, but they often struggle with context awareness, leading to inaccuracies in tasks requiring faithful adherence to provided information. We introduce FastMem, a novel method designed to enhance instruction fine-tuned LLMs\u2019 context awareness through fast memorization of the prompt. FastMem maximizes the likelihood of the prompt before inference by updating only the last Feed-Forward Network (FFN) module. This targeted approach ensures efficient optimization without overfitting, significantly improving the model\u2019s ability to comprehend and accurately follow the context. Our experiments demonstrate substantial gains in reading comprehension, text summarization and adherence to output structures. For instance, FastMem improves the accuracy of Llama 3-8B-Inst on the NQ-SWAP dataset from 59.1% to 71.6%, and reduces the output structure failure rate of Qwen 1.5-4B-Chat from 34.9% to 25.5%. Extensive experimental results highlight FastMem\u2019s potential to offer a robust solution to enhance the reliability and accuracy of LLMs in various applications. Our code is available at: https://github.com/IAAR-Shanghai/FastMem.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.687",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks": {
        "type": "INPROCEEDINGS",
        "key": "himmi-etal-2024-towards",
        "author": "Himmi, Anas and Irurozki, Ekhine and Noiry, Nathan and Cl\u00e9men\u00e7on, Stephan and Colombo, Pierre",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The evaluation of natural language processing (NLP) systems is crucial for advancing the field, but current benchmarking approaches often assume that all systems have scores available for all tasks, which is not always practical. In reality, several factors such as the cost of running baseline, private systems, computational limitations, or incomplete data may prevent some systems from being evaluated on entire tasks. This paper formalize an existing problem in NLP research: benchmarking when some systems scores are missing on the task, and proposes a novel approach to address it. Our method utilizes a compatible partial ranking approach to impute missing data, which is then aggregated using the Borda count method. It includes two refinements designed specifically for scenarios where either task-level or instance-level scores are available. We also introduce an extended benchmark, which contains over 131 million scores, an order of magnitude larger than existing benchmarks. We validate our methods and demonstrate their effectiveness in addressing the challenge of missing system evaluation on an entire task. This work highlights the need for more comprehensive benchmarking approaches that can handle real-world scenarios where not all systems are evaluated on the entire task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.688",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Mixed-Session Conversation with Egocentric Memory": {
        "type": "INPROCEEDINGS",
        "key": "jang-etal-2024-mixed",
        "author": "Jang, Jihyoung and Kim, Taeyoung and Kim, Hyounghun",
        "booktitle": "EMNLP-findings2024",
        "title": "Mixed-Session Conversation with Egocentric Memory",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently introduced dialogue systems have demonstrated high usability. However, they still fall short of reflecting real-world conversation scenarios. Current dialogue systems exhibit an inability to replicate the dynamic, continuous, long-term interactions involving multiple partners. This shortfall arises because there have been limited efforts to account for both aspects of real-world dialogues: deeply layered interactions over the long-term dialogue and widely expanded conversation networks involving multiple participants. As the effort to incorporate these aspects combined, we introduce Mixed-Session Conversation, a dialogue system designed to construct conversations with various partners in a multi-session dialogue setup. We propose a new dataset called MiSC to implement this system. The dialogue episodes of MiSC consist of 6 consecutive sessions, with four speakers (one main speaker and three partners) appearing in each episode. Also, we propose a new dialogue model with a novel memory management mechanism, called Egocentric Memory Enhanced Mixed-Session Conversation Agent (EMMA). EMMA collects and retains memories from the main speaker\u2019s perspective during conversations with partners, enabling seamless continuity in subsequent interactions. Extensive human evaluations validate that the dialogues in MiSC demonstrate a seamless conversational flow, even when conversation partners change in each session. EMMA trained with MiSC is also evaluated to maintain high memorability without contradiction throughout the entire conversation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.689",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CSLM: A Framework for Question Answering Dataset Generation through Collaborative Small Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-cslm",
        "author": "Wang, Yiming and Liu, Yang and Wang, Lingchen and Xiao, An",
        "booktitle": "EMNLP-findings2024",
        "title": "CSLM: A Framework for Question Answering Dataset Generation through Collaborative Small Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Collecting high-quality question-answer (QA) pairs is vital for the training of large language models (LLMs), yet this process is traditionally laborious and time-intensive. With the rapid evolution of LLMs, the potential for leveraging these models to autonomously generate QA pairs has become apparent, particularly through the use of large-scale models like GPT-4. However, the computational demands and associated costs often render such approaches prohibitive for the average researcher. Addressing this gap, we introduce the Collaborative Small Language Model Framework (CSLM), an innovative solution that combines a group of small-scaled, open-source LLMs to collaboratively produce QA pairs. Experiments on datasets of various domains show that CSLM unleashes the full potential of diverse small models to generate high-quality QA pairs, making it accessible to a broader range of researchers.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.690",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?": {
        "type": "INPROCEEDINGS",
        "key": "zhang-he-2024-large",
        "author": "Zhang, Yidan and He, Zhenan",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite their promising performance across various tasks, recent studies reveal that Large language models (LLMs) still exhibit significant deficiencies in handling several word-level and character-level tasks, e.g., word unscrambling and sentence editing, indicating urgent needs for substantial improvements in basic language understanding and manipulation. To address these challenges, it is crucial to develop large-scale benchmarks that can comprehensively assess the performance of LLMs in basic language tasks. In this paper, we introduce a bilingual benchmark, CWUM, to investigate the capabilities and limitations of LLMs in understanding and manipulating natural language at both character and word levels. CWUM consists of 15 simple text editing tasks, e.g., letter counting, word reversing, Chinese character inserting, etc. We conduct extensive experiments on eight advanced LLMs, including base models and instruction-tuned (chat) variants. The experimental results highlight significant failures of existing LLMs on CWUM tasks that humans can solve perfectly with 100% accuracy. On English tasks of CWUM, the average accuracy of GPT-4, LLaMA-3-70B, and Qwen-72B is 66.64%, 39.32%, and 33.16%, respectively, which lags far behind human performance. Instruction-tuning the base model does not lead to a distinct performance improvement, as the average accuracy of LLaMA-3-70B-Instruct on English tasks is only 1.44% higher than that of the base LLaMA-3-70B. Ultimately, we show that supervised fine-tuning (SFT) can enhance model performance on CWUM without compromising its ability to generalize across general tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.691",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Virtual Context Enhancing Jailbreak Attacks with Special Token Injection": {
        "type": "INPROCEEDINGS",
        "key": "zhou-etal-2024-virtual",
        "author": "Zhou, Yuqi and Lu, Lin and Sun, Ryan and Zhou, Pan and Sun, Lichao",
        "booktitle": "EMNLP-findings2024",
        "title": "Virtual Context Enhancing Jailbreak Attacks with Special Token Injection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Jailbreak attacks on large language models (LLMs) involve inducing these models to generate harmful content that violates ethics or laws, posing a significant threat to LLM security. Current jailbreak attacks face two main challenges: low success rates due to defensive measures and high resource requirements for crafting specific prompts. This paper introduces Virtual Context, which leverages special tokens, previously overlooked in LLM security, to improve jailbreak attacks. Virtual Context addresses these challenges by significantly increasing the success rates of existing jailbreak methods and requiring minimal background knowledge about the target model, thus enhancing effectiveness in black-box settings without additional overhead. Comprehensive evaluations show that Virtual Context-assisted jailbreak attacks can improve the success rates of four widely used jailbreak methods by approximately 40% across various LLMs. Additionally, applying Virtual Context to original malicious behaviors still achieves a notable jailbreak effect. In summary, our research highlights the potential of special tokens in jailbreak attacks and recommends including this threat in red-teaming testing to comprehensively enhance LLM security.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.692",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-think",
        "author": "Li, Moxin and Wang, Wenjie and Feng, Fuli and Zhu, Fengbin and Wang, Qifan and Chua, Tat-Seng",
        "booktitle": "EMNLP-findings2024",
        "title": "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Self-detection for Large Language Models (LLMs) seeks to evaluate the trustworthiness of the LLM\u2019s output by leveraging its own capabilities, thereby alleviating the issue of output hallucination. However, existing self-detection approaches only retrospectively evaluate answers generated by LLM, typically leading to the over-trust in incorrectly generated answers. To tackle this limitation, we propose a novel self-detection paradigm that considers the comprehensive answer space beyond LLM-generated answers. It thoroughly compares the trustworthiness of multiple candidate answers to mitigate the over-trust in LLM-generated incorrect answers. Building upon this paradigm, we introduce a two-step framework, which firstly instructs LLM to reflect and provide justifications for each candidate answer, and then aggregates the justifications for comprehensive target answer evaluation. This framework can be seamlessly integrated with existing approaches for superior self-detection. Extensive experiments on six datasets spanning three tasks demonstrate the effectiveness of the proposed framework.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.693",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Automating Easy Read Text Segmentation": {
        "type": "INPROCEEDINGS",
        "key": "calleja-etal-2024-automating",
        "author": "Calleja, Jesus and Etchegoyhen, Thierry and Ponce Mart\u00ednez, Antonio David",
        "booktitle": "EMNLP-findings2024",
        "title": "Automating Easy Read Text Segmentation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Easy Read text is one of the main forms of access to information for people with reading difficulties. One of the key characteristics of this type of text is the requirement to split sentences into smaller grammatical segments, to facilitate reading. Automated segmentation methods could foster the creation of Easy Read content, but their viability has yet to be addressed. In this work, we study novel methods for the task, leveraging masked and generative language models, along with constituent parsing. We conduct comprehensive automatic and human evaluations in three languages, analysing the strengths and weaknesses of the proposed alternatives, under scarce resource limitations. Our results highlight the viability of automated Easy Read segmentation and remaining deficiencies compared to expert-driven human segmentation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.694",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Position Paper: Data-Centric AI in the Age of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-position",
        "author": "Xu, Xinyi and Wu, Zhaoxuan and Qiao, Rui and Verma, Arun and Shu, Yao and Wang, Jingtan and Niu, Xinyuan and He, Zhenfeng and Chen, Jiangwei and Zhou, Zijian and Lau, Gregory Kang Ruey and Dao, Hieu and Agussurja, Lucas and Sim, Rachael Hwee Ling and Lin, Xiaoqiang and Hu, Wenyang and Dai, Zhongxiang and Koh, Pang Wei and Low, Bryan Kian Hsiang",
        "booktitle": "EMNLP-findings2024",
        "title": "Position Paper: Data-Centric AI in the Age of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This position paper proposes a data-centric viewpoint of AI research, focusing on large language models (LLMs). We start by making a key observation that data is instrumental in the developmental (e.g., pretraining and fine-tuning) and inferential stages (e.g., in-context learning) of LLMs, and advocate that data-centric research should receive more attention from the community. We identify four specific scenarios centered around data, covering data-centric benchmarks and data curation, data attribution, knowledge transfer, and inference contextualization. In each scenario, we underscore the importance of data, highlight promising research directions, and articulate the potential impacts on the research community and, where applicable, the society as a whole. For instance, we advocate for a suite of data-centric benchmarks tailored to the scale and complexity of data for LLMs. These benchmarks can be used to develop new data curation methods and document research efforts and results, which can help promote openness and transparency in AI and LLM research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.695",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MATHWELL: Generating Educational Math Word Problems Using Teacher Annotations": {
        "type": "INPROCEEDINGS",
        "key": "christ-etal-2024-mathwell",
        "author": "Christ, Bryan R. and Kropko, Jonathan and Hartvigsen, Thomas",
        "booktitle": "EMNLP-findings2024",
        "title": "MATHWELL: Generating Educational Math Word Problems Using Teacher Annotations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Math word problems are critical K-8 educational tools, but writing them is time consuming and requires extensive expertise. To be educational, problems must be solvable, have accurate answers, and, most importantly, be educationally appropriate. We propose that language models have potential to support K-8 math education by automatically generating word problems. However, evaluating educational appropriateness is hard to quantify. We fill this gap by having teachers evaluate problems generated by LLMs, who find existing models and data often fail to be educationally appropriate. We then explore automatically generating *educational* word problems, ultimately using our expert annotations to finetune a 70B language model. Our model, MATHWELL, is the first K-8 word problem generator targeted at educational appropriateness. Further expert studies find MATHWELL generates problems far more solvable, accurate, and appropriate than public models. MATHWELL also matches GPT-4\u2019s problem quality while attaining more appropriate reading levels for K-8 students and avoiding generating harmful questions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.696",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Resilience of Large Language Models for Noisy Instructions": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-resilience",
        "author": "Wang, Bin and Wei, Chengwei and Liu, Zhengyuan and Lin, Geyu and Chen, Nancy F.",
        "booktitle": "EMNLP-findings2024",
        "title": "Resilience of Large Language Models for Noisy Instructions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As the rapidly advancing domain of natural language processing (NLP), large language models (LLMs) have emerged as powerful tools for interpreting human commands and generating text across various tasks. Nonetheless, the resilience of LLMs to handle text containing inherent errors, stemming from human interactions and collaborative systems, has not been thoroughly explored. Our study investigates the resilience of LLMs against five common types of disruptions including 1) ASR (Automatic Speech Recognition) errors, 2) OCR (Optical Character Recognition) errors, 3) grammatical mistakes, 4) typographical errors, and 5) distractive content. We aim to investigate how these models react by deliberately embedding these errors into instructions. Our findings reveal that while some LLMs show a degree of resistance to certain types of noise, their overall performance significantly suffers. This emphasizes the importance of further investigation into enhancing model resilience. In response to the observed decline in performance, our study also evaluates a \u201cre-pass\u201d strategy, designed to purify the instructions of noise before the LLMs process them. Our analysis indicates that correcting noisy instructions, particularly for open-source LLMs, presents significant challenges.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.697",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Augmenting Reasoning Capabilities of LLMs with Graph Structures in Knowledge Base Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "tian-etal-2024-augmenting",
        "author": "Tian, Yuhang and Song, Dandan and Wu, Zhijing and Zhou, Changzhi and Wang, Hao and Yang, Jun and Xu, Jing and Cao, Ruanmin and Wang, HaoYu",
        "booktitle": "EMNLP-findings2024",
        "title": "Augmenting Reasoning Capabilities of LLMs with Graph Structures in Knowledge Base Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, significant progress has been made in employing Large Language Models (LLMs) for semantic parsing to address Knowledge Base Question Answering (KBQA) tasks. Previous work utilize LLMs to generate query statements on Knowledge Bases (KBs) for retrieving answers. However, LLMs often generate incorrect query statements due to the lack of relevant knowledge in the previous methods. To address this, we propose a framework called Augmenting Reasoning Capabilities of LLMs with Graph Structures in Knowledge Base Question Answering (ARG-KBQA), which retrieves question-related graph structures to improve the performance of LLMs. Unlike other methods that directly retrieve relations or triples from KBs, we introduce an unsupervised two-stage ranker to perform multi-hop beam search on KBs, which could provide LLMs with more relevant information to the questions. Experimental results demonstrate that ARG-KBQA sets a new state-of-the-art on GrailQA and WebQSP under the few-shot setting. Additionally, ARG-KBQA significantly outperforms previous few-shot methods on questions with unseen query statement in the training data.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.699",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Creative Problem Solving in Large Language and Vision Models - What Would it Take?": {
        "type": "INPROCEEDINGS",
        "key": "nair-etal-2024-creative",
        "author": "Nair, Lakshmi and Gizzi, Evana and Sinapov, Jivko",
        "booktitle": "EMNLP-findings2024",
        "title": "Creative Problem Solving in Large Language and Vision Models - What Would it Take?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We advocate for a strong integration of Computational Creativity (CC) with research in large language and vision models (LLVMs) to address a key limitation of these models, i.e., creative problem solving. We present preliminary experiments showing how CC principles can be applied to address this limitation. Our goal is to foster discussions on creative problem solving in LLVMs and CC at prestigious ML venues.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.700",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Cross-Lingual Multi-Hop Knowledge Editing": {
        "type": "INPROCEEDINGS",
        "key": "khandelwal-etal-2024-cross",
        "author": "Khandelwal, Aditi and Singh, Harman and Gu, Hengrui and Chen, Tianlong and Zhou, Kaixiong",
        "booktitle": "EMNLP-findings2024",
        "title": "Cross-Lingual Multi-Hop Knowledge Editing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) are often expected to be constantly adapted to new sources of knowledge and knowledge editing techniques aim to efficiently patch the outdated model knowledge, with minimal modification. Most prior works focus on monolingual knowledge editing in English, even though new information can emerge in any language from any part of the world. We propose the Cross-Lingual Multi-Hop Knowledge Editing paradigm, for measuring and analyzing the performance of various SoTA knowledge editing techniques in a cross-lingual setup. Specifically, we create a parallel cross-lingual benchmark, CroLin-MQuAKE for measuring the knowledge editing capabilities. Our extensive analysis over various knowledge editing techniques uncover significant gaps in performance between the cross-lingual and English-centric setting. Following this, we propose a significantly improved system for cross-lingual multi-hop knowledge editing, CLeVer-CKE. CLeVer-CKE is based on a retrieve, verify and generate knowledge editing framework, where a retriever is formulated to recall edited facts and support an LLM to adhere to knowledge edits. We develop language-aware and hard-negative based contrastive losses for improving the cross-lingual and fine-grained fact retrieval and verification process used within this framework. Extensive experiments across three LLMs, eight languages, and two datasets show the CLeVer-CKE\u2019s significant gains of up to 30% over prior methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.701",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Android in the Zoo: Chain-of-Action-Thought for GUI Agents": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-android",
        "author": "Zhang, Jiwen and Wu, Jihao and Yihua, Teng and Liao, Minghui and Xu, Nuo and Xiao, Xiao and Wei, Zhongyu and Tang, Duyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Android in the Zoo: Chain-of-Action-Thought for GUI Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language model (LLM) leads to a surge of autonomous GUI agents for smartphone, which completes a task triggered by natural language through predicting a sequence of actions of API. Even though the task highly relies on past actions and visual observations, existing studies typically consider little semantic information carried out by intermediate screenshots and screen operations. To address this, this work presents Chain-of-Action-Thought (dubbed CoAT), which takes the description of the previous actions, the current screen, and more importantly the action thinking of what actions should be performed and the outcomes led by the chosen action. We demonstrate that, in a zero-shot setting upon three off-the-shelf LMMs, CoAT significantly improves the action prediction compared to previous proposed context modeling. To further facilitate the research in this line, we construct a dataset Android-In-The-Zoo (AitZ), which contains 18,643 screen-action pairs together with chain-of-action-thought annotations. Experiments show that fine-tuning a 1B model (i.e. AUTO-UI-base) on our AitZ dataset achieves on-par performance with CogAgent-Chat-18B.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.702",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-Recognition in Language Models": {
        "type": "INPROCEEDINGS",
        "key": "davidson-etal-2024-self",
        "author": "Davidson, Tim R. and Surkov, Viacheslav and Veselovsky, Veniamin and Russo, Giuseppe and West, Robert and Gulcehre, Caglar",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-Recognition in Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "A rapidly growing number of applications rely on a small set of closed-source language models (LMs). This dependency might introduce novel security risks if LMs develop self-recognition capabilities. Inspired by human identity verification methods, we propose a novel approach for assessing self-recognition in LMs using model-generated \u201csecurity questions\u201d. Our test can be externally administered to keep track of frontier models as it does not require access to internal model parameters or output probabilities. We use our test to examine self-recognition in ten of the most capable open- and closed-source LMs currently publicly available. Our extensive experiments found no empirical evidence of general or consistent self-recognition in any examined LM. Instead, our results suggest that given a set of alternatives, LMs seek to pick the \u201cbest\u201d answer, regardless of its origin. Moreover, we find indications that preferences about which models produce the best answers are consistent across LMs. We additionally uncover novel insights on position bias considerations for LMs in multiple-choice settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.703",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning": {
        "type": "INPROCEEDINGS",
        "key": "rege-cambrin-etal-2024-beyond",
        "author": "Rege Cambrin, Daniele and Gallipoli, Giuseppe and Benedetto, Irene and Cagliero, Luca and Garza, Paolo",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across various tasks. However, current training approaches combine standard cross-entropy loss with extensive data, human feedback, or ad hoc methods to enhance performance. These solutions are often not scalable or feasible due to their associated costs, complexity, or resource requirements. This study investigates the use of established semantic segmentation loss functions in natural language generation to create a versatile, practical, and scalable solution for fine-tuning different architectures. We evaluate their effectiveness in solving Math Word Problems and question answering across different models of varying sizes. For the analyzed tasks, we found that the traditional Cross-Entropy loss represents a sub-optimal choice, while models trained to minimize alternative (task-dependent) losses, such as Focal or Lov\u00e1sz, achieve a mean improvement of +36% on exact match without requiring additional data or human feedback. These findings suggest a promising pathway for more efficient and accessible training processes.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.704",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Shape of Word Embeddings: Quantifying Non-Isometry with Topological Data Analysis": {
        "type": "INPROCEEDINGS",
        "key": "draganov-skiena-2024-shape",
        "author": "Draganov, Ond\u0159ej and Skiena, Steven",
        "booktitle": "EMNLP-findings2024",
        "title": "The Shape of Word Embeddings: Quantifying Non-Isometry with Topological Data Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Word embeddings represent language vocabularies as clouds of d-dimensional points. We investigate how information is conveyed by the general shape of these clouds, instead of representing the semantic meaning of each token. Specifically, we use the notion of persistent homology from topological data analysis (TDA) to measure the distances between language pairs from the shape of their unlabeled embeddings. These distances quantify the degree of non-isometry of the embeddings. To distinguish whether these differences are random training errors or capture real information about the languages, we use the computed distance matrices to construct language phylogenetic trees over 81 Indo-European languages. Careful evaluation shows that our reconstructed trees exhibit strong and statistically-significant similarities to the reference.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.705",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Robust Evaluation of Unlearning in LLMs via Data Transformations": {
        "type": "INPROCEEDINGS",
        "key": "joshi-etal-2024-towards",
        "author": "Joshi, Abhinav and Saha, Shaswati and Shukla, Divyaksh and Vema, Sriram and Jhamtani, Harsh and Gaur, Manas and Modi, Ashutosh",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Robust Evaluation of Unlearning in LLMs via Data Transformations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have shown to be a great success in a wide range of applications ranging from regular NLP-based use cases to AI agents. LLMs have been trained on a vast corpus of texts from various sources; despite the best efforts during the data pre-processing stage while training the LLMs, they may pick some undesirable information such as personally identifiable information (PII). Consequently, in recent times research in the area of Machine Unlearning (MUL) has become active, the main idea is to force LLMs to forget (unlearn) certain information (e.g., PII) without suffering from performance loss on regular tasks. In this work, we examine the robustness of the existing MUL techniques for their ability to enable leakage-proof forgetting in LLMs. In particular, we examine the effect of data transformation on forgetting, i.e., is an unlearned LLM able to recall forgotten information if there is a change in the format of the input? Our findings on the TOFU dataset highlight the necessity of using diverse data formats to quantify unlearning in LLMs more reliably.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.706",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Numbers Matter! Bringing Quantity-awareness to Retrieval Systems": {
        "type": "INPROCEEDINGS",
        "key": "almasian-etal-2024-numbers",
        "author": "Almasian, Satya and Bruseva, Milena and Gertz, Michael",
        "booktitle": "EMNLP-findings2024",
        "title": "Numbers Matter! Bringing Quantity-awareness to Retrieval Systems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Quantitative information plays a crucial role in understanding and interpreting the content of documents. Many user queries contain quantities and cannot be resolved without understanding their semantics, e.g., \u201ccar that costs less than $10k\u201d. Yet, modern search engines apply the same ranking mechanisms for both words and quantities, overlooking magnitude and unit information. In this paper, we introduce two quantity-aware ranking techniques designed to rank both the quantity and textual content either jointly or independently. These techniques incorporate quantity information in available retrieval systems and can address queries with numerical conditions equal, greater than, and less than. To evaluate the effectiveness of our proposed models, we introduce two novel quantity-aware benchmark datasets in the domains of finance and medicine and compare our method against various lexical and neural models. The code and data are available under https://github.com/satya77/QuantityAwareRankers.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.707",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Stark: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-stark",
        "author": "Lee, Young-Jun and Lee, Dokyong and Youn, Junyoung and Oh, Kyeong-Jin and Ko, Byungsoo and Hyeon, Jonghwan and Choi, Ho-Jin",
        "booktitle": "EMNLP-findings2024",
        "title": "Stark: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Humans share a wide variety of images related to their personal experiences within conversations via instant messaging tools. However, existing works focus on (1) image-sharing behavior in singular sessions, leading to limited long-term social interaction, and (2) a lack of personalized image-sharing behavior. In this work, we introduce , a large-scale long-term multi-modal dialogue dataset that covers a wide range of social personas in a multi-modality format, time intervals, and images. To construct automatically, we propose a novel multi-modal contextualization framework, , that generates long-term multi-modal dialogue distilled from ChatGPT and our proposed image aligner. Using our , we train a multi-modal conversation model, 7B, which demonstrates impressive visual imagination ability. Furthermore, we demonstrate the effectiveness of our dataset in human evaluation. The code, dataset, and model will be publicly released after publication.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.708",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Dual-Phase Accelerated Prompt Optimization": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-dual",
        "author": "Yang, Muchen and Li, Moxin and Li, Yongle and Chen, Zijun and Gao, Chongming and Zhang, Junqi and Li, Yangyang and Feng, Fuli",
        "booktitle": "EMNLP-findings2024",
        "title": "Dual-Phase Accelerated Prompt Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Gradient-free prompt optimization methods have made significant strides in enhancing the performance of closed-source Large Language Model (LLMs) across a wide range of tasks. However, existing approaches make light of the importance of high-quality prompt initialization and the identification of effective optimization directions, thus resulting in substantial optimization steps to obtain satisfactory performance. In this light, we aim to accelerate prompt optimization process to tackle the challenge of low convergence rate. We propose a dual-phase approach which starts with generating high-quality initial prompts by adopting a well-designed meta-instruction to delve into task-specific information, and iteratively optimize the prompts at the sentence level, leveraging previous tuning experience to expand prompt candidates and accept effective ones. Extensive experiments on eight datasets demonstrate the effectiveness of our proposed method, achieving a consistent accuracy gain over baselines with less than five optimization steps.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.709",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-chartinsights",
        "author": "Wu, Yifan and Yan, Lutao and Shen, Leixian and Wang, Yunhai and Tang, Nan and Luo, Yuyu",
        "booktitle": "EMNLP-findings2024",
        "title": "ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Chart question answering (ChartQA) tasks play a critical role in interpreting and extracting insights from visualization charts. While recent advancements in multimodal large language models (MLLMs) like GPT-4o have shown promise in high-level ChartQA tasks, such as chart captioning, their effectiveness in low-level ChartQA tasks (*e.g.*, identifying correlations) remains underexplored.In this paper, we address this gap by evaluating MLLMs on low-level ChartQA using a newly curated dataset, *ChartInsights*, which consists of 22,347 (chart, task, query, answer) covering 10 data analysis tasks across 7 chart types. We systematically evaluate 19 advanced MLLMs, including 12 open-source and 7 closed-source models. The average accuracy rate across these models is 39.8%, with GPT-4o achieving the highest accuracy at 69.17%.To further explore the limitations of MLLMs in low-level ChartQA, we conduct experiments that alter visual elements of charts (*e.g.*, changing color schemes, adding image noise) to assess their impact on the task effectiveness. Furthermore, we propose a new textual prompt strategy, *Chain-of-Charts*, tailored for low-level ChartQA tasks, which boosts performance by 14.41%, achieving an accuracy of 83.58%. Finally, incorporating a visual prompt strategy that directs attention to relevant visual elements further improves accuracy to 84.32%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.710",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication": {
        "type": "INPROCEEDINGS",
        "key": "white-etal-2024-communicate",
        "author": "White, Isadora and Pandey, Sashrika and Pan, Michelle",
        "booktitle": "EMNLP-findings2024",
        "title": "Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we study how culture leads to differences in common ground and how this influences communication. During communication, cultural differences in common ground during communication may result in pragmatic failure and misunderstandings. We develop our method Rational Speech Acts for Cross-Cultural Communication (RSA+C3) to resolve cross-cultural differences in common ground. To measure the success of our method, we study RSA+C3 in the collaborative referential game of Codenames Duet and show that our method successfully improves collaboration between simulated players of different cultures. Our contributions are threefold: (1) creating Codenames players using contrastive learning of an embedding space and LLM prompting that are aligned with human patterns of play, (2) studying culturally induced differences in common ground reflected in our trained models, and (3) demonstrating that our method RSA+C3 can ease cross-cultural communication in gameplay by inferring sociocultural context from interaction.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.711",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles": {
        "type": "INPROCEEDINGS",
        "key": "azizov-etal-2024-safari",
        "author": "Azizov, Dilshod and Mujahid, Zain Muhammad and AlQuabeh, Hilal and Nakov, Preslav and Liang, Shangsong",
        "booktitle": "EMNLP-findings2024",
        "title": "SAFARI: Cross-lingual Bias and Factuality Detection in News Media and News Articles",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In an era where information is quickly shared across many cultural and language contexts, the neutrality and integrity of news media are essential. Ensuring that media content remains unbiased and factual is crucial for maintaining public trust. With this in mind, we introduce SAFARI (CroSs-lingual BiAs and Factuality Detection in News MediA and News ARtIcles), a novel corpus of news media and articles for predicting political bias and the factuality of reporting in a multilingual and cross-lingual setup. To the best of our knowledge, this corpus is unprecedented in its collection and introduces a dataset for political bias and factuality for three tasks: (i) media-level, (ii) article-level, and (iii) joint modeling at the article-level. At the media and article levels, we evaluate the cross-lingual ability of the models; however, in joint modeling, we evaluate on English data. Our frameworks set a new benchmark in the cross-lingual evaluation of political bias and factuality. This is achieved through the use of various Multilingual Pre-trained Language Models (MPLMs) and Large Language Models (LLMs) coupled with ensemble learning methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.712",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues": {
        "type": "INPROCEEDINGS",
        "key": "sreedhar-etal-2024-canttalkaboutthis",
        "author": "Sreedhar, Makesh Narsimhan and Rebedea, Traian and Ghosh, Shaona and Zeng, Jiaqi and Parisien, Christopher",
        "booktitle": "EMNLP-findings2024",
        "title": "CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in instruction-tuning datasets have predominantly focused on specific tasks like mathematical or logical reasoning. There has been a notable gap in data designed for aligning language models to maintain topic relevance in conversations - a critical aspect for deploying chatbots to production. We introduce the CantTalkAboutThis dataset to help language models remain focused on the subject at hand during task-oriented interactions. It consists of synthetic dialogues on a wide range of conversation topics from different domains. These dialogues are interspersed with distractor turns that intentionally divert the chatbot from the predefined topic. Fine-tuning language models on this dataset helps make them resilient to deviating from the assigned role and improves their ability to maintain topical coherence compared to general-purpose instruction-tuned LLMs like gpt-4-turbo and Mixtral-Instruct. Additionally, preliminary observations suggest that training models on this dataset also enhance their performance on fine-grained instruction following tasks, including safety alignment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.713",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "An LLM-Enabled Knowledge Elicitation and Retrieval Framework for Zero-Shot Cross-Lingual Stance Identification": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-llm-enabled",
        "author": "Zhang, Ruike and Tian, Yuan and Wei, Penghui and Zeng, Daniel Dajun and Mao, Wenji",
        "booktitle": "EMNLP-findings2024",
        "title": "An LLM-Enabled Knowledge Elicitation and Retrieval Framework for Zero-Shot Cross-Lingual Stance Identification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Stance detection aims to identify the attitudes toward specific targets from text, which is an important research area in text mining and social media analytics. Existing research is mainly conducted in monolingual setting on English datasets. To tackle the data scarcity problem in low-resource languages, cross-lingual stance detection (CLSD) transfers the knowledge from high-resource (source) language to low-resource (target) language. The CLSD task is the most challenging in zero-shot setting when no training data is available in target language, and transferring stance-relevant knowledge learned from high-resource language to bridge the language gap is the key for improving the performance of zero-shot CLSD. In this paper, we leverage the capability of large language model (LLM) for stance knowledge acquisition, and propose KEAR, a knowledge elicitation and retrieval framework. The knowledge elicitation module in KEAR first derives different types of stance knowledge from LLM\u2019s reasoning process. Then, the knowledge retrieval module in KEAR matches the target language input to the most relevant stance knowledge for enhancing text representations. Experiments on multilingual datasets show the effectiveness of KEAR compared with competitive baselines as well as the CLSD approaches trained with labeled data in target language.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.714",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TuringQ: Benchmarking AI Comprehension in Theory of Computation": {
        "type": "INPROCEEDINGS",
        "key": "zahraei-asgari-2024-turingq",
        "author": "Zahraei, Pardis Sadat and Asgari, Ehsaneddin",
        "booktitle": "EMNLP-findings2024",
        "title": "TuringQ: Benchmarking AI Comprehension in Theory of Computation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We present TuringQ, the first benchmark designed to evaluate the reasoning capabilities of large language models (LLMs) in the theory of computation. TuringQ consists of 4,006 undergraduate and graduate-level question-answer pairs, categorized into four difficulty levels and covering seven core theoretical areas. We evaluate several open-source LLMs, as well as GPT-4, using Chain of Thought prompting and expert human assessment. Additionally, we propose an automated LLM-based evaluation system that demonstrates competitive accuracy when compared to human evaluation. Fine-tuning a Llama3-8B model on TuringQ shows measurable improvements in reasoning ability and out-of-domain tasks such as algebra. TuringQ serves as both a benchmark and a resource for enhancing LLM performance in complex computational reasoning tasks. Our analysis offers insights into LLM capabilities and advances in AI comprehension of theoretical computer science.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.715",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Learning to Refine with Fine-Grained Natural Language Feedback": {
        "type": "INPROCEEDINGS",
        "key": "wadhwa-etal-2024-learning-refine",
        "author": "Wadhwa, Manya and Zhao, Xinyu and Li, Junyi Jessy and Durrett, Greg",
        "booktitle": "EMNLP-findings2024",
        "title": "Learning to Refine with Fine-Grained Natural Language Feedback",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent work has explored the capability of large language models (LLMs) to identify and correct errors in LLM-generated responses. These refinement approaches frequently evaluate what sizes of models are able to do refinement for what problems, but less attention is paid to what effective feedback for refinement looks like. In this work, we propose looking at refinement with feedback as a composition of three distinct LLM competencies: (1) detection of bad generations; (2) fine-grained natural language critique generation; (3) refining with fine-grained feedback. The first step can be implemented with a high-performing discriminative model and steps 2 and 3 can be implemented either via prompted or fine-tuned LLMs. A key property of the proposed Detect, Critique, Refine (\u201cDCR\u201d) method is that the step 2 critique model can give fine-grained feedback about errors, made possible by offloading the discrimination to a separate model in step 1. We show that models of different capabilities benefit from refining with DCR on the task of improving factual consistency of document grounded summaries. Overall, DCR consistently outperforms existing end-to-end refinement approaches and current trained models not fine-tuned for factuality critiquing.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.716",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Implicit Personalization in Language Models: A Systematic Study": {
        "type": "INPROCEEDINGS",
        "key": "jin-etal-2024-implicit",
        "author": "Jin, Zhijing and Heil, Nils and Liu, Jiarui and Dhuliawala, Shehzaad and Qi, Yahang and Sch\u00f6lkopf, Bernhard and Mihalcea, Rada and Sachan, Mrinmaya",
        "booktitle": "EMNLP-findings2024",
        "title": "Implicit Personalization in Language Models: A Systematic Study",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Implicit Personalization (IP) is a phenomenon of language models inferring a user\u2019s background from the implicit cues in the input prompts and tailoring the response based on this inference. While previous work has touched upon various instances of this problem, there lacks a unified framework to study this behavior. This work systematically studies IP through a rigorous mathematical formulation, a multi-perspective moral reasoning framework, and a set of case studies. Our theoretical foundation for IP relies on a structural causal model and introduces a novel method, indirect intervention, to estimate the causal effect of a mediator variable that cannot be directly intervened upon. Beyond the technical approach, we also introduce a set of moral reasoning principles based on three schools of moral philosophy to study when IP may or may not be ethically appropriate. Equipped with both mathematical and ethical insights, we present three diverse case studies illustrating the varied nature of the IP problem and offer recommendations for future research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.717",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "When the Misidentified Adverbial Phrase Functions as a Complement": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-misidentified",
        "author": "Chen, Yige and Kim, Kyuwon and Lim, KyungTae and Park, Jungyeul and Park, Chulwoo",
        "booktitle": "EMNLP-findings2024",
        "title": "When the Misidentified Adverbial Phrase Functions as a Complement",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This study investigates the predicate-argument structure in Korean language processing. Despite the importance of distinguishing mandatory arguments and optional modifiers in sentences, research in this area has been limited. We introduce a dataset with token-level annotations which labels mandatory and optional elements as complements and adjuncts, respectively. Particularly, we reclassify certain Korean phrases, previously misidentified as adverbial phrases, as complements, addressing misuses of the term adjunct in existing Korean treebanks. Utilizing a Korean dependency treebank, we develop an automatic labeling technique for complements and adjuncts. Experiments using the proposed dataset yield satisfying results, demonstrating that the dataset is trainable and reliable.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.718",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization": {
        "type": "INPROCEEDINGS",
        "key": "seo-etal-2024-unveiling",
        "author": "Seo, Kwangwook and Yeo, Jinyoung and Lee, Dongha",
        "booktitle": "EMNLP-findings2024",
        "title": "Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner for Insightful Table Summarization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Implicit knowledge hidden within the explicit table cells, such as data insights, is the key to generating a high-quality table summary. However, unveiling such implicit knowledge is a non-trivial task. Due to the complex nature of structured tables, it is challenging even for large language models (LLMs) to mine the implicit knowledge in an insightful and faithful manner. To address this challenge, we propose a novel table reasoning framework Question-then-Pinpoint. Our work focuses on building a plug-and-play table reasoner that can self-question the insightful knowledge and answer it by faithfully pinpointing evidence on the table to provide explainable guidance for the summarizer. To train a reliable reasoner, we collect table knowledge by guiding a teacher LLM to follow the coarse-to-fine reasoning paths and refine it through two quality enhancement strategies to selectively distill the high-quality knowledge to the reasoner. Extensive experiments on two table summarization datasets, including our newly proposed InsTaSumm, validate the general effectiveness of our framework.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.719",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Few-shot Prompting for Pairwise Ranking: An Effective Non-Parametric Retrieval Model": {
        "type": "INPROCEEDINGS",
        "key": "sinhababu-etal-2024-shot",
        "author": "Sinhababu, Nilanjan and Parry, Andrew and Ganguly, Debasis and Samanta, Debasis and Mitra, Pabitra",
        "booktitle": "EMNLP-findings2024",
        "title": "Few-shot Prompting for Pairwise Ranking: An Effective Non-Parametric Retrieval Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "A supervised ranking model, despite its effectiveness over traditional approaches, usually involves complex processing - typically multiple stages of task-specific pre-training and fine-tuning. This has motivated researchers to explore simpler pipelines leveraging large language models (LLMs) that can work in a zero-shot manner. However, since zero-shot inference does not make use of a training set of pairs of queries and their relevant documents, its performance is mostly worse than that of supervised models, which are trained on such example pairs. Motivated by the existing findings that training examples generally improve zero-shot performance, in our work, we explore if this also applies to ranking models. More specifically, given a query and a pair of documents, the preference prediction task is improved by augmenting examples of preferences for similar queries from a training set. Our proposed pairwise few-shot ranker demonstrates consistent improvements over the zero-shot baseline on both in-domain (TREC DL) and out-domain (BEIR subset) retrieval benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.720",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-training Language Models for Arithmetic Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "kadlcik-stefanik-2024-self",
        "author": "Kadl\u010d\u00edk, Marek and \u0160tef\u00e1nik, Michal",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-training Language Models for Arithmetic Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent language models achieve impressive results in tasks involving complex multistep reasoning, but scaling these capabilities further traditionally requires expensive collection of more annotated data.In this work, we explore the potential of improving models\u2019 reasoning capabilities without new data, merely using automated feedback to the validity of their predictions in arithmetic reasoning (self-training).In systematic experimentation across six different arithmetic reasoning datasets, we find that models can substantially improve in both single-round (offline) and online self-training, reaching a correct result in +13.9% and +25.9% more cases, respectively, underlining the importance of actuality of self-training feedback. We further find that in the single-round, offline self-training, traditional supervised training can deliver gains comparable to preference optimization, but in online self-training, preference optimization methods largely outperform supervised training thanks to their superior stability and robustness on unseen types of problems.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.721",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-pptc",
        "author": "Zhang, Zekai and Guo, Yiduo and Liang, Yaobo and Zhao, Dongyan and Duan, Nan",
        "booktitle": "EMNLP-findings2024",
        "title": "PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The growing dependence on Large Language Models (LLMs) for finishing user instructions necessitates a comprehensive understanding of their robustness to complex task completion in real-world situations. To address this critical need, we propose the PowerPoint Task Completion-Robustness (PPTC-R) benchmark to measure LLMs\u2019 robustness to the user PPT task instruction and software version (Powerpoint). Specifically, we construct adversarial user instructions by attacking user instructions at sentence, semantic, and multi-language levels. To assess the robustness of Language Models to software versions, we vary the number of provided APIs to simulate both the newest version and earlier version settings. Subsequently, we test 3 closed-source and 4 open-source LLMs using a benchmark that incorporates these robustness settings, aiming to evaluate how deviations impact LLMs\u2019 API calls for task completion. We find that GPT-4 exhibits the highest performance and strong robustness in our benchmark, particularly in the version update and the multilingual settings. However, we find that all LLMs lose their robustness when confronted with multiple challenges (e.g., multi-turn) simultaneously, leading to significant performance drops. We further analyze the robustness behavior and error reasons of LLMs in our benchmark, which provide valuable insights for researchers to understand the LLM\u2019s robustness in task completion and develop more robust LLMs and agents.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.722",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Efficient Pointwise-Pairwise Learning-to-Rank for News Recommendation": {
        "type": "INPROCEEDINGS",
        "key": "kannen-etal-2024-efficient",
        "author": "Kannen, Nithish and Ma, Yao and Van Den Burg, Gerrit J.j. and Faddoul, Jean Baptiste",
        "booktitle": "EMNLP-findings2024",
        "title": "Efficient Pointwise-Pairwise Learning-to-Rank for News Recommendation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "News recommendation is a challenging task that involves personalization based on the interaction history and preferences of each user. Recent works have leveraged the power of pretrained language models (PLMs) to directly rank news items by using inference approaches that predominately fall into three categories: pointwise, pairwise, and listwise learning-to-rank. While pointwise methods offer linear inference complexity, they fail to capture crucial comparative information between items that is more effective for ranking tasks. Conversely, pairwise and listwise approaches excel at incorporating these comparisons but suffer from practical limitations: pairwise approaches are either computationally expensive or lack theoretical guarantees and listwise methods often perform poorly in practice. In this paper, we propose a novel framework for PLM-based news recommendation that integrates both pointwise relevance prediction and pairwise comparisons in a scalable manner. We present a rigorous theoretical analysis of our framework, establishing conditions under which our approach guarantees improved performance. Extensive experiments show that our approach outperforms the state-of-the-art methods on the MIND and Adressa news recommendation datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.723",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Fast Matrix Multiplications for Lookup Table-Quantized LLMs": {
        "type": "INPROCEEDINGS",
        "key": "guo-etal-2024-fast",
        "author": "Guo, Han and Brandon, William and Cholakov, Radostin and Ragan-Kelley, Jonathan and Xing, Eric P. and Kim, Yoon",
        "booktitle": "EMNLP-findings2024",
        "title": "Fast Matrix Multiplications for Lookup Table-Quantized LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The deployment of large language models (LLMs) is often constrained by memory bandwidth, where the primary bottleneck is the cost of transferring model parameters from the GPU\u2019s global memory to its registers. When coupled with custom kernels that fuse the dequantization and matmul operations, weight-only quantization can thus enable faster inference by reducing the amount of memory movement. However, developing high-performance kernels for weight-quantized LLMs presents substantial challenges, especially when the weights are compressed to non-evenly-divisible bit widths (e.g., 3 bits) with non-uniform, lookup table (LUT) quantization. This paper describes FLUTE, a flexible lookup table engine for LUT-quantized LLMs, which uses offline restructuring of the quantized weight matrix to minimize bit manipulations associated with unpacking, and vectorization and duplication of the lookup table to mitigate shared memory bandwidth constraints. At batch sizes \\textless 32 and quantization group size of 128 (typical in LLM inference), the FLUTE kernel can be 2-4x faster than existing GEMM kernels. As an application of FLUTE, we explore a simple extension to lookup table-based NormalFloat quantization and apply it to quantize LLaMA3 to various configurations, obtaining competitive quantization performance against strong baselines while obtaining an end-to-end throughput increase of 1.5 to 2 times.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.724",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Distance-aware Calibration for Pre-trained Language Models": {
        "type": "INPROCEEDINGS",
        "key": "gasparin-detommaso-2024-distance",
        "author": "Gasparin, Alberto and Detommaso, Gianluca",
        "booktitle": "EMNLP-findings2024",
        "title": "Distance-aware Calibration for Pre-trained Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language Models for text classification often produce overconfident predictions for both in-distribution and out-of-distribution samples, i.e., the model\u2019s output probabilities do not match their accuracy. Prior work showed that simple post-hoc approaches are effective for mitigating this issue, but are not robust in noisy settings, e.g., when the distribution shift is caused by spelling mistakes. In this work, we propose Distance Aware Calibration (DAC), a post-hoc approach that changes the confidence scores of a Language Model leveraging the distance between new samples been evaluated and the in-domain training set. We show that using DAC on top of a Language Model can improve in-domain calibration, robustness to different kind of distribution shift and also the model\u2019s ability to detect out-of-distribution samples. We provide an extensive evaluation on common text classification benchmark for both calibration and out-of-distribution detection tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.725",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks": {
        "type": "INPROCEEDINGS",
        "key": "gallifant-etal-2024-language",
        "author": "Gallifant, Jack and Chen, Shan and Moreira, Pedro Jos\u00e9 Ferreira and Munch, Nikolaj and Gao, Mingye and Pond, Jackson and Celi, Leo Anthony and Aerts, Hugo and Hartvigsen, Thomas and Bitterman, Danielle",
        "booktitle": "EMNLP-findings2024",
        "title": "Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Medical knowledge is context-dependent and requires consistent reasoning across various natural language expressions of semantically equivalent phrases. This is particularly crucial for drug names, where patients often use brand names like Advil or Tylenol instead of their generic equivalents. To study this, we create a new robustness dataset, RABBITS, to evaluate performance differences on medical benchmarks after swapping brand and generic drug names using physician expert annotations.We assess both open-source and API-based LLMs on MedQA and MedMCQA, revealing a consistent performance drop ranging from 1-10%. Furthermore, we identify a potential source of this fragility as the contamination of test data in widely used pre-training datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.726",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "To Err Is Human, but Llamas Can Learn It Too": {
        "type": "INPROCEEDINGS",
        "key": "luhtaru-etal-2024-err",
        "author": "Luhtaru, Agnes and Purason, Taido and Vainikko, Martin and Del, Maksym and Fishel, Mark",
        "booktitle": "EMNLP-findings2024",
        "title": "To Err Is Human, but Llamas Can Learn It Too",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This study explores enhancing grammatical error correction (GEC) through automatic error generation (AEG) using language models (LMs). Specifically, we fine-tune Llama 2 LMs for error generation and find that this approach yields synthetic errors akin to human errors. Next, we train GEC Llama models using these artificial errors and outperform previous state-of-the-art error correction models, with gains ranging between 0.8 and 6 F0.5 points across all tested languages (German, Ukrainian, and Estonian). Moreover, we demonstrate that generating errors by fine-tuning smaller sequence-to-sequence models and prompting large commercial LMs (GPT3.5 and GPT4) also results in synthetic errors beneficially affecting error generation models. We openly release trained models for error generation and correction as well as all the synthesized error datasets for the covered languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.727",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PizzaCommonSense: A Dataset for Commonsense Reasoning about Intermediate Steps in Cooking Recipes": {
        "type": "INPROCEEDINGS",
        "key": "diallo-etal-2024-pizzacommonsense",
        "author": "Diallo, Aissatou and Bikakis, Antonis and Dickens, Luke and Hunter, Anthony and Miller, Rob",
        "booktitle": "EMNLP-findings2024",
        "title": "PizzaCommonSense: A Dataset for Commonsense Reasoning about Intermediate Steps in Cooking Recipes",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Understanding procedural texts, such as cooking recipes, is essential for enabling machines to follow instructions and reason about tasks, a key aspect of intelligent reasoning. In cooking, these instructions can be interpreted as a series of modifications to a food preparation.For a model to effectively reason about cooking recipes, it must accurately discern and understand the inputs and outputs of intermediate steps within the recipe.We present a new corpus of cooking recipes enriched with descriptions of intermediate steps that describe the input and output for each step. PizzaCommonsense serves as a benchmark for the reasoning capabilities of LLMs because it demands rigorous explicit input-output descriptions to demonstrate the acquisition of implicit commonsense knowledge, which is unlikely to beeasily memorized. GPT-4 achieves only 26% human-evaluated preference for generations, leaving room for future improvements.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.728",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Discourse Dependency Parsing with Sentence Dependency Parsing: A Unified Generative Method Based on Code Representation": {
        "type": "INPROCEEDINGS",
        "key": "shen-etal-2024-enhancing",
        "author": "Shen, Zizhuo and Shao, Yanqiu and Li, Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Discourse Dependency Parsing with Sentence Dependency Parsing: A Unified Generative Method Based on Code Representation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Due to the high complexity of Discourse Dependency Parsing (DDP) tasks, their existing annotation resources are relatively scarce compared to other NLP tasks, and different DDP tasks also have significant differences in annotation schema. These issues have led to the dilemma of low resources for DDP tasks. Thanks to the powerful capabilities of Large Language Models (LLMs) in cross-task learning, we can use LLMs to model dependency parsing under different annotation schema in an unified manner, in order to alleviate the dilemma of low resources for DDP tasks. However, enabling LLMs to deeply comprehend dependency parsing tasks is a challenge that remains underexplored. Inspired by the application of code-based methods in complex tasks, we propose a code-based unified dependency parsing method. We treat the process of dependency parsing as a search process of dependency paths and use code to represent this search process. Furthermore, we use a curriculum-learning based instruction tuning strategy for joint training of multiple dependency parsing tasks. The experimental results show that our proposed code-based DDP system has achieved good performance on two Chinese DDP tasks (especially significant improvement on the DDP task with relatively less training data).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.729",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "\u201cKnowing When You Don\u2019t Know\u201d: A Multilingual Relevance Assessment Dataset for Robust Retrieval-Augmented Generation": {
        "type": "INPROCEEDINGS",
        "key": "thakur-etal-2024-knowing",
        "author": "Thakur, Nandan and Bonifacio, Luiz and Zhang, Crystina and Ogundepo, Odunayo and Kamalloo, Ehsan and Alfonso-Hermelo, David and Li, Xiaoguang and Liu, Qun and Chen, Boxing and Rezagholizadeh, Mehdi and Lin, Jimmy",
        "booktitle": "EMNLP-findings2024",
        "title": "\u201cKnowing When You Don\u2019t Know\u201d: A Multilingual Relevance Assessment Dataset for Robust Retrieval-Augmented Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-Augmented Generation (RAG) grounds Large Language Model (LLM) output by leveraging external knowledge sources to reduce factual hallucinations. However, prior work lacks a comprehensive evaluation of different language families, making it challenging to evaluate LLM robustness against errors in external retrieved knowledge. To overcome this, we establish **NoMIRACL**, a human-annotated dataset for evaluating LLM robustness in RAG across 18 typologically diverse languages. NoMIRACL includes both a non-relevant and a relevant subset. Queries in the non-relevant subset contain passages judged as non-relevant, whereas queries in the relevant subset include at least a single judged relevant passage. We measure relevance assessment using: (i) *hallucination rate*, measuring model tendency to hallucinate when the answer is not present in passages in the non-relevant subset, and (ii) *error rate*, measuring model inaccuracy to recognize relevant passages in the relevant subset. In our work, we observe that most models struggle to balance the two capacities. Models such as LLAMA-2 and Orca-2 achieve over 88% hallucination rate on the non-relevant subset. Mistral and LLAMA-3 hallucinate less but can achieve up to a 74.9% error rate on the relevant subset. Overall, GPT-4 is observed to provide the best tradeoff on both subsets, highlighting future work necessary to improve LLM robustness. NoMIRACL dataset and evaluation code are available at: https://github.com/project-miracl/nomiracl.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.730",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking": {
        "type": "INPROCEEDINGS",
        "key": "finch-choi-2024-diverse",
        "author": "Finch, James D. and Choi, Jinho D.",
        "booktitle": "EMNLP-findings2024",
        "title": "Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We demonstrate substantial performance gains in zero-shot dialogue state tracking (DST) by enhancing training data diversity through synthetic data generation.Existing DST datasets are severely limited in the number of application domains and slot types they cover due to the high costs of data collection, restricting their adaptability to new domains.This work addresses this challenge with a novel, fully automatic data generation approach that creates synthetic zero-shot DST datasets.Distinguished from previous methods, our approach can generate dialogues across a massive range of application domains, complete with silver-standard dialogue state annotations and slot descriptions.This technique is used to create the D0T dataset for training zero-shot DST models, encompassing an unprecedented 1,000+ domains. Experiments on the MultiWOZ benchmark show that training models on diverse synthetic data improves Joint Goal Accuracy by 6.7%, achieving results competitive with models 13.5 times larger than ours.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.731",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can We Instruct LLMs to Compensate for Position Bias?": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-instruct",
        "author": "Zhang, Meiru and Meng, Zaiqiao and Collier, Nigel",
        "booktitle": "EMNLP-findings2024",
        "title": "Can We Instruct LLMs to Compensate for Position Bias?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Position bias in large language models (LLMs) leads to difficulty in accessing information retrieved from the retriever, thus downgrading the effectiveness of Retrieval-Augmented Generation (RAG) approaches in open-question answering. Recent studies reveal that this bias is related to disproportional attention across the context. In this work, we examine how to direct LLMs to allocate more attention towards a selected segment of the context through prompting, aiming to compensate for the shortage of attention. We find that language models do not have relative position awareness of the context but can be directed by promoting instruction with an exact document index. Our analysis contributes to a deeper understanding of position bias in LLMs and provides a pathway to mitigate this bias by instruction, thus benefiting LLMs in locating and utilizing relevant information from retrieved documents in RAG applications. The code and data in our study have been made publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.732",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Textual Dataset Distillation via Language Model Embedding": {
        "type": "INPROCEEDINGS",
        "key": "tao-etal-2024-textual",
        "author": "Tao, Yefan and Kong, Luyang and Kan, Andrey and Callot, Laurent",
        "booktitle": "EMNLP-findings2024",
        "title": "Textual Dataset Distillation via Language Model Embedding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Dataset distillation is a process aimed at condensing datasets while preserving essential characteristics. In the text domain, prevailing methods typically generate distilled data as embedding vectors, which are not human-readable. This approach simplifies optimization but limits the transferability of distilled data across different model architectures. To address this limitation, we introduce a model-agnostic, data-efficient method that leverages Language Model (LM) embeddings. Compared to parameter-efficient methods such as LORA, our approach achieves comparable performance with significantly faster processing times. We evaluate our methodology through classification tasks on datasets like IMDB and AG-News, demonstrating performance that is on par with or exceeds previous model-dependent techniques. By utilizing LM embeddings, our method offers enhanced flexibility and improved transferability, expanding the range of potential applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.733",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AuriSRec: Adversarial User Intention Learning in Sequential Recommendation": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-aurisrec",
        "author": "Zhang, Junjie and Xie, Ruobing and Sun, Wenqi and Lin, Leyu and Zhao, Xin and Wen, Ji-Rong",
        "booktitle": "EMNLP-findings2024",
        "title": "AuriSRec: Adversarial User Intention Learning in Sequential Recommendation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With recommender systems broadly deployed in various online platforms, many efforts have been devoted to learning user preferences and building effective sequential recommenders. However, existing work mainly focuses on capturing user implicit preferences from historical interactions and simply matching them with the next behavior, instead of predicting user explicit intentions. This may lead to inappropriate recommendations. In light of this issue, we propose the adversarial user intention learning approach for sequential recommendaiton, named AuriSRec. The major novelty of our approach is to explicitly predict user current intentions when making recommendations, by inferring their decision-making process as explained in target reviews (reviews written after interacting with the ground-truth item). Specifically, AuriSRec conducts adversarial learning between an intention generator and a discriminator. The generator predicts user intentions by taking their historical reviews and behavioral sequences as inputs, while target reviews provide guidance. Beyond typical sequential modeling methods in the field of natural language process (NLP), a decoupling-based review encoder and a hybrid attention fusion mechanism are introduced to filter noise and enhance the generation capacity. On the other hand, the discriminator determines whether the intention is generated or real based on their matching degree to the target item, thereby guiding the generator to produce gradually improved intentions. Extensive experiments on five real-world datasets demonstrate the effectiveness of our approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.735",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Denoising Rationalization for Multi-hop Fact Verification via Multi-granular Explainer": {
        "type": "INPROCEEDINGS",
        "key": "si-etal-2024-denoising",
        "author": "Si, Jiasheng and Zhu, Yingjie and Lu, Wenpeng and Zhou, Deyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Denoising Rationalization for Multi-hop Fact Verification via Multi-granular Explainer",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The success of deep learning models on multi-hop fact verification has prompted researchers to understand the behavior behind their veracity. One feasible way is erasure search: obtaining the rationale by entirely removing a subset of input without compromising verification accuracy. Despite extensive exploration, current rationalization methods struggle to discern nuanced composition within the correlated evidence, which inevitably leads to noise rationalization in multi-hop scenarios. To address this issue, this paper explores the multi-granular rationale extraction method, aiming to realize the denoising rationalization for multi-hop fact verification. Specifically, given a pretrained veracity prediction model, two independent external explainers are introduced and trained collaboratively to enhance the discriminating ability by imposing varied constraints. Meanwhile, three key properties (Fidelity, Consistency, Salience) are introduced to regularize the denoising and faithful rationalization process. Additionally, a new Noiselessness metric is proposed to measure the purity of the rationales. Experimental results on three multi-hop fact verification datasets show that the proposed approach outperforms 12 baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.736",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP": {
        "type": "INPROCEEDINGS",
        "key": "yao-etal-2024-readme",
        "author": "Yao, Zonghai and Kantu, Nandyala Siddharth and Wei, Guanghao and Tran, Hieu and Duan, Zhangqi and Kwon, Sunjae and Yang, Zhichao and Yu, Hong",
        "booktitle": "EMNLP-findings2024",
        "title": "README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The advancement in healthcare has shifted focus toward patient-centric approaches, particularly in self-care and patient education, facilitated by access to Electronic Health Records (EHR). However, medical jargon in EHRs poses significant challenges in patient comprehension. To address this, we introduce a new task of automatically generating lay definitions, aiming to simplify complex medical terms into patient-friendly lay language. We first created the README dataset, an extensive collection of over 50,000 unique (medical term, lay definition) pairs and 300,000 mentions, each offering context-aware lay definitions manually annotated by domain experts. We have also engineered a data-centric Human-AI pipeline that synergizes data filtering, augmentation, and selection to improve data quality. We then used README as the training data for models and leveraged a Retrieval-Augmented Generation method to reduce hallucinations and improve the quality of model outputs. Our extensive automatic and human evaluations demonstrate that open-source mobile-friendly models, when fine-tuned with high-quality data, are capable of matching or even surpassing the performance of state-of-the-art closed-source large language models like ChatGPT. This research represents a significant stride in closing the knowledge gap in patient education and advancing patient-centric healthcare solutions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.737",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts": {
        "type": "INPROCEEDINGS",
        "key": "cha-lee-2024-pre",
        "author": "Cha, Taehun and Lee, Donghun",
        "booktitle": "EMNLP-findings2024",
        "title": "Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this work, we show the pre-trained language models return distinguishable generation probability and uncertainty distribution to unfaithfully hallucinated texts, regardless of their size and structure. By examining 24 models on 6 data sets, we find out that 88-98% of cases return statistically significantly distinguishable generation probability and uncertainty distributions. Using this general phenomenon, we showcase a hallucination-reducing training algorithm. Our algorithm outperforms other baselines by achieving higher faithfulness metrics while maintaining sound general text quality measures.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.738",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Cognitive Bias in Decision-Making with LLMs": {
        "type": "INPROCEEDINGS",
        "key": "echterhoff-etal-2024-cognitive",
        "author": "Echterhoff, Jessica Maria and Liu, Yao and Alessa, Abeer and McAuley, Julian and He, Zexue",
        "booktitle": "EMNLP-findings2024",
        "title": "Cognitive Bias in Decision-Making with LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. Given their training on human (created) data, LLMs have been shown to inherit societal biases against protected groups, as well as be subject to bias functionally resembling cognitive bias. Human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive science, we develop a dataset containing 13,465 prompts to evaluate LLM decisions on different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, while proposing a novel method utilizing LLMs to debias their own human-like cognitive bias within prompts. Our analysis provides a comprehensive picture of the presence and effects of cognitive bias across commercial and open-source models. We demonstrate that our selfhelp debiasing effectively mitigates model answers that display patterns akin to human cognitive bias without having to manually craft examples for each bias.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.739",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-problem",
        "author": "Wang, Rose E. and Wirawarn, Pawan and Lam, Kenny and Khattab, Omar and Demszky, Dorottya",
        "booktitle": "EMNLP-findings2024",
        "title": "Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Many open-ended conversations (e.g., tutoring lessons or business meetings) revolve around pre-defined reference materials, like worksheets or meeting bullets. To provide a framework for studying such conversation structure, we introduce *Problem-Oriented Segmentation &amp; Retrieval (POSR), the task of jointly breaking down conversations into segments and linking each segment to the relevant reference item. As a case study, we apply POSR to education where effectively structuring lessons around problems is critical yet difficult. We present *LessonLink*, the first dataset of real-world tutoring lessons, featuring 3,500 segments, spanning 24,300 minutes of instruction and linked to 116 SAT Math problems. We define and evaluate several joint and independent approaches for POSR, including segmentation (e.g., TextTiling), retrieval (e.g., ColBERT), and large language models (LLMs) methods. Our results highlight that modeling POSR as one joint task is essential: POSR methods outperform independent segmentation and retrieval pipelines by up to +76% on joint metrics and surpass traditional segmentation methods by up to +78% on segmentation metrics. We demonstrate POSR\u2019s practical impact on downstream education applications, deriving new insights on the language and time use in real-world lesson structures.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.740",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models": {
        "type": "INPROCEEDINGS",
        "key": "he-etal-2024-prompt",
        "author": "He, Kang and Long, Yinghan and Roy, Kaushik",
        "booktitle": "EMNLP-findings2024",
        "title": "Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prompt-based learning is susceptible to intrinsic bias present in pre-trained language models (LMs), leading to sub-optimal performance in prompt-based zero/few-shot settings. In this work, we propose a null-input prompting method to calibrate intrinsic bias encoded in pre-trained LMs. Different from prior efforts that address intrinsic bias primarily for social fairness and often involve excessive computational cost, our objective is to explore enhancing LMs\u2019 performance in downstream zero/few-shot learning while emphasizing the efficiency of intrinsic bias calibration. Specifically, we leverage a diverse set of auto-selected null-meaning inputs generated from GPT-4 to probe intrinsic bias of pre-trained LMs. Utilizing the bias-reflected probability distribution, we formulate a distribution disparity loss for bias calibration, where we exclusively update bias parameters (0.1% of total parameters) of LMs towards equal probability distribution. Experimental results show that the calibration promotes an equitable starting point for LMs while preserving language modeling abilities. Across a wide range of datasets, including sentiment analysis and topic classification, our method significantly improves zero/few-shot learning performance of LMs for both in-context learning and prompt-based fine-tuning (on average 9% and 2%, respectively).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.741",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can\u2019t Remember Details in Long Documents? You Need Some R&amp;R": {
        "type": "INPROCEEDINGS",
        "key": "agrawal-etal-2024-cant",
        "author": "Agrawal, Devanshu and Gao, Shang and Gajek, Martin",
        "booktitle": "EMNLP-findings2024",
        "title": "Can\u2019t Remember Details in Long Documents? You Need Some R&amp;R",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Long-context large language models (LLMs) hold promise for tasks such as question-answering (QA) over long documents, but they tend to miss important information in the middle of context documents [(Liu 2023)](https://arxiv.org/abs/2307.03172). Here, we introduce *R&amp;R*\u2014a combination of two novel prompt-based methods called *reprompting* and *in-context retrieval* (ICR)\u2014to alleviate this effect in document-based QA. In reprompting, we repeat the prompt instructions periodically throughout the context document to remind the LLM of its original task. In ICR, rather than instructing the LLM to answer the question directly, we instruct it to retrieve the top k passage numbers most relevant to the given question, which are then used as an abbreviated context in a second QA prompt. We test R&amp;R with GPT-4 Turbo and Claude-2.1 on documents up to 80k tokens in length and observe a 16-point boost in QA accuracy on average. Our further analysis suggests that R&amp;R improves performance on long document-based QA because it reduces the distance between relevant context and the instructions. Finally, we show that compared to short-context chunkwise methods, R&amp;R enables the use of larger chunks that cost fewer LLM calls and output tokens, while minimizing the drop in accuracy.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.742",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid": {
        "type": "INPROCEEDINGS",
        "key": "lamba-etal-2024-humvi",
        "author": "Lamba, Hemank and Abilov, Anton and Zhang, Ke and Olson, Elizabeth M. and Dambanemuya, Henry Kudzanai and B\u00e1rcia, Jo\u00e3o Cordovil and Batista, David S. and Wille, Christina and Cahill, Aoife and Tetreault, Joel R. and Jaimes, Alejandro",
        "booktitle": "EMNLP-findings2024",
        "title": "HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Humanitarian organizations can enhance their effectiveness by analyzing data to discover trends, gather aggregated insights, manage their security risks, support decision-making, and inform advocacy and funding proposals. However, data about violent incidents with direct impact and relevance for humanitarian aid operations is not readily available. An automatic data collection and NLP-backed classification framework aligned with humanitarian perspectives can help bridge this gap. In this paper, we present HumVI \u2013 a dataset comprising news articles in three languages (English, French, Arabic) containing instances of different types of violent incidents categorized by the humanitarian sector they impact, e.g., aid security, education, food security, health, and protection. Reliable labels were obtained for the dataset by partnering with a data-backed humanitarian organization, Insecurity Insight. We provide multiple benchmarks for the dataset, employing various deep learning architectures and techniques, including data augmentation and mask loss, to address different task-related challenges, e.g., domain expansion. The dataset is publicly available at https://github.com/dataminr-ai/humvi-dataset.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.743",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Quotation Attribution with Fictional Character Embeddings": {
        "type": "INPROCEEDINGS",
        "key": "michel-etal-2024-improving",
        "author": "Michel, Gaspard and Epure, Elena V. and Hennequin, Romain and Cerisara, Christophe",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Quotation Attribution with Fictional Character Embeddings",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Humans naturally attribute utterances of direct speech to their speaker in literary works.When attributing quotes, we process contextual information but also access mental representations of characters that we build and revise throughout the narrative. Recent methods to automatically attribute such utterances have explored simulating human logic with deterministic rules or learning new implicit rules with neural networks when processing contextual information.However, these systems inherently lack character representations, which often leads to errors in more challenging examples of attribution: anaphoric and implicit quotes.In this work, we propose to augment a popular quotation attribution system, BookNLP, with character embeddings that encode global stylistic information of characters derived from an off-the-shelf stylometric model, Universal Authorship Representation (UAR).We create DramaCV, a corpus of English drama plays from the 15th to 20th century that we automatically annotate for Authorship Verification of fictional characters utterances, and release two versions of UAR trained on DramaCV, that are tailored for literary characters analysis.Then, through an extensive evaluation on 28 novels, we show that combining BookNLP\u2019s contextual information with our proposed global character embeddings improves the identification of speakers for anaphoric and implicit quotes, reaching state-of-the-art performance.Code and data can be found at https://github.com/deezer/character_embeddings_qa.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.744",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Robust Text Classification: Analyzing Prototype-Based Networks": {
        "type": "INPROCEEDINGS",
        "key": "sourati-etal-2024-robust",
        "author": "Sourati, Zhivar and Deshpande, Darshan Girish and Ilievski, Filip and Gashteovski, Kiril and Saralajew, Sascha",
        "booktitle": "EMNLP-findings2024",
        "title": "Robust Text Classification: Analyzing Prototype-Based Networks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Downstream applications often require text classification models to be accurate and robust. While the accuracy of state-of-the-art Language Models (LMs) approximates human performance, they often exhibit a drop in performance on real-world noisy data. This lack of robustness can be concerning, as even small perturbations in text, irrelevant to the target task, can cause classifiers to incorrectly change their predictions. A potential solution can be the family of Prototype-Based Networks (PBNs) that classifies examples based on their similarity to prototypical examples of a class (prototypes) and has been shown to be robust to noise for computer vision tasks. In this paper, we study whether the robustness properties of PBNs transfer to text classification tasks under both targeted and static adversarial attack settings. Our results show that PBNs, as a mere architectural variation of vanilla LMs, offer more robustness compared to vanilla LMs under both targeted and static settings. We showcase how PBNs\u2019 interpretability can help us understand PBNs\u2019 robustness properties. Finally, our ablation studies reveal the sensitivity of PBNs\u2019 robustness to the strictness of clustering and the number of prototypes in the training phase, as tighter clustering and a low number of prototypes result in less robust PBNs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.745",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-graphreader",
        "author": "Li, Shilong and He, Yancheng and Guo, Hangyu and Bu, Xingyuan and Bai, Ge and Liu, Jie and Liu, Jiaheng and Qu, Xingwei and Li, Yangguang and Ouyang, Wanli and Su, Wenbo and Zheng, Bo",
        "booktitle": "EMNLP-findings2024",
        "title": "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Long-context capabilities are essential for large language models (LLMs) to tackle complex and long-input tasks. Despite numerous efforts made to optimize LLMs for long contexts, challenges persist in robustly processing long inputs. In this paper, we introduce GraphReader, a graph-based agent system designed to handle long texts by structuring them into a graph and employing an agent to explore this graph autonomously. Upon receiving a question, the agent first undertakes a step-by-step analysis and devises a rational plan. It then invokes a set of predefined functions to read node content and neighbors, facilitating a coarse-to-fine exploration of the graph. Throughout the exploration, the agent continuously records new insights and reflects on current circumstances to optimize the process until it has gathered sufficient information to generate an answer. Experimental results on the LV-Eval dataset reveal that GraphReader using a 4k context window, consistently outperforms GPT-4-128k across context lengths from 16k to 256k by a large margin. Additionally, our approach demonstrates superior performance on four challenging single-hop and multi-hop benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.746",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Compare without Despair: Reliable Preference Evaluation with Generation Separability": {
        "type": "INPROCEEDINGS",
        "key": "ghosh-etal-2024-compare",
        "author": "Ghosh, Sayan and Srinivasan, Tejas and Swayamdipta, Swabha",
        "booktitle": "EMNLP-findings2024",
        "title": "Compare without Despair: Reliable Preference Evaluation with Generation Separability",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Human evaluation of generated language through pairwise preference judgments is pervasive. However, under common scenarios, such as when generations from a model pair are very similar, or when stochastic decoding results in large variations in generations, it results in inconsistent preference ratings. We address these challenges by introducing a meta-evaluation measure, separability, which estimates how suitable a test instance is for pairwise preference evaluation. For a candidate test instance, separability samples multiple generations from a pair of models, and measures how distinguishable the two sets of generations are. Our experiments show that instances with high separability values yield more consistent preference ratings from both human- and auto-raters. Further, the distribution of separability allows insights into which test benchmarks are more valuable for comparing models. Finally, we incorporate separability into ELO ratings, accounting for how suitable each test instance might be for reliably ranking LLMs. Overall, separability has implications for consistent, efficient and robust preference evaluation of LLMs with both human- and auto-raters.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.747",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-lorasc",
        "author": "Li, Siwei and Yang, Yifan and Shen, Yifei and Wei, Fangyun and Lu, Zongqing and Qiu, Lili and Yang, Yuqing",
        "booktitle": "EMNLP-findings2024",
        "title": "LoRASC: Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Efficient fine-tuning plays a fundamental role in modern large models, with low-rank adaptation emerging as a particularly promising approach. However, the existing variants of LoRA are hampered by limited expressiveness, a tendency to overfit, and sensitivity to hyperparameter settings. This paper presents LoRA Slow Cascade Learning (LoRASC), an innovative technique designed to enhance LoRA\u2019s expressiveness and generalization capabilities while preserving its training efficiency. Our approach augments expressiveness through a cascaded learning strategy that enables a mixture-of-low-rank adaptation, thereby increasing the model\u2019s ability to capture complex patterns. Additionally, we introduce a slow-fast update mechanism and cascading noisy tuning to bolster generalization. The extensive experiments on various language and vision datasets, as well as robustness benchmarks, demonstrate that the proposed method not only significantly outperforms existing baselines, but also mitigates overfitting, enhances model stability, and improves OOD robustness.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.748",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models": {
        "type": "INPROCEEDINGS",
        "key": "munoz-etal-2024-sqft",
        "author": "Munoz, Juan Pablo and Yuan, Jinjie and Jain, Nilesh",
        "booktitle": "EMNLP-findings2024",
        "title": "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large pre-trained models (LPMs), such as large language models, have become ubiquitous and are employed in many applications. These models are often adapted to a desired domain or downstream task through a fine-tuning stage. This paper proposes SQFT, an end-to-end solution for low-precision sparse parameter-efficient fine-tuning of LPMs, allowing for effective model manipulation in resource-constrained environments. Additionally, an innovative strategy enables the merging of sparse weights with low-rank adapters without losing sparsity and accuracy, overcoming the limitations of previous approaches. SQFT also addresses the challenge of having quantized weights and adapters with different numerical precisions, enabling merging in the desired numerical format without sacrificing accuracy. Multiple adaptation scenarios, models, and comprehensive sparsity levels demonstrate the effectiveness of SQFT.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.749",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Securing Multi-turn Conversational Language Models From Distributed Backdoor Attacks": {
        "type": "INPROCEEDINGS",
        "key": "tong-etal-2024-securing",
        "author": "Tong, Terry and Liu, Qin and Xu, Jiashu and Chen, Muhao",
        "booktitle": "EMNLP-findings2024",
        "title": "Securing Multi-turn Conversational Language Models From Distributed Backdoor Attacks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have acquired the ability to handle longer context lengths and understand nuances in text, expanding their dialogue capabilities beyond a single utterance. A popular user-facing application of LLMs is the multi-turn chat setting. Though longer chat memory and better understanding may seemingly benefit users, our paper exposes a vulnerability that leverages the multi-turn feature and strong learning ability of LLMs to harm the end-user: the backdoor. We demonstrate that LLMs can capture the combinational backdoor representation. Only upon presentation of triggers together does the backdoor activate. We also verify empirically that this representation is invariant to the position of the trigger utterance. Subsequently, inserting a single extra token into any two utterances of 5% of the data can cause over 99% Attack Success Rate (ASR). Our results with 3 triggers demonstrate that this framework is generalizable, compatible with any trigger in an adversary\u2019s toolbox in a plug-and-play manner. Defending the backdoor can be challenging in the conversational setting because of the large input and output space. Our analysis indicates that the distributed backdoor exacerbates the current challenges by polynomially increasing the dimension of the attacked input space. Canonical textual defenses like ONION and BKI leverage auxiliary model forward passes over individual tokens, scaling exponentially with the input sequence length and struggling to maintain computational feasibility. To this end, we propose a decoding time defense \u2013 decayed contrastive decoding \u2013 that scales linearly with the assistant response sequence length and reduces the backdoor to as low as 0.35%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.750",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States": {
        "type": "INPROCEEDINGS",
        "key": "beigi-etal-2024-internalinspector",
        "author": "Beigi, Mohammad and Shen, Ying and Yang, Runing and Lin, Zihao and Wang, Qifan and Mohan, Ankith and He, Jianfeng and Jin, Ming and Lu, Chang-Tien and Huang, Lifu",
        "booktitle": "EMNLP-findings2024",
        "title": "InternalInspector I\u00b2: Robust Confidence Estimation in LLMs through Internal States",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite their vast capabilities, Large Language Models (LLMs) often struggle with generating reliable outputs, frequently producing high-confidence inaccuracies known as hallucinations. Addressing this challenge, our research introduces InternalInspector, a novel framework designed to enhance confidence estimation in LLMs by leveraging contrastive learning on internal states including attention states, feed-forward states, and activation states of all layers. Unlike existing methods that primarily focus on the final activation state, InternalInspector conducts a comprehensive analysis across all internal states of every layer to accurately identify both correct and incorrect prediction processes. By benchmarking InternalInspector against existing confidence estimation methods across various natural language understanding and generation tasks, including factual question answering, commonsense reasoning, and reading comprehension, InternalInspector achieves significantly higher accuracy in aligning the estimated confidence scores with the correctness of the LLM\u2019s predictions and lower calibration error. Furthermore, InternalInspector excels at HaluEval, a hallucination detection benchmark, outperforming other internal-based confidence estimation methods in this task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.751",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "All You Need is Attention: Lightweight Attention-based Data Augmentation for Text Classification": {
        "type": "INPROCEEDINGS",
        "key": "kim-hwang-2024-need",
        "author": "Kim, Junehyung and Hwang, Sungjae",
        "booktitle": "EMNLP-findings2024",
        "title": "All You Need is Attention: Lightweight Attention-based Data Augmentation for Text Classification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper introduces LADAM, a novel method for enhancing the performance of text classification tasks. LADAM employs attention mechanisms to exchange semantically similar words between sentences. This approach generates a greater diversity of synthetic sentences compared to simpler operations like random insertions, while maintaining the context of the original sentences. Additionally, LADAM is an easy-to-use, lightweight technique that does not require external datasets or large language models. Our experimental results across five datasets demonstrate that LADAM consistently outperforms baseline methods across diverse text classification conditions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.752",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation": {
        "type": "INPROCEEDINGS",
        "key": "shahariar-etal-2024-adversarial",
        "author": "Shahariar, G. M. and Chen, Jia and Li, Jiachen and Dong, Yue",
        "booktitle": "EMNLP-findings2024",
        "title": "Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent studies show that text-to-image (T2I) models are vulnerable to adversarial attacks, especially with noun perturbations in text prompts. In this study, we investigate the impact of adversarial attacks on different POS tags within text prompts on the images generated by T2I models. We create a high-quality dataset for realistic POS tag token swapping and perform gradient-based attacks to find adversarial suffixes that mislead T2I models into generating images with altered tokens. Our empirical results show that the attack success rate (ASR) varies significantly among different POS tag categories, with nouns, proper nouns, and adjectives being the easiest to attack. We explore the mechanism behind the steering effect of adversarial suffixes, finding that the number of critical tokens and information fusion vary among POS tags, while features like suffix transferability are consistent across categories.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.753",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Alignment using Curriculum Learning &amp; Ranked Preferences": {
        "type": "INPROCEEDINGS",
        "key": "pattnaik-etal-2024-enhancing",
        "author": "Pattnaik, Pulkit and Maheshwary, Rishabh and Ogueji, Kelechi and Yadav, Vikas and Madhusudhan, Sathwik Tejaswi",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Alignment using Curriculum Learning &amp; Ranked Preferences",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Direct Preference Optimization (DPO) is an effective technique that leverages pairwise preference data (one chosen and rejected response per prompt) to align LLMs to human preferences. In practice, multiple responses could exist for a given prompt with varying quality relative to each other. We propose to utilize these responses to create multiple preference pairs for a given prompt. Our work focuses on aligning LLMs by systematically curating multiple preference pairs and presenting them in a meaningful manner facilitating curriculum learning to enhance the prominent DPO technique. We order multiple preference pairs from easy to hard, according to various criteria thus emulating curriculum learning. Our method, which is referred to as Curri-DPO consistently shows increased performance gains on MTbench, Vicuna bench, WizardLM, highlighting its effectiveness over standard DPO setting that utilizes single preference pair. More specifically, Curri-DPO achieves a score of 7.43 on MTbench with Zephyr-7B, outperforming majority of existing LLMs with similar parameter size. Curri-DPO also achieves the highest win rates on Vicuna, WizardLM, and UltraFeedback test sets (90.7%, 87.1%, and 87.9% respectively) in our experiments, with notable gains of up to 7.5% when compared to standard DPO. We release the preference pairs used in alignment at: https://huggingface.co/datasets/ServiceNow-AI/Curriculum_DPO_preferences.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.754",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach": {
        "type": "INPROCEEDINGS",
        "key": "pernes-etal-2024-multi",
        "author": "Pernes, Diogo and Correia, Gon\u00e7alo M. and Mendes, Afonso",
        "booktitle": "EMNLP-findings2024",
        "title": "Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Cross-lingual summarization aims to bridge language barriers by summarizing documents in different languages. However, ensuring semantic coherence across languages is an overlooked challenge and can be critical in several contexts. To fill this gap, we introduce multi-target cross-lingual summarization as the task of summarizing a document into multiple target languages while ensuring that the produced summaries are semantically similar. We propose a principled re-ranking approach to this problem and a multi-criteria evaluation protocol to assess semantic coherence across target languages, marking a first step that will hopefully stimulate further research on this problem.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.755",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Tab2Text - A framework for deep learning with tabular data": {
        "type": "INPROCEEDINGS",
        "key": "lin-etal-2024-tab2text",
        "author": "Lin, Tong and Yan, Jason and Jurgens, David and Tomkins, Sabina J.",
        "booktitle": "EMNLP-findings2024",
        "title": "Tab2Text - A framework for deep learning with tabular data",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Tabular data, from public opinion surveys to records of interactions with social services, is foundational to the social sciences. One application of such data is to fit supervised learning models in order to predict consequential outcomes, for example: whether a family is likely to be evicted, whether a student will graduate from high school or is at risk of dropping out, and whether a voter will turn out in an upcoming election. While supervised learning has seen drastic improvements in performance with advancements in deep learning technology, these gains are largely lost on tabular data which poses unique difficulties for deep learning frameworks. We propose a technique for transforming tabular data to text data and demonstrate the extent to which this technique can improve the performance of deep learning models for tabular data. Overall, we find modest gains (1.5% on average). Interestingly, we find that these gains do not depend on using large language models to generate text.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.756",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "More Bang for your Context: Virtual Documents for Question Answering over Long Documents": {
        "type": "INPROCEEDINGS",
        "key": "mass-etal-2024-bang",
        "author": "Mass, Yosi and Carmeli, Boaz and Yehudai, Asaf and Toledo, Assaf and Mills, Nathaniel",
        "booktitle": "EMNLP-findings2024",
        "title": "More Bang for your Context: Virtual Documents for Question Answering over Long Documents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We deal with the problem of Question Answering (QA) over a long document, which poses a challenge for modern Large Language Models (LLMs). Although LLMs can handle increasingly longer context windows, they struggle to effectively utilize the long content. To address this issue, we introduce the concept of a virtual document (VDoc). A VDoc is created by selecting chunks from the original document that are most likely to contain the information needed to answer the user\u2019s question, while ensuring they fit within the LLM\u2019s context window. We hypothesize that providing a short and focused VDoc to the LLM is more effective than filling the entire context window with less relevant information. Our experiments confirm this hypothesis and demonstrate that using VDocs improves results on the QA task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.757",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression": {
        "type": "INPROCEEDINGS",
        "key": "gulati-etal-2024-distribution",
        "author": "Gulati, Aryan and Dong, Xingjian and Hurtado, Carlos and Shekkizhar, Sarath and Swayamdipta, Swabha and Ortega, Antonio",
        "booktitle": "EMNLP-findings2024",
        "title": "Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As language models become more general purpose, increased attention needs to be paid to detecting out-of-distribution (OOD) instances, i.e., those not belonging to any of the distributions seen during training. Existing methods for detecting OOD data are computationally complex and storage-intensive. We propose a novel soft clustering approach for OOD detection based on non-negative kernel regression. Our approach greatly reduces computational and space complexities (up to 11\\times improvement in inference time and 87% reduction in storage requirements). It outperforms existing approaches by up to 4 AUROC points on four benchmarks. We also introduce an entropy-constrained version of our algorithm, leading to further reductions in storage requirements (up to 97% lower than comparable approaches) while retaining competitive performance. Our soft clustering approach for OOD detection highlights its potential for detecting tail-end phenomena in extreme-scale data settings. Our source code is available on Github.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.758",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Synthetic Multimodal Question Generation": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-synthetic",
        "author": "Wu, Ian and Jayanthi, Sravan and Viswanathan, Vijay and Rosenberg, Simon and Pakazad, Sina Khoshfetrat and Wu, Tongshuang and Neubig, Graham",
        "booktitle": "EMNLP-findings2024",
        "title": "Synthetic Multimodal Question Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal Retrieval Augmented Generation (MMRAG) is a powerful approach to question-answering over multimodal documents. A key challenge with evaluating MMRAG is the paucity of high-quality datasets matching the question styles and modalities of interest. In light of this, we propose SMMQG, a synthetic data generation framework. SMMQG leverages interplay between a retriever, large language model (LLM) and large multimodal model (LMM) to generate question and answer pairs directly from multimodal documents, with the questions conforming to specified styles and modalities. We use SMMQG to generate an MMRAG dataset of 1024 questions over Wikipedia documents and evaluate state-of-the-art models using it, revealing insights into model performance that are attainable only through style- and modality-specific evaluation data. Next, we measure the quality of data produced by SMMQG via a human study. We find that the quality of SMMQG-generated synthetic data is on par with the quality of the crowdsourced benchmark MMQA and that downstream evaluation results using both datasets strongly concur.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.759",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures": {
        "type": "INPROCEEDINGS",
        "key": "ganeeva-etal-2024-lost",
        "author": "Ganeeva, Veronika and Sakhovskiy, Andrey and Khrabrov, Kuzma and Savchenko, Andrey and Kadurin, Artur and Tutubalina, Elena",
        "booktitle": "EMNLP-findings2024",
        "title": "Lost in Translation: Chemical Language Models and the Misunderstanding of Molecule Structures",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The recent integration of chemistry with natural language processing (NLP) has advanced drug discovery. Molecule representation in language models (LMs) is crucial in enhancing chemical understanding. We propose Augmented Molecular Retrieval (AMORE), a flexible zero-shot framework for assessment of Chemistry LMs of different natures: trained solely on molecules for chemical tasks and on a combined corpus of natural language texts and string-based structures. The framework relies on molecule augmentations that preserve an underlying chemical, such as kekulization and cycle replacements. We evaluate encoder-only and generative LMs by calculating a metric based on the similarity score between distributed representations of molecules and their augmentations. Our experiments on ChEBI-20 and QM9 benchmarks show that these models exhibit significantly lower scores than graph-based molecular models trained without language modeling objectives. Additionally, our results on the molecule captioning task for cross-domain models, MolT5 and Text+Chem T5, demonstrate that the lower the representation-based evaluation metrics, the lower the classical text generation metrics like ROUGE and METEOR.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.760",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HyQE: Ranking Contexts with Hypothetical Query Embeddings": {
        "type": "INPROCEEDINGS",
        "key": "zhou-etal-2024-hyqe",
        "author": "Zhou, Weichao and Zhang, Jiaxin and Hasson, Hilaf and Singh, Anu and Li, Wenchao",
        "booktitle": "EMNLP-findings2024",
        "title": "HyQE: Ranking Contexts with Hypothetical Query Embeddings",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In retrieval-augmented systems, context ranking techniques are commonly employed to reorder the retrieved contexts based on their relevance to a user query. A standard approach is to measure this relevance through the similarity between contexts and queries in the embedding space. However, such similarity often fails to capture the relevance. Alternatively, large language models (LLMs) have been used for ranking contexts. However, they can encounter scalability issues when the number of candidate contexts grows and the context window sizes of the LLMs remain constrained. Additionally, these approaches require fine-tuning LLMs with domain-specific data. In this work, we introduce a scalable ranking framework that combines embedding similarity and LLM capabilities without requiring LLM fine-tuning. Our framework uses a pre-trained LLM to hypothesize the user query based on the retrieved contexts and ranks the context based on the similarity between the hypothesized queries and the user query. Our framework is efficient at inference time and is compatible with many other retrieval and ranking techniques. Experimental results show that our method improves the ranking performance across multiple benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.761",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch": {
        "type": "INPROCEEDINGS",
        "key": "hammoud-etal-2024-model",
        "author": "Hammoud, Hasan Abed Al Kader and Michieli, Umberto and Pizzati, Fabio and Torr, Philip and Bibi, Adel and Ghanem, Bernard and Ozay, Mete",
        "booktitle": "EMNLP-findings2024",
        "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Merging Large Language Models (LLMs) is a cost-effective technique for combining multiple expert LLMs into a single versatile model, retaining the expertise of the original ones. However, current approaches often overlook the importance of safety alignment during merging, leading to highly misaligned models. This work investigates the effects of model merging on alignment. We evaluate several popular model merging techniques, demonstrating that existing methods do not only transfer domain expertise but also propagate misalignment. We propose a simple two-step approach to address this problem: (i) generating synthetic safety and domain-specific data, and (ii) incorporating these generated data into the optimization process of existing data-aware model merging techniques. This allows us to treat alignment as a skill that can be maximized in the resulting merged LLM. Our experiments illustrate the effectiveness of integrating alignment-related data during merging, resulting in models that excel in both domain expertise and alignment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.762",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Models Are Challenged by Habitat-Centered Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "ghaffari-krishnaswamy-2024-large",
        "author": "Ghaffari, Sadaf and Krishnaswamy, Nikhil",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Models Are Challenged by Habitat-Centered Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper we perform a novel in-depth evaluation of text-only and multimodal LLMs\u2019 abilities to reason about object *habitats* or conditions on how objects are situated in their environments that affect the types of behaviors (or *affordances*) that can be enacted upon them. We present a novel curated multimodal dataset of questions about object habitats and affordances, which are formally grounded in the underlying lexical semantics literature, with multiple images from various sources that depict the scenario described in the question. We evaluate 16 text-only and multimodal LLMs on this challenging data. Our findings indicate that while certain LLMs can perform reasonably well on reasoning about affordances, there appears to be a consistent low upper bound on habitat-centered reasoning performance. We discuss how the formal semantics of habitats in fact predicts this behavior and propose this as a challenge to the community.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.763",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-train",
        "author": "Lee, Jaeyoung and Lu, Ximing and Hessel, Jack and Brahman, Faeze and Yu, Youngjae and Bisk, Yonatan and Choi, Yejin and Gabriel, Saadia",
        "booktitle": "EMNLP-findings2024",
        "title": "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Given the growing influx of misinformation across news and social media, there is a critical need for systems that can provide effective real-time verification of news claims. Large language or multimodal model based verification has been proposed to scale up online policing mechanisms for mitigating spread of false and harmful content. While these can potentially reduce burden on human fact-checkers, such efforts may be hampered by foundation model training data becoming outdated. In this work, we test the limits of improving foundation model performance without continual updating through an initial study of knowledge transfer using either existing intra- and inter-domain benchmarks or explanations generated from large language models (LLMs).We evaluate on 12 public benchmarks for fact-checking and misinformation detection as well as two other tasks relevant to content moderation - toxicity and stance detection. Our results on two recent multi-modal fact-checking benchmarks, Mocheg and Fakeddit, indicate that knowledge transfer strategies can improve Fakeddit performance over the state-of-the-art by up to 1.7% and Mocheg performance by up to 2.9%. The code, model checkpoints, and dataset are available: https://github.com/given131/ fact-verifier-knowledge-transfer.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.764",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Benchmarking Machine Translation with Cultural Awareness": {
        "type": "INPROCEEDINGS",
        "key": "yao-etal-2024-benchmarking",
        "author": "Yao, Binwei and Jiang, Ming and Bobinac, Tara and Yang, Diyi and Hu, Junjie",
        "booktitle": "EMNLP-findings2024",
        "title": "Benchmarking Machine Translation with Cultural Awareness",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Translating culture-related content is vital for effective cross-cultural communication. However, many culture-specific items (CSIs) often lack literal translation across languages, making it challenging to collect high-quality, diverse parallel corpora with CSI annotations. This difficulty hinders the analysis of cultural awareness of machine translation (MT) systems, including traditional neural MT and the emerging MT paradigm using large language models (LLM). To address this gap, we introduce a novel parallel corpus, enriched with CSI annotations in 6 language pairs for investigating Cultural-Aware Machine Translation\u2014CAMT. Furthermore, we design two evaluation metrics to assess CSI translations, focusing on their pragmatic translation quality. Our findings show the superior ability of LLMs over neural MTs in leveraging external cultural knowledge for translating CSIs, especially those lacking translations in the target culture.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.765",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?": {
        "type": "INPROCEEDINGS",
        "key": "kew-etal-2024-turning",
        "author": "Kew, Tannon and Schottmann, Florian and Sennrich, Rico",
        "booktitle": "EMNLP-findings2024",
        "title": "Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The vast majority of today\u2019s large language models (LLMs) are English-centric, having been pretrained predominantly on English text. Yet, in order to meet user expectations, models need to be able to respond appropriately in multiple languages once deployed in downstream applications. This requires strong cross-lingual transfer abilities.In this work, we investigate the minimal amount of multilinguality required during finetuning to elicit cross-lingual generalisation in English-centric LLMs. In experiments across four LLMs, we find that multilingual instruction tuning with as few as two to three languages is both necessary and sufficient to elicit effective cross-lingual generalisation, with the limiting factor being the degree to which a target language is seen during pretraining. Evaluations on five different tasks further reveal that multilingual instruction tuning is most beneficial for generative tasks that assume input/output language agreement, such as in chat settings, while being of less importance for highly structured classification-style tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.766",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation": {
        "type": "INPROCEEDINGS",
        "key": "ouyang-etal-2024-temperature",
        "author": "Ouyang, Siru and Wang, Shuohang and Jiang, Minhao and Zhong, Ming and Yu, Donghan and Han, Jiawei and Shen, Yelong",
        "booktitle": "EMNLP-findings2024",
        "title": "Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Speculative decoding stands as a pivotal technique to expedite inference in autoregressive (large) language models. This method employs a smaller *draft* model to speculate a block of tokens, which the *target* model then evaluates for acceptance. Despite a wealth of studies aimed at increasing the efficiency of speculative decoding, the influence of generation configurations on the decoding process remains poorly understood, especially concerning decoding temperatures. This paper delves into the effects of decoding temperatures on speculative decoding\u2019s efficacy. Beginning with knowledge distillation (KD), we first highlight the challenge of decoding at higher temperatures, and demonstrate KD in a consistent temperature setting could be a remedy. We also investigate the effects of out-of-domain testing sets with out-of-range temperatures. Building upon these findings, we take an initial step to further the speedup for speculative decoding, particularly in a high-temperature generation setting. Our work offers new insights into how generation configurations drastically affect the performance of speculative decoding, and underscores the need for developing methods that focus on diverse decoding configurations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.767",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Generate then Refine: Data Augmentation for Zero-shot Intent Detection": {
        "type": "INPROCEEDINGS",
        "key": "lin-etal-2024-generate",
        "author": "Lin, I-Fan and Hasibi, Faegheh and Verberne, Suzan",
        "booktitle": "EMNLP-findings2024",
        "title": "Generate then Refine: Data Augmentation for Zero-shot Intent Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this short paper we propose a data augmentation method for intent detection in zero-resource domains.Existing data augmentation methods rely on few labelled examples for each intent category, which can be expensive in settings with many possible intents.We use a two-stage approach: First, we generate utterances for intent labels using an open-source large language model in a zero-shot setting. Second, we develop a smaller sequence-to-sequence model (the Refiner), to improve the generated utterances. The Refiner is fine-tuned on seen domains and then applied to unseen domains. We evaluate our method by training an intent classifier on the generated data, and evaluating it on real (human) data.We find that the Refiner significantly improves the data utility and diversity over the zero-shot LLM baseline for unseen domains and over common baseline approaches.Our results indicate that a two-step approach of a generative LLM in zero-shot setting and a smaller sequence-to-sequence model can provide high-quality data for intent detection.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.768",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-unleashing-power",
        "author": "Liu, Siyi and Li, Yang and Li, Jiang and Yang, Shan and Lan, Yunshi",
        "booktitle": "EMNLP-findings2024",
        "title": "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent research in zero-shot Relation Extraction (RE) has focused on using Large Language Models (LLMs) due to their impressive zero-shot capabilities. However, current methods often perform suboptimally, mainly due to a lack of detailed, context-specific prompts needed for understanding various sentences and relations. To address this, we introduce the Self-Prompting framework, a novel method designed to fully harness the embedded RE knowledge within LLMs. Specifically, our framework employs a three-stage diversity approach to prompt LLMs, generating multiple synthetic samples that encapsulate specific relations from scratch. These generated samples act as in-context learning samples, offering explicit and context-specific guidance to efficiently prompt LLMs for RE. Experimental evaluations on benchmark datasets show our approach outperforms existing LLM-based zero-shot RE methods. Additionally, our experiments confirm the effectiveness of our generation pipeline in producing high-quality synthetic data that enhances performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.769",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "\u201cWhat is the value of templates?\u201d Rethinking Document Information Extraction Datasets for LLMs": {
        "type": "INPROCEEDINGS",
        "key": "zmigrod-etal-2024-value",
        "author": "Zmigrod, Ran and Shetty, Pranav and Sibue, Mathieu and Ma, Zhiqiang and Nourbakhsh, Armineh and Liu, Xiaomo and Veloso, Manuela",
        "booktitle": "EMNLP-findings2024",
        "title": "\u201cWhat is the value of templates?\u201d Rethinking Document Information Extraction Datasets for LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The rise of large language models (LLMs) for visually rich document understanding (VRDU) has kindled a need for prompt-response, document-based datasets. As annotating new datasets from scratch is labor-intensive, the existing literature has generated prompt-response datasets from available resources using simple templates. For the case of key information extraction (KIE), one of the most common VRDU tasks, past work has typically employed the template \u201cWhat is the value for the key?\u201d. However, given the variety of questions encountered in the wild, simple and uniform templates are insufficient for creating robust models in research and industrial contexts. In this work, we present K2Q, a diverse collection of five datasets converted from KIE to a prompt-response format using a plethora of bespoke templates. The questions in K2Q can span multiple entities and be extractive or boolean. We empirically compare the performance of seven baseline generative models on K2Q with zero-shot prompting. We further compare three of these models when training on K2Q versus training on simpler templates to motivate the need of our work. We find that creating diverse and intricate KIE questions enhances the performance and robustness of VRDU models. We hope this work encourages future studies on data quality for generative model training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.770",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-matters",
        "author": "Zhao, Xin and Yoshinaga, Naoki and Oba, Daisuke",
        "booktitle": "EMNLP-findings2024",
        "title": "What Matters in Memorizing and Recalling Facts? Multifaceted Benchmarks for Knowledge Probing in Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language models often struggle with handling factual knowledge, exhibiting factual hallucination issue. This makes it vital to evaluate the models\u2019 ability to recall its parametric knowledge about facts. In this study, we introduce a knowledge probing benchmark, BELIEF(ICL), to evaluate the knowledge recall ability of both encoder- and decoder-based pre-trained language models (PLMs) from diverse perspectives. BELIEFs utilize a multi-prompt dataset to evaluate PLM\u2019s accuracy, consistency, and reliability in factual knowledge recall. To enable a more reliable evaluation with BELIEFs, we semi-automatically create MyriadLAMA, which has massively diverse prompts. We validate the effectiveness of BELIEFs in comprehensively evaluating PLM\u2019s knowledge recall ability on diverse PLMs, including recent large language models (LLMs). We then investigate key factors in memorizing and recalling facts in PLMs, such as model size, pretraining strategy and corpora, instruction-tuning process and in-context learning settings. Finally, we reveal the limitation of the prompt-based knowledge probing. The MyriadLAMA is publicized.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.771",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On Leakage of Code Generation Evaluation Datasets": {
        "type": "INPROCEEDINGS",
        "key": "matton-etal-2024-leakage",
        "author": "Matton, Alexandre and Sherborne, Tom and Aumiller, Dennis and Tommasone, Elena and Alizadeh, Milad and He, Jingyi and Ma, Raymond and Voisin, Maxime and Gilsenan-McMahon, Ellen and Gall\u00e9, Matthias",
        "booktitle": "EMNLP-findings2024",
        "title": "On Leakage of Code Generation Evaluation Datasets",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we consider contamination by code generation test sets, in particular in their use in modern large language models.We discuss three possible sources of such contamination and show findings supporting each of them: (i) direct data leakage, (ii) indirect data leakage through the use of synthetic data and (iii) overfitting to evaluation sets during model selection.To address this, we release Less Basic Python Problems (LBPP): an uncontaminated new benchmark of 161 prompts with their associated Python solutions. LBPP is released at https://huggingface.co/datasets/CohereForAI/lbpp",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.772",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI": {
        "type": "INPROCEEDINGS",
        "key": "schirmer-etal-2024-language",
        "author": "Schirmer, Miriam and Leemann, Tobias and Kasneci, Gjergji and Pfeffer, J\u00fcrgen and Jurgens, David",
        "booktitle": "EMNLP-findings2024",
        "title": "The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Psychological trauma can manifest following various distressing events and is captured in diverse online contexts. However, studies traditionally focus on a single aspect of trauma, often neglecting the transferability of findings across different scenarios. We address this gap by training various language models with progressing complexity on trauma-related datasets, including genocide-related court data, a Reddit dataset on post-traumatic stress disorder (PTSD), counseling conversations, and Incel forum posts. Our results show that the fine-tuned RoBERTa model excels in predicting traumatic events across domains, slightly outperforming large language models like GPT-4. Additionally, SLALOM-feature scores and conceptual explanations effectively differentiate and cluster trauma-related language, highlighting different trauma aspects and identifying sexual abuse and experiences related to death as a common traumatic event across all datasets. This transferability is crucial as it allows for the development of tools to enhance trauma detection and intervention in diverse populations and settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.773",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Auto-Evolve: Enhancing Large Language Model\u2019s Performance via Self-Reasoning Framework": {
        "type": "INPROCEEDINGS",
        "key": "aswani-etal-2024-auto",
        "author": "Aswani, Krishna and Lu, Huilin and Patankar, Pranav and Dhalwani, Priya and Tan, Xue and Ganeshmohan, Jayant and Lacasse, Simon",
        "booktitle": "EMNLP-findings2024",
        "title": "Auto-Evolve: Enhancing Large Language Model\u2019s Performance via Self-Reasoning Framework",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in prompt engineering strategies, such as Chain-of-Thought (CoT) and Self-Discover, have demonstrated significant potential in improving the reasoning abilities of Large Language Models (LLMs). However, these state-of-the-art (SOTA) prompting strategies rely on a fixed set of static seed reasoning modules like \u201cthink step by step\u201d or \u201cbreak down this problem\u201d intended to simulate human approach to problem-solving. This constraint limits the flexibility of models in tackling diverse problems effectively. In this paper, we introduce Auto-Evolve, a novel framework that enables LLMs to self-create dynamic reasoning modules and downstream action plan, resulting in significant improvements over current SOTA methods. We evaluate Auto-Evolve on the challenging BigBench-Hard (BBH) dataset with Claude 2.0, Claude 3 Sonnet, Mistral Large, and GPT-4, where it consistently outperforms the SOTA prompt strategies. Auto-Evolve outperforms CoT by up to 10.4% and on an average by 7% across these four models. Our framework introduces two innovations: a) Auto-Evolve dynamically generates reasoning modules for each task while aligning with human reasoning paradigm, thus eliminating the need for predefined templates. b) An iterative refinement component, that incrementally refines instruction guidance for LLMs and helps boost performance by average 2.8% compared to doing it in a single step.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.774",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization": {
        "type": "INPROCEEDINGS",
        "key": "xie-etal-2024-v",
        "author": "Xie, Yuxi and Li, Guanzhen and Xu, Xiao and Kan, Min-Yen",
        "booktitle": "EMNLP-findings2024",
        "title": "V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large vision-language models (LVLMs) suffer from hallucination, resulting in misalignment between the output textual response and the input visual content. Recent research indicates that the over-reliance on the Large Language Model (LLM) backbone, as one cause of the LVLM hallucination, inherently introduces bias from language priors, leading to insufficient context attention to the visual inputs.We tackle this issue of hallucination by mitigating such over-reliance through preference learning. We propose Vision-guided Direct Preference Optimization (V-DPO) to enhance visual context learning at training time. To interpret the effectiveness and generalizability of V-DPO on different types of training data, we construct a synthetic dataset containing both response- and image-contrast preference pairs, compared against existing human-annotated hallucination samples. Our approach achieves significant improvements compared with baseline methods across various hallucination benchmarks. Our analysis indicates that V-DPO excels in learning from image-contrast preference data, demonstrating its superior ability to elicit and understand nuances of visual context. Our code is publicly available at https://github.com/YuxiXie/V-DPOhttps://github.com/YuxiXie/V-DPO.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.775",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring the Potential of Multimodal LLM with Knowledge-Intensive Multimodal ASR": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-exploring",
        "author": "Wang, Minghan and Wang, Yuxia and Vu, Thuy-Trang and Shareghi, Ehsan and Haf, Reza",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring the Potential of Multimodal LLM with Knowledge-Intensive Multimodal ASR",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in multimodal large language models (MLLMs) have made significant progress in integrating information across various modalities, yet real-world applications in educational and scientific domains remain challenging. This paper introduces the Multimodal Scientific ASR (MS-ASR) task, which focuses on transcribing scientific conference videos by leveraging visual information from slides to enhance the accuracy of technical terminologies. Realized that traditional metrics like WER fall short in assessing performance accurately, prompting the proposal of severity-aware WER (SWER) that considers the content type and severity of ASR errors. We propose the Scientific Vision Augmented ASR (SciVASR) framework as a baseline method, enabling MLLMs to improve transcript quality through post-editing. Evaluations of state-of-the-art MLLMs, including GPT-4o, show a 45% improvement over speech-only baselines, highlighting the importance of multimodal information integration.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.776",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Better Alignment with Instruction Back-and-Forth Translation": {
        "type": "INPROCEEDINGS",
        "key": "nguyen-etal-2024-better",
        "author": "Nguyen, Thao and Li, Jeffrey and Oh, Sewoong and Schmidt, Ludwig and Weston, Jason E. and Zettlemoyer, Luke and Li, Xian",
        "booktitle": "EMNLP-findings2024",
        "title": "Better Alignment with Instruction Back-and-Forth Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We propose a new method, instruction back-and-forth translation, to improve the quality of instruction-tuning data used for aligning large language models (LLMs). Given preprocessed texts from an initial web corpus (e.g. Dolma (Soldaini et al., 2024)), we generate synthetic instructions using the backtranslation approach proposed by Li et al., (2023), filter the generated data and rewrite the responses to improve their quality further based on the initial texts. Given similar quantities of instructions, fine-tuning Llama-2 on our (synthetic instruction, rewritten response) pairs yields better AlpacaEval win rates than using other common instruction datasets such as Humpback, ShareGPT, Open Orca, Alpaca-GPT4 and Self-instruct, at both 7B and 70B parameter scales. We also demonstrate that rewriting the responses with an LLM is different from direct distillation: the former process yields better win rate at 70B scale, and the two text distributions exhibit significant distinction in the embedding space. Besides, we provide analyses showing that our backtranslated instructions are of higher quality than other sources of synthetic instructions, while our responses are more diverse and complex than what can be obtained from distillation. Overall we find that instruction back-and-forth translation combines the best of both worlds\u2014making use of the information diversity and quantity found on the web, while ensuring the quality of the responses which is necessary for effective alignment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.777",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AliGATr: Graph-based layout generation for form understanding": {
        "type": "INPROCEEDINGS",
        "key": "nourbakhsh-etal-2024-aligatr",
        "author": "Nourbakhsh, Armineh and Jin, Zhao and Parekh, Siddharth and Shah, Sameena and Rose, Carolyn",
        "booktitle": "EMNLP-findings2024",
        "title": "AliGATr: Graph-based layout generation for form understanding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Forms constitute a large portion of layout-rich documents that convey information through key-value pairs. Form understanding involves two main tasks, namely, the identification of keys and values (a.k.a Key Information Extraction or KIE) and the association of keys to corresponding values (a.k.a. Relation Extraction or RE). State of the art models for form understanding often rely on training paradigms that yield poorly calibrated output probabilities and low performance on RE. In this paper, we present AliGATr, a graph-based model that uses a generative objective to represent complex grid-like layouts that are often found in forms. Using a grid-based graph topology, our model learns to generate the layout of each page token by token in a data efficient manner. Despite using 30% fewer parameters than the smallest SotA, AliGATr performs on par with or better than SotA models on the KIE and RE tasks against four datasets. We also show that AliGATr\u2019s output probabilities are better calibrated and do not exhibit the over-confident distributions of other SotA models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.778",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification": {
        "type": "INPROCEEDINGS",
        "key": "meng-etal-2024-attribute",
        "author": "Meng, Tao and Mehrabi, Ninareh and Goyal, Palash and Ramakrishna, Anil and Galstyan, Aram and Zemel, Richard and Chang, Kai-Wei and Gupta, Rahul and Peris, Charith",
        "booktitle": "EMNLP-findings2024",
        "title": "Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We propose a constraint learning schema forfine-tuning Large Language Models (LLMs)with attribute control. Given a training corpusand control criteria formulated as a sequence-level constraint on model outputs, our methodfine-tunes the LLM on the training corpus whileenhancing constraint satisfaction with minimalimpact on its utility and generation quality.Specifically, our approach regularizes the LLMtraining by penalizing the KL divergence be-tween the desired output distribution, which sat-isfies the constraints, and the LLM\u2019s posterior.This regularization term can be approximatedby an auxiliary model trained to decomposethe sequence-level constraints into token-levelguidance, allowing the term to be measuredby a closed-form formulation. To further im-prove efficiency, we design a parallel schemefor concurrently updating both the LLM andthe auxiliary model. We evaluate the empiricalperformance of our approach by controlling thetoxicity when training an LLM. We show thatour approach leads to an LLM that producesfewer inappropriate responses while achievingcompetitive performance on benchmarks and atoxicity detection task",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.779",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement": {
        "type": "INPROCEEDINGS",
        "key": "mondal-etal-2024-scidoc2diagrammer",
        "author": "Mondal, Ishani and Li, Zongxia and Hou, Yufang and Natarajan, Anandhavelu and Garimella, Aparna and Boyd-Graber, Jordan Lee",
        "booktitle": "EMNLP-findings2024",
        "title": "SciDoc2Diagrammer-MAF: Towards Generation of Scientific Diagrams from Documents guided by Multi-Aspect Feedback Refinement",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automating the creation of scientific diagrams from academic papers can significantly streamline the development of tutorials, presentations, and posters, thereby saving time and accelerating the process. Current text-to-image models (Rombach et al., 2022a; Belouadi et al., 2023) struggle with generating accurate and visually appealing diagrams from long-context inputs. We propose SciDoc2Diagram, a task that extracts relevant information from scientific papers and generates diagrams, along with a benchmarking dataset, SciDoc2DiagramBench. We develop a multi-step pipeline SciDoc2Diagrammer that generates diagrams based on user intentions using intermediate code generation. We observed that initial diagram drafts were often incomplete or unfaithful to the source, leading us to develop SciDoc2Diagrammer-Multi-Aspect-Feedback (MAF), a refinement strategy that significantly enhances factual correctness and visual appeal and outperforms existing models on both automatic and human judgement.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.780",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TinyStyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings": {
        "type": "INPROCEEDINGS",
        "key": "horvitz-etal-2024-tinystyler",
        "author": "Horvitz, Zachary and Patel, Ajay and Singh, Kanishk and Callison-Burch, Chris and McKeown, Kathleen and Yu, Zhou",
        "booktitle": "EMNLP-findings2024",
        "title": "TinyStyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The goal of text style transfer is to transform the style of texts while preserving their original meaning, often with only a few examples of the target style. Existing style transfer methods generally rely on the few-shot capabilities of large language models or on complex controllable text generation approaches that are inefficient and underperform on fluency metrics. We introduce TinyStyler, a lightweight but effective approach, which leverages a small language model (800M params) and pre-trained authorship embeddings to perform efficient, few-shot text style transfer. We evaluate on the challenging task of authorship style transfer and find TinyStyler outperforms strong approaches such as GPT-4. We also evaluate TinyStyler\u2019s ability to perform text attribute style transfer (formal \u0142eftrightarrow informal) with automatic and human evaluations and find that the approach outperforms recent controllable text generation methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.781",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?": {
        "type": "INPROCEEDINGS",
        "key": "lin-lee-2024-llms",
        "author": "Lin, Guan-Ting and Lee, Hung-yi",
        "booktitle": "EMNLP-findings2024",
        "title": "Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Emphasis is a crucial component in human communication, which indicates speaker\u2019s intention and implication beyond pure text in dialogue. While Large Language Models (LLMs) have revolutionized natural language processing, their ability to understand emphasis in dialogue remains uncertain. This paper introduces Emphasized-Talk, a benchmark dataset with annotated dialogue samples capturing the implications of emphasis. We evaluate various LLMs, both open-source and commercial, to assess their performance in understanding and generating emphasis. Additionally, we propose an automatic evaluation pipeline using GPT-4, which achieve high correlation with human scoring. Our findings reveal that although commercial LLMs generally perform better, there is still significant room for improvement in comprehending emphasized sentences.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.782",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Why do LLaVA Vision-Language Models Reply to Images in English?": {
        "type": "INPROCEEDINGS",
        "key": "hinck-etal-2024-llava",
        "author": "Hinck, Musashi and Holtermann, Carolin and Olson, Matthew Lyle and Schneider, Florian and Yu, Sungduk and Bhiwandiwalla, Anahita and Lauscher, Anne and Tseng, Shao-Yen and Lal, Vasudev",
        "booktitle": "EMNLP-findings2024",
        "title": "Why do LLaVA Vision-Language Models Reply to Images in English?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We uncover a surprising multilingual bias occurring in a popular class of multimodal vision-language models (VLMs). Including an image in the query to a LLaVA-style VLM significantly increases the likelihood of the model returning an English response, regardless of the language of the query. This paper investigates the causes of this loss with a two-pronged approach that combines extensive ablation of the design space with a mechanistic analysis of the models\u2019 internal representations of image and text inputs. Both approaches indicate that the issue stems in the language modeling component of the LLaVA model. Statistically, we find that switching the language backbone for a bilingual language model has the strongest effect on reducing this error. Mechanistically, we provide compelling evidence that visual inputs are not mapped to a similar space as text ones, and that intervening on intermediary attention layers can reduce this bias. Our findings provide important insights to researchers and engineers seeking to understand the crossover between multimodal and multilingual spaces, and contribute to the goal of developing capable and inclusive VLMs for non-English contexts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.783",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Preference Tuning For Toxicity Mitigation Generalizes Across Languages": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-preference",
        "author": "Li, Xiaochen and Yong, Zheng Xin and Bach, Stephen",
        "booktitle": "EMNLP-findings2024",
        "title": "Preference Tuning For Toxicity Mitigation Generalizes Across Languages",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Detoxifying multilingual Large Language Models (LLMs) has become crucial due to their increasing global use. In this work, we explore zero-shot cross-lingual generalization of preference tuning in detoxifying LLMs. Unlike previous studies that show limited cross-lingual generalization for other safety tasks, we demonstrate that Direct Preference Optimization (DPO) training with only English data can significantly reduce toxicity in multilingual open-ended generations. For example, the probability of mGPT-1.3B generating toxic continuations drops from 46.8% to 3.9% across 17 different languages after training. Our results also extend to other multilingual LLMs, such as BLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal intervention and activation analysis, we identified the dual multilinguality property of MLP layers in LLMs, which explains the cross-lingual generalization of DPO. Finally, we show that bilingual sentence retrieval can predict the cross-lingual transferability of DPO preference tuning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.784",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Calibrating Long-form Generations From Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-calibrating",
        "author": "Huang, Yukun and Liu, Yixin and Thirukovalluru, Raghuveer and Cohan, Arman and Dhingra, Bhuwan",
        "booktitle": "EMNLP-findings2024",
        "title": "Calibrating Long-form Generations From Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To enhance Large Language Models\u2019 (LLMs) reliability, calibration is essential\u2014the model\u2019s confidence scores should align with the likelihood of its responses being correct. However, traditional calibration methods typically rely on a binary true/false assessment of response correctness, unsuitable for long-form generations where an answer can be partially correct. Addressing this gap, we introduce a unified calibration framework, in which both the correctness of the LLMs\u2019 responses and their associated confidence levels are treated as distributions across a range of scores. We develop three metrics for assessing LLM calibration and propose confidence elicitation methods based on self-consistency and self-evaluation. Our experiments demonstrate that larger models don\u2019t necessarily guarantee better calibration, that various calibration metrics complement each other, and that self-consistency methods excel in factoid datasets. We also find that calibration can be enhanced through techniques such as fine-tuning, scaling the temperature. Finally, we illustrate one application of long-form calibration through selective answering in long-form responses, optimizing correctness within a constrained API budget.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.785",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-train",
        "author": "Wang, Yueqi and Yue, Zhenrui and Zeng, Huimin and Wang, Dong and McAuley, Julian",
        "booktitle": "EMNLP-findings2024",
        "title": "Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite recent advancements in language and vision modeling, integrating rich multimodal knowledge into recommender systems continues to pose significant challenges. This is primarily due to the need for efficient recommendation, which requires adaptive and interactive responses. In this study, we focus on sequential recommendation and introduce a lightweight framework called full-scale Matryoshka representation learning for multimodal recommendation (fMRLRec). Our fMRLRec captures item features at different granularities, learning informative representations for efficient recommendation across multiple dimensions. To integrate item features from diverse modalities, fMRLRec employs a simple mapping to project multimodal item features into an aligned feature space. Additionally, we design an efficient linear transformation that embeds smaller features into larger ones, substantially reducing memory requirements for large-scale training on recommendation data. Combined with improved state space modeling techniques, fMRLRec scales to different dimensions and only requires one-time training to produce multiple models tailored to various granularities. We demonstrate the effectiveness and efficiency of fMRLRec on multiple benchmark datasets, which consistently achieves superior performance over state-of-the-art baseline methods. We make our code and data publicly available at https://github.com/yueqirex/fMRLRec.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.786",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Exploring Quantization for Efficient Pre-Training of Transformer Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chitsaz-etal-2024-exploring",
        "author": "Chitsaz, Kamran and Fournier, Quentin and Mordido, Goncalo and Chandar, Sarath",
        "booktitle": "EMNLP-findings2024",
        "title": "Exploring Quantization for Efficient Pre-Training of Transformer Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The increasing scale of Transformer models has led to an increase in their pre-training computational requirements. While quantization has proven to be effective after pre-training and during fine-tuning, applying quantization in Transformers during pre-training has remained largely unexplored at scale for language modeling. This study aims to explore the impact of quantization for efficient pre-training of Transformers, with a focus on linear layer components. By systematically applying straightforward linear quantization to weights, activations, gradients, and optimizer states, we assess its effects on model efficiency, stability, and performance during training. By offering a comprehensive recipe of effective quantization strategies to be applied during the pre-training of Transformers, we promote high training efficiency from scratch while retaining language modeling ability.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.787",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding": {
        "type": "INPROCEEDINGS",
        "key": "sun-etal-2024-multilingual",
        "author": "Sun, Yidan and Yu, Jianfei and Li, Boyang",
        "booktitle": "EMNLP-findings2024",
        "title": "Multilingual Synopses of Movie Narratives: A Dataset for Vision-Language Story Understanding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Story video-text alignment, a core task in computational story understanding, aims to align video clips with corresponding sentences in their descriptions. However, progress on the task has been held back by the scarcity of manually annotated video-text correspondence and the heavy concentration on English narrations of Hollywood movies. To address these issues, in this paper, we construct a large-scale multilingual video story dataset named Multilingual Synopses of Movie Narratives (M-SyMoN), containing 13,166 movie summary videos from 7 languages, as well as manual annotation of fine-grained video-text correspondences for 101.5 hours of video. Training on the human annotated data from SyMoN outperforms the SOTA methods by 15.7 and 16.2 percentage points on Clip Accuracy and Sentence IoU scores, respectively, demonstrating the effectiveness of the annotations. As benchmarks for future research, we create 6 baseline approaches with different multilingual training strategies, compare their performance in both intra-lingual and cross-lingual setups, exemplifying the challenges of multilingual video-text alignment. The dataset is released at:https://github.com/insundaycathy/M-SyMoN",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.788",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MVP-Bench: Can Large Vision-Language Models Conduct Multi-level Visual Perception Like Humans?": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-mvp",
        "author": "Li, Guanzhen and Xie, Yuxi and Kan, Min-Yen",
        "booktitle": "EMNLP-findings2024",
        "title": "MVP-Bench: Can Large Vision-Language Models Conduct Multi-level Visual Perception Like Humans?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Humans perform visual perception at multiple levels, including low-level object recognition and high-level semantic interpretation such as behavior understanding. Subtle differences in low-level details can lead to substantial changes in high-level perception. For example, substituting the shopping bag held by a person with a gun suggests violent behavior, implying criminal or violent activity. Despite significant advancements in various multimodal tasks, Large Visual Language Models (LVLMs) remain unexplored in their capabilities to conduct such multi-level visual perceptions.To investigate the perception gap between LVLMs and humans, we introduce MVP-Bench, the first visual\u2013language benchmark systematically evaluating both low- and high-level visual perception of LVLMs. We construct MVP-Bench across natural and synthetic images to investigate how manipulated content influences model perception. Using MVP-Bench, we diagnose the visual perception of 10 open-source and 2 closed-source LVLMs, showing that high-level perception tasks significantly challenge existing LVLMs. The state-of-the-art GPT-4o only achieves an accuracy of 56% on Yes/No questions, compared with 74% in low-level scenarios. Furthermore, the performance gap between natural and manipulated images indicates that current LVLMs do not generalize in understanding the visual semantics of synthetic images as humans do.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.789",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Topic Modeling: Contextual Token Embeddings Are All You Need": {
        "type": "INPROCEEDINGS",
        "key": "angelov-inkpen-2024-topic",
        "author": "Angelov, Dimo and Inkpen, Diana",
        "booktitle": "EMNLP-findings2024",
        "title": "Topic Modeling: Contextual Token Embeddings Are All You Need",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The goal of topic modeling is to find meaningful topics that capture the information present in a collection of documents. The main challenges of topic modeling are finding the optimal number of topics, labeling the topics, segmenting documents by topic, and evaluating topic model performance. Current neural approaches have tackled some of these problems but none have been able to solve all of them. We introduce a novel topic modeling approach, Contextual-Top2Vec, which uses document contextual token embeddings, it creates hierarchical topics, finds topic spans within documents and labels topics with phrases rather than just words. We propose the use of BERTScore to evaluate topic coherence and to evaluate how informative topics are of the underlying documents. Our model outperforms the current state-of-the-art models on a comprehensive set of topic model evaluation metrics.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.790",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Dense Passage Retrieval: Is it Retrieving?": {
        "type": "INPROCEEDINGS",
        "key": "reichman-heck-2024-dense",
        "author": "Reichman, Benjamin and Heck, Larry",
        "booktitle": "EMNLP-findings2024",
        "title": "Dense Passage Retrieval: Is it Retrieving?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) internally store repositories of knowledge. However, their access to this repository is imprecise and they frequently hallucinate information that is not true or does not exist. A paradigm called Retrieval Augmented Generation (RAG) promises to fix these issues. Dense passage retrieval (DPR) is the first step in this paradigm. In this paper, we analyze the role of DPR fine-tuning and how it affects the model being trained. DPR fine-tunes pre-trained networks to enhance the alignment of the embeddings between queries and relevant textual data. We explore DPR-trained models mechanistically by using a combination of probing, layer activation analysis, and model editing. Our experiments show that DPR training decentralizes how knowledge is stored in the network, creating multiple access pathways to the same information. We also uncover a limitation in this training style: the internal knowledge of the pre-trained model bounds what the retrieval model can retrieve. These findings suggest a few possible directions for dense retrieval: (1) expose the DPR training process to more knowledge so more can be decentralized, (2) inject facts as decentralized representations, (3) model and incorporate knowledge uncertainty in the retrieval process, and (4) directly map internal model knowledge to a knowledge base.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.791",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-margin",
        "author": "Kim, Kyuyoung and Seo, Ah Jeong and Liu, Hao and Shin, Jinwoo and Lee, Kimin",
        "booktitle": "EMNLP-findings2024",
        "title": "Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) fine-tuned with alignment techniques, such as reinforcement learning from human feedback, have been instrumental in developing some of the most capable AI systems to date. Despite their success, existing methods typically rely on simple binary labels, such as those indicating preferred outputs in pairwise preferences, which fail to capture the subtle differences in relative quality between pairs. To address this limitation, we introduce an approach called Margin Matching Preference Optimization (MMPO), which incorporates relative quality margins into optimization, leading to improved LLM policies and reward models. Specifically, given quality margins in pairwise preferences, we design soft target probabilities based on the Bradley-Terry model, which are then used to train models with the standard cross-entropy objective. Experiments with both human and AI feedback data demonstrate that MMPO consistently outperforms baseline methods, often by a substantial margin, on popular benchmarks including MT-bench and RewardBench. Notably, the 7B model trained with MMPO achieves state-of-the-art performance on RewardBench as of June 2024, outperforming other models of the same scale. Our analysis also shows that MMPO is more robust to overfitting, leading to better-calibrated models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.792",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AfriInstruct: Instruction Tuning of African Languages for Diverse Tasks": {
        "type": "INPROCEEDINGS",
        "key": "uemura-etal-2024-afriinstruct",
        "author": "Uemura, Kosei and Chen, Mahe and Pejovic, Alex and Maduabuchi, Chika and Sun, Yifei and Lee, En-Shiun Annie",
        "booktitle": "EMNLP-findings2024",
        "title": "AfriInstruct: Instruction Tuning of African Languages for Diverse Tasks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) for African languages perform worse compared to their performance in high-resource languages. To address this issue, we introduce AfriInstruct, which specializes in instruction-tuning of multiple African languages covering various tasks. We trained the LLaMa-2-7B using continual pretraining and instruction fine-tuning, which demonstrates superior performance across multiple tasks. Our mixed task evaluation shows that our model outperforms GPT-3.5-Turbo and other baseline models of similar size. Our contributions fill a critical gap of LLM performance between high-resource and African languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.793",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLMs as Collaborator: Demands-Guided Collaborative Retrieval-Augmented Generation for Commonsense Knowledge-Grounded Open-Domain Dialogue Systems": {
        "type": "INPROCEEDINGS",
        "key": "yu-etal-2024-llms",
        "author": "Yu, Jiong and Wu, Sixing and Chen, Jiahao and Zhou, Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "LLMs as Collaborator: Demands-Guided Collaborative Retrieval-Augmented Generation for Commonsense Knowledge-Grounded Open-Domain Dialogue Systems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Capturing the unique knowledge demands for each dialogue context plays a crucial role in commonsense knowledge-grounded response generation. However, current CoT-based and RAG-based methods are still unsatisfactory in the era of LLMs because 1) CoT often overestimates the capabilities of LLMs and treats them as isolated knowledge Producers; thus, CoT only uses the inherent knowledge of LLM itself and then suffers from the hallucination and outdated knowledge, and 2) RAG underestimates LLMs because LLMs are the passive Receivers that can only use the knowledge retrieved by external retrievers. In contrast, this work regards LLMs as interactive Collaborators and proposes a novel DCRAG (Demands-Guided Collaborative RAG) to leverage the knowledge from both LLMs and the external knowledge graph. Specifically, DCRAG designs three Thought-then-Generate stages to collaboratively investigate knowledge demands, followed by a Demands-Guided Knowledge Retrieval to retrieve external knowledge by interacting with LLMs. Extensive experiments and in-depth analyses on English DailyDialog and Chinese Diamante datasets proved DCRAG can effectively capture knowledge demands and bring higher-quality responses.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.794",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs": {
        "type": "INPROCEEDINGS",
        "key": "dammu-etal-2024-claimver",
        "author": "Dammu, Preetam Prabhu Srikar and Naidu, Himanshu and Dewan, Mouly and Kim, YoungMin and Roosta, Tanya and Chadha, Aman and Shah, Chirag",
        "booktitle": "EMNLP-findings2024",
        "title": "ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they often lack appropriate explainability or granularity to be useful in various contexts. A text validation method that is easy to use, accessible, and can perform fine-grained evidence attribution has become crucial. More importantly, building user trust in such a method requires presenting the rationale behind each prediction, as research shows this significantly influences people\u2019s belief in automated systems. Localizing and bringing users\u2019 attention to the specific problematic content is also paramount, instead of providing simple blanket labels. In this paper, we present ClaimVer, a human-centric framework tailored to meet users\u2019 informational and verification needs by generating rich annotations and thereby reducing cognitive load. Designed to deliver comprehensive evaluations of texts, it highlights each claim, verifies it against a trusted knowledge graph (KG), presents the evidence, and provides succinct, clear explanations for each claim prediction. Finally, our framework introduces an attribution score, enhancing applicability across a wide range of downstream tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.795",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Empirical Prior for Text Autoencoders": {
        "type": "INPROCEEDINGS",
        "key": "yin-etal-2024-empirical",
        "author": "Yin, Yongjing and Gao, Wenyang and Wu, Haodong and Yan, Jianhao and Zhang, Yue",
        "booktitle": "EMNLP-findings2024",
        "title": "Empirical Prior for Text Autoencoders",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper explores the application of Variational Autoencoders (VAE) in text generation, focusing on overcoming challenges like posterior collapse and the limitations of simplistic prior distributions. We investigate a transition from VAE to text autoencoders (AE), which model a compact latent space and preserves the capability of the language model itself. Our method involves layer-wise latent vectors regularized by orthogonal constraints to encourage distinct semantic spaces. In particular, we estimate an empirical prior online from the learned latent vectors to support sampling during generation like VAE. Experimental results on standard benchmarks demonstrate that the autoencoders generate higher quality and more diverse text than the VAE-based Transformer baselines, offering an effective alternative for generative language modeling.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.796",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Pedagogical Alignment of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "sonkar-etal-2024-pedagogical",
        "author": "Sonkar, Shashank and Ni, Kangqi and Chaudhary, Sapana and Baraniuk, Richard",
        "booktitle": "EMNLP-findings2024",
        "title": "Pedagogical Alignment of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs), when used in educational settings without pedagogical fine-tuning, often provide immediate answers rather than guiding students through the problem-solving process. This approach falls short of pedagogically best practices and limits their effectiveness as educational tools. We term the objective of training LLMs to emulate effective teaching strategies as \u2018pedagogical alignment.\u2019 In this paper, we investigate Learning from Human Preferences () algorithms to achieve this alignment objective. A key challenge in this process is the scarcity of high-quality preference datasets to guide the alignment. To address this, we propose a novel approach for constructing a large-scale dataset using synthetic data generation techniques, eliminating the need for time-consuming and costly manual annotation. Leveraging this dataset, our experiments with Llama and Mistral models demonstrate that LHP methods outperform standard supervised fine-tuning (SFT), improving pedagogical alignment accuracy by 13.1% and 8.7% respectively.Existing evaluation methods also lack quantitative metrics to adequately measure the pedagogical alignment of LLMs. To address this gap, we propose novel perplexity-based metrics that quantify LLMs\u2019 tendency to provide scaffolded guidance versus direct answers, offering a robust measure of pedagogical alignment. Our analysis provides compelling evidence for the superiority of methods over SFT in optimizing LLMs\u2019 behavior, underscoring the potential of methods in better aligning LLMs with educational objectives and fostering effective learning experiences. Code and models are available here.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.797",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Reference-based Metrics Disprove Themselves in Question Generation": {
        "type": "INPROCEEDINGS",
        "key": "nguyen-etal-2024-reference",
        "author": "Nguyen, Bang and Yu, Mengxia and Huang, Yun and Jiang, Meng",
        "booktitle": "EMNLP-findings2024",
        "title": "Reference-based Metrics Disprove Themselves in Question Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reference-based metrics such as BLEU and BERTScore are widely used to evaluate question generation (QG). In this study, on QG benchmarks such as SQuAD and HotpotQA, we find that using human-written references cannot guarantee the effectiveness of the reference-based metrics. Most QG benchmarks have only one reference; we replicate the annotation process and collect another reference. A good metric is expected to grade a human-validated question no worse than generated questions. However, the results of reference-based metrics on our newly collected reference disproved the metrics themselves. We propose a reference-free metric consisted of multi-dimensional criteria such as naturalness, answerability, and complexity, utilizing large language models. These criteria are not constrained to the syntactic or semantic of a single reference question, and the metric does not require a diverse set of references. Experiments reveal that our metric accurately distinguishes between high-quality questions and flawed ones, and achieves state-of-the-art alignment with human judgment.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.798",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Regression Aware Inference with LLMs": {
        "type": "INPROCEEDINGS",
        "key": "lukasik-etal-2024-regression",
        "author": "Lukasik, Michal and Narasimhan, Harikrishna and Menon, Aditya Krishna and Yu, Felix and Kumar, Sanjiv",
        "booktitle": "EMNLP-findings2024",
        "title": "Regression Aware Inference with LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have shown strong results on a range of applications, including regression and scoring tasks.Typically, one obtains outputs from an LLM via autoregressive sampling from the model\u2019s output distribution. We show that this inference strategy can be sub-optimal for common regression and scoring evaluation metrics. As a remedy, we build on prior work on Minimum Bayes Risk decoding,and propose alternate inference strategies that estimate the Bayes-optimal solution for regression and scoring metrics in closed-form from sampled responses.We show that our proposal significantly improves over baselines across datasets and models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.799",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "R\u00b3-NL2GQL: A Model Coordination and Knowledge Graph Alignment Approach for NL2GQL": {
        "type": "INPROCEEDINGS",
        "key": "zhou-etal-2024-r3",
        "author": "Zhou, Yuhang and He, Yu and Tian, Siyu and Ni, Yuchen and Yin, Zhangyue and Liu, Xiang and Ji, Chuanjun and Liu, Sen and Qiu, Xipeng and Ye, Guangnan and Chai, Hongfeng",
        "booktitle": "EMNLP-findings2024",
        "title": "R\u00b3-NL2GQL: A Model Coordination and Knowledge Graph Alignment Approach for NL2GQL",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While current tasks of converting natural language to SQL (NL2SQL) using Foundation Models have shown impressive achievements, adapting these approaches for converting natural language to Graph Query Language (NL2GQL) encounters hurdles due to the distinct nature of GQL compared to SQL, alongside the diverse forms of GQL. Moving away from traditional rule-based and slot-filling methodologies, we introduce a novel approach, R\u00b3-NL2GQL, integrating both small and large Foundation Models for ranking, rewriting, and refining tasks. This method leverages the interpretative strengths of smaller models for initial ranking and rewriting stages, while capitalizing on the superior generalization and query generation prowess of larger models for the final transformation of natural language queries into GQL formats. Addressing the scarcity of datasets in this emerging field, we have developed a bilingual dataset, sourced from graph database manuals and selected open-source Knowledge Graphs (KGs). Our evaluation of this methodology on this dataset demonstrates its promising efficacy and robustness.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.800",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Updating Large Language Models\u2019 Memories with Time Constraints": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-updating",
        "author": "Wu, Xin and Bu, Yuqi and Cai, Yi and Wang, Tao",
        "booktitle": "EMNLP-findings2024",
        "title": "Updating Large Language Models\u2019 Memories with Time Constraints",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "By incorporating the latest external knowledge, large language models (LLMs) can modify their internal memory. However, in practical applications, LLMs may encounter outdated information, necessitating the filtering of such data and updating of knowledge beyond internal memory. This paper explores whether LLMs can selectively update their memories based on the time constraints between internal memory and external knowledge. We evaluate existing LLMs using three types of data that exhibit different time constraints. Our experimental results reveal the challenges most LLMs face with time-constrained knowledge and highlight the differences in how various LLMs handle such information. Additionally, to address the difficulties LLMs encounter in understanding time constraints, we propose a two-stage decoupling framework that separates the identification and computation of time constraint into a symbolic system. Experimental results demonstrate that the proposed framework yields an improvement of over 60% in ChatGPT\u2019s performance, and achieves a 12-24% enhancement in state-of-the-art LLM GPT-4.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.801",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model": {
        "type": "INPROCEEDINGS",
        "key": "gao-zhang-2024-dlora",
        "author": "Gao, Chao and Zhang, Sai Qian",
        "booktitle": "EMNLP-findings2024",
        "title": "DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To enhance the performance of large language models (LLM) on downstream tasks, one solution is to fine-tune certain LLM parameters and make them better align with the characteristics of the training dataset. This process is commonly known as parameter-efficient fine-tuning (PEFT). Due to the scale of LLM, PEFT operations are usually executed in the public environment (e.g., cloud server). This necessitates sharing sensitive user data across public environments, thereby raising potential privacy concerns. To tackle these challenges, we propose a distributed PEFT framework called DLoRA. DLoRA enables scalable PEFT operations to be performed collaboratively between the cloud and user devices. Coupled with the proposed Kill and Revive algorithm, the evaluation results demonstrate that DLoRA can significantly reduce the computation and communication workload over user devices while achieving superior accuracy and privacy protection.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.802",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions": {
        "type": "INPROCEEDINGS",
        "key": "thota-nilizadeh-2024-attacks",
        "author": "Thota, Poojitha and Nilizadeh, Shirin",
        "booktitle": "EMNLP-findings2024",
        "title": "Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have introduced novel opportunities for text comprehension and generation. Yet, they are vulnerable to adversarial perturbations and data poisoning attacks, particularly in tasks like text classification and translation. However, the adversarial robustness of abstractive text summarization models remains less explored. In this work, we unveil a novel approach by exploiting the inherent lead bias in summarization models, to perform adversarial perturbations. Furthermore, we introduce an innovative application of influence functions, to execute data poisoning, which compromises the model\u2019s integrity. This approach not only shows a skew in the models\u2019 behavior to produce desired outcomes but also shows a new behavioral change, where models under attack tend to generate extractive summaries rather than abstractive summaries.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.804",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks": {
        "type": "INPROCEEDINGS",
        "key": "nehrdich-etal-2024-one",
        "author": "Nehrdich, Sebastian and Hellwig, Oliver and Keutzer, Kurt",
        "booktitle": "EMNLP-findings2024",
        "title": "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Morphologically rich languages are notoriously challenging to process for downstream NLP applications. This paper presents a new pretrained language model, ByT5-Sanskrit, designed for NLP applications involving the morphologically rich language Sanskrit. We evaluate ByT5-Sanskrit on established Sanskrit word segmentation tasks, where it outperforms previous data-driven approaches by a considerable margin and matches the performance of the current best lexicon-based model. It is easier to deploy and more robust to data not covered by external linguistic resources. It also achieves new state-of-the-art results in Vedic Sanskrit dependency parsing and OCR post-correction tasks. Additionally, based on the Digital Corpus of Sanskrit, we introduce a novel multitask dataset for the joint training of Sanskrit word segmentation, lemmatization, and morphosyntactic tagging tasks. We fine-tune ByT5-Sanskrit on this dataset, creating a versatile multitask model for various downstream Sanskrit applications. We have used this model in Sanskrit linguistic annotation projects, in information retrieval setups, and as a preprocessing step in a Sanskrit machine translation pipeline. We also show that our approach yields new best scores for lemmatization and dependency parsing of other morphologically rich languages. We thus demonstrate that byte-level pretrained language models can achieve excellent performance for morphologically rich languages, outperforming tokenizer-based models and presenting an important vector of exploration when constructing NLP pipelines for such languages.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.805",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "NALA: an Effective and Interpretable Entity Alignment Method": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-nala",
        "author": "Xu, Chuanhao and Cheng, Jingwei and Zhang, Fu",
        "booktitle": "EMNLP-findings2024",
        "title": "NALA: an Effective and Interpretable Entity Alignment Method",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Entity alignment (EA) aims to find equivalent entities between two Knowledge Graphs. Existing embedding-based EA methods usually encode entities as embeddings, triples as embeddings\u2019 constraint and learn to align the embeddings. However, the details of the underlying logical inference steps among the alignment process are usually omitted, resulting in inadequate inference process. In this paper, we introduce NALA, an entity alignment method that captures three types of logical inference paths with Non-Axiomatic Logic (NAL). Type 1&amp;2 align the entity pairs and type 3 aligns relations. NALA iteratively aligns entities and relations by integrating the conclusions of the inference paths. Our method is logically interpretable and extensible by introducing NAL, and thus suitable for various EA settings. Experimental results show that NALA outperforms state-of-the-art methods in terms of Hits@1, achieving 0.98+ on all three datasets of DBP15K with both supervised and unsupervised settings. We offer a pioneering in-depth analysis of the fundamental principles of entity alignment, approaching the subject from a unified and logical perspective. Our code is available at https://github.com/13998151318/NALA.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.806",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation": {
        "type": "INPROCEEDINGS",
        "key": "roy-etal-2024-contregen",
        "author": "Roy, Kashob Kumar and Akash, Pritom Saha and Chang, Kevin Chen-Chuan and Popa, Lucian",
        "booktitle": "EMNLP-findings2024",
        "title": "ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Open-domain long-form text generation requires generating coherent, comprehensive responses that address complex queries with both breadth and depth. This task is challenging due to the need to accurately capture diverse facets of input queries. Existing iterative retrieval-augmented generation (RAG) approaches often struggle to delve deeply into each facet of complex queries and integrate knowledge from various sources effectively. This paper introduces ConTReGen, a novel framework that employs a context-driven, tree-structured retrieval approach to enhance the depth and relevance of retrieved content. ConTReGen integrates a hierarchical, top-down in-depth exploration of query facets with a systematic bottom-up synthesis, ensuring comprehensive coverage and coherent integration of multifaceted information. Extensive experiments on multiple datasets, including LFQA and ODSUM, alongside a newly introduced dataset, ODSUM-WikiHow, demonstrate that ConTReGen outperforms existing state-of-the-art RAG models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.807",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Aligners: Decoupling LLMs and Alignment": {
        "type": "INPROCEEDINGS",
        "key": "ngweta-etal-2024-aligners",
        "author": "Ngweta, Lilian and Agarwal, Mayank and Maity, Subha and Gittens, Alex and Sun, Yuekai and Yurochkin, Mikhail",
        "booktitle": "EMNLP-findings2024",
        "title": "Aligners: Decoupling LLMs and Alignment",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) need to be aligned with human expectations to ensure their safety and utility in most applications. Alignment is challenging, costly, and needs to be repeated for every LLM and alignment criterion. We propose to decouple LLMs and alignment by training *aligner* models that can be used to align any LLM for a given criteria on an as-needed basis, thus also reducing the potential negative impacts of alignment on performance. Our recipe for training the aligner models solely relies on synthetic data generated with a (prompted) LLM and can be easily adjusted for a variety of alignment criteria. We use the same synthetic data to train *inspectors*, binary miss-alignment classification models to guide a *squad* of multiple aligners. Our empirical results demonstrate consistent improvements when applying aligner squad to various LLMs, including chat-aligned models, across several instruction-following and red-teaming datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.808",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TOWER: Tree Organized Weighting for Evaluating Complex Instructions": {
        "type": "INPROCEEDINGS",
        "key": "ziems-etal-2024-tower",
        "author": "Ziems, Noah and Zhang, Zhihan and Jiang, Meng",
        "booktitle": "EMNLP-findings2024",
        "title": "TOWER: Tree Organized Weighting for Evaluating Complex Instructions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Evaluating the ability of large language models (LLMs) to follow complex human-written instructions is essential for their deployment in real-world applications. While benchmarks like Chatbot Arena use human judges to assess model performance, they are resource-intensive and time-consuming. Alternative methods using LLMs as judges, such as AlpacaEval, MT Bench, WildBench, and InFoBench offer improvements but still do not capture that certain complex instruction aspects are more important than others to follow.To address this gap, we propose a novel evaluation metric, TOWER, that incorporates human-judged importance into the assessment of complex instruction following. We show that human annotators agree with tree-based representations of these complex instructions nearly as much as they agree with other human annotators. We release tree-based annotations of the InFoBench dataset and the corresponding evaluation code to facilitate future research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.809",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Extractive Medical Entity Disambiguation with Memory Mechanism and Memorized Entity Information": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-extractive",
        "author": "Zhang, Guobiao and Peng, Xueping and Shen, Tao and Long, Guodong and Si, Jiasheng and Qin, Libo and Lu, Wenpeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Extractive Medical Entity Disambiguation with Memory Mechanism and Memorized Entity Information",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Medical entity disambiguation (MED) aims to ground medical mentions in text with ontological entities in knowledge bases (KBs). A notable challenge of MED is the long medical text usually contains multiple entities\u2019 mentions with intricate correlations. However, limited by computation overhead, many existing methods consider only a single candidate entity mention during the disambiguation process. As such, they focus only on local MED optimal while ignoring the sole-mention disambiguation possibly boosted by richer context from other mentions\u2019 disambiguating processes \u2013 missing global optimal on entity combination in the text. Motivated by this, we propose a new approach called Extractive Medical Entity Disambiguation with Memory Mechanism and Memorized Entity Information (M3E). Specifically, we reformulate MED as a text extraction task, which simultaneously accepts the context of medical mentions, all possible candidate entities, and entity definitions, and it is then trained to extract the text span corresponding to the correct entity. Upon our new formulation, 1) to alleviate the computation overhead from the enriched context, we devise a memory mechanism module that performs memory caching, retrieval, fusion and cross-network residual; and 2) to utilize the disambiguation clues from other mentions, we design an auxiliary disambiguation module that employs a gating mechanism to assist the disambiguation of remaining mentions. Extensive experiments on two benchmark datasets demonstrate the superiority of M3E over the state-of-the-art MED methods on all metrics.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.810",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "QEFT: Quantization for Efficient Fine-Tuning of LLMs": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-qeft",
        "author": "Lee, Changhun and Jin, Jun-gyu and Cho, YoungHyun and Park, Eunhyeok",
        "booktitle": "EMNLP-findings2024",
        "title": "QEFT: Quantization for Efficient Fine-Tuning of LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "With the rapid growth in the use of fine-tuning for large language models (LLMs), optimizing fine-tuning while keeping inference efficient has become highly important. However, this is a challenging task as it requires improvements in all aspects, including inference speed, fine-tuning speed, memory consumption, and, most importantly, model quality. Previous studies have attempted to achieve this by combining quantization with fine-tuning, but they have failed to enhance all four aspects simultaneously. In this study, we propose a new lightweight technique called Quantization for Efficient Fine-Tuning (QEFT). QEFT accelerates both inference and fine-tuning, is supported by robust theoretical foundations, offers high flexibility, and maintains good hardware compatibility. Our extensive experiments demonstrate that QEFT matches the quality and versatility of full-precision parameter-efficient fine-tuning, while using fewer resources. Our code is available at https://github.com/xvyaward/qeft.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.811",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Skills-in-Context: Unlocking Compositionality in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-skills",
        "author": "Chen, Jiaao and Pan, Xiaoman and Yu, Dian and Song, Kaiqiang and Wang, Xiaoyang and Yu, Dong and Chen, Jianshu",
        "booktitle": "EMNLP-findings2024",
        "title": "Skills-in-Context: Unlocking Compositionality in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We investigate how to elicit compositional generalization capabilities in large language models (LLMs). Compositional generalization empowers LLMs to solve complex problems by combining foundational skills, a critical reasoning ability akin to human intelligence. However, even the most advanced LLMs currently struggle with this form of reasoning. We examine this problem within the framework of in-context learning and find that demonstrating both foundational skills and compositional examples grounded in these skills within the same prompt context is crucial. We refer to this prompt structure as skills-in-context (SKiC). With as few as two exemplars, this in-context learning structure enables LLMs to tackle more challenging problems requiring innovative skill combinations, achieving near-perfect systematic generalization across a broad range of tasks. Intriguingly, SKiC also unlocks the latent potential of LLMs, allowing them to more actively utilize pre-existing internal skills acquired during earlier pretraining stages to solve complex reasoning problems. The SKiC structure is robust across different skill constructions and exemplar choices and demonstrates strong transferability to new tasks. Finally, inspired by our in-context learning study, we show that fine-tuning LLMs with SKiC-style data can elicit zero-shot weak-to-strong generalization, enabling the models to solve much harder problems directly with standard prompting.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.812",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLMs Jailbreakers": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-drattack",
        "author": "Li, Xirui and Wang, Ruochen and Cheng, Minhao and Zhou, Tianyi and Hsieh, Cho-Jui",
        "booktitle": "EMNLP-findings2024",
        "title": "DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLMs Jailbreakers",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Safety-aligned Large Language Models (LLMs) are still vulnerable to some manual and automated jailbreak attacks, which adversarially trigger LLMs to output harmful content. However, existing jailbreaking methods usually view a harmful prompt as a whole but they are not effective at reducing LLMs\u2019 attention on combinations of words with malice, which well-aligned LLMs can easily reject. This paper discovers that decomposing a malicious prompt into separated sub-prompts can effectively reduce LLMs\u2019 attention on harmful words by presenting them to LLMs in a fragmented form, thereby addressing these limitations and improving attack effectiveness. We introduce an automatic prompt Decomposition and Reconstruction framework for jailbreaking Attack (DrAttack). DrAttack consists of three key components: (a) \u2018Decomposition\u2019 of the original prompt into sub-prompts, (b) \u2018Reconstruction\u2019 of these sub-prompts implicitly by In-Context Learning with semantically similar but benign reassembling example, and (c) \u2018Synonym Search\u2019 of sub-prompts, aiming to find sub-prompts\u2019 synonyms that maintain the original intent while jailbreaking LLMs. An extensive empirical study across multiple open-source and closed-source LLMs demonstrates that, with fewer queries, DrAttack obtains a substantial gain of success rate on powerful LLMs over prior SOTA attackers. Notably, the success rate of 80% on GPT-4 surpassed previous art by 65%. Code and data are made publicly available at https://turningpoint-ai.github.io/DrAttack/.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.813",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-llms",
        "author": "Zhao, Yutian and Wang, Huimin and Liu, Yuqi and Suhuang, Wu and Wu, Xian and Zheng, Yefeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Can LLMs Replace Clinical Doctors? Exploring Bias in Disease Diagnosis by Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The bias of disease prediction in Large Language Models (LLMs) is a critical yet underexplored issue, with potential implications for healthcare outcomes and equity. As LLMs increasingly find applications in healthcare, understanding and addressing their biases becomes paramount. This study focuses on this crucial topic, investigating the bias of disease prediction in models such as GPT-4, ChatGPT, and Qwen1.5-72b across gender, age range, and disease judgment behaviors. Utilizing a comprehensive real-clinical health record dataset of over 330,000 entries, we uncover that all three models exhibit distinct biases, indicating a pervasive issue of unfairness. To measure this, we introduce a novel metric\u2013the diagnosis bias score, which reflects the ratio of prediction numbers to label numbers. Our in-depth analysis, based on this score, sheds light on the inherent biases in these models. In response to these findings, we propose a simple yet effective prompt-based solution to alleviate the observed bias in disease prediction with LLMs. This research underscores the importance of fairness in AI, particularly in healthcare applications, and offers a practical approach to enhance the equity of disease prediction models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.814",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BLADE: Benchmarking Language Model Agents for Data-Driven Science": {
        "type": "INPROCEEDINGS",
        "key": "gu-etal-2024-blade",
        "author": "Gu, Ken and Shang, Ruoxi and Jiang, Ruien and Kuang, Keying and Lin, Richard-John and Lyu, Donghe and Mao, Yue and Pan, Youran and Wu, Teng and Yu, Jiaqian and Zhang, Yikun and Zhang, Tianmai M. and Zhu, Lanyi and Merrill, Mike A. and Heer, Jeffrey and Althoff, Tim",
        "booktitle": "EMNLP-findings2024",
        "title": "BLADE: Benchmarking Language Model Agents for Data-Driven Science",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Data-driven scientific discovery requires the iterative integration of scientific domain knowledge, statistical expertise, and an understanding of data semantics to make nuanced analytical decisions, e.g., about which variables, transformations, and statistical models to consider. LM-based agents equipped with planning, memory, and code execution capabilities have the potential to support data-driven science. However, evaluating agents on such open-ended tasks is challenging due to multiple valid approaches, partially correct steps, and different ways to express the same decisions. To address these challenges, we present BLADE, a benchmark to automatically evaluate agents\u2019 multifaceted approaches to open-ended research questions. BLADE consists of 12 datasets and research questions drawn from existing scientific literature, with ground truth collected from independent analyses by expert data scientists and researchers. To automatically evaluate agent responses, we developed corresponding computational methods to match different representations of analyses to this ground truth. Though language models possess considerable world knowledge, our evaluation shows that they are often limited to basic analyses. However, agents capable of interacting with the underlying data demonstrate improved, but still non-optimal, diversity in their analytical decision making. Our work enables the evaluation of agents for data-driven science and provides researchers deeper insights into agents\u2019 analysis approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.815",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Phonetic and Lexical Discovery of Canine Vocalization": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-phonetic",
        "author": "Wang, Theron S. and Li, Xingyuan and Zhang, Chunhao and Wu, Mengyue and Zhu, Kenny Q.",
        "booktitle": "EMNLP-findings2024",
        "title": "Phonetic and Lexical Discovery of Canine Vocalization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper attempts to discover communication patterns automatically within dog vocalizations in a data-driven approach, which breaks the barrier previous approaches that rely on human prior knowledge on limited data. We present a self-supervised approach with HuBERT, enabling the accurate classification of phones, and an adaptive grammar induction method that identifies phone sequence patterns that suggest a preliminary vocabulary within dog vocalizations. Our results show that a subset of this vocabulary has substantial causality relations with certain canine activities, suggesting signs of stable semantics associated with these \u201cwords\u201d.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.816",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-audio",
        "author": "Kim, Youngjae and Jeon, Yejin and Lee, Gary",
        "booktitle": "EMNLP-findings2024",
        "title": "Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The difficulty of acquiring abundant, high-quality data, especially in multi-lingual contexts, has sparked interest in addressing low-resource scenarios. Moreover, current literature rely on fixed expressions from language IDs, which results in the inadequate learning of language representations, and the failure to generate speech in unseen languages. To address these challenges, we propose a novel method that directly extracts linguistic features from audio input while effectively filtering out miscellaneous acoustic information including speaker-specific attributes like timbre. Subjective and objective evaluations affirm the effectiveness of our approach for multi-lingual text-to-speech, and highlight its superiority in low-resource transfer learning for previously unseen language.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.817",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons": {
        "type": "INPROCEEDINGS",
        "key": "yong-etal-2024-lexc",
        "author": "Yong, Zheng Xin and Menghini, Cristina and Bach, Stephen",
        "booktitle": "EMNLP-findings2024",
        "title": "LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Data scarcity in low-resource languages can be addressed with word-to-word translations from labeled task data in high-resource languages using bilingual lexicons. However, bilingual lexicons often have limited lexical overlap with task data, which results in poor translation coverage and lexicon utilization. We propose lexicon-conditioned data generation LexC-Gen, a method that generates low-resource-language classification task data at scale. Specifically, LexC-Gen first uses high-resource-language words from bilingual lexicons to generate lexicon-compatible task data, and then it translates them into low-resource languages with bilingual lexicons via word translation. Across 17 extremely low-resource languages, LexC-Gen generated data is competitive with expert-translated gold data, and yields on average 5.6 and 8.9 points improvement over existing lexicon-based word translation methods on sentiment analysis and topic classification tasks respectively. Through ablation study, we show that conditioning on bilingual lexicons is the key component of LexC-Gen. LexC-Gen serves as a potential solution to close the performance gap between open-source multilingual models, such as BLOOMZ and Aya-101, and state-of-the-art commercial models like GPT-4o on low-resource-language tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.818",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks": {
        "type": "INPROCEEDINGS",
        "key": "chuang-etal-2024-beyond",
        "author": "Chuang, Yun-Shiuan and Nirunwiroj, Krirk and Studdiford, Zach and Goyal, Agam and Frigo, Vincent V. and Yang, Sijia and Shah, Dhavan V. and Hu, Junjie and Rogers, Timothy T.",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Creating human-like large language model (LLM) agents is crucial for faithful social simulation. Having LLMs role-play based on demographic information sometimes improves human likeness but often does not. This study assessed whether LLM alignment with human behavior can be improved by integrating information from empirically-derived human belief networks. Using data from a human survey, we estimated a belief network encompassing 64 topics loading on nine non-overlapping latent factors. We then seeded LLM-based agents with an opinion on one topic, and assessed the alignment of its expressed opinions on remaining test topics with corresponding human data. Role-playing based on demographic information alone did not align LLM and human opinions, but seeding the agent with a single belief greatly improved alignment for topics related in the belief network, and not for topics outside the network. These results suggest a novel path for human-LLM belief alignment in work seeking to simulate and understand patterns of belief distributions in society.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.819",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PRoDeliberation: Parallel Robust Deliberation for End-to-End Spoken Language Understanding": {
        "type": "INPROCEEDINGS",
        "key": "le-etal-2024-prodeliberation",
        "author": "Le, Trang and Lazar, Daniel and Kim, Suyoun and Jiang, Shan and Le, Duc and Sagar, Adithya and Livshits, Aleksandr and Aly, Ahmed A. and Shrivastava, Akshat",
        "booktitle": "EMNLP-findings2024",
        "title": "PRoDeliberation: Parallel Robust Deliberation for End-to-End Spoken Language Understanding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Spoken Language Understanding (SLU) is a critical component of voice assistants; it consists of converting speech to semantic parses for task execution. Previous works have explored end-to-end models to improve the quality and robustness of SLU models with Deliberation, however these models have remained autoregressive, resulting in higher latencies. In this work we introduce PRoDeliberation, a novel method leveraging a Connectionist Temporal Classification-based decoding strategy as well as a denoising objective to train robust non-autoregressive deliberation models. We show that PRoDeliberation achieves the latency reduction of parallel decoding (2-10x improvement over autoregressive models) while retaining the ability to correct Automatic Speech Recognition (ASR) mistranscriptions of autoregressive deliberation systems. We further show that the design of the denoising training allows PRoDeliberation to overcome the limitations of small ASR devices, and we provide analysis on the necessity of each component of the system.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.820",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Downstream Trade-offs of a Family of Text Watermarks": {
        "type": "INPROCEEDINGS",
        "key": "ajith-etal-2024-downstream",
        "author": "Ajith, Anirudh and Singh, Sameer and Pruthi, Danish",
        "booktitle": "EMNLP-findings2024",
        "title": "Downstream Trade-offs of a Family of Text Watermarks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Watermarking involves implanting an imperceptible signal into generated text that can later be detected via statistical tests. A prominent family of watermarking strategies for LLMs embeds this signal by upsampling a (pseudorandomly-chosen) subset of tokens at every generation step. However, such signals alter the model\u2019s output distribution and can have unintended effects on its downstream performance. In this work, we evaluate the performance of LLMs watermarked using three different strategies over a diverse suite of tasks including those cast as k-class classification (CLS), multiple choice question answering (MCQ), short-form generation (e.g., open-ended question answering) and long-form generation (e.g., translation) tasks. We find that watermarks (under realistic hyperparameters) can cause significant drops in LLMs\u2019 effective utility across all tasks. We observe drops of 10 to 20% in CLS tasks in the average case, which shoot up to 100% in the worst case. We notice degradations of about 7% in MCQ tasks, 10-15% in short-form generation, and 5-15% in long-form generation tasks. Our findings highlight the trade-offs that users should be cognizant of when using watermarked models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.821",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables": {
        "type": "INPROCEEDINGS",
        "key": "mathur-etal-2024-knowledge",
        "author": "Mathur, Suyash Vardhan and Bafna, Jainit Sushil and Kartik, Kunal and Khandelwal, Harshita and Shrivastava, Manish and Gupta, Vivek and Bansal, Mohit and Roth, Dan",
        "booktitle": "EMNLP-findings2024",
        "title": "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing datasets for tabular question answering typically focus exclusively on text within cells. However, real-world data is inherently multimodal, often blending images such as symbols, faces, icons, patterns, and charts with textual content in tables. With the evolution of AI models capable of multimodal reasoning, it is pertinent to assess their efficacy in handling such structured data. This study investigates whether current AI models can perform knowledge-aware reasoning on multimodal structured data. We explore their ability to reason on tables that integrate both images and text, introducing MMTabQA, a new dataset designed for this purpose. Our experiments highlight substantial challenges for current AI models in effectively integrating and interpreting multiple text and image inputs, understanding visual context, and comparing visual content across images. These findings establish our dataset as a robust benchmark for advancing AI\u2019s comprehension and capabilities in analyzing multimodal structured data.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.822",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Representational Isomorphism and Alignment of Multilingual Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wu-etal-2024-representational",
        "author": "Wu, Di and Lei, Yibin and Yates, Andrew and Monz, Christof",
        "booktitle": "EMNLP-findings2024",
        "title": "Representational Isomorphism and Alignment of Multilingual Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we investigate the capability of Large Language Models (LLMs) to represent texts in multilingual contexts. Our findings show that sentence representations derived from LLMs exhibit a high degree of isomorphism across languages.This existing isomorphism can facilitate representational alignments in zero-shot and few-shot settings.Specifically, by applying a contrastive objective at the representation level with only a small number of translation pairs (e.g., 100), we substantially improve models\u2019 performance on Semantic Textual Similarity (STS) tasks across languages. This representation-level approach proves to be more efficient and effective for semantic alignment than continued pretraining or instruction tuning. Interestingly, we also observe substantial STS improvements within individual languages, even without a monolingual objective specifically designed for this purpose.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.823",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SWAG: Storytelling With Action Guidance": {
        "type": "INPROCEEDINGS",
        "key": "pei-etal-2024-swag",
        "author": "Pei, Jonathan and Patel, Zeeshan and El-Refai, Karim and Li, Tianle",
        "booktitle": "EMNLP-findings2024",
        "title": "SWAG: Storytelling With Action Guidance",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automated long-form story generation typically employs long-context large language models (LLMs) for one-shot creation, which can produce cohesive but not necessarily engaging content. We introduce Storytelling With Action Guidance (SWAG), a novel approach to storytelling with LLMs. Our approach reduces story writing to a search problem through a two-model feedback loop: one LLM generates story content, and another auxiliary LLM is used to choose the next best \u201caction\u201d to steer the story\u2019s future direction. Our results show that SWAG can substantially outperform previous end-to-end story generation techniques when evaluated by GPT-4 and through human evaluation. Our SWAG pipeline using only small open-source models surpasses GPT-3.5-Turbo.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.824",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems": {
        "type": "INPROCEEDINGS",
        "key": "chen-lin-2024-random",
        "author": "Chen, Sheng-Wei and Lin, Chih-Jen",
        "booktitle": "EMNLP-findings2024",
        "title": "Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Text classification is one of the essential topics in natural language processing, and each text is often associated with multiple labels. Recently, the number of labels has become larger and larger, especially in the applications of e-commerce, so handling text-related e-commerce problems further requires a large memory space in many existing multi-label learning methods. To address the space concern, utilizing a distributed system to share that large memory requirement is a possible solution. We propose \u201crandom label forests,\u201d a distributed ensemble method with label subsampling, for handling extremely large-scale labels. Random label forests can reduce memory usage per computer while keeping competitive performances over real-world data sets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.825",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting": {
        "type": "INPROCEEDINGS",
        "key": "bowden-etal-2024-active",
        "author": "Bowden, Kevin and Fan, Yue and Chen, Winson and Cui, Wen and Harrison, Davan and Wang, Xin Eric and Walker, Marilyn",
        "booktitle": "EMNLP-findings2024",
        "title": "Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) capable of casual conversation have recently become widely available. We hypothesize that users of conversational systems want a more personalized experience, and existing work shows that users are highly receptive to personalized questions (PQs). Question Generation tasks, however, focus on factual questions from textual excerpts. To create a PQ generator, we first identify over 400 real user interests by anonymously aggregating ~39K user models. We then populate prompt templates with these 400 interests and use an LLM to generate PQs customized to user interests. The result is PerQs, a novel corpus of ~19K question/answer pairs. We evaluate PerQs at scale in the unique context of the Alexa Prize. Our results show significant positive effects on perceived conversation quality. We then fine-tune, deploy, and evaluate PerQy, a neural model that generates PQs in real-time. When evaluated against several competitive LLM baselines, PerQy produced the most natural and engaging responses.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.826",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM": {
        "type": "INPROCEEDINGS",
        "key": "eom-etal-2024-query",
        "author": "Eom, SooHwan and Shim, Jay and Koo, Gwanhyeong and Na, Haebin and Hasegawa-Johnson, Mark A. and Kim, Sungwoong and Yoo, Chang D.",
        "booktitle": "EMNLP-findings2024",
        "title": "Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The Transformer\u2019s quadratic complexity with input length imposes an unsustainable computational load on large language models (LLMs). In contrast, the Selective Scan Structured State-Space Model, or Mamba, addresses this computational challenge effectively. This paper explores a query-based cross-modal projector designed to bolster Mamba\u2019s efficiency for vision-language modeling by compressing visual tokens based on input through the cross-attention mechanism. This innovative projector also removes the need for manually designing the 2D scan order of original image features when converting them into an input sequence for Mamba LLM. Experimental results across various vision-language understanding benchmarks show that the proposed cross-modal projector enhances Mamba-based multimodal LLMs, boosting both performance and throughput.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.827",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM as a metric critic for low resource relation identification": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-llm",
        "author": "Yang, Zhe and Huang, Yi and Chen, Yaqin and Wu, Xiaoting and Feng, Junlan and Deng, Chao",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM as a metric critic for low resource relation identification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In extremely low resource relation identification scenario, small language models (SLMs) incline to overfit, which significantly diminishes their accuracy. Recently, large language models (LLMs) are gradually applied to classification tasks with converting original objective into the generation task via in-context learning. However, abundance of the classifier categories poses challenges in selecting demonstrations. Moreover, the mapping between category labels and textual descriptions requires expensive expert knowledge, thereby constraining the efficacy of in-context learning for LLMs. We uphold that SLM is optimal for handling classification tasks, and its shortcomings in the low resource setting can be mitigated by leveraging LLM. Hence, we propose a co-evolution strategy on SLM &amp; LLM for relation identification. Specifically, LLM provides essential background knowledge to assist training process of the SLM classifier, while evaluation metrics from the classifier, in turn, offer valuable insights to refine the generation prompts of the LLM. We conduct experiments on several datasets which demonstrates preponderance of the proposed model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.828",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Experience as Source for Anticipation and Planning: Experiential Policy Learning for Target-driven Recommendation Dialogues": {
        "type": "INPROCEEDINGS",
        "key": "dao-etal-2024-experience",
        "author": "Dao, Huy Quang and Deng, Yang and Bui, Khanh-Huyen and Le, Dung D. and Liao, Lizi",
        "booktitle": "EMNLP-findings2024",
        "title": "Experience as Source for Anticipation and Planning: Experiential Policy Learning for Target-driven Recommendation Dialogues",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Target-driven recommendation dialogues present unique challenges in dialogue management due to the necessity of anticipating user interactions for successful conversations. Current methods face significant limitations: (I) inadequate capabilities for conversation anticipation, (II) computational inefficiencies due to costly simulations, and (III) neglect of valuable past dialogue experiences. To address these limitations, we propose a new framework, Experiential Policy Learning (EPL), for enhancing such dialogues. EPL embodies the principle of Learning From Experience, facilitating anticipation with an experiential scoring function that estimates dialogue state potential using similar past interactions stored in long-term memory. To demonstrate its flexibility, we introduce Tree-structured EPL (T-EPL) as one possible training-free realization with Large Language Models (LLMs) and Monte-Carlo Tree Search (MCTS). T-EPL assesses past dialogue states with LLMs while utilizing MCTS to achieve hierarchical and multi-level reasoning. Extensive experiments on two published datasets demonstrate the superiority and efficacy of T-EPL.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.829",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-checkers": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-factcheck",
        "author": "Wang, Yuxia and Gangi Reddy, Revanth and Mujahid, Zain Muhammad and Arora, Arnav and Rubashevskii, Aleksandr and Geng, Jiahui and Mohammed Afzal, Osama and Pan, Liangming and Borenstein, Nadav and Pillai, Aditya and Augenstein, Isabelle and Gurevych, Iryna and Nakov, Preslav",
        "booktitle": "EMNLP-findings2024",
        "title": "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-checkers",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The increased use of large language models (LLMs) across a variety of real-world applications calls for mechanisms to verify the factual accuracy of their outputs. In this work, we present Factcheck-Bench, a holistic end-to-end framework for annotating and evaluating the factuality of LLM-generated responses, which encompasses a multi-stage annotation scheme designed to yield detailed labels for fact-checking and correcting not just the final prediction, but also the intermediate steps that a fact-checking system might need to take. Based on this framework, we construct an open-domain factuality benchmark in three-levels of granularity: claim, sentence, and document. We further propose a system, Factcheck-GPT, which follows our framework, and we show that it outperforms several popular LLM fact-checkers. We make our annotation tool, annotated data, benchmark, and code available at https://github.com/yuxiaw/Factcheck-GPT.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.830",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Open-RAG: Enhanced Retrieval Augmented Reasoning with Open-Source Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "islam-etal-2024-open",
        "author": "Islam, Shayekh Bin and Rahman, Md Asib and Hossain, K. S. M. Tozammel and Hoque, Enamul and Joty, Shafiq and Parvez, Md Rizwan",
        "booktitle": "EMNLP-findings2024",
        "title": "Open-RAG: Enhanced Retrieval Augmented Reasoning with Open-Source Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval Augmented Generation (RAG) has been shown to enhance the factual accuracy of Large Language Models (LLMs) by providing external evidence, but existing methods often suffer from limited reasoning capabilities (e.g., multi-hop complexities) in effectively using such evidence, particularly when using open-source LLMs. To mitigate this gap, in this paper, we introduce a novel framework, **Open-RAG**, designed to enhance reasoning capabilities in RAG with open-source LLMs. Our framework transforms an arbitrary dense LLM into a parameter-efficient sparse mixture of experts (MoE) model capable of handling complex reasoning tasks, including both single- and multi-hop queries. Open-RAG uniquely trains the model to navigate challenging distractors that appear relevant but are misleading. By combining the constructive learning and architectural transformation, Open-RAG leverages latent learning, dynamically selecting relevant experts and integrating external knowledge effectively for more accurate and contextually relevant responses. Additionally, we propose a hybrid adaptive retrieval method to determine retrieval necessity and balance the trade-off between performance gain and inference speed. Experimental results show that Open-RAG outperforms state-of-the-art LLMs and RAG models in various knowledge-intensive tasks. Our method based on Llama2-7B sets new benchmarks, surpassing ChatGPT-RAG and Self-RAG. For example, in multi-hop HotpotQA, it achieves an EM score of 63.3, compared to RAG 2.0\u2019s 54 and Command R+\u2019s 60.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.831",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-cactus",
        "author": "Lee, Suyeon and Kim, Sunghwan and Kim, Minju and Kang, Dongjin and Yang, Dongil and Kim, Harim and Kang, Minseok and Jung, Dayi and Kim, Min Hee and Lee, Seungbeen and Chung, Kyong-Mee and Yu, Youngjae and Lee, Dongha and Yeo, Jinyoung",
        "booktitle": "EMNLP-findings2024",
        "title": "Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, the demand for psychological counseling has significantly increased as more individuals express concerns about their mental health. This surge has accelerated efforts to improve the accessibility of counseling by using large language models (LLMs) as counselors. To ensure client privacy, training open-source LLMs faces a key challenge: the absence of realistic counseling datasets. To address this, we introduce Cactus, a multi-turn dialogue dataset that emulates real-life interactions using the goal-oriented and structured approach of Cognitive Behavioral Therapy (CBT).We create a diverse and realistic dataset by designing clients with varied, specific personas, and having counselors systematically apply CBT techniques in their interactions. To assess the quality of our data, we benchmark against established psychological criteria used to evaluate real counseling sessions, ensuring alignment with expert evaluations.Experimental results demonstrate that Camel, a model trained with Cactus, outperforms other models in counseling skills, highlighting its effectiveness and potential as a counseling agent.We make our data, model, and code publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.832",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TextLap: Customizing Language Models for Text-to-Layout Planning": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-textlap",
        "author": "Chen, Jian and Zhang, Ruiyi and Zhou, Yufan and Healey, Jennifer and Gu, Jiuxiang and Xu, Zhiqiang and Chen, Changyou",
        "booktitle": "EMNLP-findings2024",
        "title": "TextLap: Customizing Language Models for Text-to-Layout Planning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automatic generation of graphical layouts is crucial for many real-world applications, including designing posters, flyers, advertisements, and graphical user interfaces. Given the incredible ability of Large language models (LLMs) in both natural language understanding and generation, we believe that we could customize an LLM to help people create compelling graphical layouts starting with only text instructions from the user. We call our method TextLap (text-based layout planning). It uses a curated instruction-based layout planning dataset (InsLap) to customize LLMs as a graphic designer. Human annotators are asked to build a benchmark to evaluate different layout planning models. We demonstrate the effectiveness of TextLap and show that it outperforms strong baselines, including GPT-4 based methods, for document generation and graphical design benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.833",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Data-driven Coreference-based Ontology Building": {
        "type": "INPROCEEDINGS",
        "key": "ashury-tahan-etal-2024-data",
        "author": "Ashury Tahan, Shir and Cohen, Amir David Nissan and Cohen, Nadav and Louzoun, Yoram and Goldberg, Yoav",
        "booktitle": "EMNLP-findings2024",
        "title": "Data-driven Coreference-based Ontology Building",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While coreference resolution is traditionally used as a component in individual document understanding, in this work we take a more global view and explore what can we learn about a domain from the set of all document-level coreference relations that are present in a large corpus. We derive coreference chains from a corpus of 30 million biomedical abstracts and construct a graph based on the string phrases within these chains, establishing connections between phrases if they co-occur within the same coreference chain. We then use the graph structure and the betweeness centrality measure to distinguish between edges denoting hierarchy, identity and noise, assign directionality to edges denoting hierarchy, and split nodes (strings) that correspond to multiple distinct concepts. The result is a rich, data-driven ontology over concepts in the biomedical domain, parts of which overlaps significantly with human-authored ontologies. We release the coreference chains and resulting ontology under a creative-commons license.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.834",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision": {
        "type": "INPROCEEDINGS",
        "key": "christmann-etal-2024-retrieving",
        "author": "Christmann, Philipp and Vakulenko, Svitlana and Sorodoc, Ionut Teodor and Byrne, Bill and de Gispert, Adri\u00e0",
        "booktitle": "EMNLP-findings2024",
        "title": "Retrieving Contextual Information for Long-Form Question Answering using Weak Supervision",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Long-form question answering (LFQA) aims at generating in-depth answers to end-user questions, providing relevant information beyond the direct answer. However, existing retrievers are typically optimized towards information that directly targets the question, missing out on such contextual information. Furthermore, there is a lack of training data for relevant context. To this end, we propose and compare different weak supervision techniques to optimize retrieval for contextual information. Experiments demonstrate improvements on the end-to-end QA performance on ASQA, a dataset for long-form question answering. Importantly, as more contextual information is retrieved, we improve the relevant page recall for LFQA by 14.7% and the groundedness of generated long-form answers by 12.5%. Finally, we show that long-form answers often anticipate likely follow-up questions, via experiments on a conversational QA dataset.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.835",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking": {
        "type": "INPROCEEDINGS",
        "key": "elaraby-etal-2024-persuasiveness",
        "author": "Elaraby, Mohamed and Litman, Diane and Li, Xiang Lorraine and Magooda, Ahmed",
        "booktitle": "EMNLP-findings2024",
        "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generating free-text rationales is among the emergent capabilities of Large Language Models (LLMs). These rationales have been found to enhance LLM performance across various NLP tasks. Recently, there has been growing interest in using these rationales to provide insights for various important downstream tasks. In this paper, we analyze generated free-text rationales in tasks with subjective answers, emphasizing the importance of rationalization in such scenarios. We focus on pairwise argument ranking, a highly subjective task with significant potential for real-world applications, such as debate assistance. We evaluate the persuasiveness of rationales generated by nine LLMs to support their subjective choices. Our findings suggest that open-source LLMs, particularly Llama2-70B-chat, are capable of providing highly persuasive rationalizations, surpassing even GPT models. Additionally, our experiments demonstrate that the persuasiveness of the generated rationales can be enhanced by guiding their persuasive elements through prompting or self-refinement techniques.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.836",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in CLIP": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-semantic",
        "author": "Kim, Eunji and Shim, Kyuhong and Chang, Simyung and Yoon, Sungroh",
        "booktitle": "EMNLP-findings2024",
        "title": "Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in CLIP",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "A text encoder within Vision-Language Models (VLMs) like CLIP plays a crucial role in translating textual input into an embedding space shared with images, thereby facilitating the interpretative analysis of vision tasks through natural language. Despite the varying significance of different textual elements within a sentence depending on the context, efforts to account for variation of importance in constructing text embeddings have been lacking. We propose a framework of Semantic Token Reweighting to build Interpretable text embeddings (SToRI), which incorporates controllability as well. SToRI refines the text encoding process in CLIP by differentially weighting semantic elements based on contextual importance, enabling finer control over emphasis responsive to data-driven insights and user preferences. The efficacy of SToRI is demonstrated through comprehensive experiments on few-shot image classification and image retrieval tailored to user preferences.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.837",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models": {
        "type": "INPROCEEDINGS",
        "key": "marjanovic-etal-2024-dynamicqa",
        "author": "Marjanovic, Sara Vera and Yu, Haeun and Atanasova, Pepa and Maistro, Maria and Lioma, Christina and Augenstein, Isabelle",
        "booktitle": "EMNLP-findings2024",
        "title": "DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Knowledge-intensive language understanding tasks require Language Models (LMs) to integrate relevant context, mitigating their inherent weaknesses, such as incomplete or outdated knowledge. However, conflicting knowledge can be present in the LM\u2019s parameters, termed intra-memory conflict, which can affect a model\u2019s propensity to accept contextual knowledge. To study the effect of intra-memory conflict on LM\u2019s ability to accept the relevant context, we utilise two knowledge conflict measures and a novel dataset containing inherently conflicting data, DYNAMICQA. This dataset includes facts with a temporal dynamic nature where facts can change over time and disputable dynamic facts, which can change depending on the viewpoint. DYNAMICQA is the first to include real-world knowledge conflicts and provide context to study the link between the different types of knowledge conflicts. We also evaluate several measures on their ability to reflect the presence of intra-memory conflict: semantic entropy and a novel coherent persuasion score. With our extensive experiments, we verify that LMs show a greater degree of intra-memory conflict with dynamic facts compared to facts that have a single truth value. Further, we reveal that facts with intra-memory conflict are harder to update with context, suggesting that retrieval-augmented generation will struggle with the most commonly adapted facts",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.838",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification": {
        "type": "INPROCEEDINGS",
        "key": "moskovskiy-etal-2024-llms",
        "author": "Moskovskiy, Daniil and Pletenev, Sergey and Panchenko, Alexander",
        "booktitle": "EMNLP-findings2024",
        "title": "LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The lack of high-quality training data remains a significant challenge in NLP. Manual annotation methods, such as crowdsourcing, are costly, require intricate task design skills, and, if used incorrectly, may result in poor data quality. From the other hand, LLMs have demonstrated proficiency in many NLP tasks, including zero-shot and few-shot data annotation. However, they often struggle with text detoxification due to alignment constraints and fail to generate the required detoxified text. This work explores the potential of modern open source LLMs to annotate parallel data for text detoxification. Using the recent technique of activation patching, we generate a pseudo-parallel detoxification dataset based on ParaDetox. The detoxification model trained on our generated data shows comparable performance to the original dataset in automatic detoxification evaluation metrics and superior quality in manual evaluation and side-by-side comparisons.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.839",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Efficient Active Learning with Adapters": {
        "type": "INPROCEEDINGS",
        "key": "galimzianova-sanochkin-2024-efficient",
        "author": "Galimzianova, Daria and Sanochkin, Leonid",
        "booktitle": "EMNLP-findings2024",
        "title": "Efficient Active Learning with Adapters",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "One of the main obstacles for deploying Active Learning (AL) in practical NLP tasks is high computational cost of modern deep learning models. This issue can be partially mitigated by applying lightweight models as an acquisition model, but it can lead to the acquisition-successor mismatch (ASM) problem. Previous works show that the ASM problem can be partially alleviated by using distilled versions of a successor models as acquisition ones. However, distilled versions of pretrained models are not always available. Also, the exact pipeline of model distillation that does not lead to the ASM problem is not clear. To address these issues, we propose to use adapters as an alternative to full fine-tuning for acquisition model training. Since adapters are lightweight, this approach reduces the training cost of the model. We provide empirical evidence that it does not cause the ASM problem and can help to deploy active learning in practical NLP tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.840",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection": {
        "type": "INPROCEEDINGS",
        "key": "koike-etal-2024-prompt",
        "author": "Koike, Ryuto and Kaneko, Masahiro and Okazaki, Naoaki",
        "booktitle": "EMNLP-findings2024",
        "title": "How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "To combat the misuse of Large Language Models (LLMs), many recent studies have presented LLM-generated-text detectors with promising performance. When users instruct LLMs to generate texts, the instruction can include different constraints depending on the user\u2019s need. However, most recent studies do not cover such diverse instruction patterns when creating datasets for LLM detection. In this paper, we reveal that even task-oriented constraints \u2014 constraints that would naturally be included in an instruction and are not related to detection-evasion \u2014 cause existing powerful detectors to have a large variance in detection performance. We focus on student essay writing as a realistic domain and manually create task-oriented constraints based on several factors for essay quality. Our experiments show that the standard deviation (SD) of current detector performance on texts generated by an instruction with such a constraint is significantly larger (up to an SD of 14.4 F1-score) than that by generating texts multiple times or paraphrasing the instruction. We also observe an overall trend where the constraints can make LLM detection more challenging than without them. Finally, our analysis indicates that the high instruction-following ability of LLMs fosters the large impact of such constraints on detection performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.841",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "\u201cSeeing the Big through the Small\u201d: Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-seeing",
        "author": "Chen, Beiduo and Wang, Xinpeng and Peng, Siyao and Litschko, Robert and Korhonen, Anna and Plank, Barbara",
        "booktitle": "EMNLP-findings2024",
        "title": "\u201cSeeing the Big through the Small\u201d: Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Human label variation (HLV) is a valuable source of information that arises when multiple human annotators provide different labels for valid reasons. In Natural Language Inference (NLI) earlier approaches to capturing HLV involve either collecting annotations from many crowd workers to represent human judgment distribution (HJD) or use expert linguists to provide detailed explanations for their chosen labels. While the former method provides denser HJD information, obtaining it is resource-intensive. In contrast, the latter offers richer textual information but it is challenging to scale up to many human judges. Besides, large language models (LLMs) are increasingly used as evaluators (\u201cLLM judges\u201d) but with mixed results, and few works aim to study HJDs. This study proposes to exploit LLMs to approximate HJDs using a small number of expert labels and explanations. Our experiments show that a few explanations significantly improve LLMs\u2019 ability to approximate HJDs with and without explicit labels, thereby providing a solution to scale up annotations for HJD. However, fine-tuning smaller soft-label aware models with the LLM-generated model judgment distributions (MJDs) presents partially inconsistent results: while similar in distance, their resulting fine-tuned models and visualized distributions differ substantially. We show the importance of complementing instance-level distance measures with a global-level shape metric and visualization to more effectively evaluate MJDs against human judgment distributions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.842",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Language Models in Dialogue: Conversational Maxims for Human-AI Interactions": {
        "type": "INPROCEEDINGS",
        "key": "miehling-etal-2024-language",
        "author": "Miehling, Erik and Nagireddy, Manish and Sattigeri, Prasanna and Daly, Elizabeth M. and Piorkowski, David and Richards, John T.",
        "booktitle": "EMNLP-findings2024",
        "title": "Language Models in Dialogue: Conversational Maxims for Human-AI Interactions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Modern language models, while sophisticated, exhibit some inherent shortcomings, particularly in conversational settings. We claim that many of the observed shortcomings can be attributed to violation of one or more conversational principles. By drawing upon extensive research from both the social science and AI communities, we propose a set of maxims \u2013 quantity, quality, relevance, manner, benevolence, and transparency \u2013 for describing effective human-AI conversation. We first justify the applicability of the first four maxims (from Grice) in the context of human-AI interactions. We then argue that two new maxims, benevolence (concerning the generation of, and engagement with, harmful content) and transparency (concerning recognition of one\u2019s knowledge boundaries, operational constraints, and intents), are necessary for addressing behavior unique to modern human-AI interactions. We evaluate the degree to which various language models are able to understand these maxims and find that models possess an internal prioritization of principles that can significantly impact accurate interpretability of the maxims.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.843",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-llm",
        "author": "Chen, Ruirui and Jiang, Weifeng and Qin, Chengwei and Rawal, Ishaan Singh and Tan, Cheston and Choi, Dongkyu and Xiong, Bo and Ai, Bo",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The important challenge of keeping knowledge in Large Language Models (LLMs) up-to-date has led to the development of various methods for incorporating new facts. However, existing methods for such knowledge editing still face difficulties with multi-hop questions that require accurate fact identification and sequential logical reasoning, particularly among numerous fact updates. To tackle these challenges, this paper introduces Graph Memory-based Editing for Large Language Models (GMeLLo), a straightforward and effective method that merges the explicit knowledge representation of Knowledge Graphs (KGs) with the linguistic flexibility of LLMs. Beyond merely leveraging LLMs for question answering, GMeLLo employs these models to convert free-form language into structured queries and fact triples, facilitating seamless interaction with KGs for rapid updates and precise multi-hop reasoning. Our results show that GMeLLo significantly surpasses current state-of-the-art (SOTA) knowledge editing methods in the multi-hop question answering benchmark, MQuAKE, especially in scenarios with extensive knowledge edits.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.844",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-self-supervised-preference",
        "author": "Li, Jian and Huang, Haojing and Zhang, Yujia and Xu, Pengfei and Chen, Xi and Song, Rui and Shi, Lida and Wang, Jingwen and Xu, Hao",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, there has been significant interest in replacing the reward model in Reinforcement Learning with Human Feedback (RLHF) methods for Large Language Models (LLMs), such as Direct Preference Optimization (DPO) and its variants. These approaches commonly use a binary cross-entropy mechanism on pairwise samples, i.e., minimizing and maximizing the loss based on preferred or dis-preferred responses, respectively. However, while this training strategy omits the reward model, it also overlooks the varying preference degrees within different responses. We hypothesize that this is a key factor hindering LLMs from sufficiently understanding human preferences. To address this problem, we propose a novel Self-supervised Preference Optimization (SPO) framework, which constructs a self-supervised preference degree loss combined with the alignment loss, thereby helping LLMs improve their ability to understand the degree of preference. Extensive experiments are conducted on two widely used datasets of different tasks. The results demonstrate that SPO can be seamlessly integrated with existing preference optimization methods and significantly boost their performance to achieve state-of-the-art performance. We also conduct detailed analyses to offer comprehensive insights into SPO, which verifies its effectiveness. The code is available at https://github.com/lijian16/SPO.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.845",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Mitigating Hallucination in Fictional Character Role-Play": {
        "type": "INPROCEEDINGS",
        "key": "sadeq-etal-2024-mitigating",
        "author": "Sadeq, Nafis and Xie, Zhouhang and Kang, Byungkyu and Lamba, Prarit and Gao, Xiang and McAuley, Julian",
        "booktitle": "EMNLP-findings2024",
        "title": "Mitigating Hallucination in Fictional Character Role-Play",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Role-playing has wide-ranging applications in customer support, embodied agents, and computational social science. The influence of parametric world knowledge of large language models (LLMs) often causes role-playing characters to act out of character and to hallucinate about things outside the scope of their knowledge. In this work, we focus on the evaluation and mitigation of hallucination in fictional character role-play. We introduce a dataset with over 2,000 characters and 72,000 interviews, including 18,000 adversarial questions. We propose RoleFact, a role-playing method that mitigates hallucination by modulating the influence of parametric knowledge using a pre-calibrated confidence threshold. Experiments show that the proposed method improves the factual precision of generated responses by 18% for adversarial questions with a 44% reduction in temporal hallucination for time-sensitive interviews. The code and the dataset are available at https://github.com/NafisSadeq/rolefact.git.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.846",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "I\u2019m sure you\u2019re a real scholar yourself: Exploring Ironic Content Generation by Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "balestrucci-etal-2024-im",
        "author": "Balestrucci, Pier Felice and Casola, Silvia and Lo, Soda Marem and Basile, Valerio and Mazzei, Alessandro",
        "booktitle": "EMNLP-findings2024",
        "title": "I\u2019m sure you\u2019re a real scholar yourself: Exploring Ironic Content Generation by Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generating ironic content is challenging: it requires a nuanced understanding of context and implicit references and balancing seriousness and playfulness. Moreover, irony is highly subjective and can depend on various factors, such as social, cultural, or generational aspects. This paper explores whether Large Language Models (LLMs) can learn to generate ironic responses to social media posts. To do so, we fine-tune two models to generate ironic and non-ironic content and deeply analyze their outputs\u2019 linguistic characteristics, their connection to the original post, and their similarity to the human-written replies. We also conduct a large-scale human evaluation of the outputs. Additionally, we investigate whether LLMs can learn a form of irony tied to a generational perspective, with mixed results.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.847",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-enhancing-temporal",
        "author": "Yang, Wanqi and Li, Yanda and Fang, Meng and Chen, Ling",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Time-Sensitive Question Answering (TSQA) demands the effective utilization of specific temporal contexts, encompassing multiple time-evolving facts, to address time-sensitive questions. This necessitates not only the parsing of temporal information within questions but also the identification and understanding of time-evolving facts to generate accurate answers. However, current large language models still have limited sensitivity to temporal information and their inadequate temporal reasoning capabilities. In this paper, we propose a novel framework that enhances temporal awareness and reasoning through Temporal Information-Aware Embedding and Granular Contrastive Reinforcement Learning. Experimental results on four TSQA datasets demonstrate that our framework significantly outperforms existing LLMs in TSQA tasks, marking a step forward in bridging the performance gap between machine and human temporal understanding and reasoning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.848",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Minimal Yet Big Impact: How AI Agent Back-channeling Enhances Conversational Engagement through Conversation Persistence and Context Richness": {
        "type": "INPROCEEDINGS",
        "key": "jang-etal-2024-minimal",
        "author": "Jang, Jin Yea and Shin, Saim and Gweon, Gahgene",
        "booktitle": "EMNLP-findings2024",
        "title": "Minimal Yet Big Impact: How AI Agent Back-channeling Enhances Conversational Engagement through Conversation Persistence and Context Richness",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The increasing use of AI agents in conversational services, such as counseling, highlights the importance of back-channeling (BC) as an active listening strategy to enhance conversational engagement. BC improves conversational engagement by providing timely acknowledgments and encouraging the speaker to talk. This study investigates the effect of BC provided by an AI agent on conversational engagement, offering insights for future AI conversational service design. We conducted an experiment with 55 participants, divided into Todak_BC and Todak_NoBC groups based on the presence or absence of the BC feature in Todak, a conversational agent. Each participant engaged in nine sessions with predetermined subjects and questions. We collected and analyzed approximately 6 hours and 30 minutes of conversation logs to evaluate conversational engagement using both quantitative (conversation persistence, including conversation duration and number of utterances) and qualitative metrics (context richness, including self-disclosure and topic diversity). The findings reveal significantly higher conversational engagement in the Todak_BC group compared to the Todak_NoBC group across all metrics (p\\textless0.05). Additionally, the impact of BC varies across sessions, suggesting that conversation characteristics such as question type and topic sensitivity can influence BC effectiveness.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.849",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Models for Propaganda Span Annotation": {
        "type": "INPROCEEDINGS",
        "key": "hasanain-etal-2024-large",
        "author": "Hasanain, Maram and Ahmad, Fatema and Alam, Firoj",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Models for Propaganda Span Annotation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The use of propagandistic techniques in online content has increased in recent years aiming to manipulate online audiences. Fine-grained propaganda detection and extraction of textual spans where propaganda techniques are used, are essential for more informed content consumption. Automatic systems targeting the task over lower resourced languages are limited, usually obstructed by lack of large scale training datasets. Our study investigates whether Large Language Models (LLMs), such as GPT-4, can effectively extract propagandistic spans. We further study the potential of employing the model to collect more cost-effective annotations. Finally, we examine the effectiveness of labels provided by GPT-4 in training smaller language models for the task. The experiments are performed over a large-scale in-house manually annotated dataset. The results suggest that providing more annotation context to GPT-4 within prompts improves its performance compared to human annotators. Moreover, when serving as an expert annotator (consolidator), the model provides labels that have higher agreement with expert annotators, and lead to specialized models that achieve state-of-the-art over an unseen Arabic testing set. Finally, our work is the first to show the potential of utilizing LLMs to develop annotated datasets for propagandistic spans detection task prompting it with annotations from human annotators with limited expertise. All scripts and annotations will be shared with the community.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.850",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles": {
        "type": "INPROCEEDINGS",
        "key": "pu-etal-2024-style",
        "author": "Pu, Xiao and He, Tianxing and Wan, Xiaojun",
        "booktitle": "EMNLP-findings2024",
        "title": "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prompt compression condenses contexts while maintaining their informativeness for different usage scenarios. It not only shortens the inference time and reduces computational costs during the usage of large language models, but also lowers expenses when using closed-source models. In a preliminary study, we discover that when instructing language models to compress prompts, different compression styles (e.g., extractive or abstractive) impact performance of compressed prompts on downstream tasks. Building on this insight, we propose Style-Compress, a lightweight framework that adapts a smaller language model to compress prompts for a larger model on a new task without additional training. Our approach iteratively generates and selects effective compressed prompts as task-specific demonstrations through style variation and in-context learning, enabling smaller models to act as efficient compressors with task-specific examples. Style-Compress outperforms two baseline compression models in four tasks: original prompt reconstruction, text summarization, multi-hop QA, and CoT reasoning. In addition, with only 10 samples and 100 queries for adaptation, prompts compressed by Style-Compress achieve performance on par with or better than original prompts at a compression ratio of 0.25 or 0.5.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.851",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "POSIX: A Prompt Sensitivity Index For Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chatterjee-etal-2024-posix",
        "author": "Chatterjee, Anwoy and Renduchintala, H. S. V. N. S. Kowndinya and Bhatia, Sumit and Chakraborty, Tanmoy",
        "booktitle": "EMNLP-findings2024",
        "title": "POSIX: A Prompt Sensitivity Index For Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite their remarkable capabilities, Large Language Models (LLMs) are found to be surprisingly sensitive to minor variations in prompts, often generating significantly divergent outputs in response to minor variations in the prompts, such as spelling errors, alteration of wording or the prompt template. However, while assessing the quality of an LLM, the focus often tends to be solely on its performance on downstream tasks, while very little to no attention is paid to prompt sensitivity. To fill this gap, we propose POSIX \u2013 a novel PrOmpt Sensitivity IndeX as a reliable measure of prompt sensitivity, thereby offering a more comprehensive evaluation of LLM performance. The key idea behind POSIX is to capture the relative change in loglikelihood of a given response upon replacing the corresponding prompt with a different intent-preserving prompt. We provide thorough empirical evidence demonstrating the efficacy of POSIX in capturing prompt sensitivity and subsequently use it to measure and thereby compare prompt sensitivity of various open source LLMs. We find that merely increasing the parameter count or instruction tuning does not necessarily reduce prompt sensitivity whereas adding some few-shot exemplars, even just one, almost always leads to significant decrease in prompt sensitivity. We also find that alterations to prompt template lead to the highest sensitivity in the case of MCQ type tasks, whereas paraphrasing results in the highest sensitivity in open-ended generation tasks. The code for reproducing our results is open-sourced at https://github.com/kowndinya-renduchintala/POSIX.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.852",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data": {
        "type": "INPROCEEDINGS",
        "key": "ran-etal-2024-capturing",
        "author": "Ran, Yiting and Wang, Xintao and Xu, Rui and Yuan, Xinfeng and Liang, Jiaqing and Xiao, Yanghua and Yang, Deqing",
        "booktitle": "EMNLP-findings2024",
        "title": "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Role-playing agents (RPA) have been a popular application area for large language models (LLMs), attracting significant interest from both industry and academia. While existing RPAs well portray the characters\u2019 knowledge and tones, they face challenges in capturing their minds, especially for small role-playing language models (RPLMs). In this paper, we propose to enhance RPLMs via personality-indicative data. Specifically, we leverage questions from psychological scales and distill advanced RPAs to generate dialogues that grasp the minds of characters. Experimental results validate that RPLMs trained with our dataset exhibit advanced role-playing capabilities for both general and personality-related evaluations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.853",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Local and Global Decoding in Text Generation": {
        "type": "INPROCEEDINGS",
        "key": "gareev-etal-2024-local",
        "author": "Gareev, Daniel and Hofmann, Thomas and Krishnasamy, Ezhilmathi and Pimentel, Tiago",
        "booktitle": "EMNLP-findings2024",
        "title": "Local and Global Decoding in Text Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Text generation, a component in applications such as dialogue systems, relies heavily on decoding algorithms that sample strings from a language model distribution. Traditional methods like top-k and top-\u03c0 decoding locally normalise the model\u2019s output, which can significantly distort the original distribution. In this paper, we investigate the effects of such distortions by introducing globally-normalised versions of these decoding methods. Further, we propose an independent Metropolis-Hastings (IMH) algorithm to approximate sampling from these globally-normalised distributions without explicitly computing them. Our empirical analyses compare the performance of local and global decoding across two algorithms (top-k and top-\u03c0) with various hyperparameters, using the Pythia language models. Results show that in most configuration, global decoding performs worse than the local decoding versions of the same algorithms, despite preserving the distribution\u2019s integrity. Our results thus suggest that distortion might be an important feature of local decoding algorithms.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.854",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LEGOBench: Scientific Leaderboard Generation Benchmark": {
        "type": "INPROCEEDINGS",
        "key": "singh-etal-2024-legobench",
        "author": "Singh, Shruti and Alam, Shoaib and Malwat, Husain and Singh, Mayank",
        "booktitle": "EMNLP-findings2024",
        "title": "LEGOBench: Scientific Leaderboard Generation Benchmark",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The ever-increasing volume of paper submissions makes it difficult to stay informed about the latest state-of-the-art research. To address this challenge, we introduce LEGOBench, a benchmark for evaluating systems that generate scientific leaderboards. LEGOBench is curated from 22 years of preprint submission data on arXiv and more than 11k machine learning leaderboards on the PapersWithCode portal. We present a language model-based and four graph-based leaderboard generation task configuration. We evaluate popular encoder-only scientific language models as well as decoder-only large language models across these task configurations. State-of-the-art models showcase significant performance gaps in automatic leaderboard generation on LEGOBench. The code is available on GitHub and the dataset is hosted on OSF.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.855",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "H-LegalKI: A Hierarchical Legal Knowledge Integration Framework for Legal Community Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "jiang-etal-2024-h",
        "author": "Jiang, Yue and Guan, Ziyu and Zhao, Jie and Zhao, Wei and Yang, Jiaqi",
        "booktitle": "EMNLP-findings2024",
        "title": "H-LegalKI: A Hierarchical Legal Knowledge Integration Framework for Legal Community Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Legal question answering (LQA) aims to bridge the gap between the limited availability of legal professionals and the high demand for legal assistance. Traditional LQA approaches typically either select the optimal answers from an answer set or extract answers from law texts. However, they often struggle to provide relevant answers to complex, real-world questions due to the rigidity of predetermined answers. Although recent advancements in legal large language models have shown some potential in enhancing answer relevance, they fail to address the multiple user-specific circumstances, i.e., factual details in questions. To address these issues, we (1) construct the first publicly available legal community question-answering (LegalCQA) dataset; and (2) propose a Hierarchical Legal Knowledge Integration (H-LegalKI) framework. LegalCQA is collected from two widely used legal forums for developing user-centered LQA models. For H-LegalKI, we design a legal knowledge retriever that gathers comprehensive legal knowledge based on both entire questions and individual sentences. And an answer generation model is designed to understand question- and sentence-level factual details and integrate corresponding legal knowledge in a hierarchical way. Additionally, we design a de-redundancy module to remove redundant legal knowledge. Experiments on LegalCQA demonstrate the superiority of our framework over competitive baselines.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.856",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Identifying Factual Inconsistencies in Summaries: Grounding LLM Inference via Task Taxonomy": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-identifying",
        "author": "Xu, Liyan and Su, Zhenlin and Yu, Mo and Xu, Jin and Choi, Jinho D. and Zhou, Jie and Liu, Fei",
        "booktitle": "EMNLP-findings2024",
        "title": "Identifying Factual Inconsistencies in Summaries: Grounding LLM Inference via Task Taxonomy",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Factual inconsistencies pose a significant hurdle for the faithful summarization by generative models. While a major direction to enhance inconsistency detection is to derive stronger Natural Language Inference (NLI) models, we propose an orthogonal aspect that underscores the importance of incorporating task-specific taxonomy into the inference. To this end, we consolidate key error types of inconsistent facts in summaries, and incorporate them to facilitate both the zero-shot and supervised paradigms of LLMs. Extensive experiments on ten datasets of five distinct domains suggest that, zero-shot LLM inference could benefit from the explicit solution space depicted by the error type taxonomy, and achieves state-of-the-art performance overall, surpassing specialized non-LLM baselines, as well as recent LLM baselines. We further distill models that fuse the taxonomy into parameters through our designed prompt completions and supervised training strategies, efficiently substituting state-of-the-art zero-shot inference with much larger LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.857",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning": {
        "type": "INPROCEEDINGS",
        "key": "feng-etal-2024-long",
        "author": "Feng, Aosong and Ying, Rex and Tassiulas, Leandros",
        "booktitle": "EMNLP-findings2024",
        "title": "Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As the demand for processing extended textual data grows, the ability to handle long-range dependencies and maintain computational efficiency is more critical than ever. One of the key issues for long-sequence modeling using attention-based model is the mismatch between the limited-range modeling power of full attention and the long-range token dependency in the input sequence. In this work, we propose to scale up the attention receptive field by tensorizing long input sequences into compact tensor representations followed by attention on each transformed dimension. The resulting Tensorized Attention can be adopted as efficient transformer backbones to extend input context length with improved memory and time efficiency. We show that the proposed attention tensorization encodes token dependencies as a multi-hop attention process, and is equivalent to Kronecker decomposition of full attention. Extensive experiments show that tensorized attention can be used to adapt pretrained LLMs with improved efficiency. Notably, using customized Triton kernels, tensorization enables Llama-8B training under 32,768 context length and can steadily extrapolate to 128k length during inference with 11 times speedup (compared to full attention with FlashAttention-2).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.858",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla": {
        "type": "INPROCEEDINGS",
        "key": "fahim-etal-2024-banglatlit",
        "author": "Fahim, Md and Shifat, Fariha Tanjim and Haider, Fabiha and Barua, Deeparghya Dutta and Sourove, MD Sakib Ul Rahman and Ishmam, Md Farhan and Bhuiyan, Md Farhad Alam",
        "booktitle": "EMNLP-findings2024",
        "title": "BanglaTLit: A Benchmark Dataset for Back-Transliteration of Romanized Bangla",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Low-resource languages like Bangla are severely limited by the lack of datasets. Romanized Bangla texts are ubiquitous on the internet, offering a rich source of data for Bangla NLP tasks and extending the available data sources. However, due to the informal nature of romanized text, they often lack the structure and consistency needed to provide insights. We address these challenges by proposing: (1) BanglaTLit, the large-scale Bangla transliteration dataset consisting of 42.7k samples, (2) BanglaTLit-PT, a pre-training corpus on romanized Bangla with 245.7k samples, (3) encoders further-pretrained on BanglaTLit-PT achieving state-of-the-art performance in several romanized Bangla classification tasks, and (4) multiple back-transliteration baseline methods, including a novel encoder-decoder architecture using further pre-trained encoders. Our results show the potential of automated Bangla back-transliteration in utilizing the untapped sources of romanized Bangla to enrich this language. The code and datasets are publicly available: https://github.com/farhanishmam/BanglaTLit.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.859",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Finding the Optimal Byte-Pair Encoding Merge Operations for Neural Machine Translation in a Low-Resource Setting": {
        "type": "INPROCEEDINGS",
        "key": "adlaon-marcos-2024-finding",
        "author": "Adlaon, Kristine Mae M. and Marcos, Nelson",
        "booktitle": "EMNLP-findings2024",
        "title": "Finding the Optimal Byte-Pair Encoding Merge Operations for Neural Machine Translation in a Low-Resource Setting",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper investigates the impact of different Byte Pair Encoding (BPE) configurations, specifically, merge operations on neural machine translation (NMT) performance for the Filipino-Cebuano language pair across various text domains. Results demonstrate that smaller BPE configurations, notably 2k, 5k, and 8k consistently yield higher BLEU scores, indicating improved translation quality through finer tokenization granularity. Conversely, larger BPE configurations and the absence of BPE result in lower BLEU scores, suggesting a decline in translation quality due to coarser tokenization. Additionally, these findings help us understand how the size of the model and how finely we break down words affect the quality of translations. This knowledge will be useful for improving translation systems, especially for languages that don\u2019t have many parallel texts available for training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.860",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs": {
        "type": "INPROCEEDINGS",
        "key": "manzoor-etal-2024-machines",
        "author": "Manzoor, Muhammad Arslan and Wang, Yuxia and Wang, Minghan and Nakov, Preslav",
        "booktitle": "EMNLP-findings2024",
        "title": "Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Empathy plays a pivotal role in fostering prosocial behavior, often triggered by the sharing of personal experiences through narratives. However, modeling empathy using NLP approaches remains challenging due to its deep interconnection with human interaction dynamics. Previous approaches, which involve fine-tuning language models (LMs) on human-annotated empathic datasets, have had limited success. In our pursuit of improving empathy understanding in LMs, we propose several strategies, including contrastive learning with masked LMs and supervised fine-tuning with large language models. While these methods show improvements over previous methods, the overall results remain unsatisfactory. To better understand this trend, we performed an analysis which reveals a low agreement among annotators. This lack of consensus hinders training and highlights the subjective nature of the task. We also explore the cultural impact on annotations. To study this, we meticulously collected story pairs in Urdu language and find that subjectivity in interpreting empathy among annotators appears to be independent of cultural background. Our systematic exploration of LMs\u2019 understanding of empathy reveals substantial opportunities for further investigation in both task formulation and modeling.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.861",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "EU DisinfoTest: a Benchmark for Evaluating Language Models\u2019 Ability to Detect Disinformation Narratives": {
        "type": "INPROCEEDINGS",
        "key": "sosnowski-etal-2024-eu",
        "author": "Sosnowski, Witold and Modzelewski, Arkadiusz and Skorupska, Kinga and Otterbacher, Jahna and Wierzbicki, Adam",
        "booktitle": "EMNLP-findings2024",
        "title": "EU DisinfoTest: a Benchmark for Evaluating Language Models\u2019 Ability to Detect Disinformation Narratives",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As narratives shape public opinion and influence societal actions, distinguishing between truthful and misleading narratives has become a significant challenge. To address this, we introduce the EU DisinfoTest, a novel benchmark designed to evaluate the efficacy of Language Models in identifying disinformation narratives. Developed through a Human-in-the-Loop methodology and grounded in research from EU DisinfoLab, the EU DisinfoTest comprises more than 1,300 narratives. Our benchmark includes persuasive elements under Logos, Pathos, and Ethos rhetorical dimensions. We assessed state-of-the-art LLMs, including the newly released GPT-4o, on their capability to perform zero-shot classification of disinformation narratives versus credible narratives. Our findings reveal that LLMs tend to regard narratives with authoritative appeals as trustworthy, while those with emotional appeals are frequently incorrectly classified as disinformative. These findings highlight the challenges LLMs face in nuanced content interpretation and suggest the need for tailored adjustments in LLM training to better handle diverse narrative structures.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.862",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression": {
        "type": "INPROCEEDINGS",
        "key": "choi-etal-2024-reading",
        "author": "Choi, Eunseong and Lee, Sunkyung and Choi, Minjin and Park, Jun and Lee, Jongwuk",
        "booktitle": "EMNLP-findings2024",
        "title": "From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have achieved significant performance gains using advanced prompting techniques over various tasks. However, the increasing length of prompts leads to high computational costs and often obscures crucial information. Prompt compression has been proposed to alleviate these issues, but it faces challenges in (i) capturing the global context and (ii) training the compressor effectively. To tackle these challenges, we introduce a novel prompt compression method, namely Reading To Compressing (R2C), utilizing the Fusion-in-Decoder (FiD) architecture to identify the important information in the prompt. Specifically, the cross-attention scores of the FiD are used to discern essential chunks and sentences from the prompt. R2C effectively captures the global context without compromising semantic consistency while detouring the necessity of pseudo-labels for training the compressor. Empirical results show that R2C retains key contexts, enhancing the LLM performance by 6% in out-of-domain evaluations while reducing the prompt length by 80%.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.864",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Knowledge-Guided Dynamic Modality Attention Fusion Framework for Multimodal Sentiment Analysis": {
        "type": "INPROCEEDINGS",
        "key": "feng-etal-2024-knowledge",
        "author": "Feng, Xinyu and Lin, Yuming and He, Lihua and Li, You and Chang, Liang and Zhou, Ya",
        "booktitle": "EMNLP-findings2024",
        "title": "Knowledge-Guided Dynamic Modality Attention Fusion Framework for Multimodal Sentiment Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multimodal Sentiment Analysis (MSA) utilizes multimodal data to infer the users\u2019 sentiment. Previous methods focus on equally treating the contribution of each modality or statically using text as the dominant modality to conduct interaction, which neglects the situation where each modality may become dominant. In this paper, we propose a Knowledge-Guided Dynamic Modality Attention Fusion Framework (KuDA) for multimodal sentiment analysis. KuDA uses sentiment knowledge to guide the model dynamically selecting the dominant modality and adjusting the contributions of each modality. In addition, with the obtained multimodal representation, the model can further highlight the contribution of dominant modality through the correlation evaluation loss. Extensive experiments on four MSA benchmark datasets indicate that KuDA achieves state-of-the-art performance and is able to adapt to different scenarios of dominant modality.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.865",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation": {
        "type": "INPROCEEDINGS",
        "key": "yin-etal-2024-lexmatcher",
        "author": "Yin, Yongjing and Zeng, Jiali and Li, Yafu and Meng, Fandong and Zhang, Yue",
        "booktitle": "EMNLP-findings2024",
        "title": "LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The fine-tuning of open-source large language models (LLMs) for machine translation has recently received considerable attention, marking a shift towards data-centric research from traditional neural machine translation. However, the area of data collection for instruction fine-tuning in machine translation remains relatively underexplored. In this paper, we present LexMatcher, a simple yet effective method for data curation,the design of which is driven by the coverage of senses found in bilingual dictionaries. The construction process comprises data retrieval from an existing corpus and data augmentation that supplements the infrequent senses of polysemous words. Utilizing LLaMA2 as our base model, our method outperforms the established baselines on the WMT2022 test sets and also exhibits remarkable performance in tasks related to word sense disambiguation and specialized terminology translation. Our method is also applicable to other pre-trained models, and complements the method of continual pre-training using monolingual data, demonstrating the effectiveness of LexMatcher in enhancing LLM-based machine translation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.866",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SARCAT: Generative Span-Act Guided Response Generation using Copy-enhanced Target Augmentation": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-sarcat",
        "author": "Lee, Jeong-Doo and Choi, Hyeongjun and Hong, Beomseok and Han, Youngsub and Jeon, Byoung-Ki and Na, Seung-Hoon",
        "booktitle": "EMNLP-findings2024",
        "title": "SARCAT: Generative Span-Act Guided Response Generation using Copy-enhanced Target Augmentation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we present a novel extension to improve the document grounded response generation, by proposing the Generative Span Act Guided Response Generation using Copy enhanced Target Augmentation (SARCAT) that consists of two major components as follows: 1) Copy-enhanced target-side input augmentation is an extended data augmentation to deal with the exposure bias problem by additionally incorporating the copy mechanism on top of the target-side augmentation (Xie et al., 2021). 2) Span-act guided response generation, which first predicts grounding spans and dialogue acts before generating a response. Experiment results on validation set in MultiDoc2Dial show that the proposed SARSAT leads to improvement over strong baselines on both seen and unseen settings and achieves the start-of the-art performance, even with the base reader using the pretrained T5-base model.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.867",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Does Context Help Mitigate Gender Bias in Neural Machine Translation?": {
        "type": "INPROCEEDINGS",
        "key": "gete-etchegoyhen-2024-context",
        "author": "Gete, Harritxu and Etchegoyhen, Thierry",
        "booktitle": "EMNLP-findings2024",
        "title": "Does Context Help Mitigate Gender Bias in Neural Machine Translation?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Neural Machine Translation models tend to perpetuate gender bias present in their training data distribution. Context-aware models have been previously suggested as a means to mitigate this type of bias. In this work, we examine this claim by analysing in detail the translation of stereotypical professions in English to German, and translation with non-informative context in Basque to Spanish. Our results show that, although context-aware models can significantly enhance translation accuracy for feminine terms, they can still maintain or even amplify gender bias. These results highlight the need for more fine-grained approaches to bias mitigation in Neural Machine Translation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.868",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Critical Look at Meta-evaluating Summarisation Evaluation Metrics": {
        "type": "INPROCEEDINGS",
        "key": "dai-etal-2024-critical",
        "author": "Dai, Xiang and Karimi, Sarvnaz and Fang, Biaoyan",
        "booktitle": "EMNLP-findings2024",
        "title": "A Critical Look at Meta-evaluating Summarisation Evaluation Metrics",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Effective summarisation evaluation metrics enable researchers and practitioners to compare different summarisation systems efficiently. Estimating the effectiveness of an automatic evaluation metric, termed meta-evaluation, is a critically important research question. In this position paper, we review recent meta-evaluation practices for summarisation evaluation metrics and find that (1) evaluation metrics are primarily meta-evaluated on datasets consisting of examples from news summarisation datasets, and (2) there has been a noticeable shift in research focus towards evaluating the faithfulness of generated summaries. We argue that the time is ripe to build more diverse benchmarks that enable the development of more robust evaluation metrics and analyze the generalization ability of existing evaluation metrics. In addition, we call for research focusing on user-centric quality dimensions that consider the generated summary\u2019s communicative goal and the role of summarisation in the workflow.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.869",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study": {
        "type": "INPROCEEDINGS",
        "key": "nguyen-etal-2024-llms",
        "author": "Nguyen, Van Bach and Youssef, Paul and Seifert, Christin and Schl\u00f6tterer, J\u00f6rg",
        "booktitle": "EMNLP-findings2024",
        "title": "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As NLP models become more complex, understanding their decisions becomes more crucial. Counterfactuals (CFs), where minimal changes to inputs flip a model\u2019s prediction, offer a way to explain these models. While Large Language Models (LLMs) have shown remarkable performance in NLP tasks, their efficacy in generating high-quality CFs remains uncertain. This work fills this gap by investigating how well LLMs generate CFs for three tasks. We conduct a comprehensive comparison of several common LLMs, and evaluate their CFs, assessing both intrinsic metrics, and the impact of these CFs on data augmentation. Moreover, we analyze differences between human and LLM-generated CFs, providing insights for future research directions. Our results show that LLMs generate fluent CFs, but struggle to keep the induced changes minimal. Generating CFs for Sentiment Analysis (SA) is less challenging than NLI and Hate Speech (HS) where LLMs show weaknesses in generating CFs that flip the original label. This also reflects on the data augmentation performance, where we observe a large gap between augmenting with human and LLM CFs. Furthermore, we evaluate LLMs\u2019 ability to assess CFs in a mislabelled data setting, and show that they have a strong bias towards agreeing with the provided labels. GPT4 is more robust against this bias, but it shows strong preference to its own generations. Our analysis suggests that safety training is causing GPT4 to prefer its generations, since these generations do not contain harmful content. Our findings reveal several limitations and point to potential future work directions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.870",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization": {
        "type": "INPROCEEDINGS",
        "key": "zhan-etal-2024-unlocking",
        "author": "Zhan, Heshen and Chen, Congliang and Ding, Tian and Li, Ziniu and Sun, Ruoyu",
        "booktitle": "EMNLP-findings2024",
        "title": "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prompt optimization emerges as an important technique for adapting Large Language Models (LLMs) to specific tasks. Unfortunately, LLM proprietors often limit access to models\u2019 internal weights, confining users to inference API services. This restriction poses a significant challenge for prompt optimization, as conventional optimization-based algorithms rely heavily on gradient information, which is unavailable via inference APIs. Addressing this challenge, this paper presents the Zeroth-Order Tuning (ZOT) approach, which enables efficient prompt tuning solely via inference APIs. ZOT adopts the zeroth-order optimization framework, utilizing finite differences to approximate gradient information. We further incorporate ZOT with gradient clipping and momentum techniques to enhance the tuning effectiveness. Experimental results show that ZOT outperforms existing black-box prompt tuning methods in terms of both task-specific performance and convergence speed. Furthermore, we provide a theoretical explanation for the unexpectedly strong performance of zeroth-order methods on LLM prompt tuning. By introducing the concept of effective dimension, we establish a strong connection between the inherently low effective dimension of prompt spaces and the superior convergence speed of zeroth-order methods. Our code is available at https://github.com/ZhanHeshen/ZOT.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.871",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses": {
        "type": "INPROCEEDINGS",
        "key": "su-etal-2024-unveiling",
        "author": "Su, Hung-Ting and Hsu, Ya-Ching and Lin, Xudong and Shi, Xiang-Qian and Niu, Yulei and Hsu, Han-Yuan and Lee, Hung-yi and Hsu, Winston H.",
        "booktitle": "EMNLP-findings2024",
        "title": "Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) equipped with chain-of-thoughts (CoT) prompting have shown significant multi-step reasoning capabilities in factual content like mathematics, commonsense, and logic. However, their performance in narrative reasoning, which demands greater abstraction capabilities, remains unexplored. This study utilizes tropes in movie synopses to assess the abstract reasoning abilities of state-of-the-art LLMs and uncovers their low performance. We introduce a trope-wise querying approach to address these challenges and boost the F1 score by 11.8 points. Moreover, while prior studies suggest that CoT enhances multi-step reasoning, this study shows CoT can cause hallucinations in narrative content, reducing GPT-4\u2019s performance. We also introduce an Adversarial Injection method to embed trope-related text tokens into movie synopses without explicit tropes, revealing CoT\u2019s heightened sensitivity to such injections. Our comprehensive analysis provides insights for future research directions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.872",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-unveiling-flaws",
        "author": "Chen, Jie and Zhang, Yupeng and Wang, Bingning and Zhao, Xin and Wen, Ji-Rong and Chen, Weipeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Synthetic data has been proposed as a solution to address the issue of high-quality data scarcity in the training of large language models (LLMs). Studies have shown that synthetic data can effectively improve the performance of LLMs on downstream benchmarks. However, despite its potential benefits, our analysis suggests that there may be inherent flaws in synthetic data. The uniform format of synthetic data can lead to pattern overfitting and cause significant shifts in the output distribution, thereby reducing the model\u2019s instruction-following capabilities. Our work delves into these specific flaws associated with question-answer (Q-A) pairs, a prevalent type of synthetic data, and presents a method based on unlearning techniques to mitigate these flaws. The empirical results demonstrate the effectiveness of our approach, which can reverse the instruction-following issues caused by pattern overfitting without compromising performance on benchmarks at relatively low cost. Our work has yielded key insights into the effective use of synthetic data, aiming to promote more robust and efficient LLM training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.873",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text": {
        "type": "INPROCEEDINGS",
        "key": "lee-etal-2024-ced",
        "author": "Lee, Hakyung and Park, Keon-Hee and Byun, Hoyoon and Yeom, Jeyoon and Kim, Jihee and Park, Gyeong-Moon and Song, Kyungwoo",
        "booktitle": "EMNLP-findings2024",
        "title": "CED: Comparing Embedding Differences for Detecting Out-of-Distribution and Hallucinated Text",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety and robustness of models deployed in real-world scenarios. While most studies on OOD detection focus on fine-tuned models trained on in-distribution (ID) data, detecting OOD in pre-trained models is also important due to computational limitations and the widespread use of open-source pre-trained models. However, in the same domain shift setting, the OOD detection performance of pre-trained models is insufficient because both ID and OOD samples originate from the same domain, leading to a high overlap in their embeddings. To address this issue, we introduce a new method called CED, a training-free OOD detection technique designed to enhance the distinction between ID and OOD datasets. We theoretically validate that specific auxiliary and oracle samples that satisfy certain conditions improve this distinction. Motivated by our theoretical analysis, CED enhances the differentiation by utilizing these specially designed auxiliary and oracle samples. As a result, CED significantly improves the ability of pre-trained models to distinguish between ID and OOD samples in text classification and hallucination detection tasks. Furthermore, we verify that CED is a plug-and-play method compatible with various backbone networks, such as RoBERTa, Llama, and OpenAI Embedding.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.874",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-chambi",
        "author": "Zhang, Qin and Cai, Sihan and Zhao, Jiaxu and Pechenizkiy, Mykola and Fang, Meng",
        "booktitle": "EMNLP-findings2024",
        "title": "CHAmbi: A New Benchmark on Chinese Ambiguity Challenges for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Ambiguity is an inherent feature of language, whose management is crucial for effective communication and collaboration. This is particularly true for Chinese, a language with extensive lexical-morphemic ambiguity. Despite the wide use of large language models (LLMs) in numerous domains and their growing proficiency in Chinese, there is a notable lack of datasets to thoroughly evaluate LLMs\u2019 ability to handle ambiguity in Chinese. To bridge this gap, we introduce the CHAmbi dataset, a specialized Chinese multi-label disambiguation dataset formatted in Natural Language Inference. It comprises 4,991 pairs of premises and hypotheses, including 824 examples featuring a wide range of ambiguities. In addition to the dataset, we develop a series of tests and conduct an extensive evaluation of pre-trained LLMs\u2019 proficiency in identifying and resolving ambiguity in the Chinese language. Our findings reveal that GPT-4 consistently delivers commendable performance across various evaluative measures, albeit with limitations in robustness. The performances of other LLMs, however, demonstrate variability in handling ambiguity-related tasks, underscoring the complexity of such tasks in the context of Chinese. The overall results highlight the challenge of ambiguity handling for current LLMs and underscore the imperative need for further enhancement in LLM capabilities for effective ambiguity resolution in the Chinese language.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.875",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Analyzing Context Contributions in LLM-based Machine Translation": {
        "type": "INPROCEEDINGS",
        "key": "zaranis-etal-2024-analyzing",
        "author": "Zaranis, Emmanouil and Guerreiro, Nuno M. and Martins, Andre",
        "booktitle": "EMNLP-findings2024",
        "title": "Analyzing Context Contributions in LLM-based Machine Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have achieved state-of-the-art performance in machine translation (MT) and demonstrated the ability to leverage in-context learning through few-shot examples. However, the mechanisms by which LLMs use different parts of the input context remain largely unexplored. In this work, we provide a comprehensive analysis of context utilization in MT, studying how LLMs use various context parts, such as few-shot examples and the source text, when generating translations. We highlight several key findings: (1) the source part of few-shot examples appears to contribute more than its corresponding targets, irrespective of translation direction; (2) finetuning LLMs with parallel data alters the contribution patterns of different context parts; and (3) there is a positional bias where earlier few-shot examples have higher contributions to the translated sequence. Finally, we demonstrate that inspecting anomalous context contributions can potentially uncover pathological translations, such as hallucinations. Our findings shed light on the internal workings of LLM-based MT which go beyond those known for standard encoder-decoder MT models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.876",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ARTS: Assessing Readability &amp; Text Simplicity": {
        "type": "INPROCEEDINGS",
        "key": "engelmann-etal-2024-arts",
        "author": "Engelmann, Bj\u00f6rn and Kreutz, Christin Katharina and Haak, Fabian and Schaer, Philipp",
        "booktitle": "EMNLP-findings2024",
        "title": "ARTS: Assessing Readability &amp; Text Simplicity",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automatic text simplification aims to reduce a text\u2019s complexity. Its evaluation should quantify how easy it is to understand a text. Datasets with simplicity labels on text level are a prerequisite for developing such evaluation approaches. However, current publicly available datasets do not align with this, as they mainly treat text simplification as a relational concept (\u201cHow much simpler has this text gotten compared to the original version?\u201d) or assign discrete readability levels.This work alleviates the problem of Assessing Readability &amp; Text Simplicity. We present ARTS, a method for language-independent construction of datasets for simplicity assessment. We propose using pairwise comparisons of texts in conjunction with an Elo algorithm to produce a simplicity ranking and simplicity scores. Additionally, we provide a high-quality human-labeled and three GPT-labeled simplicity datasets. Our results show a high correlation between human and LLM-based labels, allowing for an effective and cost-efficient way to construct large synthetic datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.877",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "AXCEL: Automated eXplainable Consistency Evaluation using LLMs": {
        "type": "INPROCEEDINGS",
        "key": "sreekar-etal-2024-axcel",
        "author": "Sreekar, P. Aditya and Verma, Sahil and Chopra, Suransh and Persad, Abhishek and Ghazarian, Sarik and Sadagopan, Narayanan",
        "booktitle": "EMNLP-findings2024",
        "title": "AXCEL: Automated eXplainable Consistency Evaluation using LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are widely used in both industry and academia for various tasks, yet evaluating the consistency of generated text responses continues to be a challenge. Traditional metrics like ROUGE and BLEU show a weak correlation with human judgment. More sophisticated metrics using Natural Language Inference (NLI) have shown improved correlations but are complex to implement, require domain-specific training due to poor cross-domain generalization, and lack explainability. More recently, prompt-based metrics using LLMs as evaluators have emerged; while they are easier to implement, they still lack explainability and depend on task-specific prompts, which limits their generalizability. This work introduces Automated eXplainable Consistency Evaluation using LLMs (AXCEL), a prompt-based consistency metric which offers explanations for the consistency scores by providing detailed reasoning and pinpointing inconsistent text spans. AXCEL is also a generalizable metric which can be adopted to multiple tasks without changing the prompt. AXCEL outperforms both non-prompt and prompt-based state-of-the-art (SOTA) metrics in detecting inconsistencies across summarization by 8.7%, free text generation by 6.2%, and data-to-text conversion tasks by 29.4%. We also evaluate the influence of underlying LLMs on prompt based metric performance and recalibrate the SOTA prompt-based metrics with the latest LLMs for fair comparison. Further, we show that AXCEL demonstrates strong performance using open source LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.878",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-prospector",
        "author": "Kim, Byoungjip and Jang, Youngsoo and Logeswaran, Lajanugen and Kim, Geon-Hyeong and Kim, Yu Jin and Lee, Honglak and Lee, Moontae",
        "booktitle": "EMNLP-findings2024",
        "title": "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have shown the ability to solve complex decision-making tasks beyond natural language processing tasks. LLM agents based on few-shot in-context learning (ICL) achieve surprisingly high performance without training. Despite their simplicity and generalizability, ICL-based agents are limited in their ability to incorporate feedback from an environment. In this paper, we introduce Prospector, an LLM agent that consists of two complementary LLMs, an Actor and a Critic. To elicit better instruction-aligned actions from the LLM agent, we propose AskAct prompting that performs an additional self-asking step such as goal and progress checking before generating an action. Furthermore, to implicitly incorporate the environment feedback, we propose Trajectory Ranking that orders generated trajectories by predicting the expected total reward. Prospector encourages the LLM Actor to generate diverse (creative) trajectories, and harnesses the LLM Critic to select the most rewarding trajectory. On representative decision-making benchmark environments such as ALFWorld and WebShop, we empirically demonstrate that Prospector can considerably increase the success rate of given tasks, while outperforming recent advancements such as ReAct and Reflexion.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.879",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Characterizing Text Datasets with Psycholinguistic Features": {
        "type": "INPROCEEDINGS",
        "key": "monteiro-etal-2024-characterizing",
        "author": "Monteiro, Marcio and Karakkaparambil James, Charu and Kloft, Marius and Fellenz, Sophie",
        "booktitle": "EMNLP-findings2024",
        "title": "Characterizing Text Datasets with Psycholinguistic Features",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Fine-tuning pretrained language models on task-specific data is a common practice in Natural Language Processing (NLP) applications. However, the number of pretrained models available to choose from can be very large, and it remains unclear how to select the optimal model without spending considerable amounts of computational resources, especially for the text domain. To address this problem, we introduce PsyMatrix, a novel framework designed to efficiently characterize text datasets. PsyMatrix evaluates multiple dimensions of text and discourse, producing interpretable, low-dimensional embeddings. Our framework has been tested using a meta-dataset repository that includes the performance of 24 pretrained large language models fine-tuned across 146 classification datasets. Using the proposed embeddings, we successfully developed a meta-learning system capable of recommending the most effective pretrained models (optimal and near-optimal) for fine-tuning on new datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.880",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Talking the Talk Does Not Entail Walking the Walk: On the Limits of Large Language Models in Lexical Entailment Recognition": {
        "type": "INPROCEEDINGS",
        "key": "greco-etal-2024-talking",
        "author": "Greco, Candida Maria and La Cava, Lucio and Tagarelli, Andrea",
        "booktitle": "EMNLP-findings2024",
        "title": "Talking the Talk Does Not Entail Walking the Walk: On the Limits of Large Language Models in Lexical Entailment Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Verbs form the backbone of language, providing the structure and meaning to sentences. Yet, their intricate semantic nuances pose a longstanding challenge. Understanding verb relations through the concept of lexical entailment is crucial for comprehending sentence meanings and grasping verb dynamics. This work investigates the capabilities of eight Large Language Models in recognizing lexical entailment relations among verbs through differently devised prompting strategies and zero-/few-shot settings over verb pairs from two lexical databases, namely WordNet and HyperLex. Our findings unveil that the models can tackle the lexical entailment recognition task with moderately good performance, although at varying degree of effectiveness and under different conditions. Also, utilizing few-shot prompting can enhance the models\u2019 performance. However, perfectly solving the task arises as an unmet challenge for all examined LLMs, which raises an emergence for further research developments on this topic.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.881",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "paul-etal-2024-making",
        "author": "Paul, Debjit and West, Robert and Bosselut, Antoine and Faltings, Boi",
        "booktitle": "EMNLP-findings2024",
        "title": "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) have been shown to perform better when asked to reason step-by-step before answering a question. However, it is unclear to what degree the model\u2019s final answer is faithful to the stated reasoning steps. In this paper, we perform a causal mediation analysis on twelve LLMs to examine how intermediate reasoning steps generated by the LLM influence the final outcome and find that LLMs do not reliably use their intermediate reasoning steps when generating an answer. To address this issue, we introduce FRODO, a framework to tailor small-sized LMs to generate correct reasoning steps and robustly reason over these steps. FRODO consists of an inference module that learns to generate correct reasoning steps using an implicit causal reward function and a reasoning module that learns to faithfully reason over these intermediate inferences using a counterfactual and causal preference objective. Our experiments show that FRODO significantly outperforms four competitive baselines. Furthermore, FRODO improves the robustness and generalization ability of the reasoning LM, yielding higher performance on out-of-distribution test sets. Finally, we find that FRODO\u2019s rationales are more faithful to its final answer predictions than standard supervised fine-tuning.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.882",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Self-training Large Language Models through Knowledge Detection": {
        "type": "INPROCEEDINGS",
        "key": "wei-jie-etal-2024-self",
        "author": "Wei Jie, Yeo and Ferdinan, Teddy and Kazienko, Przemyslaw and Satapathy, Ranjan and Cambria, Erik",
        "booktitle": "EMNLP-findings2024",
        "title": "Self-training Large Language Models through Knowledge Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) often necessitate extensive labeled datasets and training compute to achieve impressive performance across downstream tasks. This paper explores a self-training paradigm, where the LLM autonomously curates its own labels and selectively trains on unknown data samples identified through a reference-free consistency method. Empirical evaluations demonstrate significant improvements in reducing hallucination in generation across multiple subjects. Furthermore, the selective training framework mitigates catastrophic forgetting in out-of-distribution benchmarks, addressing a critical limitation in training LLMs. Our findings suggest that such an approach can substantially reduce the dependency on large labeled datasets, paving the way for more scalable and cost-effective language model training.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.883",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models": {
        "type": "INPROCEEDINGS",
        "key": "gao-etal-2024-kd",
        "author": "Gao, Pengju and Yamasaki, Tomohiro and Imoto, Kazunori",
        "booktitle": "EMNLP-findings2024",
        "title": "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We propose VE-KD, a novel method that balances knowledge distillation and vocabulary expansion with the aim of training efficient domain-specific language models. Compared with traditional pre-training approaches, VE-KD exhibits competitive performance in downstream tasks while reducing model size and using fewer computational resources. Additionally, VE-KD refrains from overfitting in domain adaptation. Our experiments with different biomedical domain tasks demonstrate that VE-KD performs well compared with models such as BioBERT (+1% at HoC) and PubMedBERT (+1% at PubMedQA), with about 96% less training time. Furthermore, it outperforms DistilBERT and Adapt-and-Distill, showing a significant improvement in document-level tasks. Investigation of vocabulary size and tolerance, which are hyperparameters of our method, provides insights for further model optimization. The fact that VE-KD consistently maintains its advantages, even when the corpus size is small, suggests that it is a practical approach for domain-specific language tasks and is transferrable to different domains for broader applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.884",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation": {
        "type": "INPROCEEDINGS",
        "key": "garces-arias-etal-2024-adaptive",
        "author": "Garces Arias, Esteban and Rodemann, Julian and Li, Meimingwei and Heumann, Christian and A\u00dfenmacher, Matthias",
        "booktitle": "EMNLP-findings2024",
        "title": "Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Despite the remarkable capabilities of large language models, generating high-quality text remains a challenging task. Numerous decoding strategies\u2014such as beam search, sampling with temperature, top\u2010k sampling, nucleus (top\u2010p) sampling, typical decoding, contrastive decoding, and contrastive search\u2014have been proposed to address these challenges by improving coherence, diversity, and resemblance to human-generated text. In this study, we introduce Adaptive Contrastive Search (ACS), a novel decoding strategy that extends contrastive search (CS) by incorporating an adaptive degeneration penalty informed by the model\u2019s estimated uncertainty at each generation step. ACS aims to enhance creativity and diversity while maintaining coherence to produce high-quality outputs. Extensive experiments across various model architectures, languages, and datasets demonstrate that our approach improves both creativity and coherence, underscoring its effectiveness in text-generation tasks. We release our code, datasets, and models to facilitate further research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.885",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "rathore-etal-2024-ssp",
        "author": "Rathore, Vipul Kumar and Deb, Aniruddha and Chandresh, Ankish Kumar and Singla, Parag and ., Mausam",
        "booktitle": "EMNLP-findings2024",
        "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recently, very large language models (LLMs) have shown exceptional performance on several English NLP tasks with just in-context learning (ICL), but their utility in other languages is still underexplored. We investigate their effectiveness for NLP tasks in low-resource languages (LRLs), especially in the setting of zero-labelled cross-lingual transfer (0-CLT), where no labelled training data for the target language is available \u2013 however training data from one or more related medium-resource languages (MRLs) is utilized, alongside the available unlabeled test data for a target language. We introduce Self-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT setting. SSP is based on the key observation that LLMs output more accurate labels if in-context exemplars are from the target language (even if their labels are slightly noisy). To operationalize this, since target language training data is not available in 0-CLT, SSP operates in two stages. In Stage I, using source MRL training data, target language\u2019s test data is noisily labeled. In Stage II, these noisy test data points are used as exemplars in ICL for further improved labelling. Additionally, our implementation of SSP uses a novel Integer Linear Programming (ILP)-based exemplar selection that balances similarity, prediction confidence (when available) and label coverage. Experiments on three tasks and eleven LRLs (from three regions) demonstrate that SSP strongly outperforms existing SOTA fine-tuned and prompting-based baselines in 0-CLT setup.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.886",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Re-examining Sexism and Misogyny Classification with Annotator Attitudes": {
        "type": "INPROCEEDINGS",
        "key": "jiang-etal-2024-examining",
        "author": "Jiang, Aiqi and Vitsakis, Nikolas and Dinkar, Tanvi and Abercrombie, Gavin and Konstas, Ioannis",
        "booktitle": "EMNLP-findings2024",
        "title": "Re-examining Sexism and Misogyny Classification with Annotator Attitudes",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Gender-Based Violence (GBV) is an increasing problem online, but existing datasets fail to capture the plurality of possible annotator perspectives or ensure the representation of affected groups. We revisit two important stages in the moderation pipeline for GBV: (1) manual data labelling; and (2) automated classification. For (1), we examine two datasets to investigate the relationship between annotator identities and attitudes and the responses they give to two GBV labelling tasks. To this end, we collect demographic and attitudinal information from crowd-sourced annotators using three validated surveys from Social Psychology. We find that higher Right Wing Authoritarianism scores are associated with a higher propensity to label text as sexist, while for Social Dominance Orientation and Neosexist Attitudes, higher scores are associated with a negative tendency to do so.For (2), we conduct classification experiments using Large Language Models and five prompting strategies, including infusing prompts with annotator information. We find: (i) annotator attitudes affect the ability of classifiers to predict their labels; (ii) including attitudinal information can boost performance when we use well-structured brief annotator descriptions; and (iii) models struggle to reflect the increased complexity and imbalanced classes of the new label sets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.887",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "When \u201dA Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "zheng-etal-2024-helpful",
        "author": "Zheng, Mingqian and Pei, Jiaxin and Logeswaran, Lajanugen and Lee, Moontae and Jurgens, David",
        "booktitle": "EMNLP-findings2024",
        "title": "When \u201dA Helpful Assistant\u201d Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prompting serves as the major way humans interact with Large Language Models (LLM). Commercial AI systems commonly define the role of the LLM in system prompts. For example, ChatGPT uses \u201dYou are a helpful assistant\u201d as part of its default system prompt. Despite current practices of adding personas to system prompts, it remains unclear how different personas affect a model\u2019s performance on objective tasks. In this study, we present a systematic evaluation of personas in system prompts. We curate a list of 162 roles covering 6 types of interpersonal relationships and 8 domains of expertise. Through extensive analysis of 4 popular families of LLMs and 2,410 factual questions, we demonstrate that adding personas in system prompts does not improve model performance across a range of questions compared to the control setting where no persona is added. Nevertheless, further analysis suggests that the gender, type, and domain of the persona can all influence the resulting prediction accuracies. We further experimented with a list of persona search strategies and found that, while aggregating results from the best persona for each question significantly improves prediction accuracy, automatically identifying the best persona is challenging, with predictions often performing no better than random selection. Overall, our findings suggest that while adding a persona may lead to performance gains in certain settings, the effect of each persona can be largely random. %Our results can help inform the design of system prompts for AI systems. Code and data are available at https://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.888",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-towards-efficient",
        "author": "Kim, Sungkyung and Lee, Adam and Park, Junyoung and Chung, Andrew and Oh, Jusang and Lee, Jay-Yoon",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in large language models have demonstrated enhanced capabilities in visual reasoning tasks by employing additional encoders for aligning different modalities. While the Q-Former has been widely used as a general encoder for aligning several modalities including image, video, audio, and 3D with large language models, previous works on its efficient training and the analysis of its individual components have been limited. In this work, we investigate the effectiveness of parameter efficient fine-tuning (PEFT) the Q-Former using InstructBLIP with visual reasoning benchmarks ScienceQA and IconQA. We observe that applying PEFT to the Q-Former achieves comparable performance to full fine-tuning using under 2% of the trainable parameters. Additionally, we employ AdaLoRA for dynamic parameter budget reallocation to examine the relative importance of the Q-Former\u2019s sublayers with 4 different benchmarks. Our findings reveal that the self-attention layers are noticeably more important in perceptual visual-language reasoning tasks, and relative importance of FFN layers depends on the complexity of visual-language patterns involved in tasks. The code is available at https://github.com/AttentionX/InstructBLIP_PEFT.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.889",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Modeling Gender and Dialect Bias in Automatic Speech Recognition": {
        "type": "INPROCEEDINGS",
        "key": "harris-etal-2024-modeling",
        "author": "Harris, Camille and Mgbahurike, Chijioke and Kumar, Neha and Yang, Diyi",
        "booktitle": "EMNLP-findings2024",
        "title": "Modeling Gender and Dialect Bias in Automatic Speech Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Dialect and gender-based biases have become an area of concern in language-dependent AI systemsincluding around automatic speech recognition (ASR) which processes speech audio into text. These potential biases raise concern for discriminatory outcomes with AI systems depending on demographic- particularly gender discrimination against women, and racial discrimination against minorities with ethnic or cultural English dialects.As such we aim to evaluate the performance of ASR systems across different genders and across dialects of English. Concretely, we take a deep dive of the performance of ASR systems on men and women across four US-based English dialects: Standard American English (SAE), African American Vernacular English (AAVE), Chicano English, and Spanglish. To do this, we construct a labeled dataset of 13 hours of podcast audio, transcribed by speakers of the represented dialects. We then evaluate zero-shot performance of different automatic speech recognition models on our dataset, and further finetune models to better understand how finetuning can impact performance. Our work fills the gap of investigating possible gender disparities within underrepresented dialects.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.890",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Are Large Language Models Consistent over Value-laden Questions?": {
        "type": "INPROCEEDINGS",
        "key": "moore-etal-2024-large",
        "author": "Moore, Jared and Deshpande, Tanvi and Yang, Diyi",
        "booktitle": "EMNLP-findings2024",
        "title": "Are Large Language Models Consistent over Value-laden Questions?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) appear to bias their survey answers toward certain values. Nonetheless, some argue that LLMs are too inconsistent to simulate particular values. Are they? To answer, we first define value consistency as the similarity of answers across 1) paraphrases of one question, 2) related questions under one topic, 3) multiple-choice and open-ended use-cases of one question, and 4) multilingual translations of a question to English, Chinese, German, and Japanese. We apply these measures to a few large, open LLMs including llama-3, as well as gpt-4o, using eight thousand questions spanning more than 300 topics. Unlike prior work, we find that models are relatively consistent across paraphrases, use-cases, translations, and within a topic. Still, some inconsistencies remain. Models are more consistent on uncontroversial topics (e.g., in the U.S., \u201cThanksgiving\u201d) than on controversial ones (e.g. \u201ceuthanasia\u201d). Base models are both more consistent compared to fine-tuned models and are uniform in their consistency across topics, while fine-tuned models are more inconsistent about some topics (e.g. \u201ceuthanasia\u201d) than others (e.g. \u201cWomen\u2019s rights\u201d) like our human participants.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.891",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "xTower: A Multilingual LLM for Explaining and Correcting Translation Errors": {
        "type": "INPROCEEDINGS",
        "key": "treviso-etal-2024-xtower",
        "author": "Treviso, Marcos V. and Guerreiro, Nuno M. and Agrawal, Sweta and Rei, Ricardo and Pombal, Jos\u00e9 and Vaz, Tania and Wu, Helena and Silva, Beatriz and Stigt, Daan Van and Martins, Andre",
        "booktitle": "EMNLP-findings2024",
        "title": "xTower: A Multilingual LLM for Explaining and Correcting Translation Errors",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While machine translation (MT) systems are achieving increasingly strong performance on benchmarks, they often produce translations with errors and anomalies. Understanding these errors can potentially help improve the translation quality and user experience. This paper introduces xTower, an open large language model (LLM) built on top of TowerBase designed to provide free-text explanations for translation errors in order to guide the generation of a corrected translation. The quality of the generated explanations by xTower are assessed via both intrinsic and extrinsic evaluation. We ask expert translators to evaluate the quality of the explanations across two dimensions: relatedness towards the error span being explained and helpfulness in error understanding and improving translation quality. Extrinsically, we test xTower across various experimental setups in generating translation corrections, demonstrating significant improvements in translation quality. Our findings highlight xTower\u2019s potential towards not only producing plausible and helpful explanations of automatic translations, but also leveraging them to suggest corrected translations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.892",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LAMBDA: Large Language Model-Based Data Augmentation for Multi-Modal Machine Translation": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-lambda",
        "author": "Wang, Yusong and Li, Dongyuan and Shen, Jialun and Xu, Yicheng and Xu, Mingkun and Funakoshi, Kotaro and Okumura, Manabu",
        "booktitle": "EMNLP-findings2024",
        "title": "LAMBDA: Large Language Model-Based Data Augmentation for Multi-Modal Machine Translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Multi-modal machine translation (MMT) can reduce ambiguity and semantic distortion compared with traditional machine translation (MT) by utilizing auxiliary information such as images. However, current MMT methods face two primary challenges. The first is their underperformance compared to MT methods based on pre-trained models. The second is the inadequate exploitation and integration of the image modality within the model, primarily due to a lack of triplet training data. A mainstream approach is to introduce large amounts of parallel and monolingual data to train the text model and the visual model separately. However, incorporating extensive external data can result in data imbalance, which may introduce biases during training. Additionally, the collection and cleaning of such large datasets is labor-intensive. To overcome these challenges, we introduce a novel, low-cost, large language model-based data augmentation method called LAMBDA, which can enrich the original samples and expand the dataset without requiring external images and text. We propose a fine-grained image captioning module with a noise filter to hierarchically and accurately extract unexploited information from images. Additionally, we design two specific prompts to guide the GPT-3.5 model in generating enriched texts and the corresponding translations. The enriched samples contain diverse text and strong connections between text and images, leading to significant improvements for MMT baselines, with the highest being an increase of up to 3.83 BLEU score and 3.61 METEOR score.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.893",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains": {
        "type": "INPROCEEDINGS",
        "key": "ramesh-etal-2024-evaluating",
        "author": "Ramesh, Krithika and Gandhi, Nupoor and Madaan, Pulkit and Bauer, Lisa and Peris, Charith and Field, Anjalie",
        "booktitle": "EMNLP-findings2024",
        "title": "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The difficulty of anonymizing text data hinders the development and deployment of NLP in high-stakes domains that involve private data, such as healthcare and social services. Poorly anonymized sensitive data cannot be easily shared with annotators or external researchers, nor can it be used to train public models. In this work, we explore the feasibility of using synthetic data generated from differentially private language models in place of real data to facilitate the development of NLP in these domains without compromising privacy. In contrast to prior work, we generate synthetic data for real high-stakes domains, and we propose and conduct use-inspired evaluations to assess data quality. Our results show that prior simplistic evaluations have failed to highlight utility, privacy, and fairness issues in the synthetic data. Overall, our work underscores the need for further improvements to synthetic data generation for it to be a viable way to enable privacy-preserving data sharing.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.894",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Dual Process Masking for Dialogue Act Recognition": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-dual",
        "author": "Kim, Yeo Jin and Acosta, Halim and Min, Wookhee and Rowe, Jonathan and Mott, Bradford and Chaturvedi, Snigdha and Lester, James",
        "booktitle": "EMNLP-findings2024",
        "title": "Dual Process Masking for Dialogue Act Recognition",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Dialogue act recognition is the task of classifying conversational utterances based on their communicative intent or function. To address this problem, we propose a novel two-phase processing approach called Dual-Process Masking. This approach streamlines the task by masking less important tokens in the input, identified through retrospective analysis of their estimated contribution during training. It enhances interpretability by using the masks applied during classification learning. Dual-Process Masking significantly improves performance over strong baselines for dialogue act recognition on a collaborative problem-solving dataset and three public dialogue benchmarks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.895",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference": {
        "type": "INPROCEEDINGS",
        "key": "monteiro-etal-2024-xc",
        "author": "Monteiro, Joao and Marcotte, \u00c9tienne and Noel, Pierre-Andre and Zantedeschi, Valentina and Vazquez, David and Chapados, Nicolas and Pal, Christopher and Taslakian, Perouz",
        "booktitle": "EMNLP-findings2024",
        "title": "XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prompts are often employed to condition decoder-only language model generation on reference information. Just-in-time processing of a context is inefficient due to the quadratic cost of self-attention operations, and caching is desirable. However, caching transformer states can easily require almost as much space as the model parameters. When the right context is not known in advance, caching the prompt can be challenging. This work addresses these limitations by introducing models that, inspired by the encoder-decoder architecture, use cross-attention to condition generation on reference text without the prompt. More precisely, we leverage pre-trained decoder-only models and only train a small number of added layers. We use Question-Answering (QA) as a testbed to evaluate the ability of our models to perform conditional generation and observe that they outperform prompt-based inference methods, are comparable to fine-tuned prompted LLMs, and drastically reduce the space footprint relative to standard KV caching by two orders of magnitude. Specifically, we introduced XC-Llama which converts a pre-trained Llama 2 into an encoder-decoder architecture by integrating cross-attention layers interleaved in between existing self-attention layers.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.896",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion": {
        "type": "INPROCEEDINGS",
        "key": "gu-etal-2024-pioneering",
        "author": "Gu, Hengrui and Zhou, Kaixiong and Wang, Yili and Wang, Ruobing and Wang, Xin",
        "booktitle": "EMNLP-findings2024",
        "title": "Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "During pre-training, the Text-to-Image (T2I) diffusion models encode factual knowledge into their parameters. These parameterized facts enable realistic image generation, but they may become obsolete over time, thereby misrepresenting the current state of the world. Knowledge editing techniques aim to update model knowledge in a targeted way. However, facing the dual challenges posed by inadequate editing datasets and unreliable evaluation criterion, the development of T2I knowledge editing encounter difficulties in effectively generalizing injected knowledge. In this work, we design a T2I knowledge editing framework by comprehensively spanning on three phases: First, we curate a dataset CAKE, comprising paraphrase and multi-object test, to enable more fine-grained assessment on knowledge generalization. Second, we propose a novel criterion, adaptive CLIP threshold, to effectively filter out false successful images under the current criterion and achieve reliable editing evaluation. Finally, we introduce MPE, a simple but effective approach for T2I knowledge editing. Instead of tuning parameters, MPE precisely recognizes and edits the outdated part of the conditioning text-prompt to accommodate the up-to-date knowledge. A straightforward implementation of MPE (Based on in-context learning) exhibits better overall performance than previous model editors. We hope these efforts can further promote faithful evaluation of T2I knowledge editing methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.897",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression": {
        "type": "INPROCEEDINGS",
        "key": "saxena-etal-2024-eigen",
        "author": "Saxena, Utkarsh and Saha, Gobinda and Choudhary, Sakshi and Roy, Kaushik",
        "booktitle": "EMNLP-findings2024",
        "title": "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) represent a groundbreaking advancement in the domain of natural language processing due to their impressive reasoning abilities. Recently, there has been considerable interest in increasing the context lengths for these models to enhance their applicability to complex tasks. However, at long context lengths and large batch sizes, the key-value (KV) cache, which stores the attention keys and values, emerges as the new bottleneck in memory usage during inference. To address this, we propose Eigen Attention, which performs the attention operation in a low-rank space, thereby reducing the KV cache memory overhead. Our proposed approach is orthogonal to existing KV cache compression techniques and can be used synergistically with them. Through extensive experiments over OPT, MPT, and Llama model families, we demonstrate that Eigen Attention results in up to 40% reduction in KV cache sizes and up to 60% reduction in attention operation latency with minimal drop in performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.899",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning": {
        "type": "INPROCEEDINGS",
        "key": "lin-etal-2024-accept",
        "author": "Lin, Yu-Chen and Li, Wei-Hua and Chen, Jun-cheng and Chen, Chu-Song",
        "booktitle": "EMNLP-findings2024",
        "title": "ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Prompt Tuning has been a popular Parameter-Efficient Fine-Tuning method attributed to its remarkable performance with few updated parameters on various large-scale pretrained Language Models (PLMs). Traditionally, each prompt has been considered indivisible and updated independently, leading the parameters increase proportionally as prompt length grows. To address this issue, we propose Adaptive Codebook for Composite and Efficient Prompt Tuning (ACCEPT). In our method, we refer to the concept of product quantization (PQ), allowing all soft prompts to share a set of learnable codebook vectors in each subspace, with each prompt differentiated by a set of adaptive weights. We achieve the superior performance on 17 diverse natural language tasks including natural language understanding (NLU) and question answering (QA) tasks by tuning only 0.3% of parameters of the PLMs. Our approach also excels in few-shot and large model settings, highlighting its significant potential.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.900",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression": {
        "type": "INPROCEEDINGS",
        "key": "xu-etal-2024-beyond-perplexity",
        "author": "Xu, Zhichao and Gupta, Ashim and Li, Tao and Bentham, Oliver and Srikumar, Vivek",
        "booktitle": "EMNLP-findings2024",
        "title": "Beyond Perplexity: Multi-dimensional Safety Evaluation of LLM Compression",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Increasingly, model compression techniques enable large language models (LLMs) to be deployed in real-world applications. As a result of this momentum towards local deployment, compressed LLMs will interact with a large population. Prior work on compression typically prioritize preserving perplexity, which is directly analogous to training loss. The impact of compression method on other critical aspects of model behavior\u2014particularly safety\u2014requires systematic assessment. To this end, we investigate the impact of model compression along four dimensions: (1) degeneration harm, i.e., bias and toxicity in generation; (2) representational harm, i.e., biases in discriminative tasks; (3) dialect bias; and (4) language modeling and downstream task performance. We examine a wide spectrum of LLM compression techniques, including unstructured pruning, semi-structured pruning, and quantization. Our analysis reveals that compression can lead to unexpected consequences. Although compression may unintentionally alleviate LLMs\u2019 degeneration harm, it can still exacerbate representational harm. Furthermore, increasing compression produces a divergent impact on different protected groups. Finally, different compression methods have drastically different safety impacts: for example, quantization mostly preserves bias while pruning degrades quickly. Our findings underscore the importance of integrating safety assessments into the development of compressed LLMs to ensure their reliability across real-world applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.901",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "One-to-many testing for code generation from (just) natural language": {
        "type": "INPROCEEDINGS",
        "key": "uniyal-etal-2024-one",
        "author": "Uniyal, Mansi and Singh, Mukul and Verbruggen, Gust and Gulwani, Sumit and Le, Vu",
        "booktitle": "EMNLP-findings2024",
        "title": "One-to-many testing for code generation from (just) natural language",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "MBPP is a popular dataset for evaluating the task of code generation from natural language. Despite its popularity, there are three problems: (1) it relies on providing test cases to generate the right signature, (2) there is poor alignment between instruction and evaluation test cases, and (3) contamination of the exact phrasing being present in training datasets. We adapt MBPP to emphasize on generating code from just natural language by (1) removing ambiguity about the semantics of the task from the descriptions, and (2) evaluating generated code on multiple sets of assertions to account for ambiguity in the syntax. We compare popular open and closed weight models on the original (MBPP) and adapted (MBUPP) datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.902",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Unified Framework for Model Editing": {
        "type": "INPROCEEDINGS",
        "key": "gupta-etal-2024-unified",
        "author": "Gupta, Akshat and Sajnani, Dev and Anumanchipalli, Gopala",
        "booktitle": "EMNLP-findings2024",
        "title": "A Unified Framework for Model Editing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "ROME and MEMIT are largely believed to be two different model editing algorithms, with the major difference between them being the ability to perform batched edits. In this paper, we unify these two algorithms under a single conceptual umbrella, optimizing for the same goal, which we call the preservation-memorization objective. ROME uses an equality constraint to optimize this objective to perform one edit at a time, whereas MEMIT employs a more flexible least-square constraint that allows for batched edits. We generalize ROME and enable batched editing with equality constraint in the form of EMMET - an Equality-constrained Mass Model Editing algorithm for Transformers, a new batched memory-editing algorithm. EMMET can perform batched-edits up to a batch-size of 10,000, with very similar performance to MEMIT across multiple dimensions. With the introduction of EMMET, we truly unify ROME and MEMIT and show that both algorithms are equivalent in terms of their optimization objective, their abilities (singular and batched editing), their model editing performance and their limitations.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.903",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-m3sciqa",
        "author": "Li, Chuhan and Shangguan, Ziyao and Zhao, Yilun and Li, Deyuan and Liu, Yixin and Cohan, Arman",
        "booktitle": "EMNLP-findings2024",
        "title": "M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing evaluation benchmarks for foundation models in understanding scientific literature predominantly focus on single-document, text-only tasks. Such benchmarks often do not adequately represent the complexity of research workflows, which typically also involve interpreting non-textual data, such as figures and tables, and gathering information across multiple documents and related literature. To address this gap, we introduce M3SciQA, a multi-modal, multi-document scientific question answering benchmark designed for a more comprehensive evaluation of foundation models. M3Sci QA consists of 1452 expert-annotated questions spanning 70 natural language processing paper clusters, where each cluster represents a primary paper along with all its cited documents, mirroring the workflow of comprehending a single paper by requiring multi-modal and multi-document data. With M3SciQA, we conduct a comprehensive evaluation of 18 frontier foundation models. Our results indicate that current foundation models still significantly underperform compared to human experts in multi-modal information retrieval and in reasoning across multiple scientific documents. Additionally, we explore the implications of these findings for the future advancement of applying foundation models in multi-modal scientific literature analysis.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.904",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction": {
        "type": "INPROCEEDINGS",
        "key": "george-etal-2024-probing",
        "author": "George, Sonny and Sypherd, Chris and Cashman, Dylan",
        "booktitle": "EMNLP-findings2024",
        "title": "Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language model (LLM) agents show promise in an increasing number of domains. In many proposed applications, it is expected that the agent reasons over accumulated experience presented in an input prompt. We propose the OEDD (Operationalize Experience Despite Distraction) corpus, a human-annotator-validated body of scenarios with pre-scripted agent histories where the agent must make a decision based on disparate experiential information in the presence of a distractor. We evaluate three state-of-the-art LLMs (GPT-3.5 Turbo, GPT-4o, and Gemini 1.5 Pro) using a minimal chain-of-thought prompting strategy and observe that when (1) the input context contains over 1,615 tokens of historical interactions, (2) a crucially decision-informing premise is the rightful conclusion over two disparate environment premises, and (3) a trivial, but distracting red herring fact follows, all LLMs perform worse than random choice at selecting the better of two actions. Our code and test corpus are publicly available at: [github.com/sonnygeorge/OEDD](github.com/sonnygeorge/OEDD).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.905",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Knowledge-Centric Templatic Views of Documents": {
        "type": "INPROCEEDINGS",
        "key": "cachola-etal-2024-knowledge",
        "author": "Cachola, Isabel Alyssa and Cucerzan, Silviu and Herring, Allen and Mijovic, Vuksan and Oveson, Erik and Jauhar, Sujay Kumar",
        "booktitle": "EMNLP-findings2024",
        "title": "Knowledge-Centric Templatic Views of Documents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Authors seeking to communicate with broader audiences often share their ideas in various document formats, such as slide decks, newsletters, reports, and posters. Prior work on document generation has generally tackled the creation of each separate format to be a different task, leading to fragmented learning processes, redundancy in models and methods, and disjointed evaluation. We consider each of these documents as templatic views of the same underlying knowledge/content, and we aim to unify the generation and evaluation of these templatic views. We begin by showing that current LLMs are capable of generating various document formats with little to no supervision. Further, a simple augmentation involving a structured intermediate representation can improve performance, especially for smaller models. We then introduce a novel unified evaluation framework that can be adapted to measuring the quality of document generators for heterogeneous downstream applications. This evaluation is adaptable to a range of user defined criteria and application scenarios, obviating the need for task specific evaluation metrics. Finally, we conduct a human evaluation, which shows that people prefer 82% of the documents generated with our method, while correlating more highly with our unified evaluation framework than prior metrics in the literature.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.906",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction": {
        "type": "INPROCEEDINGS",
        "key": "peper-etal-2024-shoes",
        "author": "Peper, Joseph J. and Qiu, Wenzhao and Bruggeman, Ryan and Han, Yi and Chehade, Estefania Ciliotta and Wang, Lu",
        "booktitle": "EMNLP-findings2024",
        "title": "Shoes-ACOSI: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We explore *implicit opinion extraction* as a new component of aspect-based sentiment analysis (ABSA) systems. Prior work in ABSA has investigated opinion extraction as an important subtask, however, these works only label concise, *explicitly*-stated opinion spans. In this work, we present **Shoes-ACOSI**, a new and challenging ABSA dataset in the e-commerce domain with implicit opinion span annotations, the first of its kind. Shoes-ACOSI builds upon the existing Aspect-Category-Opinion-Sentiment (ACOS) quadruple extraction task, extending the task to quintuple extraction\u2014now localizing and differentiating both implicit and explicit opinion. In addition to the new annotation schema, our dataset contains paragraph-length inputs which, importantly, present complex challenges through increased input length, increased number of sentiment expressions, and more mixed-sentiment-polarity examples when compared with existing benchmarks. We quantify the difficulty of our new dataset by evaluating with state-of-the-art fully-supervised and prompted-LLM baselines. We find our dataset presents significant challenges for both supervised models and LLMs, particularly from the new implicit opinion extraction component of the ACOSI task, highlighting the need for continued research into implicit opinion understanding.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.907",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation": {
        "type": "INPROCEEDINGS",
        "key": "chidambaram-etal-2024-socratic",
        "author": "Chidambaram, Subramanian and Li, Li Erran and Bai, Min and Li, Xiaopeng and Lin, Kaixiang and Zhou, Xiong and Williams, Alex C.",
        "booktitle": "EMNLP-findings2024",
        "title": "Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are increasingly used for generating code solutions, empowered by features like self-debugging and self-reflection. However, LLMs often struggle with complex programming problems without human guidance. This paper investigates the strategies employed by expert programmers to steer code-generating LLMs toward successful outcomes. Through a study involving experts using natural language to guide GPT-4, Gemini Ultra, and, Claude 3.5 Sonnet on highly difficult programming challenges, we frame our analysis using the \u201cSocratic Feedback\u201d paradigm for understanding effective steering strategies. By analyzing 30 conversational transcripts across all three models, we map observed feedback strategies to five stages of Socratic Questioning: Definition, Elenhus, Maieutic, Dialectic, and Counter-factual reasoning. We find evidence that by employing a combination of different Socratic feedback strategies across multiple turns, programmers successfully guided the models to solve 74% of the problems that the models initially failed to solve on their own.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.908",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Models Know What To Say But Not When To Speak": {
        "type": "INPROCEEDINGS",
        "key": "umair-etal-2024-large",
        "author": "Umair, Muhammad and Sarathy, Vasanth and Ruiter, Jan",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Models Know What To Say But Not When To Speak",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Turn-taking is a fundamental mechanism in human communication that ensures smooth and coherent verbal interactions. Recent advances in Large Language Models (LLMs) have motivated their use in improving the turn-taking capabilities of Spoken Dialogue Systems (SDS), such as their ability to respond at appropriate times. However, existing models often struggle to predict opportunities for speaking \u2014 called Transition Relevance Places (TRPs) \u2014 in natural, unscripted conversations, focusing only on turn-final TRPs and not within-turn TRPs. To address these limitations, we introduce a novel dataset of participant-labeled within-turn TRPs and use it to evaluate the performance of state-of-the-art LLMs in predicting opportunities for speaking. Our experiments reveal the current limitations of LLMs in modeling unscripted spoken interactions, highlighting areas for improvement and paving the way for more naturalistic dialogue systems.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.909",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method": {
        "type": "INPROCEEDINGS",
        "key": "shen-etal-2024-towards",
        "author": "Shen, Xinshu and Wu, Hongyi and Zhang, Yadong and Lan, Man and Bai, Xiaopeng and Mao, Shaoguang and Wu, Yuanbin and Zhuang, Xinlin and Cai, Li",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Grammatical Error Correction (GEC) is a crucial technique in Automated Essay Scoring (AES) for evaluating the fluency of essays. However, in Chinese, existing GEC datasets often fail to consider the importance of specific grammatical error types within compositional scenarios, lack research on data collected from native Chinese speakers, and largely overlook cross-sentence grammatical errors. Furthermore, the measurement of the overall fluency of an essay is often overlooked. To address these issues, we present CEFA (Chinese Essay Fluency Assessment), an extensive corpus that is derived from essays authored by native Chinese-speaking primary and secondary students and encapsulates essay fluency scores along with both coarse and fine-grained grammatical error types and corrections. Experiments employing various benchmark models on CEFA substantiate the challenge of our dataset. Our findings further highlight the significance of fine-grained annotations in fluency assessment and the mutually beneficial relationship between error types and corrections",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.910",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CoCoHD: Congress Committee Hearing Dataset": {
        "type": "INPROCEEDINGS",
        "key": "hiray-etal-2024-cocohd",
        "author": "Hiray, Arnav and Liu, Yunsong and Song, Mingxiao and Shah, Agam and Chava, Sudheer",
        "booktitle": "EMNLP-findings2024",
        "title": "CoCoHD: Congress Committee Hearing Dataset",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "U.S. congressional hearings significantly influence the national economy and social fabric, impacting individual lives. Despite their importance, there is a lack of comprehensive datasets for analyzing these discourses. To address this, we propose the **Co**ngress **Co**mmittee **H**earing **D**ataset (CoCoHD), covering hearings from 1997 to 2024 across 86 committees, with 32,697 records. This dataset enables researchers to study policy language on critical issues like healthcare, LGBTQ+ rights, and climate justice. We demonstrate its potential with a case study on 1,000 energy-related sentences, analyzing the Energy and Commerce Committee\u2019s stance on fossil fuel consumption. By fine-tuning pre-trained language models, we create energy-relevant measures for each hearing. Our market analysis shows that natural language analysis using CoCoHD can predict and highlight trends in the energy sector.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.911",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning": {
        "type": "INPROCEEDINGS",
        "key": "sonkar-etal-2024-student",
        "author": "Sonkar, Shashank and Liu, Naiming and Baraniuk, Richard",
        "booktitle": "EMNLP-findings2024",
        "title": "Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The pursuit of personalized education has led to the integration of Large Language Models (LLMs) in developing intelligent tutoring systems. To better understand and adapt to individual student needs, including their misconceptions, LLMs need to be trained on extensive datasets of student-tutor dialogues. Our research uncovers a fundamental challenge in this approach: the \u201cStudent Data Paradox\u201d. This paradox emerges when LLMs, trained on student data to understand learner behavior, inadvertently compromise their own factual knowledge and reasoning abilities. We investigate this paradox by training state-of-the-art language models on student-tutor dialogue datasets and evaluating their performance across multiple benchmarks. These benchmarks assess various aspects of language model capabilities, including reasoning, truthfulness, and common sense understanding. Our findings reveal significant declines in the models\u2019 performance across these diverse benchmarks, indicating a broad impact on their capabilities when trained to model student behavior. Our research makes two primary contributions: (1) empirical demonstration of the Student Data Paradox through quantitative analysis of model performance, and (2) introduction of \u201challucination tokens\u201d as a mitigation strategy. These tokens, while improving performance, highlight the persistent challenge of balancing accurate student behavior modeling with maintaining the LLM\u2019s integrity as an educational tool.This study emphasizes the need for innovative solutions to reconcile the conflicting goals of faithfully understanding diverse student cognition while preserving the model\u2019s ability to provide accurate information and guidance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.912",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MalAlgoQA: Pedagogical Evaluation of Counterfactual Reasoning in Large Language Models and Implications for AI in Education": {
        "type": "INPROCEEDINGS",
        "key": "sonkar-etal-2024-malalgoqa",
        "author": "Sonkar, Shashank and Liu, Naiming and Le, MyCo and Baraniuk, Richard",
        "booktitle": "EMNLP-findings2024",
        "title": "MalAlgoQA: Pedagogical Evaluation of Counterfactual Reasoning in Large Language Models and Implications for AI in Education",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This paper introduces MalAlgoQA, a novel dataset designed to evaluate the counterfactual reasoning capabilities of Large Language Models (LLMs) through a pedagogical approach. The dataset comprises mathematics and reading comprehension questions, each accompanied by four answer choices and their corresponding rationales. At the heart of MalAlgoQA are \u201cmalgorithms\u201d - rationales behind incorrect answer choices that represent flawed yet logically coherent reasoning paths. These malgorithms serve as counterfactual scenarios, allowing us to assess an LLM\u2019s ability to identify and analyze flawed reasoning patterns. We propose the Malgorithm Identification task, where LLMs are assessed based on their ability to identify corresponding malgorithm given an incorrect answer choice. To evaluate the model performance, we introduce two metrics: Algorithm Identification Accuracy (AIA) for correct answer rationale identification, and Malgorithm Identification Accuracy (MIA) for incorrect answer rationale identification. Our experiments reveal that state-of-the-art LLMs exhibit significant performance drops in MIA compared to AIA, highlighting the challenges in counterfactual reasoning.Surprisingly, we find that the chain-of-thought prompting technique not only fails to consistently enhance MIA but can sometimes lead to underperformance compared to simple prompting. These findings have important implications for developing LLMs with improved counterfactual reasoning, particularly relevant for AI-powered tutoring systems, where identifying and addressing student misconceptions is essential. MalAlgoQA dataset is available here.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.913",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets": {
        "type": "INPROCEEDINGS",
        "key": "walsh-etal-2024-sonnet",
        "author": "Walsh, Melanie and Antoniak, Maria and Preus, Anna",
        "booktitle": "EMNLP-findings2024",
        "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) can now generate and recognize poetry. But what do LLMs really know about poetry? We develop a task to evaluate how well LLMs recognize one aspect of English-language poetry\u2014poetic form\u2014which captures many different poetic features, including rhyme scheme, meter, and word or line repetition. By using a benchmark dataset of over 4.1k human expert-annotated poems, we show that state-of-the-art LLMs can successfully identify both common and uncommon fixed poetic forms\u2014such as sonnets, sestinas, and pantoums\u2014with surprisingly high accuracy. However, performance varies significantly by poetic form; the models struggle to identify unfixed poetic forms, especially those based on topic or visual features. We additionally measure how many poems from our benchmark dataset are present in popular pretraining datasets or memorized by GPT-4, finding that pretraining presence and memorization may improve performance on this task, but results are inconclusive. We release a benchmark evaluation dataset with 1.4k public domain poems and form annotations, results of memorization experiments and data audits, and code.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.914",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging": {
        "type": "INPROCEEDINGS",
        "key": "morrison-etal-2024-merge",
        "author": "Morrison, Jacob and Smith, Noah A. and Hajishirzi, Hannaneh and Koh, Pang Wei and Dodge, Jesse and Dasigi, Pradeep",
        "booktitle": "EMNLP-findings2024",
        "title": "Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Adapting general-purpose language models to new skills is currently an expensive process that must be repeated as new instruction datasets targeting new skills are created, or can cause the models to forget older skills. In this work, we investigate the effectiveness of adding new skills to preexisting models by training on the new skills in isolation and later merging with the general model (e.g. using task vectors). In experiments focusing on scientific literature understanding, safety, and coding, we find that the parallel-train-then-merge procedure, which is significantly cheaper than retraining the models on updated data mixtures, is often comparably effective. Our experiments also show that parallel training is especially well-suited for enabling safety features in LMs relative to continued finetuning and retraining, as it dramatically improves model compliance with safe prompts while preserving its ability to refuse dangerous or harmful prompts.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.915",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "To Ask LLMs about English Grammaticality, Prompt Them in a Different Language": {
        "type": "INPROCEEDINGS",
        "key": "behzad-etal-2024-ask",
        "author": "Behzad, Shabnam and Zeldes, Amir and Schneider, Nathan",
        "booktitle": "EMNLP-findings2024",
        "title": "To Ask LLMs about English Grammaticality, Prompt Them in a Different Language",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In addition to asking questions about facts in the world, some internet users\u2014in particular, second language learners\u2014ask questions about language itself. Depending on their proficiency level and audience, they may pose these questions in an L1 (first language) or an L2 (second language). We investigate how multilingual LLMs perform at crosslingual metalinguistic question answering. Focusing on binary questions about sentence grammaticality constructed from error-annotated learner corpora, we prompt three LLMs (Aya, Llama, and GPT) in multiple languages, including English, German, Korean, Russian, and Ukrainian. Our study reveals that the language of the prompt can significantly affect model performance, and despite English being the dominant training language for all three models, prompting in a different language with questions about English often yields better results.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.916",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs": {
        "type": "INPROCEEDINGS",
        "key": "akash-chang-2024-enhancing",
        "author": "Akash, Pritom Saha and Chang, Kevin Chen-Chuan",
        "booktitle": "EMNLP-findings2024",
        "title": "Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Topic modeling is a powerful technique for uncovering hidden themes within a collection of documents. However, the effectiveness of traditional topic models often relies on sufficient word co-occurrence, which is lacking in short texts. Therefore, existing approaches, whether probabilistic or neural, frequently struggle to extract meaningful patterns from such data, resulting in incoherent topics. To address this challenge, we propose a novel approach that leverages large language models (LLMs) to extend short texts into more detailed sequences before applying topic modeling. To further improve the efficiency and solve the problem of semantic inconsistency from LLM-generated texts, we propose to use prefix tuning to train a smaller language model coupled with a variational autoencoder for short-text topic modeling. Our method significantly improves short-text topic modeling performance, as demonstrated by extensive experiments on real-world datasets with extreme data sparsity, outperforming current state-of-the-art topic models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.917",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Targeted Multilingual Adaptation for Low-resource Language Families": {
        "type": "INPROCEEDINGS",
        "key": "downey-etal-2024-targeted",
        "author": "Downey, C. M. and Blevins, Terra and Serai, Dhwani and Parikh, Dwija and Steinert-Threlkeld, Shane",
        "booktitle": "EMNLP-findings2024",
        "title": "Targeted Multilingual Adaptation for Low-resource Language Families",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Massively multilingual models are known to have limited utility in any one language, and to perform particularly poorly on low-resource languages. By contrast, targeted multinguality has been shown to benefit low-resource languages. To test this approach more rigorously, we systematically study best practices for adapting a pre-trained model to a language family. Focusing on the Uralic family as a test case, we adapt XLM-R under various configurations to model 15 languages; we then evaluate the performance of each experimental setting on two downstream tasks and 11 evaluation languages. Our adapted models significantly outperform mono- and multilingual baselines. A regression analysis reveals that adapted vocabulary size is relatively unimportant for low-resource languages, and that low-resource languages can be aggressively up-sampled during training at little detriment to performance in high-resource languages. These results introduce new best practices for performing language adaptation in a targeted setting.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.918",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents": {
        "type": "INPROCEEDINGS",
        "key": "mullick-etal-2024-pointer",
        "author": "Mullick, Ankan and Bose, Sombit and Nandy, Abhilash and Chaitanya, Gajula Sai and Goyal, Pawan",
        "booktitle": "EMNLP-findings2024",
        "title": "A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In task-oriented dialogue systems, intent detection is crucial for interpreting user queries and providing appropriate responses. Existing research primarily addresses simple queries with a single intent, lacking effective systems for handling complex queries with multiple intents and extracting different intent spans. Additionally, there is a notable absence of multilingual, multi-intent datasets. This study addresses three critical tasks: extracting multiple intent spans from queries, detecting multiple intents, and developing a multilingual multi-label intent dataset. We introduce a novel multi-label multi-class intent detection dataset (MLMCID-dataset) curated from existing benchmark datasets. We also propose a pointer network-based architecture (MLMCID) to extract intent spans and detect multiple intents with coarse and fine-grained labels in the form of sextuplets. Comprehensive analysis demonstrates the superiority of our pointer network based system over baseline approaches in terms of accuracy and F1-score across various datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.919",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs": {
        "type": "INPROCEEDINGS",
        "key": "nag-etal-2024-cost",
        "author": "Nag, Arijit and Mukherjee, Animesh and Ganguly, Niloy and Chakrabarti, Soumen",
        "booktitle": "EMNLP-findings2024",
        "title": "Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) exhibit impressive zero/few-shot inference and generation quality for high-resource languages (HRLs). A few of them have been trained on low-resource languages (LRLs) and give decent performance. Owing to the prohibitive costs of training LLMs, they are usually used as a network service, with the client charged by the count of input and output tokens. The number of tokens strongly depends on the script and language, as well as the LLM\u2019s subword vocabulary. We show that LRLs are at a pricing disadvantage, because the well-known LLMs produce more tokens for LRLs than HRLs. This is because most currently popular LLMs are optimized for HRL vocabularies. Our objective is to level the playing field: reduce the cost of processing LRLs in contemporary LLMs while ensuring that predictive and generative qualities are not compromised. As means to reduce the number of tokens processed by the LLM, we consider code-mixing, translation, and transliteration of LRLs to HRLs. We perform an extensive study using the IndicXTREME classification and six generative tasks dataset, covering 15 Indic and 3 other languages, while using GPT-4 (one of the costliest LLM services released so far) as a commercial LLM. We observe and analyze interesting patterns involving token count, cost, and quality across a multitude of languages and tasks. We show that choosing the best policy to interact with the LLM can reduce cost by ~90% while giving better or comparable performance, compared to communicating with the LLM in the original LRL.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.920",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Advancing Vision-Language Models with Adapter Ensemble Strategies": {
        "type": "INPROCEEDINGS",
        "key": "bai-etal-2024-advancing-vision",
        "author": "Bai, Yue and Zhao, Handong and Lin, Zhe and Kale, Ajinkya and Gu, Jiuxiang and Yu, Tong and Kim, Sungchul and Fu, Yun",
        "booktitle": "EMNLP-findings2024",
        "title": "Advancing Vision-Language Models with Adapter Ensemble Strategies",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "CLIP revolutes vision-language pretraining by using contrastive learning on paired web data. However, the sheer size of these pretrained models makes full-model finetuning exceedingly costly. One common solution is the \u201cadapter\u201d, which finetunes a few additional parameters while freezing the backbone. It harnesses the heavy-duty backbone while offering a light finetuning for small downstream tasks. This synergy prompts us to explore the potential of augmenting large-scale backbones with traditional machine learning techniques. Often employed in traditional fields and overlooked in the large-scale era, these techniques could provide valuable enhancements. Herein, we delve into the \u201cadapter ensembles\u201d in the realm of large-scale pretrained vision-language models. We begin with a proof-of-concept study to establish the efficacy of combining multiple adapters. We then present extensive evidence showing these ensembles excel in a variety of settings, particularly when employing a Multi-Scale Attention (MSA) approach thoughtfully integrated into the ensemble framework. We further incorporate the LoRA to mitigate the additional parameter burden. We focus on vision-language retrieval, using different backbones under constraints of minimal data, parameters, and finetuning budgets. This research paves the way for a synergistic blend of traditional, yet effective, strategies with modern large-scale networks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.921",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Who Wrote When? Author Diarization in Social Media Discussions": {
        "type": "INPROCEEDINGS",
        "key": "boenninghoff-etal-2024-wrote",
        "author": "Boenninghoff, Benedikt and Hosseini, Henry and Nickel, Robert M. and Kolossa, Dorothea",
        "booktitle": "EMNLP-findings2024",
        "title": "Who Wrote When? Author Diarization in Social Media Discussions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We are proposing a novel framework for author diarization, i.e. attributing comments in online discussions to individual authors. We consider an innovative approach that merges pre-trained neural representations of writing style with author-conditional encoder-decoder diarization, enhanced by a Conditional Random Field with Viterbi decoding for alignment refinement. Additionally, we introduce two new large-scale German language datasets, one for authorship verification and the other for author diarization. We evaluate the performance of our diarization framework on these datasets, offering insights into the strengths and limitations of this approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.922",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Controlled Transformation of Text-Attributed Graphs": {
        "type": "INPROCEEDINGS",
        "key": "vakil-amiri-2024-controlled",
        "author": "Vakil, Nidhi and Amiri, Hadi",
        "booktitle": "EMNLP-findings2024",
        "title": "Controlled Transformation of Text-Attributed Graphs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Graph generation is the process of generating novel graphs with similar attributes to real world graphs. The explicit and precise control of granular structural attributes, such as node centrality and graph density, is crucial for effective graph generation. This paper introduces a controllable multi-objective translation model for text-attributed graphs, titled Controlled Graph Translator (CGT). It is designed to effectively and efficiently translate a given source graph to a target graph, while satisfying multiple desired graph attributes at granular level. Designed with an encoder-decoder architecture, CGT develops fusion and graph attribute predictor neural networks for controlled graph translation. We validate the effectiveness of CGT through extensive experiments on different genres of datasets. In addition, we illustrate the application of CGT in data augmentation and taxonomy creation, particularly in low resource settings.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.923",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation": {
        "type": "INPROCEEDINGS",
        "key": "luo-etal-2024-misinformation",
        "author": "Luo, Chu Fei and Shayanfar, Radin and Bhambhoria, Rohan V. and Dahan, Samuel and Zhu, Xiaodan",
        "booktitle": "EMNLP-findings2024",
        "title": "Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Misinformation, defined as false or inaccurate information, can result in significant societal harm when it is spread with malicious or even unintentional intent. The rapid online information exchange necessitates advanced detection mechanisms to mitigate misinformation-induced harm. Existing research, however, has predominantly focused on the veracity of information, overlooking the legal implications and consequences of misinformation. In this work, we take a novel angle to consolidate the definition of misinformation detection using legal issues as a measurement of societal ramifications, aiming to bring interdisciplinary efforts to tackle misinformation and its consequence. We introduce a new task: Misinformation with Legal Consequence (MisLC), which leverages definitions from a wide range of legal domains covering 4 broader legal topics and 11 fine-grained legal issues, including hate speech, election laws, and privacy regulations. For this task, we advocate a two-step dataset curation approach that utilizes crowd-sourced checkworthiness and expert evaluations of misinformation. We provide insights about the MisLC task through empirical evidence, from the problem definition to experiments and expert involvement. While the latest large language models and retrieval-augmented generation are effective baselines for the task, we find they are still far from replicating expert performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.924",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models": {
        "type": "INPROCEEDINGS",
        "key": "harne-etal-2024-case",
        "author": "Harne, Sarthak and Choudhury, Monjoy Narayan and Rao, Madhav and Srikanth, T. K. and Mehrotra, Seema and Vashisht, Apoorva and Basu, Aarushi and Sodhi, Manjit Singh",
        "booktitle": "EMNLP-findings2024",
        "title": "CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The limited availability of psychologists necessitates efficient identification of individuals requiring urgent mental healthcare. This study explores the use of Natural Language Processing (NLP) pipelines to analyze text data from online mental health forums used for consultations. By analyzing forum posts, these pipelines can flag users who may require immediate professional attention. A crucial challenge in this domain is data privacy and scarcity. To address this, we propose utilizing readily available curricular texts used in institutes specializing in mental health for pre-training the NLP pipelines. This helps us mimic the training process of a psychologist. Our work presents CASE-BERT that flags potential mental health disorders based on forum text. CASE-BERT demonstrates superior performance compared to existing methods, achieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the most commonly reported mental health disorders. Our code and data are publicly available.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.925",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Explicit Inductive Inference using Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-explicit",
        "author": "Liu, Tianyang and Li, Tianyi and Cheng, Liang and Steedman, Mark",
        "booktitle": "EMNLP-findings2024",
        "title": "Explicit Inductive Inference using Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are reported to hold undesirable attestation bias on inference tasks: when asked to predict if a premise P entails a hypothesis H, instead of considering H\u2018s conditional truthfulness entailed by P, LLMs tend to use the out-of-context truth label of H as a fragile proxy. In this paper, we propose a pipeline that exploits this bias to do explicit inductive inference. Our pipeline uses an LLM to transform a premise into a set of attested alternatives, and then aggregate answers of the derived new entailment inquiries to support the original inference prediction. On a directional predicate entailment benchmark, we demonstrate that by applying this simple pipeline, we can improve the overall performance of LLMs on inference and substantially alleviate the impact of their attestation bias.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.926",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-less",
        "author": "Huang, Wenyu and Zhou, Guancheng and Wang, Hongru and Vougiouklis, Pavlos and Lapata, Mirella and Pan, Jeff Z.",
        "booktitle": "EMNLP-findings2024",
        "title": "Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Retrieval-Augmented Generation (RAG) is widely used to inject external non-parametric knowledge into large language models (LLMs). Recent works suggest that Knowledge Graphs (KGs) contain valuable external knowledge for LLMs. Retrieving information from KGs differs from extracting it from document sets. Most existing approaches seek to directly retrieve relevant subgraphs, thereby eliminating the need for extensive SPARQL annotations, traditionally required by semantic parsing methods. In this paper, we model the subgraph retrieval task as a conditional generation task handled by small language models. Specifically, we define a subgraph identifier as a sequence of relations, each represented as a special token stored in the language models. Our base generative subgraph retrieval model, consisting of only 220M parameters, achieves competitive retrieval performance compared to state-of-the-art models relying on 7B parameters, demonstrating that small language models are capable of performing the subgraph retrieval task. Furthermore, our largest 3B model, when plugged with an LLM reader, sets new SOTA end-to-end performance on both the WebQSP and CWQ benchmarks. Our model and data will be made available online: https://github.com/hwy9855/GSR.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.927",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Evaluating Gender Bias of LLMs in Making Morality Judgements": {
        "type": "INPROCEEDINGS",
        "key": "bajaj-etal-2024-evaluating",
        "author": "Bajaj, Divij and Lei, Yuanyuan and Tong, Jonathan and Huang, Ruihong",
        "booktitle": "EMNLP-findings2024",
        "title": "Evaluating Gender Bias of LLMs in Making Morality Judgements",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in a multitude of Natural Language Processing (NLP) tasks. However, these models are still not immune to limitations such as social biases, especially gender bias. This work investigates whether current closed and open-source LLMs possess gender bias, especially when asked to give moral opinions. To evaluate these models, we curate and introduce a new dataset GenMO (Gender-bias in Morality Opinions) comprising parallel short stories featuring male and female characters respectively. Specifically, we test models from the GPT family (GPT-3.5-turbo, GPT-3.5-turbo-instruct, GPT-4-turbo), Llama 3 and 3.1 families (8B/70B), Mistral-7B and Claude 3 families (Sonnet and Opus). Surprisingly, despite employing safety checks, all production-standard models we tested display significant gender bias with GPT-3.5-turbo giving biased opinions in 24% of the samples. Additionally, all models consistently favour female characters, with GPT showing bias in 68-85% of cases and Llama 3 in around 81-85% instances. Additionally, our study investigates the impact of model parameters on gender bias and explores real-world situations where LLMs reveal biases in moral decision-making.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.928",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune": {
        "type": "INPROCEEDINGS",
        "key": "ceritli-etal-2024-study",
        "author": "Ceritli, Taha and Ozkan, Savas and Min, Jeongwon and Noh, Eunchung and Min, Cho Jung and Ozay, Mete",
        "booktitle": "EMNLP-findings2024",
        "title": "A Study of Parameter Efficient Fine-tuning by Learning to Efficiently Fine-Tune",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The growing size of large language models (LLMs) requires parameter-efficient fine-tuning (PEFT) methods for their adaptation to new tasks. Existing methods, such as Low-Rank Adaptation (LoRA), typically involve model adaptation by training the PEFT parameters. One open problem required to be solved to effectively employ these methods is the identification of PEFT parameters. More precisely, related works identify PEFT parameters by projecting high dimensional parameters of LLMs onto low dimensional parameter manifolds with predefined projections, or identifying PEFT parameters as projections themselves. To study this problem, we propose a new approach called Learning to Efficiently Fine-tune (LEFT) where we aim to learn spaces of PEFT parameters from data. In order to learn how to generate the PEFT parameters on a learned parameter space while fine-tuning the LLMs, we propose the Parameter Generation (PG) method. In the experimental analyses, we examine the effectiveness of our solutions exploring accuracy of fine-tuned LLMs and characteristics of PEFT parameters on benchmark GLUE tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.929",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Explaining Mixtures of Sources in News Articles": {
        "type": "INPROCEEDINGS",
        "key": "spangher-etal-2024-explaining",
        "author": "Spangher, Alexander and Youn, James and DeButts, Matt and Peng, Nanyun and Ferrara, Emilio and May, Jonathan",
        "booktitle": "EMNLP-findings2024",
        "title": "Explaining Mixtures of Sources in News Articles",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Human writers plan, _then_ write. For large language models (LLMs) to play a role in longer-form article generation, we must understand the planning steps humans make before writing. We explore one kind of planning, source-selection in news, as a case-study for evaluating plans in long-form generation. We ask: why do _specific_ stories call for _specific_ kinds of sources? We imagine a generative process for story writing where a source-selection schema is first selected by a journalist, and then sources are chosen based on categories in that schema. Learning the article\u2019s _plan_ means predicting the schema initially chosen by the journalist. Working with professional journalists, we adapt five existing schemata and introduce three new ones to describe journalistic plans for the inclusion of sources in documents. Then, inspired by Bayesian latent-variable modeling, we develop metrics to select the most likely plan, or schema, underlying a story, which we use to compare schemata. We find that two schemata: _stance_ and _social affiliation_ best explain source plans in most documents. However, other schemata like _textual entailment_ explain source plans in factually rich topics like \u201cScience\u201d. Finally, we find we can predict the most suitable schema given just the article\u2019s headline with reasonable accuracy. We see this as an important case-study for human planning, and provides a framework and approach for evaluating other kinds of plans, like discourse or plot-oriented plans. We release a corpora, _NewsSources_, with annotations for 4M articles, for further study.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.930",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM generated responses to mitigate the impact of hate speech": {
        "type": "INPROCEEDINGS",
        "key": "podolak-etal-2024-llm",
        "author": "Podolak, Jakub and \u0141ukasik, Szymon and Balawender, Pawe\u0142 and Ossowski, Jan and Piotrowski, Jan and Bakowicz, Katarzyna and Sankowski, Piotr",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM generated responses to mitigate the impact of hate speech",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this study, we explore the use of Large Language Models (LLMs) to counteract hate speech. We conducted the first real-life A/B test assessing the effectiveness of LLM-generated counter-speech. During the experiment, we posted 753 automatically generated responses aimed at reducing user engagement under tweets that contained hate speech toward Ukrainian refugees in Poland.Our work shows that interventions with LLM-generated responses significantly decrease user engagement, particularly for original tweets with at least ten views, reducing it by over 20%. This paper outlines the design of our automatic moderation system, proposes a simple metric for measuring user engagement and details the methodology of conducting such an experiment. We discuss the ethical considerations and challenges in deploying generative AI for discourse moderation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.931",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Locally Measuring Cross-lingual Lexical Alignment: A Domain and Word Level Perspective": {
        "type": "INPROCEEDINGS",
        "key": "karidi-etal-2024-locally",
        "author": "Karidi, Taelin and Grossman, Eitan and Abend, Omri",
        "booktitle": "EMNLP-findings2024",
        "title": "Locally Measuring Cross-lingual Lexical Alignment: A Domain and Word Level Perspective",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "NLP research on aligning lexical representation spaces to one another has so far focused on aligning language spaces in their entirety. However, cognitive science has long focused on a local perspective, investigating whether translation equivalents truly share the same meaning or the extent that cultural and regional influences result in meaning variations. With recent technological advances and the increasing amounts of available data, the longstanding question of cross-lingual lexical alignment can now be approached in a more data-driven manner. However, developing metrics for the task requires some methodology for comparing metric efficacy. We address this gap and present a methodology for analyzing both synthetic validations and a novel naturalistic validation using lexical gaps in the kinship domain.We further propose new metrics, hitherto unexplored on this task, based on contextualized embeddings. Our analysis spans 16 diverse languages, demonstrating that there is substantial room for improvement with the use of newer language models. Our research paves the way for more accurate and nuanced cross-lingual lexical alignment methodologies and evaluation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.932",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "yang-etal-2024-sasr",
        "author": "Yang, Tianyu and Nan, Yiyang and Dai, Lisen and Liang, Zhenwen and Tian, Yapeng and Zhang, Xiangliang",
        "booktitle": "EMNLP-findings2024",
        "title": "SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Audio-Visual Question Answering (AVQA) is a challenging task that involves answering questions based on both auditory and visual information in videos. A significant challenge is interpreting complex multi-modal scenes, which include both visual objects and sound sources, and connecting them to the given question. In this paper, we introduce the Source-aware Semantic Representation Network (SaSR-Net), a novel model designed for AVQA. SaSR-Net utilizes source-wise learnable tokens to efficiently capture and align audio-visual elements with the corresponding question. It streamlines the fusion of audio and visual information using spatial and temporal attention mechanisms to identify answers in multi-modal scenes. Extensive experiments on the Music-AVQA and AVQA-Yang datasets show that SaSR-Net outperforms state-of-the-art AVQA methods. We will release our source code and pre-trained models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.933",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Grounding Partially-Defined Events in Multimodal Data": {
        "type": "INPROCEEDINGS",
        "key": "sanders-etal-2024-grounding",
        "author": "Sanders, Kate and Kriz, Reno and Etter, David and Recknor, Hannah and Martin, Alexander and Carpenter, Cameron and Lin, Jingyang and Van Durme, Benjamin",
        "booktitle": "EMNLP-findings2024",
        "title": "Grounding Partially-Defined Events in Multimodal Data",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "How are we able to learn about complex current events just from short snippets of video? While natural language enables straightforward ways to represent under-specified, partially observable events, visual data does not facilitate analogous methods and, consequently, introduces unique challenges in event understanding. With the growing prevalence of vision-capable AI agents, these systems must be able to model events from collections of unstructured video data. To tackle robust event modeling in multimodal settings, we introduce a multimodal formulation for partially-defined events and cast the extraction of these events as a three-stage span retrieval task. We propose a corresponding benchmark for this task, MultiVENT-G, that consists of 14.5 hours of densely annotated current event videos and 1,168 text documents, containing 22.8K labeled event-centric entities. We propose a collection of LLM-driven approaches to the task of multimodal event analysis, and evaluate them on MultiVENT-G. Results illustrate the challenges that abstract event understanding poses and demonstrates promise in event-centric video-language systems.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.934",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "How Does Quantization Affect Multilingual LLMs?": {
        "type": "INPROCEEDINGS",
        "key": "marchisio-etal-2024-quantization",
        "author": "Marchisio, Kelly and Dash, Saurabh and Chen, Hongyu and Aumiller, Dennis and \u00dcst\u00fcn, Ahmet and Hooker, Sara and Ruder, Sebastian",
        "booktitle": "EMNLP-findings2024",
        "title": "How Does Quantization Affect Multilingual LLMs?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Quantization techniques are widely used to improve inference speed and deployment of large language models. While a wide body of work examines the impact of quantization on LLMs in English, none have evaluated across languages. We conduct a thorough analysis of quantized multilingual LLMs, focusing on performance across languages and at varying scales. We use automatic benchmarks, LLM-as-a-Judge, and human evaluation, finding that (1) harmful effects of quantization are apparent in human evaluation, which automatic metrics severely underestimate: a 1.7% average drop in Japanese across automatic tasks corresponds to a 16.0% drop reported by human evaluators on realistic prompts; (2) languages are disparately affected by quantization, with non-Latin script languages impacted worst; and (3) challenging tasks like mathematical reasoning degrade fastest. As the ability to serve low-compute models is critical for wide global adoption of NLP technologies, our results urge consideration of multilingual performance as a key evaluation criterion for efficient models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.935",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution": {
        "type": "INPROCEEDINGS",
        "key": "maheshwari-etal-2024-presentations",
        "author": "Maheshwari, Himanshu and Bandyopadhyay, Sambaran and Garimella, Aparna and Natarajan, Anandhavelu",
        "booktitle": "EMNLP-findings2024",
        "title": "Presentations are not always linear! GNN meets LLM for Text Document-to-Presentation Transformation with Attribution",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Automatically generating a presentation from the text of a long document is a challenging and useful problem. In contrast to a flat summary, a presentation needs to have a better and non-linear narrative, i.e., the content of a slide can come from different and non-contiguous parts of the given document. However, it is difficult to incorporate such non-linear mapping of content to slides and ensure that the content is faithful to the document. LLMs are prone to hallucination and their performance degrades with the length of the input document. Towards this, we propose a novel graph based solution where we learn a graph from the input document and use a combination of graph neural network and LLM to generate a presentation with attribution of content for each slide. We conduct thorough experiments to show the merit of our approach compared to directly using LLMs for this task.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.936",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Domain Adaptation via Prompt Learning for Alzheimer\u2019s Detection": {
        "type": "INPROCEEDINGS",
        "key": "farzana-parde-2024-domain",
        "author": "Farzana, Shahla and Parde, Natalie",
        "booktitle": "EMNLP-findings2024",
        "title": "Domain Adaptation via Prompt Learning for Alzheimer\u2019s Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Spoken language presents a compelling medium for non-invasive Alzheimer\u2019s disease (AD) screening, and prior work has examined the use of fine-tuned pretrained language models (PLMs) for this purpose. However, PLMs are often optimized on tasks that are inconsistent with AD classification. Spoken language corpora for AD detection are also small and disparate, making generalizability difficult. This paper investigates the use of domain-adaptive prompt fine-tuning for AD detection, using AD classification loss as the training objective and leveraging spoken language corpora from a variety of language tasks. Extensive experiments using voting-based combinations of different prompting paradigms show an impressive mean detection F1=0.8952 (with std=0.01 and best F1=0.9130) for the highest-performing approach when using BERT as the base PLM.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.937",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-spinach",
        "author": "Liu, Shicheng and Semnani, Sina and Triedman, Harold and Xu, Jialiang and Zhao, Isaac Dan and Lam, Monica",
        "booktitle": "EMNLP-findings2024",
        "title": "SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have led to significant improvements in the Knowledge Base Question Answering (KBQA) task. However, datasets used in KBQA studies do not capture the true complexity of KBQA tasks. They either have simple questions, use synthetically generated logical forms, or are based on small knowledge base (KB) schemas.We introduce the SPINACH dataset, an expert-annotated KBQA dataset collected from discussions on Wikidata\u2019s \u201cRequest a Query\u201d forum with 320 decontextualized question-SPARQL pairs. The complexity of these in-the-wild queries calls for a KBQA system that can dynamically explore large and often incomplete schemas and reason about them, as it is infeasible to create a comprehensive training dataset. We also introduce an in-context learning KBQA agent, also called SPINACH, that mimics how a human expert would write SPARQLs to handle challenging questions. SPINACH achieves a new state of the art on the QALD-7, QALD-9 Plus and QALD-10 datasets by 31.0%, 27.0%, and 10.0% in F\u2081, respectively, and coming within 1.6% of the fine-tuned LLaMA SOTA model on WikiWebQuestions.On our new SPINACH dataset, the SPINACH agent outperforms all baselines, including the best GPT-4-based KBQA agent, by at least 38.1% in F\u2081.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.938",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models": {
        "type": "INPROCEEDINGS",
        "key": "lin-etal-2024-navigating-noisy",
        "author": "Lin, Muhan and Shi, Shuyang and Guo, Yue and Chalaki, Behdad and Tadiparthi, Vaishnav and Moradi Pari, Ehsan and Stepputtis, Simon and Campbell, Joseph and Sycara, Katia P.",
        "booktitle": "EMNLP-findings2024",
        "title": "Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The correct specification of reward models is a well-known challenge in reinforcement learning.Hand-crafted reward functions often lead to inefficient or suboptimal policies and may not be aligned with user values.Reinforcement learning from human feedback is a successful technique that can mitigate such issues, however, the collection of human feedback can be laborious.Recent works have solicited feedback from pre-trained large language models rather than humans to reduce or eliminate human effort, however, these approaches yield poor performance in the presence of hallucination and other errors.This paper studies the advantages and limitations of reinforcement learning from large language model feedback and proposes a simple yet effective method for soliciting and applying feedback as a potential-based shaping function.We theoretically show that inconsistent rankings \u2013 which approximate ranking errors \u2013 lead to uninformative rewards with our approach. Our method empirically improves convergence speed and policy returns over commonly used baselines even with significant ranking errors, and eliminates the need for complex post-processing of reward functions.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.939",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization": {
        "type": "INPROCEEDINGS",
        "key": "lin-etal-2024-limited",
        "author": "Lin, Yong and Seto, Skyler and Ter Hoeve, Maartje and Metcalf, Katherine and Theobald, Barry-John and Wang, Xuan and Zhang, Yizhe and Huang, Chen and Zhang, Tong",
        "booktitle": "EMNLP-findings2024",
        "title": "On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) is an effective approach for aligning language models to human preferences. Central to RLHF is learning a reward function for scoring human preferences. Two main approaches for learning a reward model are 1) training an EXplicit Reward Model (EXRM) as in RLHF, and 2) using an implicit reward learned from preference data through methods such as Direct Preference Optimization (DPO). Prior work has shown that the implicit reward model of DPO (denoted as DPORM) can approximate an EXRM on the limit infinite samples. However, it is unclear how effective is DPORM in practice. DPORM\u2019s effectiveness directly implies the optimality of learned policy of DPO and also has practical implication for more advanced alignment methods, such as iterative DPO. We compare the accuracy at distinguishing preferred and rejected answers using both DPORM and EXRM. Our findings indicate that even though DPORM can fit the training dataset, it generalizes less effective than EXRM, especially when the validation datasets contain distributional shifts. Across five out-of-distribution settings, DPORM has a mean drop in accuracy of 3% and a maximum drop of 7%. These findings highlight that DPORM has limited generalization ability and substantiates the integration of an explicit reward model in iterative DPO approaches.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.940",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Gazelle: An Instruction Dataset for Arabic Writing Assistance": {
        "type": "INPROCEEDINGS",
        "key": "magdy-etal-2024-gazelle",
        "author": "Magdy, Samar Mohamed and Alwajih, Fakhraddin and Kwon, Sang Yun and Abdel-Salam, Reem and Abdul-Mageed, Muhammad",
        "booktitle": "EMNLP-findings2024",
        "title": "Gazelle: An Instruction Dataset for Arabic Writing Assistance",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Writing has long been considered a hallmark of human intelligence and remains a pinnacle task for artificial intelligence (AI) due to the intricate cognitive processes involved. Recently, rapid advancements in generative AI, particularly through the development of Large Language Models (LLMs), have significantly transformed the landscape of writing assistance. However, underrepresented languages like Arabic encounter significant challenges in the development of advanced AI writing tools, largely due to the limited availability of data. This scarcity constrains the training of effective models, impeding the creation of sophisticated writing assistance technologies. To address these issues, we present *Gazelle*, a comprehensive dataset for Arabic writing assistance. In addition, we offer an evaluation framework designed to enhance Arabic writing assistance tools. Our human evaluation of leading LLMs, including GPT-**4**, GPT-**4o**, Cohere Command R+, and Gemini **1.5** Pro, highlights their respective strengths and limitations in addressing the challenges of Arabic writing. Our findings underscore the need for continuous model training and dataset enrichment to manage the complexities of Arabic language processing, paving the way for more effective AI-powered Arabic writing tools",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.941",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Extrinsic Evaluation of Cultural Competence in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "bhatt-diaz-2024-extrinsic",
        "author": "Bhatt, Shaily and Diaz, Fernando",
        "booktitle": "EMNLP-findings2024",
        "title": "Extrinsic Evaluation of Cultural Competence in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Productive interactions between diverse users and language technologies require outputs from the latter to be culturally relevant and sensitive. Prior works have evaluated models\u2019 knowledge of cultural norms, values, and artefacts, without considering how this knowledge manifests in downstream applications. In this work, we focus on extrinsic evaluation of cultural competence in two text generation tasks, open-ended question answering and story generation. We quantitatively and qualitatively evaluate model outputs when an explicit cue of culture, specifically nationality, is perturbed in the prompts. Although we find that model outputs do vary when varying nationalities and feature culturally relevant words, we also find weak correlations between text similarity of outputs for different countries and the cultural values of these countries. Finally, we discuss important considerations in designing comprehensive evaluation of cultural competence in user-facing tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.942",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation": {
        "type": "INPROCEEDINGS",
        "key": "dale-costa-jussa-2024-blaser",
        "author": "Dale, David and Costa-juss\u00e0, Marta R.",
        "booktitle": "EMNLP-findings2024",
        "title": "BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We present BLASER 2.0, an automatic metric of machine translation quality which supports both speech and text modalities. Compared to its predecessor BLASER (Chen et al., 2023), BLASER 2.0 is based on better underlying text and speech representations that cover 202 text languages and 57 speech ones and extends the training data. BLASER 2.0 comes in two varieties: a reference-based and a reference-free (quality estimation) model. We demonstrate that the reference-free version is applicable not only at the dataset level, for evaluating the overall model performance, but also at the sentence level, for scoring individual translations. In particular, we show its applicability for detecting translation hallucinations and filtering training datasets to obtain more reliable translation models. The BLASER 2.0 models are publicly available at https://github.com/facebookresearch/sonar.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.943",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multi-label Sequential Sentence Classification via Large Language Model": {
        "type": "INPROCEEDINGS",
        "key": "lan-etal-2024-multi",
        "author": "Lan, Mengfei and Zheng, Lecheng and Ming, Shufan and Kilicoglu, Halil",
        "booktitle": "EMNLP-findings2024",
        "title": "Multi-label Sequential Sentence Classification via Large Language Model",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Sequential sentence classification (SSC) in scientific publications is crucial for supporting downstream tasks such as fine-grained information retrieval and extractive summarization. However, current SSC methods are constrained by model size, sequence length, and single-label setting. To address these limitations, this paper proposes LLM-SSC, a large language model (LLM)-based framework for both single- and multi-label SSC tasks. Unlike previous approaches that employ small- or medium-sized language models, the proposed framework utilizes LLMs to generate SSC labels through designed prompts, which enhance task understanding by incorporating demonstrations and a query to describe the prediction target. We also present a multi-label contrastive learning loss with auto-weighting scheme, enabling the multi-label classification task. To support our multi-label SSC analysis, we introduce and release a new dataset, biorc800, which mainly contains unstructured abstracts in the biomedical domain with manual annotations. Experiments demonstrate LLM-SSC\u2019s strong performance in SSC under both in-context learning and task-specific tuning settings. We release biorc800 and our code at: https://github.com/ScienceNLP-Lab/LLM-SSC.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.944",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants": {
        "type": "INPROCEEDINGS",
        "key": "ferreira-etal-2024-multi",
        "author": "Ferreira, Rafael and Semedo, David and Magalhaes, Joao",
        "booktitle": "EMNLP-findings2024",
        "title": "Multi-trait User Simulation with Adaptive Decoding for Conversational Task Assistants",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Conversational systems must be robust to user interactions that naturally exhibit diverse conversational traits. Capturing and simulating these diverse traits coherently and efficiently presents a complex challenge. This paper introduces Multi-Trait Adaptive Decoding (mTAD), a method that generates diverse user profiles at decoding-time by sampling from various trait-specific Language Models (LMs). mTAD provides an adaptive and scalable approach to user simulation, enabling the creation of multiple user profiles without the need for additional fine-tuning. By analyzing real-world dialogues from the Conversational Task Assistant (CTA) domain, we identify key conversational traits and developed a framework to generate profile-aware dialogues that enhance conversational diversity. Experimental results validate the effectiveness of our approach in modeling single-traits using specialized LMs, which can capture less common patterns, even in out-of-domain tasks. Furthermore, the results demonstrate that mTAD is a robust and flexible framework for combining diverse user simulators.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.945",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation": {
        "type": "INPROCEEDINGS",
        "key": "qian-etal-2024-varbench",
        "author": "Qian, Kun and Wan, Shunji and Tang, Claudia and Wang, Youzhi and Zhang, Xuanming and Chen, Maximillian and Yu, Zhou",
        "booktitle": "EMNLP-findings2024",
        "title": "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As large language models achieve impressive scores on traditional benchmarks, an increasing number of researchers are becoming concerned about benchmark data leakage during pre-training, commonly known as the data contamination problem. To ensure fair evaluation, recent benchmarks release only the training and validation sets, keeping the test set labels closed-source. They require anyone wishing to evaluate his language model to submit the model\u2019s predictions for centralized processing and then publish the model\u2019s result on their leaderboard. However, this submission process is inefficient and prevents effective error analysis. To address this issue, we propose to variabilize benchmarks and evaluate language models dynamically. Specifically, we extract variables from each test case and define a value range for each variable. For each evaluation, we sample new values from these value ranges to create unique test cases, thus ensuring a fresh evaluation each time. We applied this variable perturbation method to four datasets: GSM8K, ARC, CommonsenseQA, and TruthfulQA, which cover mathematical generation and multiple-choice tasks. Our experimental results demonstrate that this approach provides a more accurate assessment of the true capabilities of language models, effectively mitigating the contamination problem.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.946",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing": {
        "type": "INPROCEEDINGS",
        "key": "fayyazsanavi-etal-2024-gloss2text",
        "author": "Fayyazsanavi, Pooya and Anastasopoulos, Antonios and Kosecka, Jana",
        "booktitle": "EMNLP-findings2024",
        "title": "Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Sign language translation from video to spoken text presents unique challenges owing to the distinct grammar, expression nuances, and high variation of visual appearance across different speakers and contexts. Gloss annotations serve as an intermediary to guide the translation process. In our work, we focus on Gloss2Text translation stage and propose several advances by leveraging pre-trained large language models (LLMs), data augmentation, and novel label-smoothing loss function exploiting gloss translation ambiguities improving significantly the performance of state-of-the-art approaches. Through extensive experiments and ablation studies on the PHOENIX Weather 2014T dataset, our approach surpasses state-of-the-art performance in Gloss2Text translation, indicating its efficacy in addressing sign language translation and suggesting promising avenues for future research and development.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.947",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations": {
        "type": "INPROCEEDINGS",
        "key": "sultan-etal-2024-structured",
        "author": "Sultan, Md Arafat and Ganhotra, Jatin and Astudillo, Ram\u00f3n Fernandez",
        "booktitle": "EMNLP-findings2024",
        "title": "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We introduce a structured chain-of-thought (SCoT) prompting approach to generating content-grounded multi-turn question-answer conversations with a pre-trained large language model (LLM). At the core of our proposal is a structured breakdown of the complex task into a number of states in a state machine, so that actions corresponding to various subtasks, e.g., content reading and utterance generation, can be executed in their own dedicated states. Each state leverages a unique set of resources, including prompts and (optionally) additional tools, to augment the generation process. Automatic evaluation shows that SCoT prompting with designated states for hallucination mitigation can increase agent faithfulness to grounding documents by up to 16.8%. When used as training data, our open-domain conversations synthesized from only 6 Wikipedia-based seed demonstrations train strong conversational QA agents. In out-of-domain evaluation, for example, we observe improvements of up to 13.9% in F1-score against ground truth over target domain gold data when the latter is augmented with our generated examples.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.948",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Gradient Localization Improves Lifelong Pretraining of Language Models": {
        "type": "INPROCEEDINGS",
        "key": "fernandez-etal-2024-gradient",
        "author": "Fernandez, Jared and Bisk, Yonatan and Strubell, Emma",
        "booktitle": "EMNLP-findings2024",
        "title": "Gradient Localization Improves Lifelong Pretraining of Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) trained on web-scale text corpora have been shown to capture world knowledge in their parameters. However, the mechanism by which language models store different types of knowledge is poorly understood. In this work, we examine two types of knowledge relating to temporally sensitive entities and demonstrate that each type is localized to different sets of parameters within the LLMs. We hypothesize that the lack of consideration of the locality of knowledge in existing continual learning methods contributes to both: the failed uptake of new information, and catastrophic forgetting of previously learned information. We observe that sequences containing references to updated and newly mentioned entities exhibit larger gradient norms in a subset of layers. We demonstrate that targeting parameter updates to these relevant layers can improve the performance of continually pretraining on language containing temporal drift.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.949",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PFA-ERC: Psuedo-Future Augmented Dynamic Emotion Recognition in Conversations": {
        "type": "INPROCEEDINGS",
        "key": "khule-etal-2024-pfa",
        "author": "Khule, Tanmay and Agrawal, Rishabh and Narayan, Apurva",
        "booktitle": "EMNLP-findings2024",
        "title": "PFA-ERC: Psuedo-Future Augmented Dynamic Emotion Recognition in Conversations",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "AI systems\u2019 ability to interpret human emotions and adapt to variations is becoming more crucial as AI gets embedded into everyone\u2019s daily lives. Emotion Recognition in Conversations (ERC) is based on this fundamental challenge. Current state-of-the-art technologies in ERC are limited due to the need for future information. We introduce High-Dimensional Temporal Fusion Transformer (HiTFT), a time-series forecasting transformer that predicts pseudo-future information to overcome this constraint. This retains the models\u2019 dynamic nature and provides future information more efficiently than other methods. Our proposed method combines pseudo future embeddings with an encoder that models the speaker\u2019s emotional state using past and pseudo-future information as well as inter and intra speaker interactions; these speaker states are then passed through a decoder block that predicts the inferred emotion of that utterance. We further evaluate our method and show that it achieves state of the art performance on three ERC datasets - MELD, EmoryNLP, and IEMOCap.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.950",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Textless Speech-to-Speech Translation With Limited Parallel Data": {
        "type": "INPROCEEDINGS",
        "key": "diwan-etal-2024-textless",
        "author": "Diwan, Anuj and Srinivasan, Anirudh and Harwath, David and Choi, Eunsol",
        "booktitle": "EMNLP-findings2024",
        "title": "Textless Speech-to-Speech Translation With Limited Parallel Data",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing speech-to-speech translation (S2ST) models fall into two camps: they either leverage text as an intermediate step or require hundreds of hours of parallel speech data. Both approaches are incompatible with textless languages or language pairs with limited parallel data. We present PFB, a framework for training textless S2ST models that require just dozens of hours of parallel speech data. We first pretrain a model on large-scale monolingual speech data, finetune it with a small amount of parallel speech data (20-60 hours), and lastly train with an unsupervised backtranslation objective. We train and evaluate our models for English-to-German, German-to-English and Marathi-to-English translation on three different domains (European Parliament, Common Voice, and All India Radio) with single-speaker synthesized speech. Evaluated using the ASR-BLEU metric, our models achieve reasonable performance on all three domains, with some being within 1-2 points of our higher-resourced topline.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.951",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "The Overlooked Repetitive Lengthening Form in Sentiment Analysis": {
        "type": "INPROCEEDINGS",
        "key": "wang-dragut-2024-overlooked",
        "author": "Wang, Lei and Dragut, Eduard",
        "booktitle": "EMNLP-findings2024",
        "title": "The Overlooked Repetitive Lengthening Form in Sentiment Analysis",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Individuals engaging in online communication frequently express personal opinions with informal styles (e.g., memes and emojis). While Language Models (LMs) with informal communications have been widely discussed, a unique and emphatic style, the Repetitive Lengthening Form (RLF), has been overlooked for years. In this paper, we explore answers to two research questions: 1) Is RLF important for SA? 2) Can LMs understand RLF? Inspired by previous linguistic research, we curate **Lengthening**, the first multi-domain dataset with 850k samples focused on RLF for sentiment analysis. Moreover, we introduce **Explnstruct**, a two-stage Explainable Instruction Tuning framework aimed at improving both the performance and explainability of LLMs for RLF. We further propose a novel unified approach to quantify LMs\u2019 understanding of informal expressions. We show that RLF sentences are expressive expressions and can serve as signatures of document-level sentiment. Additionally, RLF has potential value for online content analysis. Our comprehensive results show that fine-tuned Pre-trained Language Models (PLMs) can surpass zero-shot GPT-4 in performance but not in explanation for RLF. Finally, we show ExpInstruct can improve the open-sourced LLMs to match zero-shot GPT-4 in performance and explainability for RLF with limited samples. Code and sample data are available at https://github.com/Tom-Owl/OverlookedRLF",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.952",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "beniwal-etal-2024-remember",
        "author": "Beniwal, Himanshu and Patel, Dishant and D, Kowsik Nandagopan and Ladia, Hritik and Yadav, Ankit and Singh, Mayank",
        "booktitle": "EMNLP-findings2024",
        "title": "Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) are increasingly ubiquitous, yet their ability to retain and reason about temporal information remains limited, hindering their application in real-world scenarios where understanding the sequential nature of events is crucial. Our study experiments with 12 state-of-the-art models (ranging from 2B to 70B+ parameters) on a novel numerical-temporal dataset, TempUN, spanning from 10,000 BCE to 2100 CE, to uncover significant temporal retention and comprehension limitations. We propose six metrics to assess three learning paradigms to enhance temporal knowledge acquisition. Our findings reveal that open-source models exhibit knowledge gaps more frequently, suggesting a trade-off between limited knowledge and incorrect responses. Additionally, various fine-tuning approaches significantly improved performance, reducing incorrect outputs and impacting the identification of \u2018information not available\u2019 in the generations. The associated dataset and code are available at the [URL](https://anonymous.4open.science/r/TempUN-ARR/).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.953",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "subramanian-etal-2024-hop",
        "author": "Subramanian, Shreyas and Ganapathiraman, Vignesh and Barrett, Corey D.",
        "booktitle": "EMNLP-findings2024",
        "title": "Hop, skip, jump to Convergence: Dynamics of Learning Rate Transitions for Improved Training of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Various types of learning rate (LR) schedulers are being used for training or fine tuning of Large Language Models today. In practice, several mid-flight changes are required in the LR schedule either manually, or with careful choices around warmup steps, peak LR, type of decay and restarts. To study this further, we consider the effect of switching the learning rate at a predetermined time during training, which we refer to as \u201cSkipLR\u201d. We model SGD as a stochastic gradient flow and show that when starting from the same initial parameters, switching the learning rate causes the loss curves to contract towards each other. We demonstrate this theoretically for some simple cases, and empirically on large language models. Our analysis provides insight into how learning rate schedules affect the training dynamics, and could inform the design of new schedules to accelerate convergence.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.954",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "FactAlign: Long-form Factuality Alignment of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "huang-chen-2024-factalign",
        "author": "Huang, Chao-Wei and Chen, Yun-Nung",
        "booktitle": "EMNLP-findings2024",
        "title": "FactAlign: Long-form Factuality Alignment of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models have demonstrated significant potential as the next-generation information access engines. However, their reliability is hindered by issues of hallucination and generating non-factual content. This is particularly problematic in long-form responses, where assessing and ensuring factual accuracy is complex. In this paper, we address this gap by proposing FactAlign, a novel alignment framework designed to enhance the factuality of LLMs\u2019 long-form responses while maintaining their helpfulness. We introduce fKTO, a fine-grained, sentence-level alignment algorithm that extends the Kahneman-Tversky Optimization (KTO) alignment method. Leveraging recent advances in automatic factuality evaluation, FactAlign utilizes fine-grained factuality assessments to guide the alignment process. Our experiments on open-domain prompts and information-seeking questions demonstrate that FactAlign significantly improves the factual accuracy of LLM responses while also improving their helpfulness. Further analyses identify that FactAlign is capable of training LLMs to provide more information without losing factual precision, thus improving the factual F1 score. Our source code, datasets, and trained models are publicly available at https://github.com/MiuLab/FactAlign",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.955",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation": {
        "type": "INPROCEEDINGS",
        "key": "lv-etal-2024-hyperlora",
        "author": "Lv, Chuancheng and Li, Lei and Zhang, Shitou and Chen, Gang and Qi, Fanchao and Zhang, Ningyu and Zheng, Hai-Tao",
        "booktitle": "EMNLP-findings2024",
        "title": "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Adapting pre-trained language models (PLMs) for cross-task generalization is a crucial research area within the field of NLP. While fine-tuning and in-context learning are effective approaches for adapting LMs to emerging tasks, they can be costly and inefficient. Recently, some researchers have focused on achieving efficient task adaptation via hypernetwork, which is a meta network that generates task-specific weights based on task-oriented information without any optimization. However, the training of hypernetworks often lacks stability since the optimization signal is not straightforward, and the task information is not adequately representative. Moreover, previous works train hypenetworks with the general corpus, which is struggling with few-shot adaptation. To address these issues, we introduce HyperLoRA, a hypernetwork for LoRA parameters generation involving hypernetwork pre-training on instruction-following data and generalization fine-tuning on sparse task data. Furthermore, we utilize a constrained training loss and a gradient-based demonstration selection strategy to enhance the training stability and performance. Experimental results and analysis across four benchmark datasets (P3, S-NI, BBH, and SuperGLUE) demonstrate the proposed approach has flexible generalization ability and superior performance.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.956",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Inference and Verbalization Functions During In-Context Learning": {
        "type": "INPROCEEDINGS",
        "key": "tao-etal-2024-inference",
        "author": "Tao, Junyi and Chen, Xiaoyin and Liu, Nelson F.",
        "booktitle": "EMNLP-findings2024",
        "title": "Inference and Verbalization Functions During In-Context Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LMs) are capable of in-context learning from a few demonstrations (example-label pairs) to solve new tasks during inference. Despite the intuitive importance of high-quality demonstrations, previous work has observed that, in some settings, ICL performance is minimally affected by irrelevant labels (Min et al., 2022). We hypothesize that LMs perform ICL with irrelevant labels via two sequential processes: an inference function that solves the task, followed by a verbalization function that maps the inferred answer to the label space. Importantly, we hypothesize that the inference function is invariant to remappings of the label space (e.g., \u201ctrue\u201d/\u201cfalse\u201d to \u201ccat\u201d/\u201cdog\u201d), enabling LMs to share the same inference function across settings with different label words. We empirically validate this hypothesis with controlled layer-wise interchange intervention experiments. Our findings confirm the hypotheses on multiple datasets and tasks (natural language inference, sentiment analysis, and topic classification) and further suggest that the two functions can be localized in specific layers across various open-sourced models, including GEMMA-7B, MISTRAL-7B-V0.3, GEMMA-2-27B, and LLAMA-3.1-70B.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.957",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction": {
        "type": "INPROCEEDINGS",
        "key": "wang-huang-2024-debate",
        "author": "Wang, Sijia and Huang, Lifu",
        "booktitle": "EMNLP-findings2024",
        "title": "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "We propose a multi-agent debate as optimization (DAO) system for event extraction, where the primary objective is to iteratively refine the large language models (LLMs) outputs through debating without parameter tuning. In DAO, we introduce two novel modules: the Diverse-RAG (DRAG) module and the Adaptive Conformal Prediction (AdaCP) module. DRAG systematically retrieves supporting information that best fits the debate discussion, while AdaCP enhances the accuracy and reliability of event extraction by effectively rejecting less promising answers. Experimental results demonstrate a significant reduction in the performance gap between supervised approaches and tuning-free LLM-based methods by 18.1% and 17.8% on ACE05 and 17.9% and 15.2% on CASIE for event detection and argument extraction respectively.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.958",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MiRAGeNews: Multimodal Realistic AI-Generated News Detection": {
        "type": "INPROCEEDINGS",
        "key": "huang-etal-2024-miragenews",
        "author": "Huang, Runsheng and Dugan, Liam and Yang, Yue and Callison-Burch, Chris",
        "booktitle": "EMNLP-findings2024",
        "title": "MiRAGeNews: Multimodal Realistic AI-Generated News Detection",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The proliferation of inflammatory or misleading \u201cfake\u201d news content has become increasingly common in recent years. Simultaneously, it has become easier than ever to use AI tools to generate photorealistic images depicting any scene imaginable. Combining these two\u2014AI-generated fake news content\u2014is particularly potent and dangerous. To combat the spread of AI-generated fake news, we propose the MiRAGeNews Dataset, a dataset of 12,500 high-quality real and AI-generated image-caption pairs from state-of-the-art generators. We find that our dataset poses a significant challenge to humans (60% F-1) and state-of-the-art multi-modal LLMs (\\textless 24% F-1). Using our dataset we train a multi-modal detector (MiRAGe) that improves by +5.1% F-1 over state-of-the-art baselines on image-caption pairs from out-of-domain image generators and news publishers. We release our code and data to aid future work on detecting AI-generated content.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.959",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective": {
        "type": "INPROCEEDINGS",
        "key": "chen-etal-2024-quantifying",
        "author": "Chen, Meiqi and Cao, Yixin and Zhang, Yan and Lu, Chaochao",
        "booktitle": "EMNLP-findings2024",
        "title": "Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent advancements in Large Language Models (LLMs) have facilitated the development of Multimodal LLMs (MLLMs). Despite their impressive capabilities, MLLMs often suffer from over-reliance on unimodal biases (e.g., language bias and vision bias), leading to incorrect answers in complex multimodal tasks. To investigate this issue, we propose a causal framework to interpret the biases in Visual Question Answering (VQA) problems. Within this framework, we conduct an in-depth causal analysis to assess the causal effect of these biases on MLLM predictions. Based on the analysis, we introduce 1) a novel MORE dataset with 12,000 challenging VQA instances requiring multi-hop reasoning and overcoming unimodal biases. 2) a causality-enhanced agent framework CAVE that guides models to comprehensively integrate information from different modalities and mitigate biases. Our experiments show that MLLMs perform poorly on MORE, indicating strong unimodal biases and limited semantic understanding. However, when integrated with our CAVE, promising improvements in reasoning and bias mitigation can be seen. These findings provide important insights for the development of more robust MLLMs and contribute to the broader goal of advancing multimodal AI systems capable of deeper understanding and reasoning. Our project page is at https://github.com/OpenCausaLab/MORE.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.960",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Large Language Models are In-context Teachers for Knowledge Reasoning": {
        "type": "INPROCEEDINGS",
        "key": "zhao-etal-2024-large-language",
        "author": "Zhao, Jiachen and Yao, Zonghai and Yang, Zhichao and Yu, Hong",
        "booktitle": "EMNLP-findings2024",
        "title": "Large Language Models are In-context Teachers for Knowledge Reasoning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this work, we study in-context teaching(ICT), where a teacher provides in-context example rationales to teach a student to reasonover unseen cases. Human teachers are usually required to craft in-context demonstrations, which are costly and have high variance. We ask whether a large language model (LLM) can serve as a more effective in-context teacher for itself or otherLLMs, compared to humans. Inspired by the Encoding Specificity Hypothesis from human episodic memory, we hypothesize thatin-context exemplars crafted by the teacher should match the training data of the student. This hypothesis motivates us to propose Self-Explain where an LLM\u2019s self-elicited explanations are used as in-context demonstrations for prompting it as they are generalized fromthe model\u2019s training examples. Self-Explain is shown to significantly outperform using human-crafted exemplars and other baselines.Furthermore, we reveal that for ICT, rationales from different teacher LLMs or human experts that more resemble the student LLM\u2019s self-explanations are better in-context demonstrations. This supports our encoding specificity hypothesis. We then propose Teach-Back that aligns a teacher LLM with the student to enhance the ICT performance. For example, Teach-Back enables a 7B model to teach the much larger GPT-3.5 in context, surpassing human teachers by around 5% in test accuracy on medical question answering.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.961",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SocialGaze: Improving the Integration of Human Social Norms in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "vijjini-etal-2024-socialgaze",
        "author": "Vijjini, Anvesh Rao and R Menon, Rakesh and Fu, Jiayi and Srivastava, Shashank and Chaturvedi, Snigdha",
        "booktitle": "EMNLP-findings2024",
        "title": "SocialGaze: Improving the Integration of Human Social Norms in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "While much research has explored enhancing the reasoning capabilities of large language models (LLMs) in the last few years, there is a gap in understanding the alignment of these models with social values and norms. We introduce the task of judging social acceptance. Social acceptance requires models to judge and rationalize the acceptability of people\u2019s actions in social situations. For example, is it socially acceptable for a neighbor to ask others in the community to keep their pets indoors at night? We find that LLMs\u2019 understanding of social acceptance is often misaligned with human consensus. To alleviate this, we introduce SocialGaze, a multi-step prompting framework, in which a language model verbalizes a social situation from multiple perspectives before forming a judgment. Our experiments demonstrate that the SocialGaze approach improves the alignment with human judgments by up to 11 F1 points with the GPT-3.5 model. We also identify biases and correlations in LLMs in assigning blame that is related to features such as the gender (males are significantly more likely to be judged unfairly) and age (LLMs are more aligned with humans for older narrators).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.962",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-narrative",
        "author": "Zhang, Xinliang Frederick and Beauchamp, Nicholas and Wang, Lu",
        "booktitle": "EMNLP-findings2024",
        "title": "Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Reasoning about time and temporal relations is an integral aspect of human cognition, essential for perceiving the world and navigating our experiences. Though large language models (LLMs) have demonstrated impressive performance in many reasoning tasks, temporal reasoning remains challenging due to its intrinsic complexity. In this work, we first study an essential task of temporal reasoning\u2014temporal graph generation, to unveil LLMs\u2019 inherent, global reasoning capabilities. We show that this task presents great challenges even for the most powerful LLMs, such as GPT-3.5/4. We also notice a significant performance gap by small models (\\textless 10B) that lag behind LLMs by 50%. Next, we study how to close this gap with a budget constraint, e.g., not using model finetuning. We propose a new prompting technique tailored for temporal reasoning, Narrative-of-Thought (NoT), that first converts the events set to a Python class, then prompts a small model to generate a temporally grounded narrative, guiding the final generation of a temporal graph. Extensive experiments showcase the efficacy of NoT in improving various metrics. Notably, NoT attains the highest F1 on the Schema-11 evaluation set, while securing an overall F1 on par with GPT-3.5. NoT also achieves the best structural similarity across the board, even compared with GPT-3.5/4.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.963",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents": {
        "type": "INPROCEEDINGS",
        "key": "kim-etal-2024-auto",
        "author": "Kim, Jaekyeom and Kim, Dong-Ki and Logeswaran, Lajanugen and Sohn, Sungryull and Lee, Honglak",
        "booktitle": "EMNLP-findings2024",
        "title": "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we introduce Auto-Intent, a method to adapt a pre-trained large language model (LLM) as an agent for a target domain without direct fine-tuning, where we empirically focus on web navigation tasks. Our approach first discovers the underlying intents from target domain demonstrations unsupervisedly, in a highly compact form (up to three words). With the extracted intents, we train our intent predictor to predict the next intent given the agent\u2019s past observations and actions. In particular, we propose a self-exploration approach where top-k probable intent predictions are provided as a hint to the pre-trained LLM agent, which leads to enhanced decision-making capabilities. Auto-Intent substantially improves the performance of GPT-3.5, 4 and Llama-3.1-70B, 405B agents on the large-scale real-website navigation benchmarks from Mind2Web and online navigation tasks from WebArena with its cross-benchmark generalization from Mind2Web.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.964",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning": {
        "type": "INPROCEEDINGS",
        "key": "zheng-etal-2024-see",
        "author": "Zheng, Chengxin and Ji, Junzhong and Shi, Yanzhao and Zhang, Xiaodan and Qu, Liangqiong",
        "booktitle": "EMNLP-findings2024",
        "title": "See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Brain CT report generation is significant to aid physicians in diagnosing cranial diseases.Recent studies concentrate on handling the consistency between visual and textual pathological features to improve the coherence of report.However, there exist some challenges: 1) Redundant visual representing: Massive irrelevant areas in 3D scans distract models from representing salient visual contexts.2) Shifted semantic representing: Limited medical corpus causes difficulties for models to transfer the learned textual representations to generative layers. This study introduces a Pathological Clue-driven Representation Learning (PCRL) model to build cross-modal representations based on pathological clues and naturally adapt them for accurate report generation.Specifically, we construct pathological clues from perspectives of segmented regions, pathological entities, and report themes, to fully grasp visual pathological patterns and learn cross-modal feature representations. To adapt the representations for the text generation task, we bridge the gap between representation learning and report generation by using a unified large language model (LLM) with task-tailored instructions. These crafted instructions enable the LLM to be flexibly fine-tuned across tasks and smoothly transfer the semantic representation for report generation.Experiments demonstrate that our method outperforms previous methods and achieves SoTA performance.Our code is available at https://github.com/Chauncey-Jheng/PCRL-MRG.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.965",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains": {
        "type": "INPROCEEDINGS",
        "key": "han-etal-2024-p",
        "author": "Han, Simeng and Yu, Aaron and Shen, Rui and Qi, Zhenting and Riddell, Martin and Zhou, Wenfei and Qiao, Yujie and Zhao, Yilun and Yavuz, Semih and Liu, Ye and Joty, Shafiq and Zhou, Yingbo and Xiong, Caiming and Radev, Dragomir and Ying, Rex and Cohan, Arman",
        "booktitle": "EMNLP-findings2024",
        "title": "P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Existing methods on understanding the capabilities of LLMs in logical reasoning rely on binary entailment classification or synthetically derived rationales, which are not sufficient for properly assessing model\u2019s capabilities. We present P-FOLIO, a human-annotated dataset consisting of diverse and complex reasoning chains for a set of realistic logical reasoning stories also written by humans. P-FOLIO is collected with an annotation protocol that facilitates humans to annotate well-structured natural language proofs for first-order logic reasoning problems in a step-by-step manner. The number of reasoning steps in P-FOLIO span from 0 to 20. We further use P-FOLIO to evaluate and improve large-language-model (LLM) reasoning capabilities. We evaluate LLM reasoning capabilities at a fine granularity via single-step inference rule classification, with more diverse inference rules of more diverse and higher levels of complexities than previous works. Given that a single model-generated reasoning chain could take a completely different path than the human-annotated one, we sample multiple reasoning chains from a model and use pass@k metrics for evaluating the quality of model-generated reasoning chains. We show that human-written reasoning chains significantly boost the logical reasoning capabilities of LLMs via many-shot prompting and fine-tuning. Furthermore, fine-tuning Llam3-7B on P-FOLIO improves the model performance by 10% or more on three other out-of-domain logical reasoning datasets.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.966",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TRIP NEGOTIATOR: A Travel Persona-aware Reinforced Dialogue Generation Model for Personalized Integrative Negotiation in Tourism": {
        "type": "INPROCEEDINGS",
        "key": "priya-etal-2024-trip",
        "author": "Priya, Priyanshu and Yasheshbhai, Desai Vishesh and Joshi, Ratnesh Kumar and Ramnani, Roshni and Maitra, Anutosh and Sengupta, Shubhashis and Ekbal, Asif",
        "booktitle": "EMNLP-findings2024",
        "title": "TRIP NEGOTIATOR: A Travel Persona-aware Reinforced Dialogue Generation Model for Personalized Integrative Negotiation in Tourism",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "A sophisticated negotiation dialogue system for tourism should engage in negotiations beyond mere price considerations, encompassing various other aspects and amenities inherent in the tourism package. To ensure such tailored interaction, it is imperative to understand the intricacies of traveler preferences, constraints, and expectations. Incorporating these personality facets allows for customizing negotiation strategies, resulting in a more personalized and integrative experience. With this aim, we take a pivotal step in advancing automated dialogue systems for personalized integrative negotiation tasks. We develop DEAL, a pioneering Dialogue datasEt for personALized integrative negotiation task in the tourism domain. Further, we propose TRIP NEGOTIATOR, a novel Travel persona-aware Reinforced dIalogue generation model for Personalized iNtegrative nEGOTIATion within the tOuRism domain. TRIP NEGOTIATOR is built to discern the traveler\u2019s persona and intent, systematically adjusts negotiation strategies, and directs the negotiation toward a pertinent phase to ensure effective negotiation. Through reinforcement learning with Proximal Policy Optimization (PPO), we guide TRIP NEGOTIATOR to generate coherent and diverse responses consistent with the traveler\u2019s personality. Extensive qualitative and quantitative analyses demonstrate the effectiveness of TRIP NEGOTIATOR in generating personalized responses during negotiation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.967",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Chain of Condition: Construct, Verify and Solve Conditions for Conditional Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "lin-etal-2024-chain",
        "author": "Lin, Jiuheng and Lai, Yuxuan and Feng, Yansong",
        "booktitle": "EMNLP-findings2024",
        "title": "Chain of Condition: Construct, Verify and Solve Conditions for Conditional Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Conditional question answering (CQA) is an important task that aims to find probable answers and identify missing conditions. Existing approaches struggle with CQA due to two challenges: (1) precisely identifying necessary conditions and the logical relationship, and (2) verifying conditions to detect any that are missing. In this paper, we propose a novel prompting approach, Chain of condition, by first identifying all conditions and constructing their logical relationships explicitly according to the document, then verifying whether these conditions are satisfied, finally solving the logical expression to indicate any missing conditions and generating the answer accordingly. Experiments on two CQA benchmark datasets show our chain of condition outperforms existing prompting baselines, establishing a new state of the art. Furthermore, with only a few examples, our method can facilitate GPT-3.5-Turbo or GPT-4 to outperform all existing supervised models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.968",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization": {
        "type": "INPROCEEDINGS",
        "key": "tseng-etal-2024-two",
        "author": "Tseng, Yu-Min and Huang, Yu-Chao and Hsiao, Teng-Yun and Chen, Wei-Lin and Huang, Chao-Wei and Meng, Yu and Chen, Yun-Nung",
        "booktitle": "EMNLP-findings2024",
        "title": "Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The concept of *persona*, originally adopted in dialogue literature, has re-surged as a promising framework for tailoring large language models (LLMs) to specific context (*e.g.*, personalized search, LLM-as-a-judge). However, the growing research on leveraging persona in LLMs is relatively disorganized and lacks a systematic taxonomy. To close the gap, we present a comprehensive survey to categorize the current state of the field. We identify two lines of research, namely (1) *LLM Role-Playing*, where personas are assigned to LLMs, and (2) *LLM Personalization*, where LLMs take care of user personas. Additionally, we introduce existing methods for LLM personality evaluation. To the best of our knowledge, we present the first survey for role-playing and personalization in LLMs under the unified view of persona. We continuously maintain a paper collection to foster future endeavors.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.969",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information": {
        "type": "INPROCEEDINGS",
        "key": "hui-etal-2024-toxicraft",
        "author": "Hui, Zheng and Guo, Zhaoxiao and Zhao, Hang and Duan, Juanyong and Huang, Congrui",
        "booktitle": "EMNLP-findings2024",
        "title": "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In different NLP tasks, detecting harmful content is crucial for online environments, especially with the growing influence of social media. However, previous research has two main issues: 1) a lack of data in low-resource settings, and 2) inconsistent definitions and criteria for judging harmful content, requiring classification models to be robust to spurious features and diverse. We propose Toxicraft, a novel framework for synthesizing datasets of harmful information to address these weaknesses. With only a small amount of seed data, our framework can generate a wide variety of synthetic, yet remarkably realistic, examples of toxic information. Experimentation across various datasets showcases a notable enhancement in detection model robustness and adaptability, surpassing or close to the gold labels.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.970",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Look Who\u2019s Talking Now: Covert Channels From Biased LLMs": {
        "type": "INPROCEEDINGS",
        "key": "silva-etal-2024-look",
        "author": "Silva, Daniel and Sala, Frederic and Gabrys, Ryan",
        "booktitle": "EMNLP-findings2024",
        "title": "Look Who\u2019s Talking Now: Covert Channels From Biased LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language model-based steganography encodes hidden messages into model-generated tokens. The key tradeoff is between how much hidden information can be introduced and how much the model can be perturbed. To address this tradeoff, we show how to adapt strategies previously used for LLM watermarking to encode large amounts of information. We tackle the practical (but difficult) setting where we do not have access to the full model when trying to recover the hidden information. Theoretically, we study the fundamental limits in how much steganographic information can be inserted into LLM-created outputs. We provide practical encoding schemes and present experimental results showing that our proposed strategies are nearly optimal.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.971",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ValueScope: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions": {
        "type": "INPROCEEDINGS",
        "key": "park-etal-2024-valuescope",
        "author": "Park, Chan Young and Li, Shuyue Stella and Jung, Hayoung and Volkova, Svitlana and Mitra, Tanu and Jurgens, David and Tsvetkov, Yulia",
        "booktitle": "EMNLP-findings2024",
        "title": "ValueScope: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "This study introduces ValueScope, a framework leveraging language models to quantify social norms and values within online communities, grounded in social science perspectives on normative structures. We employ ValueScope to dissect and analyze linguistic and stylistic expressions across 13 Reddit communities categorized under gender, politics, science, and finance. Our analysis provides a quantitative foundation confirming that even closely related communities exhibit remarkably diverse norms. This diversity supports existing theories and adds a new dimension to understanding community interactions. ValueScope not only delineates differences in social norms but also effectively tracks their evolution and the influence of significant external events like the U.S. presidential elections and the emergence of new sub-communities. The framework thus highlights the pivotal role of social norms in shaping online interactions, presenting a substantial advance in both the theory and application of social norm studies in digital spaces.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.972",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unraveling the Truth: Do VLMs really Understand Charts? A Deep Dive into Consistency and Robustness": {
        "type": "INPROCEEDINGS",
        "key": "mukhopadhyay-etal-2024-unraveling",
        "author": "Mukhopadhyay, Srija and Qidwai, Adnan and Garimella, Aparna and Ramu, Pritika and Gupta, Vivek and Roth, Dan",
        "booktitle": "EMNLP-findings2024",
        "title": "Unraveling the Truth: Do VLMs really Understand Charts? A Deep Dive into Consistency and Robustness",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Chart question answering (CQA) is a crucial area of Visual Language Understanding. However, the robustness and consistency of current Visual Language Models (VLMs) in this field remain under-explored. This paper evaluates state-of-the-art VLMs on comprehensive datasets, developed specifically for this study, encompassing diverse question categories and chart formats. We investigate two key aspects: 1) the models\u2019 ability to handle varying levels of chart and question complexity, and 2) their robustness across different visual representations of the same underlying data. Our analysis reveals significant performance variations based on question and chart types, highlighting both strengths and weaknesses of current models. Additionally, we identify areas for improvement and propose future research directions to build more robust and reliable CQA systems. This study sheds light on the limitations of current models and paves the way for future advancements in the field.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.973",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification": {
        "type": "INPROCEEDINGS",
        "key": "shui-etal-2024-fine",
        "author": "Shui, Zeren and Karypis, Petros and Karls, Daniel S. and Wen, Mingjian and Manchanda, Saurav and Tadmor, Ellad B. and Karypis, George",
        "booktitle": "EMNLP-findings2024",
        "title": "Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Citation intention Classification (CIC) tools classify citations by their intention (e.g., background, motivation) and assist readers in evaluating the contribution of scientific literature. Prior research has shown that pretrained language models (PLMs) such as SciBERT can achieve state-of-the-art performance on CIC benchmarks. PLMs are trained via self-supervision tasks on a large corpus of general text and can quickly adapt to CIC tasks via moderate fine-tuning on the corresponding dataset. Despite their advantages, PLMs can easily overfit small datasets during fine-tuning. In this paper, we propose a multi-task learning (MTL) framework that jointly fine-tunes PLMs on a dataset of primary interest together with multiple auxiliary CIC datasets to take advantage of additional supervision signals. We develop a data-driven task relation learning (TRL) method that controls the contribution of auxiliary datasets to avoid negative transfer and expensive hyper-parameter tuning. We conduct experiments on three CIC datasets and show that fine-tuning with additional datasets can improve the PLMs\u2019 generalization performance on the primary dataset. PLMs fine-tuned with our proposed framework outperform the current state-of-the-art models by 7% to 11% on small datasets while aligning with the best-performing model on a large dataset.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.974",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling": {
        "type": "INPROCEEDINGS",
        "key": "choi-etal-2024-transfercvlm",
        "author": "Choi, Dongha and Kim, Jung-jae and Lee, Hyunju",
        "booktitle": "EMNLP-findings2024",
        "title": "TransferCVLM: Transferring Cross-Modal Knowledge for Vision-Language Modeling",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Recent large vision-language multimodal models pre-trained with huge amount of image-text pairs show remarkable performances in downstream tasks. However, the multimodal pre-training has limitations in terms of resources and training time when it comes to obtaining new models that surpass existing models. To overcome these issues, we propose TransferCVLM, a method of efficient knowledge transfer that integrates pre-trained uni-modal models (and cross-modal fusion-encoder) into a combined vision-language model (CVLM), without pre-training the CVLM with large amount of multimodal data, and then for each task application, fine-tunes the CVLM and transfers the multimodal knowledge of a teacher vision-language model to the CVLM by using knowledge distillation techniques. We demonstrate that 1) the fine-tuned CVLM performs comparable to other vision-language models of similar size, that 2) the multimodal knowledge transfer consistently enhances the CVLM, and the knowledge-transferred CVLM composed of large-size unimodal models outperforms the teacher multimodal model in most of downstream tasks, and that 3) TransferCVLM can also be used for model compression when using small-size unimodal models. We estimate that the training of TransferCVLM takes only 6% of pre-training of other vision-language models. Our code is available at https://github.com/DMCB-GIST/TransferCVLM.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.975",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper": {
        "type": "INPROCEEDINGS",
        "key": "thorbecke-etal-2024-fast",
        "author": "Thorbecke, Iuliia and Zuluaga Gomez, Juan Pablo and Villatoro-tello, Esa\u00fa and Kumar, Shashi and Rangappa, Pradeep and Burdisso, Sergio and Motlicek, Petr and S, Karthik Pandia D. and Ganapathiraju, Aravind",
        "booktitle": "EMNLP-findings2024",
        "title": "Fast Streaming Transducer ASR Prototyping via Knowledge Distillation with Whisper",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The training of automatic speech recognition (ASR) with little to no supervised data remains an open question. In this work, we demonstrate that streaming Transformer-Transducer (TT) models can be trained from scratch in consumer and accessible GPUs in their entirety with pseudo-labeled (PL) speech from foundational speech models (FSM). This allows training a robust ASR model just in one stage and does not require large data and computational budget compared to the two-step scenario with pre-training and fine-tuning. We perform a comprehensive ablation on different aspects of PL-based streaming TT models such as the impact of (1) shallow fusion of n-gram LMs, (2) contextual biasing with named entities, (3) chunk-wise decoding for low-latency streaming applications, and (4) TT overall performance as the function of the FSM size. Our results demonstrate that TT can be trained from scratch without supervised data, even with very noisy PLs. We validate the proposed framework on 6 languages from CommonVoice and propose multiple heuristics to filter out hallucinated PLs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.976",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths": {
        "type": "INPROCEEDINGS",
        "key": "chia-etal-2024-reasoning",
        "author": "Chia, Yew Ken and Chen, Guizhen and Xu, Weiwen and Luu, Anh Tuan and Poria, Soujanya and Bing, Lidong",
        "booktitle": "EMNLP-findings2024",
        "title": "Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Advanced models such as OpenAI o1 exhibit impressive problem-solving capabilities through step-by-step reasoning. However, they may still falter on more complex problems, making errors that disrupt their reasoning paths. We attribute this to the expansive solution space, where each step has the risk of diverging into mistakes. To enhance language model reasoning, we introduce a specialized training framework called Reasoning Paths Optimization (RPO), which enables learning to reason and explore from diverse paths. Our approach encourages favorable branches at each reasoning step while penalizing unfavorable ones, enhancing the model\u2019s overall problem-solving performance. Reasoning Paths Optimization does not rely on large-scale human-annotated rationales or outputs from closed-source models, making it scalable and data-efficient. We focus on multi-step reasoning tasks, such as math word problems and science-based exam questions. The experiments demonstrate that our framework significantly enhances the reasoning performance of large language models, with up to 3.1% and 4.3% improvement on GSM8K and MMLU (STEM) respectively. Our data and code can be found at https://reasoning-paths.github.io.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.977",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Uncertainty Calibration for Tool-Using Language Agents": {
        "type": "INPROCEEDINGS",
        "key": "liu-etal-2024-uncertainty",
        "author": "Liu, Hao and Dou, Zi-Yi and Wang, Yixin and Peng, Nanyun and Yue, Yisong",
        "booktitle": "EMNLP-findings2024",
        "title": "Uncertainty Calibration for Tool-Using Language Agents",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "There is increasing interest in equipping language models with the ability to leverage external tools for complex, goal-oriented tasks. However, interacting with external tools introduces inherent uncertainties due to imperfections and misalignments between the tools\u2019 outputs and the agents\u2019 internal models, often leading to suboptimal outcomes. We thus study the problem of tool-use calibration in language agents, and identify prompt design and execution trace selection as two primary areas that suffer from miscalibration. We then propose ProbeCal, which recalibrates the internal probabilities of tool-using language agents to better reflect the actual effectiveness of tool, and enables a more appropriate selection of prompts and execution paths. We empirically show that ProbeCal can significantly and consistently improve off-the-shelf language models in tool-using applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.978",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Personalized Video Comment Generation": {
        "type": "INPROCEEDINGS",
        "key": "lin-etal-2024-personalized",
        "author": "Lin, Xudong and Zare, Ali and Huang, Shiyuan and Yang, Ming-Hsuan and Chang, Shih-Fu and Zhang, Li",
        "booktitle": "EMNLP-findings2024",
        "title": "Personalized Video Comment Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Generating personalized responses, particularly in the context of video, poses a unique challenge for language models. This paper introduces the novel task of Personalized Video Comment Generation (PVCG), aiming to predict user comments tailored to both the input video and the user\u2019s comment history, where the user is unseen during the model training process. Unlike existing video captioning tasks that ignores the personalization in the text generation process, we introduce PerVidCom, a new dataset specifically collected for this novel task with diverse personalized comments from YouTube. Recognizing the limitations of existing captioning metrics for evaluating this task, we propose a new automatic metric based on Large Language Models (LLMs) with few-shot in-context learning, named FICL-Score, specifically measuring quality from the aspects of emotion, language style and content relevance. We verify the proposed metric with human evaluations. We establish baselines using prominent Multimodal LLMs (MLLMs), analyze their performance discrepancies through extensive evaluation, and identifies directions for future improvement on this important task. Our research opens up a new direction of personalizing MLLMs and paves the way for future research.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.979",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?": {
        "type": "INPROCEEDINGS",
        "key": "kao-etal-2024-solving",
        "author": "Kao, Kuei-Chun and Wang, Ruochen and Hsieh, Cho-Jui",
        "booktitle": "EMNLP-findings2024",
        "title": "Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models have demonstrates remarkable performance in solving math problems, a hallmark of human intelligence.Despite high success rates on current benchmarks, however, these often feature simple problems with only one or two unknowns, which do not sufficiently challenge their reasoning capacities. This paper introduces a novel benchmark, BeyondX, designed to address these limitations by incorporating problems with multiple unknowns. Recognizing the challenges in proposing multi-unknown problems from scratch, we developed BeyondX using an innovative automated pipeline that progressively increases complexity by expanding the number of unknowns in simpler problems. Empirical study on BeyondX reveals that the performance of existing LLMs, even those fine-tuned specifically on math tasks, significantly decreases as the number of unknowns increases - with a performance drop of up to 70% observed in GPT-4. To tackle these challenges, we propose the Formulate-and-Solve strategy, a generalized prompting approach that effectively handles problems with an arbitrary number of unknowns. Our findings reveal that this strategy not only enhances LLM performance on the BeyondX benchmark but also provides deeper insights into the computational limits of LLMs when faced with more complex mathematical challenges.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.980",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MedLogic-AQA: Enhancing Medicare Question Answering with Abstractive Models Focusing on Logical Structures": {
        "type": "INPROCEEDINGS",
        "key": "zafar-etal-2024-medlogic",
        "author": "Zafar, Aizan and Mishra, Kshitij and Ekbal, Asif",
        "booktitle": "EMNLP-findings2024",
        "title": "MedLogic-AQA: Enhancing Medicare Question Answering with Abstractive Models Focusing on Logical Structures",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In Medicare question-answering (QA) tasks, the need for effective systems is pivotal in delivering accurate responses to intricate medical queries. However, existing approaches often struggle to grasp the intricate logical structures and relationships inherent in medical contexts, thus limiting their capacity to furnish precise and nuanced answers. In this work, we address this gap by proposing a novel Abstractive QA system MedLogic-AQA that harnesses first-order logic-based rules extracted from both context and questions to generate well-grounded answers. Through initial experimentation, we identified six pertinent first-order logical rules, which were then used to train a Logic-Understanding (LU) model capable of generating logical triples for a given context, question, and answer. These logic triples are then integrated into the training of MediLogic-AQA, enabling reasoned and coherent reasoning during answer generation. This distinctive fusion of logical reasoning with abstractive question answering equips our system to produce answers that are logically sound, relevant, and engaging. Evaluation with respect to both automated and human-based demonstrates the robustness of MedLogic-AQA against strong baselines. Through empirical assessments and case studies, we validate the efficacy of MedLogic-AQA in elevating the quality and comprehensiveness of answers in terms of reasoning as well as informativeness.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.981",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "EmbodiedBERT: Cognitively Informed Metaphor Detection Incorporating Sensorimotor Information": {
        "type": "INPROCEEDINGS",
        "key": "li-etal-2024-embodiedbert",
        "author": "Li, Yu Xi and Peng, Bo and Hsu, Yu-Yin and Huang, Chu-Ren",
        "booktitle": "EMNLP-findings2024",
        "title": "EmbodiedBERT: Cognitively Informed Metaphor Detection Incorporating Sensorimotor Information",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The identification of metaphor is a crucial prerequisite for many downstream language tasks, such as sentiment analysis, opinion mining, and textual entailment. State-of-the-art systems of metaphor detection implement heuristic principles such as Metaphor Identification Procedure (MIP) and Selection Preference Violation (SPV). We propose an innovative approach that leverages the cognitive information of embodiment that can be derived from word embeddings, and explicitly models the process of sensorimotor change that has been demonstrated as essential for human metaphor processing. We showed that this cognitively motivated module is effective and can improve metaphor detection, compared with the heuristic MIP that has been applied previously.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.982",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-positionid",
        "author": "Wang, Noah and Duan, Feiyu and Zhang, Yibo and Zhou, Wangchunshu and Xu, Ke and Huang, Wenhao and Fu, Jie",
        "booktitle": "EMNLP-findings2024",
        "title": "PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities across various domains, including role-playing, creative writing, mathematical reasoning, and coding. Despite these advancements, LLMs still encounter challenges with length control, frequently failing to adhere to specific length constraints due to their token-level operations and insufficient training on data with strict length limitations. We identify this issue as stemming from a lack of positional awareness and propose novel approaches\u2014PositionID Prompting and PositionID Fine-Tuning\u2014to address it. These methods enhance the model\u2019s ability to continuously monitor and manage text length during generation. Additionally, we introduce PositionID CP Prompting to enable LLMs to perform copy and paste operations accurately. Furthermore, we develop two benchmarks for evaluating length control and copy-paste abilities. Our experiments demonstrate that our methods significantly improve the model\u2019s adherence to length constraints and copy-paste accuracy without compromising response quality.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.983",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "SedarEval: Automated Evaluation using Self-Adaptive Rubrics": {
        "type": "INPROCEEDINGS",
        "key": "fan-etal-2024-sedareval",
        "author": "Fan, Zhiyuan and Wang, Weinong and W, Xing and Zhang, Debing",
        "booktitle": "EMNLP-findings2024",
        "title": "SedarEval: Automated Evaluation using Self-Adaptive Rubrics",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The evaluation paradigm of LLM-as-judge gains popularity due to its significant reduction in human labor and time costs. This approach utilizes one or more large language models (LLMs) to assess the quality of outputs from other LLMs. However, existing methods rely on generic scoring rubrics that fail to consider the specificities of each question and its problem-solving process, compromising precision and stability in assessments. Inspired by human examination scoring processes, we propose a new evaluation paradigm based on self-adaptive rubrics. Specifically, we create detailed scoring rubrics for each question, capturing the primary and secondary criteria in a structured format of scoring and deduction points that mimic a human evaluator\u2019s analytical process. Building on this paradigm, we further develop a novel benchmark called SedarEval, which covers a range of domains including long-tail knowledge, mathematics, coding, and logical reasoning. SedarEval consists of 1,000 meticulously crafted questions, each with its own self-adaptive rubric. To further streamline the evaluation, we train a specialized evaluator language model (evaluator LM) to supplant human graders. Using the same training data, our evaluator LM achieves a higher concordance rate with human grading results than other paradigms, including GPT-4, highlighting the superiority and efficiency of our approach.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.984",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Towards One-to-Many Visual Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "ji-etal-2024-towards",
        "author": "Ji, Huishan and Si, Qingyi and Lin, Zheng and Cao, Yanan and Wang, Weiping",
        "booktitle": "EMNLP-findings2024",
        "title": "Towards One-to-Many Visual Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Most existing Visual Question Answering (VQA) systems are constrained to support domain-specific questions, i.e., to train different models separately for different VQA tasks, thus generalizing poorly to others. For example, models trained on the reasoning-focused dataset GQA struggle to effectively handle samples from the knowledge-emphasizing dataset OKVQA. Meanwhile, in real-world scenarios, it is user-unfriendly to restrict the domain of questions. Therefore, this paper proposes a necessary task: One-to-Many Visual Question Answering, of which the ultimate goal is to enable a single model to answer as many different domains of questions as possible by the effective integration of available VQA resources. To this end, we first investigate into ten common VQA datasets, and break the task of VQA down into the integration of three key abilities.Then, considering assorted questions rely on different VQA abilities, this paper proposes a novel dynamic Mixture of LoRAs (MoL) strategy. MoL mixes three individually trained LoRA adapters (corresponding to each VQA ability) dynamically for different samples demanding various VQA abilities. The proposed MoL strategy is verified to be highly effective by experiments, establishing SOTAs on four datasets. In addition, MoL generalizes well to three extra zero-shot datasets.Data and codes will be released.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.985",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-document-level",
        "author": "Wang, Zimu and Xia, Lei and Xjtlu, Wei Wang and Du, Xinya",
        "booktitle": "EMNLP-findings2024",
        "title": "Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As an essential task in information extraction (IE), Event-Event Causal Relation Extraction (ECRE) aims to identify and classify the causal relationships between event mentions in natural language texts. However, existing research on ECRE has highlighted two critical challenges, including the lack of document-level modeling and causal hallucinations. In this paper, we propose a Knowledge-guided binary Question Answering (KnowQA) method with event structures for ECRE, consisting of two stages: Event Structure Construction and Binary Question Answering. We conduct extensive experiments under both zero-shot and fine-tuning settings with large language models (LLMs) on the MECI and MAVEN-ERE datasets. Experimental results demonstrate the usefulness of event structures on document-level ECRE and the effectiveness of KnowQA by achieving state-of-the-art on the MECI dataset. We observe not only the effectiveness but also the high generalizability and low inconsistency of our method, particularly when with complete event structures after fine-tuning the models.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.986",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding": {
        "type": "INPROCEEDINGS",
        "key": "zhu-shimodaira-2024-block",
        "author": "Zhu, Yihua and Shimodaira, Hidetoshi",
        "booktitle": "EMNLP-findings2024",
        "title": "Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The primary aim of Knowledge Graph Embeddings (KGE) is to learn low-dimensional representations of entities and relations for predicting missing facts. While rotation-based methods like RotatE and QuatE perform well in KGE, they face two challenges: limited model flexibility requiring proportional increases in relation size with entity dimension, and difficulties in generalizing the model for higher-dimensional rotations. To address these issues, we introduce OrthogonalE, a novel KGE model employing matrices for entities and block-diagonal orthogonal matrices with Riemannian optimization for relations. This approach not only enhances the generality and flexibility of KGE models but also captures several relation patterns that rotation-based methods can identify. Experimental results indicate that our new KGE model, OrthogonalE, offers generality and flexibility, captures several relation patterns, and significantly outperforms state-of-the-art KGE models while substantially reducing the number of relation parameters.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.987",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wang-etal-2024-compression",
        "author": "Wang, Weilan and Mao, Yu and Dongdong, Tang and Hongchao, Du and Guan, Nan and Xue, Chun Jason",
        "booktitle": "EMNLP-findings2024",
        "title": "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large language models (LLMs) exhibit excellent performance in various tasks. However, the memory requirements of LLMs present a great challenge when deploying on memory-limited devices, even for quantized LLMs. This paper introduces a framework to compress LLM after quantization further, achieving about 2.2x compression ratio. A compression-aware quantization is first proposed to enhance model weight compressibility by re-scaling the model parameters before quantization, followed by a pruning method to improve further. Upon this, we notice that decompression can be a bottleneck during practical scenarios. We then give a detailed analysis of the trade-off between memory usage and latency brought by the proposed method. A speed-adaptive method is proposed to overcome it. The experimental results show inference with the compressed model can achieve a 40% reduction in memory size with negligible loss in accuracy and inference speed.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.988",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "BiMediX: Bilingual Medical Mixture of Experts LLM": {
        "type": "INPROCEEDINGS",
        "key": "pieri-etal-2024-bimedix",
        "author": "Pieri, Sara and Mullappilly, Sahal Shaji and Khan, Fahad Shahbaz and Anwer, Rao Muhammad and Khan, Salman and Baldwin, Timothy and Cholakkal, Hisham",
        "booktitle": "EMNLP-findings2024",
        "title": "BiMediX: Bilingual Medical Mixture of Experts LLM",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In this paper, we introduce BiMediX, the first bilingual medical mixture of experts LLM designed for seamless interaction in both English and Arabic. Our model facilitates a wide range of medical interactions in English and Arabic, including multi-turn chats to inquire about additional details such as patient symptoms and medical history, multiple-choice question answering, and open-ended question answering. We propose a semi-automated English-to-Arabic translation pipeline with human refinement to ensure high-quality translations. We also introduce a comprehensive evaluation benchmark for Arabic medical LLMs. Furthermore, we introduce BiMed1.3M, an extensive Arabic-English bilingual instruction set that covers 1.3 Million diverse medical interactions, including 200k synthesized multi-turn doctor-patient chats, in a 1:2 Arabic-to-English ratio. Our model outperforms state-of-the-art Med42 and Meditron by average absolute gains of 2.5% and 4.1%, respectively, computed across multiple medical evaluation benchmarks in English, while operating at 8-times faster inference. Moreover, our BiMediX outperforms the generic Arabic-English bilingual LLM, Jais-30B, by average absolute gains of 10% on our Arabic and 15% on our bilingual evaluations across multiple datasets. Additionally, BiMediX exceeds the accuracy of GPT4 by 4.4% in open-ended question UPHILL evaluation and largely outperforms state-of-the-art open source medical LLMs in human evaluations of multi-turn conversations. Our trained models, instruction set, and source code are available at https://github.com/mbzuai-oryx/BiMediX.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.989",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design": {
        "type": "INPROCEEDINGS",
        "key": "bhagwatkar-etal-2024-improving",
        "author": "Bhagwatkar, Rishika and Nayak, Shravan and Bashivan, Pouya and Rish, Irina",
        "booktitle": "EMNLP-findings2024",
        "title": "Improving Adversarial Robustness in Vision-Language Models with Architecture and Prompt Design",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Vision-Language Models (VLMs) have seen a significant increase in both research interest and real-world applications across various domains, including healthcare, autonomous systems, and security. However, their growing prevalence demands higher reliability and safety including robustness to adversarial attacks. We systematically examine the possibility of incorporating adversarial robustness through various model design choices. We explore the effects of different vision encoders, the resolutions of vision encoders, and the size and type of language models. Additionally, we introduce novel, cost-effective approaches to enhance robustness through prompt engineering. By simply suggesting the possibility of adversarial perturbations or rephrasing questions, we demonstrate substantial improvements in model robustness against strong image-based attacks such as Auto-PGD. Our findings provide important guidelines for developing more robust VLMs, particularly for deployment in safety-critical environments where reliability and security are paramount. These insights are crucial for advancing the field of VLMs, ensuring they can be safely and effectively utilized in a wide range of applications.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.990",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Zero-Shot Fact Verification via Natural Logic and Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "strong-etal-2024-zero",
        "author": "Strong, Marek and Aly, Rami and Vlachos, Andreas",
        "booktitle": "EMNLP-findings2024",
        "title": "Zero-Shot Fact Verification via Natural Logic and Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "The recent development of fact verification systems with natural logic has enhanced their explainability by aligning claims with evidence through set-theoretic operators, providing faithful justifications. Despite these advancements, such systems often rely on a large amount of training data annotated with natural logic. To address this issue, we propose a zero-shot method that utilizes the generalization capabilities of instruction-tuned large language models. To comprehensively assess the zero-shot capabilities of our method and other fact verification systems, we evaluate all models on both artificial and real-world claims, including multilingual datasets. We also compare our method against other fact verification systems in two setups. First, in the zero-shot generalization setup, we demonstrate that our approach outperforms other systems that were not specifically trained on natural logic data, achieving an average accuracy improvement of 8.96 points over the best-performing baseline. Second, in the zero-shot transfer setup, we show that current systems trained on natural logic data do not generalize well to other domains, and our method outperforms these systems across all datasets with real-world claims.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.991",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Robust AI-Generated Text Detection by Restricted Embeddings": {
        "type": "INPROCEEDINGS",
        "key": "kuznetsov-etal-2024-robust",
        "author": "Kuznetsov, Kristian and Tulchinskii, Eduard and Kushnareva, Laida and Magai, German and Barannikov, Serguei and Nikolenko, Sergey and Piontkovskaya, Irina",
        "booktitle": "EMNLP-findings2024",
        "title": "Robust AI-Generated Text Detection by Restricted Embeddings",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Growing amount and quality of AI-generated texts makes detecting such content more difficult. In most real-world scenarios, the domain (style and topic) of generated data and the generator model are not known in advance. In this work, we focus on the robustness of classifier-based detectors of AI-generated text, namely their ability to transfer to unseen generators or semantic domains. We investigate the geometry of the embedding space of Transformer-based text encoders and show that clearing out harmful linear subspaces helps to train a robust classifier, ignoring domain-specific spurious features. We investigate several subspace decomposition and feature selection strategies and achieve significant improvements over state of the art methods in cross-domain and cross-generator transfer. Our best approaches for head-wise and coordinate-based subspace removal increase the mean out-of-distribution (OOD) classification score by up to 9% and 14% in particular setups for RoBERTa and BERT embeddings respectively. We release our code and data: https://github.com/SilverSolver/RobustATD",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.992",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack": {
        "type": "INPROCEEDINGS",
        "key": "sun-etal-2024-crowd",
        "author": "Sun, Siqi and Sen, Procheta and Ruan, Wenjie",
        "booktitle": "EMNLP-findings2024",
        "title": "CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Language models are vulnerable to clandestinely modified data and manipulation by attackers. Despite considerable research dedicated to enhancing robustness against adversarial attacks, the realm of provable robustness for backdoor attacks remains relatively unexplored. In this paper, we initiate a pioneering investigation into the certified robustness of NLP models against backdoor triggers.We propose a model-agnostic mechanism for large-scale models that applies to complex model structures without the need for assessing model architecture or internal knowledge. More importantly, we take recent advances in randomized smoothing theory and propose a novel weight-based distribution algorithm to enable semantic similarity and provide theoretical robustness guarantees.Experimentally, we demonstrate the efficacy of our approach across a diverse range of datasets and tasks, highlighting its utility in mitigating backdoor triggers. Our results show strong performance in terms of certified accuracy, scalability, and semantic preservation.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.993",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning": {
        "type": "INPROCEEDINGS",
        "key": "zhang-etal-2024-milora",
        "author": "Zhang, Jingfan and Zhao, Yi and Chen, Dan and Tian, Xing and Zheng, Huanran and Zhu, Wei",
        "booktitle": "EMNLP-findings2024",
        "title": "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Low-rank adaptation (LoRA) and its mixture-of-experts (MOE) variants are highly effective parameter-efficient fine-tuning (PEFT) methods. However, they introduce significant latency in multi-tenant settings due to the LoRA modules and MOE routers added to multiple linear modules in the Transformer layer. To address this issue, we propose Mixture of Low-Rank Adaptation (MiLoRA), a novel and efficient LoRA variant. MiLoRA differs from previous MOE-style LoRA methods by considering each LoRA module as an expert and employing a prompt-aware routing mechanism. This mechanism calculates expert routing results once before generating the first new token and reuses these results for subsequent tokens, reducing latency. Extensive experiments and analysis on commonsense reasoning tasks, math reasoning tasks, and widely used LLM evaluation benchmarks demonstrate that MiLoRA consistently outperforms strong PEFT baselines with comparable tunable parameter budgets. Additionally, MiLoRA significantly reduces latency in multi-tenant settings compared to previous LoRA-based methods.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.994",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "wright-etal-2024-llm",
        "author": "Wright, Dustin and Arora, Arnav and Borenstein, Nadav and Yadav, Srishti and Belongie, Serge and Augenstein, Isabelle",
        "booktitle": "EMNLP-findings2024",
        "title": "LLM Tropes: Revealing Fine-Grained Values and Opinions in Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Uncovering latent values and opinions embedded in large language models (LLMs) can help identify biases and mitigate potential harm. Recently, this has been approached by prompting LLMs with survey questions and quantifying the stances in the outputs towards morally and politically charged statements. However, the stances generated by LLMs can vary greatly depending on how they are prompted, and there are many ways to argue for or against a given position. In this work, we propose to address this by analysing a large and robust dataset of 156k LLM responses to the 62 propositions of the Political Compass Test (PCT) generated by 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of their generated stances and fine-grained analysis of the plain text justifications for those stances. For fine-grained analysis, we propose to identify tropes in the responses: semantically similar phrases that are recurrent and consistent across different prompts, revealing natural patterns in the text that a given LLM is prone to produce. We find that demographic features added to prompts significantly affect outcomes on the PCT, reflecting bias, as well as disparities between the results of tests when eliciting closed-form vs. open domain responses. Additionally, patterns in the plain text rationales via tropes show that similar justifications are repeatedly generated across models and prompts even with disparate stances.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.995",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLMs": {
        "type": "INPROCEEDINGS",
        "key": "yadav-etal-2024-pythonsaga",
        "author": "Yadav, Ankit and Beniwal, Himanshu and Singh, Mayank",
        "booktitle": "EMNLP-findings2024",
        "title": "PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLMs",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Driven by the surge in code generation using large language models (LLMs), numerous benchmarks have emerged to evaluate these LLMs capabilities. We conducted a large-scale human evaluation of *HumanEval* and *MBPP*, two popular benchmarks for Python code generation, analyzing their diversity and difficulty. Our findings unveil a critical bias towards a limited set of programming concepts, neglecting most of the other concepts entirely. Furthermore, we uncover a worrying prevalence of easy tasks that can inflate model performance estimations. To address these limitations, we propose a novel benchmark, *PythonSaga*, featuring 185 hand-crafted prompts in a balanced representation of 38 programming concepts across diverse difficulty levels. The robustness of our benchmark is demonstrated by the poor performance of existing Code-LLMs. The code and data set are openly available to the NLP community at this [URL](https://github.com/PythonSaga/PythonSaga).",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.996",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Efficient and Interpretable Grammatical Error Correction with Mixture of Experts": {
        "type": "INPROCEEDINGS",
        "key": "qorib-etal-2024-efficient",
        "author": "Qorib, Muhammad Reza and Aji, Alham Fikri and Ng, Hwee Tou",
        "booktitle": "EMNLP-findings2024",
        "title": "Efficient and Interpretable Grammatical Error Correction with Mixture of Experts",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Error type information has been widely used to improve the performance of grammatical error correction (GEC) models, whether for generating corrections, re-ranking them, or combining GEC models. Combining GEC models that have complementary strengths in correcting different error types is very effective in producing better corrections. However, system combination incurs a high computational cost due to the need to run inference on the base systems before running the combination method itself. Therefore, it would be more efficient to have a single model with multiple sub-networks that specialize in correcting different error types. In this paper, we propose a mixture-of-experts model, MoECE, for grammatical error correction. Our model successfully achieves the performance of T5-XL with three times fewer effective parameters. Additionally, our model produces interpretable corrections by also identifying the error type during inference.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.997",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Dial BeInfo for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning": {
        "type": "INPROCEEDINGS",
        "key": "razumovskaia-etal-2024-dial",
        "author": "Razumovskaia, Evgeniia and Vuli\u0107, Ivan and Markovi\u0107, Pavle and Cichy, Tomasz and Zheng, Qian and Wen, Tsung-Hsien and Budzianowski, Pawe\u0142",
        "booktitle": "EMNLP-findings2024",
        "title": "Dial BeInfo for Faithfulness: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Factual faithfulness is a crucial requirement in information-seeking dialogue: the system should respond to the user queries so that the responses are meaningful and aligned with the knowledge provided to the system. However, most modern large language models (LLMs) suffer from hallucinations, that is, they generate responses not supported by or even contradicting the knowledge source. To mitigate the issue and increase faithfulness of information-seeking dialogue systems supported by the LLMs, we introduce BeInfo, a simple yet effective method that applies \u2018behavioural tuning\u2019 on the LLMs to aid information-seeking dialogue. Relying on three standard information seeking dialogue datasets, we show that models tuned with BeInfo become considerably more faithful to the knowledge source both for datasets and domains seen during BeInfo-tuning, as well as on unseen domains, when applied in a zero-shot manner. In addition, we present a \u2018real-life\u2019 case study on conversations with real users, showcasing that the models with 3B parameters (e.g., Flan-T5) tuned with BeInfo demonstrate strong performance on data from real \u2018production\u2019 conversations: when tuned on a limited amount of such realistic in-domain dialogues, they surpass much larger LLMs used \u2018off-the-shelf\u2019, both on automatic and human evaluation metrics.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.998",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Unified Active Retrieval for Retrieval Augmented Generation": {
        "type": "INPROCEEDINGS",
        "key": "cheng-etal-2024-unified",
        "author": "Cheng, Qinyuan and Li, Xiaonan and Li, Shimin and Zhu, Qin and Yin, Zhangyue and Shao, Yunfan and Li, Linyang and Sun, Tianxiang and Yan, Hang and Qiu, Xipeng",
        "booktitle": "EMNLP-findings2024",
        "title": "Unified Active Retrieval for Retrieval Augmented Generation",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "In Retrieval-Augmented Generation (RAG), retrieval is not always helpful and applying it to every instruction is sub-optimal. Therefore, determining whether to retrieve is crucial for RAG, which is usually referred to as Active Retrieval. However, existing active retrieval methods face two challenges: 1. They usually rely on a single criterion, which struggles with handling various types of instructions. 2. They depend on specialized and highly differentiated procedures, and thus combining them makes the RAG system more complicated and leads to higher response latency. To address these challenges, we propose Unified Active Retrieval (UAR). UAR contains four orthogonal criteria and casts them into plug-and-play classification tasks, which achieves multifaceted retrieval timing judgements with negligible extra inference cost. We further introduce the Unified Active Retrieval Criteria (UAR-Criteria), designed to process diverse active retrieval scenarios through a standardized procedure. Experiments on four representative types of user instructions show that UAR significantly outperforms existing work on the retrieval timing judgement and the performance of downstream tasks, which shows the effectiveness of UAR and its helpfulness to downstream tasks.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.999",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Mitigating Catastrophic Forgetting in Language Transfer via Model Merging": {
        "type": "INPROCEEDINGS",
        "key": "alexandrov-etal-2024-mitigating",
        "author": "Alexandrov, Anton and Raychev, Veselin and Mueller, Mark Niklas and Zhang, Ce and Vechev, Martin and Toutanova, Kristina",
        "booktitle": "EMNLP-findings2024",
        "title": "Mitigating Catastrophic Forgetting in Language Transfer via Model Merging",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "As open-weight large language models (LLMs) achieve ever more impressive performance across a wide range of tasks in English, practitioners aim to adapt these models to different languages. However, such language adaptation is often accompanied by catastrophic forgetting of the base model\u2019s capabilities, severely limiting the usefulness of the resulting model. We address this issue by proposing Branch-and-Merge (BaM), a new adaptation method based on iteratively merging multiple models, fine-tuned on a subset of the available training data. BaM is based on the insight that this yields lower magnitude but higher quality weight changes, reducing forgetting of the source domain while maintaining learning on the target domain. We demonstrate in an extensive empirical study on Bulgarian and German that BaM can significantly reduce forgetting while matching or even improving target domain performance compared to both standard continued pretraining and instruction finetuning across different model architectures.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.1000",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "ATQ: Activation Transformation forWeight-Activation Quantization of Large Language Models": {
        "type": "INPROCEEDINGS",
        "key": "gai-li-2024-atq",
        "author": "Gai, Yundong and Li, Ping",
        "booktitle": "EMNLP-findings2024",
        "title": "ATQ: Activation Transformation forWeight-Activation Quantization of Large Language Models",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "There are many emerging quantization methods to resolve the problem that the huge demand on computational and storage costs hinders the deployment of Large language models (LLMs). However, their accuracy performance still can not satisfy the entire academic and industry community. In this work, we propose ATQ, an INT8 weight-activation quantization of LLMs, that can achieve almost lossless accuracy. We employ a mathematically equivalent transformation and a triangle inequality to constrain weight-activation quantization error to the sum of a weight quantization error and an activation quantization error. For the weight part, transformed weights are quantized along the |in-feature| dimension and the quantization error is compensated by optimizing following in-features. For the activation part, transformed activations are in the normal range and can be quantized easily. We provide comparison experiments to demonstrate that our ATQ method can achieve almost lossless in accuracy on OPT and LLaMA families in W8A8 quantization settings. The increase of perplexity is within 1 and the accuracy degradation is within 0.5 percent even in the worst case.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.1001",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "Stochastic Fine-Tuning of Language Models Using Masked Gradients": {
        "type": "INPROCEEDINGS",
        "key": "akbar-tajari-pilehvar-2024-stochastic",
        "author": "Akbar-Tajari, Mohammad and Pilehvar, Mohammad Taher",
        "booktitle": "EMNLP-findings2024",
        "title": "Stochastic Fine-Tuning of Language Models Using Masked Gradients",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "Large Language Models (LLMs) have emerged as the dominant paradigm in Natural Language Processing owing to their remarkable performance across various target tasks. However, naively fine-tuning them for specific downstream tasks often requires updating a vast number of parameters, resulting in high computational costs and overfitting when training data is limited. In this paper, we propose a novel approach, called *Stochastic Tuning*, that addresses these challenges by selectively updating a small subset of parameters in each step of the tuning process. Our approach is characterized by its customization of updates based on task-specific partial gradients with respect to stochastic sub-networks. The advantage of Stochastic Tuning over existing solutions lies in its ability to consider both parameter weights as well as forward values which guarantees a context-sensitive fine-tuning. Our experiments demonstrate that Stochastic Tuning outperforms existing lightweight fine-tuning methods, improving average performance by over two points on RoBERTa across several tasks in the GLUE benchmark while updating merely **0.08**% of the model\u2019s parameters. The code for our implementation can be found at https://github.com/m-Tajari/StocTuning_LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.1002",
        "doi": "",
        "ISSN": "",
        "month": "November"
    },
    "To Know or Not To Know? Analyzing Self-Consistency of Large Language Models under Ambiguity": {
        "type": "INPROCEEDINGS",
        "key": "sedova-etal-2024-know",
        "author": "Sedova, Anastasiia and Litschko, Robert and Frassinelli, Diego and Roth, Benjamin and Plank, Barbara",
        "booktitle": "EMNLP-findings2024",
        "title": "To Know or Not To Know? Analyzing Self-Consistency of Large Language Models under Ambiguity",
        "year": "2024",
        "volume": "",
        "number": "",
        "pages": "",
        "abstract": "One of the major aspects contributing to the striking performance of large language models (LLMs) is the vast amount of factual knowledge accumulated during pre-training. Yet, many LLMs suffer from self-inconsistency, which raises doubts about their trustworthiness and reliability. This paper focuses on entity type ambiguity, analyzing the proficiency and consistency of state-of-the-art LLMs in applying factual knowledge when prompted with ambiguous entities. To do so, we propose an evaluation protocol that disentangles knowing from applying knowledge, and test state-of-the-art LLMs on 49 ambiguous entities. Our experiments reveal that LLMs struggle with choosing the correct entity reading, achieving an average accuracy of only 85%, and as low as 75% with underspecified prompts. The results also reveal systematic discrepancies in LLM behavior, showing that while the models may possess knowledge, they struggle to apply it consistently, exhibit biases toward preferred readings, and display self-inconsistencies. This highlights the need to address entity ambiguity in the future for more trustworthy LLMs.",
        "keywords": "",
        "url": "https://aclanthology.org/2024.findings-emnlp.1003",
        "doi": "",
        "ISSN": "",
        "month": "November"
    }
}