{
    "Graded Refinement, Retrenchment, and Simulation": {
        "type": "article",
        "key": "10.1145/3534116",
        "author": "Banach, Richard",
        "title": "Graded Refinement, Retrenchment, and Simulation",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3534116",
        "doi": "10.1145/3534116",
        "abstract": "Refinement of formal system models towards implementation has been a mainstay of system development since the inception of formal and Correct by Construction approaches to system development. However, pure refinement approaches do not always deal fluently with all desirable system requirements. This prompted the development of alternatives and generalizations, such as retrenchment. The crucial concept of simulation is key to judging the quality of the conformance between abstract and more concrete system models. Reformulations of these theoretical approaches are reprised and are embedded in a graded framework. The added flexibility this offers is intended to deal more effectively with the needs of applications in which the relationship between different levels of abstraction is not straightforward, and in which behavior can oscillate between conforming quite closely to an idealized abstraction and deviating quite far from it. The framework developed is confronted with an intentionally demanding case study: a model active control system for the protection of buildings during earthquakes. This offers many challenges: it is hybrid/cyber-physical; it has to respond to rather unpredictable inputs; and it has to straddle the gap between continuous behavior and discretized/quantized/numerical implementation.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "29",
        "numpages": "69",
        "keywords": "Refinement, retrenchment, simulation"
    },
    "On the Significance of Category Prediction for Code-Comment Synchronization": {
        "type": "article",
        "key": "10.1145/3534117",
        "author": "Yang, Zhen and Keung, Jacky Wai and Yu, Xiao and Xiao, Yan and Jin, Zhi and Zhang, Jingyu",
        "title": "On the Significance of Category Prediction for Code-Comment Synchronization",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3534117",
        "doi": "10.1145/3534117",
        "abstract": "Software comments sometimes are not promptly updated in sync when the associated code is changed. The inconsistency between code and comments may mislead the developers and result in future bugs. Thus, studies concerning code-comment synchronization have become highly important, which aims to automatically synchronize comments with code changes. Existing code-comment synchronization approaches mainly contain two types, i.e., (1) deep learning-based (e.g., CUP), and (2) heuristic-based (e.g., HebCUP). The former constructs a neural machine translation-structured semantic model, which has a more generalized capability on synchronizing comments with software evolution and growth. However, the latter designs a series of rules for performing token-level replacements on old comments, which can generate the completely correct comments for the samples fully covered by their fine-designed heuristic rules. In this article, we propose a composite approach named CBS (i.e., Classifying Before Synchronizing) to further improve the code-comment synchronization performance, which combines the advantages of CUP and HebCUP with the assistance of inferred categories of Code-Comment Inconsistent (CCI) samples. Specifically, we firstly define two categories (i.e., heuristic-prone and non-heuristic-prone) for CCI samples and propose five features to assist category prediction. The samples whose comments can be correctly synchronized by HebCUP are heuristic-prone, while others are non-heuristic-prone. Then, CBS employs our proposed Multi-Subsets Ensemble Learning (MSEL) classification algorithm to alleviate the class imbalance problem and construct the category prediction model. Next, CBS uses the trained MSEL to predict the category of the new sample. If the predicted category is heuristic-prone, CBS employs HebCUP to conduct the code-comment synchronization for the sample, otherwise, CBS allocates CUP to handle it. Our extensive experiments demonstrate that CBS statistically significantly outperforms CUP and HebCUP, and obtains an average improvement of 23.47\\%, 22.84\\%, 3.04\\%, 3.04\\%, 1.64\\%, and 19.39\\% in terms of Accuracy, Recall@5, Average Edit Distance (AED), Relative Edit Distance (RED), BLEU-4, and Effective Synchronized Sample (ESS) ratio, respectively, which highlights that category prediction for CCI samples can boost the code-comment synchronization performance.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "30",
        "numpages": "41",
        "keywords": "Code-comment synchronization, category classification, deep learning, heuristic rules"
    },
    "Dealing with Belief Uncertainty in Domain Models": {
        "type": "article",
        "key": "10.1145/3542947",
        "author": "Burgue\\~{n}o, Lola and Mu\\~{n}oz, Paula and Claris\\'{o}, Robert and Cabot, Jordi and G\\'{e}rard, S\\'{e}bastien and Vallecillo, Antonio",
        "title": "Dealing with Belief Uncertainty in Domain Models",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3542947",
        "doi": "10.1145/3542947",
        "abstract": "There are numerous domains in which information systems need to deal with uncertain information. These uncertainties may originate from different reasons such as vagueness, imprecision, incompleteness, or inconsistencies, and in many cases, they cannot be neglected. In this article, we are interested in representing and processing uncertain information in domain models, considering the stakeholders\u2019 beliefs (opinions). We show how to associate beliefs to model elements and how to propagate and operate with their associated uncertainty so that domain experts can individually reason about their models enriched with their personal opinions. In addition, we address the challenge of combining the opinions of different domain experts on the same model elements, with the goal to come up with informed collective decisions. We provide different strategies and a methodology to optimally merge individual opinions.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "31",
        "numpages": "34",
        "keywords": "Information systems, software, domain models, uncertainty, belief, belief fusion, consensus, subjective logic, vagueness, decision-making"
    },
    "Aide-m\\'{e}moire: Improving a Project\u2019s Collective Memory via Pull Request\u2013Issue Links": {
        "type": "article",
        "key": "10.1145/3542937",
        "author": "P\\^{a}r\\c{t}achi, Profir-Petru and White, David R. and Barr, Earl T.",
        "title": "Aide-m\\'{e}moire: Improving a Project\u2019s Collective Memory via Pull Request\u2013Issue Links",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3542937",
        "doi": "10.1145/3542937",
        "abstract": "Links between pull request and the issues they address document and accelerate the development of a software project but are often omitted. We present a new tool, Aide-m\\'{e}moire, to suggest such links when a developer submits a pull request or closes an issue, smoothly integrating into existing workflows. In contrast to previous state-of-the-art approaches that repair related commit histories, Aide-m\\'{e}moire is designed for continuous, real-time, and long-term use, employing Mondrian forest to adapt over a project\u2019s lifetime and continuously improve traceability. Aide-m\\'{e}moire is tailored for two specific instances of the general traceability problem\u2014namely, commit to issue and pull request to issue links, with a focus on the latter\u2014and exploits data inherent to these two problems to outperform tools for general purpose link recovery. Our approach is online, language-agnostic, and scalable. We evaluate over a corpus of 213 projects and six programming languages, achieving a mean average precision of 0.95. Adopting Aide-m\\'{e}moire is both efficient and effective: A programmer need only evaluate a single suggested link 94\\% of the time, and 16\\% of all discovered links were originally missed by developers.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "32",
        "numpages": "36",
        "keywords": "Traceability, link inference, missing link"
    },
    "iBiR: Bug-report-driven Fault Injection": {
        "type": "article",
        "key": "10.1145/3542946",
        "author": "Khanfir, Ahmed and Koyuncu, Anil and Papadakis, Mike and Cordy, Maxime and Bissyand\\'{e}, Tegawende F. and Klein, Jacques and Le Traon, Yves",
        "title": "iBiR: Bug-report-driven Fault Injection",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3542946",
        "doi": "10.1145/3542946",
        "abstract": "Much research on software engineering relies on experimental studies based on fault injection. Fault injection, however, is not often relevant to emulate real-world software faults since it \u201cblindly\u201d injects large numbers of faults. It remains indeed challenging to inject few but realistic faults that target a particular functionality in a program. In this work, we introduce iBiR , a fault injection tool that addresses this challenge by exploring change patterns associated to user-reported faults. To inject realistic faults, we create mutants by re-targeting a bug-report-driven automated program repair system, i.e., reversing its code transformation templates. iBiR is further appealing in practice since it requires deep knowledge of neither code nor tests, just of the program\u2019s relevant bug reports. Thus, our approach focuses the fault injection on the feature targeted by the bug report. We assess iBiR by considering the Defects4J dataset. Experimental results show that our approach outperforms the fault injection performed by traditional mutation testing in terms of semantic similarity with the original bug, when applied at either system or class levels of granularity, and provides better, statistically significant estimations of test effectiveness (fault detection). Additionally, when injecting 100 faults, iBiR injects faults that couple with the real ones in around 36\\% of the cases, while mutation testing achieves less than 4\\%.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "33",
        "numpages": "31",
        "keywords": "Fault injection, mutation, bug reports, information retrieval"
    },
    "deGraphCS: Embedding Variable-based Flow Graph for Neural Code Search": {
        "type": "article",
        "key": "10.1145/3546066",
        "author": "Zeng, Chen and Yu, Yue and Li, Shanshan and Xia, Xin and Wang, Zhiming and Geng, Mingyang and Bai, Linxiao and Dong, Wei and Liao, Xiangke",
        "title": "deGraphCS: Embedding Variable-based Flow Graph for Neural Code Search",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546066",
        "doi": "10.1145/3546066",
        "abstract": "With the rapid increase of public code repositories, developers maintain a great desire to retrieve precise code snippets by using natural language. Despite existing deep learning-based approaches that provide end-to-end solutions (i.e., accept natural language as queries and show related code fragments), the performance of code search in the large-scale repositories is still low in accuracy because of the code representation (e.g., AST) and modeling (e.g., directly fusing features in the attention stage). In this paper, we propose a novel learnable deep Graph for Code Search (called deGraphCS) to transfer source code into variable-based flow graphs based on an intermediate representation technique, which can model code semantics more precisely than directly processing the code as text or using the syntax tree representation. Furthermore, we propose a graph optimization mechanism to refine the code representation and apply an improved gated graph neural network to model variable-based flow graphs. To evaluate the effectiveness of deGraphCS, we collect a large-scale dataset from GitHub containing 41,152 code snippets written in the C language and reproduce several typical deep code search methods for comparison. The experimental results show that deGraphCS can achieve state-of-the-art performance and accurately retrieve code snippets satisfying the needs of the users.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "34",
        "numpages": "27",
        "keywords": "Intermediate representation, graph neural networks, code search, deep learning"
    },
    "Nudge: Accelerating Overdue Pull Requests toward Completion": {
        "type": "article",
        "key": "10.1145/3544791",
        "author": "Maddila, Chandra and Upadrasta, Sai Surya and Bansal, Chetan and Nagappan, Nachiappan and Gousios, Georgios and van Deursen, Arie",
        "title": "Nudge: Accelerating Overdue Pull Requests toward Completion",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3544791",
        "doi": "10.1145/3544791",
        "abstract": "Pull requests are a key part of the collaborative software development and code review process today. However, pull requests can also slow down the software development process when the reviewer(s) or the author do not actively engage with the pull request. In this work, we design an end-to-end service, Nudge, for accelerating overdue pull requests toward completion by reminding the author or the reviewer(s) to engage with their overdue pull requests. First, we use models based on effort estimation and machine learning to predict the completion time for a given pull request. Second, we use activity detection to filter out pull requests that may be overdue but for which sufficient action is taking place nonetheless. Last, we use actor identification to understand who the blocker of the pull request is and nudge the appropriate actor (author or reviewer(s)). The&nbsp;key novelty of Nudge is that it succeeds in reducing pull request resolution time, while ensuring that developers perceive the notifications sent as useful, at the scale of thousands of repositories. In a randomized trial on 147 repositories in use at Microsoft, Nudge was able to reduce pull request resolution time by 60\\% for 8,500 pull requests, when compared to overdue pull requests for which Nudge did not send a notification. Furthermore, developers receiving Nudge notifications resolved 73\\% of these notifications as positive. We&nbsp;observed similar results when scaling up the deployment of Nudge to 8,000 repositories at Microsoft, for which Nudge sent 210,000 notifications during a full year. This demonstrates Nudge\u2019s ability to scale to thousands of repositories. Last, our qualitative analysis of a selection of Nudge notifications indicates areas for future research, such as taking dependencies among pull requests and developer availability into account.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "35",
        "numpages": "30",
        "keywords": "Pull-based software development, pull request, merge conflict, distributed software development"
    },
    "Toward More Efficient Statistical Debugging with Abstraction Refinement": {
        "type": "article",
        "key": "10.1145/3544790",
        "author": "Zuo, Zhiqiang and Niu, Xintao and Zhang, Siyi and Fang, Lu and Khoo, Siau Cheng and Lu, Shan and Sun, Chengnian and Xu, Guoqing Harry",
        "title": "Toward More Efficient Statistical Debugging with Abstraction Refinement",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3544790",
        "doi": "10.1145/3544790",
        "abstract": "Debugging is known to be a notoriously painstaking and time-consuming task. As one major family of automated debugging, statistical debugging approaches have been well investigated over the past decade, which collect failing and passing executions and apply statistical techniques to identify discriminative elements as potential bug causes. Most of the existing approaches instrument the entire program to produce execution profiles for debugging, thus incurring hefty instrumentation and analysis cost. However, as in fact a major part of the program code is error-free, full-scale program instrumentation is wasteful and unnecessary. This article presents a systematic abstraction refinement-based pruning technique for statistical debugging. Our technique only needs to instrument and analyze the code partially. While guided by a mathematically rigorous analysis, our technique is guaranteed to produce the same debugging results as an exhaustive analysis in deterministic settings. With the help of the effective and safe pruning, our technique greatly saves the cost of failure diagnosis without sacrificing any debugging capability. We apply this technique to two different statistical debugging scenarios: in-house and production-run statistical debugging. The comprehensive evaluations validate that our technique can significantly improve the efficiency of statistical debugging in both scenarios, while without jeopardizing the debugging capability.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "36",
        "numpages": "38",
        "keywords": "Statistical debugging, fault localization, abstraction refinement, selective instrumentation"
    },
    "Estimating Probabilistic Safe WCET Ranges of Real-Time Systems at Design Stages": {
        "type": "article",
        "key": "10.1145/3546941",
        "author": "Lee, Jaekwon and Shin, Seung Yeob and Nejati, Shiva and Briand, Lionel and Parache, Yago Isasi",
        "title": "Estimating Probabilistic Safe WCET Ranges of Real-Time Systems at Design Stages",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546941",
        "doi": "10.1145/3546941",
        "abstract": "Estimating worst-case execution time (WCET) is an important activity at early design stages of real-time systems. Based on WCET estimates, engineers make design and implementation decisions to ensure that task executions always complete before their specified deadlines. However, in practice, engineers often cannot provide precise point WCET estimates and prefer to provide plausible WCET ranges. Given a set of real-time tasks with such ranges, we provide an automated technique to determine for what WCET values the system is likely to meet its deadlines and, hence, operate safely with a probabilistic guarantee. Our approach combines a search algorithm for generating worst-case scheduling scenarios with polynomial logistic regression for inferring probabilistic safe WCET ranges. We evaluated our approach by applying it to three industrial systems from different domains and several synthetic systems. Our approach efficiently and accurately estimates probabilistic safe WCET ranges within which deadlines are likely to be satisfied with a high degree of confidence.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "37",
        "numpages": "33",
        "keywords": "Schedulability analysis, worst-case execution time, meta-heuristic search, machine learning, search-based software engineering"
    },
    "Coverage-Based Debloating for Java Bytecode": {
        "type": "article",
        "key": "10.1145/3546948",
        "author": "Soto-Valero, C\\'{e}sar and Durieux, Thomas and Harrand, Nicolas and Baudry, Benoit",
        "title": "Coverage-Based Debloating for Java Bytecode",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546948",
        "doi": "10.1145/3546948",
        "abstract": "Software bloat is code that is packaged in an application but is actually not necessary to run the application. The presence of software bloat is an issue for security, performance, and for maintenance. In this article, we introduce a novel technique for debloating, which we call coverage-based debloating. We implement the technique for one single language: Java bytecode. We leverage a combination of state-of-the-art Java bytecode coverage tools to precisely capture what parts of a project and its dependencies are used when running with a specific workload. Then, we automatically remove the parts that are not covered, in order to generate a debloated version of the project. We succeed to debloat 211&nbsp;library versions from a dataset of 94 unique &nbsp;open-source Java libraries. The debloated versions are syntactically correct and preserve their original behaviour according to the workload. Our results indicate that 68.3\\% of the libraries\u2019 bytecode and 20.3\\% of their total dependencies can be removed through coverage-based debloating.For the first time in the literature on software debloating, we assess the utility of debloated libraries with respect to client applications that reuse them. We select 988 client projects that either have a direct reference to the debloated library in their source code or which test suite covers at least one class of the libraries that we debloat. Our results show that 81.5\\% of the clients, with at least one test that uses the library, successfully compile and pass their test suite when the original library is replaced by its debloated version.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "38",
        "numpages": "34",
        "keywords": "Software bloat, code coverage, program specialization, bytecode, software maintenance"
    },
    "DIRE and its Data: Neural Decompiled Variable Renamings with Respect to Software Class": {
        "type": "article",
        "key": "10.1145/3546946",
        "author": "Dramko, Luke and Lacomis, Jeremy and Yin, Pengcheng and Schwartz, Ed and Allamanis, Miltiadis and Neubig, Graham and Vasilescu, Bogdan and Le Goues, Claire",
        "title": "DIRE and its Data: Neural Decompiled Variable Renamings with Respect to Software Class",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546946",
        "doi": "10.1145/3546946",
        "abstract": "The decompiler is one of the most common tools for examining executable binaries without the corresponding source code. It transforms binaries into high-level code, reversing the compilation process. Unfortunately, decompiler output is far from readable because the decompilation process is often incomplete. State-of-the-art techniques use machine learning to predict missing information like variable names. While these approaches are often able to suggest good variable names in context, no existing work examines how the selection of training data influences these machine learning models. We investigate how data provenance and the quality of training data affect performance, and how well, if at all, trained models generalize across software domains. We focus on the variable renaming problem using one such machine learning model, DIRE. We first describe DIRE in detail and the accompanying technique used to generate training data from raw code. We also evaluate DIRE\u2019s overall performance without respect to data quality. Next, we show how training on more popular, possibly higher quality code (measured using GitHub stars) leads to a more generalizable model because popular code tends to have more diverse variable names. Finally, we evaluate how well DIRE predicts domain-specific identifiers, propose a modification to incorporate domain information, and show that it can predict identifiers in domain-specific scenarios 23\\% more frequently than the original DIRE model.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "39",
        "numpages": "34",
        "keywords": "Machine learning, decompilation, data provenance"
    },
    "A Characterization Study of Merge Conflicts in Java Projects": {
        "type": "article",
        "key": "10.1145/3546944",
        "author": "Shen, Bowen and Gulzar, Muhammad Ali and He, Fei and Meng, Na",
        "title": "A Characterization Study of Merge Conflicts in Java Projects",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546944",
        "doi": "10.1145/3546944",
        "abstract": "In collaborative software development, programmers create software branches to add features and fix bugs tentatively, and then merge branches to integrate edits. When edits from different branches textually overlap (i.e., textual conflicts) or lead to compilation and runtime errors (i.e., build and test conflicts), it is challenging for developers to remove such conflicts. Prior work proposed tools to detect and solve conflicts. They investigate how conflicts relate to code smells and the software development process. However, many questions are still not fully investigated, such as what types of conflicts exist in real-world applications and how developers or tools handle them. For this article, we used automated textual merge, compilation, and testing to reveal three types of conflicts in 208 open-source repositories: textual conflicts, build conflicts (i.e., conflicts causing build errors), and test conflicts (i.e., conflicts triggering test failures). We manually inspected 538 conflicts and their resolutions to characterize merge conflicts from different angles. Our analysis revealed three interesting phenomena. First, higher-order conflicts (i.e., build and test conflicts) are harder to detect and resolve, while existing tools mainly focus on textual conflicts. Second, developers manually resolved most higher-order conflicts by applying similar edits to multiple program locations; their conflict resolutions share common editing patterns implying great opportunities for future tool design. Third, developers resolved 64\\% of true textual conflicts by keeping complete edits from either a left or right branch. Unlike prior studies, our research for the first time thoroughly characterizes three types of conflicts, with a special focus on higher-order conflicts and limitations of existing tool design. Our work will shed light on future research of software merge.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "40",
        "numpages": "28",
        "keywords": "Empirical, software merge, conflict detection, conflict resolution"
    },
    "Hippodrome: Data Race Repair Using Static Analysis Summaries": {
        "type": "article",
        "key": "10.1145/3546942",
        "author": "Costea, Andreea and Tiwari, Abhishek and Chianasta, Sigmund and R, Kishore and Roychoudhury, Abhik and Sergey, Ilya",
        "title": "Hippodrome: Data Race Repair Using Static Analysis Summaries",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546942",
        "doi": "10.1145/3546942",
        "abstract": "Implementing bug-free concurrent programs is a challenging task in modern software development. State-of-the-art static analyses find hundreds of concurrency bugs in production code, scaling to large codebases. Yet, fixing these bugs in constantly changing codebases represents a daunting effort for programmers, particularly because a fix in the concurrent code can introduce other bugs in a subtle way. In this work, we show how to harness compositional static analysis for concurrency bug detection, to enable a new Automated Program Repair (APR) technique for data races in large concurrent Java codebases. The key innovation of our work is an algorithm that translates procedure summaries inferred by the analysis tool for the purpose of bug reporting into small local patches that fix concurrency bugs (without introducing new ones). This synergy makes it possible to extend the virtues of compositional static concurrency analysis to APR, making our approach effective (it can detect and fix many more bugs than existing tools for data race repair), scalable (it takes seconds to analyze and suggest fixes for sizeable codebases), and usable (generally, it does not require annotations from the users and can perform continuous automated repair). Our study, conducted on popular open-source projects, has confirmed that our tool automatically produces concurrency fixes similar to those proposed by the developers in the past.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "41",
        "numpages": "33",
        "keywords": "Concurrency, program repair, static analysis"
    },
    "Evaluating Surprise Adequacy for Deep Learning System Testing": {
        "type": "article",
        "key": "10.1145/3546947",
        "author": "Kim, Jinhan and Feldt, Robert and Yoo, Shin",
        "title": "Evaluating Surprise Adequacy for Deep Learning System Testing",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546947",
        "doi": "10.1145/3546947",
        "abstract": "The rapid adoption of Deep Learning (DL) systems in safety critical domains such as medical imaging and autonomous driving urgently calls for ways to test their correctness and robustness. Borrowing from the concept of test adequacy in traditional software testing, existing work on testing of DL systems initially investigated DL systems from structural point of view, leading to a number of coverage metrics. Our lack of understanding of the internal mechanism of Deep Neural Networks (DNNs), however, means that coverage metrics defined on the Boolean dichotomy of coverage are hard to intuitively interpret and understand. We propose the degree of out-of-distribution-ness of a given input as its adequacy for testing: the more surprising a given input is to the DNN under test, the more likely the system will show unexpected behavior for the input. We develop the concept of surprise into a test adequacy criterion, called Surprise Adequacy (SA). Intuitively, SA measures the difference in the behavior of the DNN for the given input and its behavior for the training data. We posit that a good test input should be sufficiently, but not overtly, surprising compared to the training dataset. This article evaluates SA using a range of DL systems from simple image classifiers to autonomous driving car platforms, as well as both small and large data benchmarks ranging from MNIST to ImageNet. The results show that the SA value of an input can be a reliable predictor of the correctness of the mode behavior. We also show that SA can be used to detect adversarial examples, and also be efficiently computed against large training dataset such as ImageNet using sampling.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "42",
        "numpages": "29",
        "keywords": "Test adequacy, deep learning systems"
    },
    "Assessing the Alignment between the Information Needs of Developers and the Documentation of Programming Languages: A Case Study on Rust": {
        "type": "article",
        "key": "10.1145/3546945",
        "author": "Cogo, Filipe Roseiro and Xia, Xin and Hassan, Ahmed E.",
        "title": "Assessing the Alignment between the Information Needs of Developers and the Documentation of Programming Languages: A Case Study on Rust",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546945",
        "doi": "10.1145/3546945",
        "abstract": "Programming language documentation refers to the set of technical documents that provide application developers with a description of the high-level concepts of a language (e.g., manuals, tutorials, and API references). Such documentation is essential to support application developers in effectively using a programming language. One of the challenges faced by documenters (i.e., personnel that design and produce documentation for a programming language) is to ensure that documentation has relevant information that aligns with the concrete needs of developers, defined as the missing knowledge that developers acquire via voluntary search. In this article, we present an automated approach to support documenters in evaluating the differences and similarities between the concrete information need of developers and the current state of documentation (a problem that we refer to as the topical alignment of a programming language documentation). Our approach leverages semi-supervised topic modelling that uses domain knowledge to guide the derivation of topics. We initially train a baseline topic model from a set of Rust-related Q&amp;A posts. We then use this baseline model to determine the distribution of topic probabilities of each document of the official Rust documentation. Afterwards, we assess the similarities and differences between the topics of the Q&amp;A posts and the official documentation. Our results show a relatively high level of topical alignment in Rust documentation. Still, information about specific topics is scarce in both the Q&amp;A websites and the documentation, particularly related topics with programming niches such as network, game, and database development. For other topics (e.g., related topics with language features such as structs, patterns and matchings, and foreign function interface), information is only available on Q&amp;A websites while lacking in the official documentation. Finally, we discuss implications for programming language documenters, particularly how to leverage our approach to prioritize topics that should be added to the documentation.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "43",
        "numpages": "48",
        "keywords": "Documentation, programming languages, Rust, Q&amp;A websites, Stack Overflow, RustForum, topic models, domain knowledge"
    },
    "On Proving the Correctness of Refactoring Class Diagrams of MDE Metamodels": {
        "type": "article",
        "key": "10.1145/3549541",
        "author": "Altoyan, Najd and Batory, Don",
        "title": "On Proving the Correctness of Refactoring Class Diagrams of MDE Metamodels",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3549541",
        "doi": "10.1145/3549541",
        "abstract": "Model Driven Engineering (\t\t\t\t\t\tMDE\t\t\t\t\t) is a general-purpose engineering methodology to elevate system design, maintenance, and analysis to corresponding activities on models. Models (graphical and/or textual) of a target application are automatically transformed into source code, performance models, Promela files (for model checking), and so on for system analysis and construction.Models are instances of metamodels. One form an MDE metamodel can take is a [class diagram, constraints] pair: the class diagram defines all object diagrams that could be metamodel instances; object constraint language (OCL) constraints eliminate semantically undesirable instances.A metamodel refactoring is an invertible semantics-preserving co-transformation, i.e., it transforms both a metamodel and its models without losing data. This article addresses a subproblem of metamodel refactoring: how to prove the correctness of refactorings of class diagrams without OCL constraints using the Coq Proof Assistant.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "44",
        "numpages": "42",
        "keywords": "Class diagram refactorings, object diagram refactorings, Coq"
    },
    "Suboptimal Comments in Java Projects: From Independent Comment Changes to Commenting Practices": {
        "type": "article",
        "key": "10.1145/3546949",
        "author": "Wang, Chao and He, Hao and Pal, Uma and Marinov, Darko and Zhou, Minghui",
        "title": "Suboptimal Comments in Java Projects: From Independent Comment Changes to Commenting Practices",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546949",
        "doi": "10.1145/3546949",
        "abstract": "High-quality source code comments are valuable for software development and maintenance, however, code often contains low-quality comments or lacks them altogether. We name such source code comments as suboptimal comments. Such suboptimal comments create challenges in code comprehension and maintenance. Despite substantial research on low-quality source code comments, empirical knowledge about commenting practices that produce suboptimal comments and reasons that lead to suboptimal comments are lacking. We help bridge this knowledge gap by investigating (1)&nbsp;independent comment changes (ICCs)\u2014comment changes committed independently of code changes\u2014which likely address suboptimal comments, (2)&nbsp;commenting guidelines, and (3)&nbsp;comment-checking tools and comment-generating tools, which are often employed to help commenting practice\u2014especially to prevent suboptimal comments. We collect 24M+ comment changes from 4,392 open-source GitHub Java repositories and find that ICCs widely exist. The ICC ratio\u2014proportion of ICCs among all comment changes\u2014is ~15.5\\%, with 98.7\\% of the repositories having ICC. Our thematic analysis of 3,533 randomly sampled ICCs provides a three-dimensional taxonomy for what is changed (four comment categories and 13 subcategories), how it changed (six commenting activity categories), and what factors are associated with the change (three factors). We investigate 600 repositories to understand the prevalence, content, impact, and violations of commenting guidelines. We find that only 15.5\\% of the 600 sampled repositories have any commenting guidelines. We provide the first taxonomy for elements in commenting guidelines: where and what to comment are particularly important. The repositories without such guidelines have a statistically significantly higher ICC ratio, indicating the negative impact of the lack of commenting guidelines. However, commenting guidelines are not strictly followed: 85.5\\% of checked repositories have violations. We also systematically study how developers use two kinds of tools, comment-checking tools and comment-generating tools, in the 4,392 repositories. We find that the use of Javadoc tool is negatively correlated with the ICC ratio, while the use of Checkstyle has no statistically significant correlation; the use of comment-generating tools leads to a higher ICC ratio. To conclude, we reveal issues and challenges in current commenting practice, which help understand how suboptimal comments are introduced. We propose potential research directions on comment location prediction, comment generation, and comment quality assessment; suggest how developers can formulate commenting guidelines and enforce rules with tools; and recommend how to enhance current comment-checking and comment-generating tools.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "45",
        "numpages": "33",
        "keywords": "Code comments, software documentation, coding guidelines, software evolution"
    },
    "HINNPerf: Hierarchical Interaction Neural Network for Performance Prediction of Configurable Systems": {
        "type": "article",
        "key": "10.1145/3528100",
        "author": "Cheng, Jiezhu and Gao, Cuiyun and Zheng, Zibin",
        "title": "HINNPerf: Hierarchical Interaction Neural Network for Performance Prediction of Configurable Systems",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3528100",
        "doi": "10.1145/3528100",
        "abstract": "Modern software systems are usually highly configurable, providing users with customized functionality through various configuration options. Understanding how system performance varies with different option combinations is important to determine optimal configurations that meet specific requirements. Due to the complex interactions among multiple options and the high cost of performance measurement under a huge configuration space, it is challenging to study how different configurations influence the system performance. To address these challenges, we propose HINNPerf, a novel hierarchical interaction neural network for performance prediction of configurable systems. HINNPerf employs the embedding method and hierarchic network blocks to model the complicated interplay between configuration options, which improves the prediction accuracy of the method. In addition, we devise a hierarchical regularization strategy to enhance the model robustness. Empirical results on 10 real-world configurable systems show that our method statistically significantly outperforms state-of-the-art approaches by achieving average 22.67\\% improvement in prediction accuracy. In addition, combined with the Integrated Gradients method, the designed hierarchical architecture provides some insights about the interaction complexity and the significance of configuration options, which might help users and developers better understand how the configurable system works and efficiently identify significant options affecting the performance.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "46",
        "numpages": "30",
        "keywords": "Software performance prediction, highly configurable systems, deep neural network, machine learning"
    },
    "A Machine Learning Approach for Automated Filling of Categorical Fields in Data Entry Forms": {
        "type": "article",
        "key": "10.1145/3533021",
        "author": "Belgacem, Hichem and Li, Xiaochen and Bianculli, Domenico and Briand, Lionel",
        "title": "A Machine Learning Approach for Automated Filling of Categorical Fields in Data Entry Forms",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3533021",
        "doi": "10.1145/3533021",
        "abstract": "Users frequently interact with software systems through data entry forms. However, form filling is time-consuming and error-prone. Although several techniques have been proposed to auto-complete or pre-fill fields in the forms, they provide limited support to help users fill categorical fields, i.e., fields that require users to choose the right value among a large set of options.In this article, we propose LAFF, a learning-based automated approach for filling categorical fields in data entry forms. LAFF first builds Bayesian Network models by learning field dependencies from a set of historical input instances, representing the values of the fields that have been filled in the past. To improve its learning ability, LAFF uses local modeling to effectively mine the local dependencies of fields in a cluster of input instances. During the form filling phase, LAFF uses such models to predict possible values of a target field, based on the values in the already-filled fields of the form and their dependencies; the predicted values (endorsed based on field dependencies and prediction confidence) are then provided to the end-user as a list of suggestions.We evaluated LAFF by assessing its effectiveness and efficiency in form filling on two datasets, one of them proprietary from the banking domain. Experimental results show that LAFF is able to provide accurate suggestions with a Mean Reciprocal Rank value above 0.73. Furthermore, LAFF is efficient, requiring at most 317 ms per suggestion.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "47",
        "numpages": "40",
        "keywords": "Form filling, data entry forms, machine learning, software data quality, user interfaces"
    },
    "Towards Learning Generalizable Code Embeddings Using Task-agnostic Graph Convolutional Networks": {
        "type": "article",
        "key": "10.1145/3542944",
        "author": "Ding, Zishuo and Li, Heng and Shang, Weiyi and Chen, Tse-Hsun (Peter)",
        "title": "Towards Learning Generalizable Code Embeddings Using Task-agnostic Graph Convolutional Networks",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3542944",
        "doi": "10.1145/3542944",
        "abstract": "Code embeddings have seen increasing applications in software engineering (SE) research and practice recently. Despite the advances in embedding techniques applied in SE research, one of the main challenges is their generalizability. A recent study finds that code embeddings may not be readily leveraged for the downstream tasks that the embeddings are not particularly trained for. Therefore, in this article, we propose GraphCodeVec, which represents the source code as graphs and leverages the Graph Convolutional Networks to learn more generalizable code embeddings in a task-agnostic manner. The edges in the graph representation are automatically constructed from the paths in the abstract syntax trees, and the nodes from the tokens in the source code. To evaluate the effectiveness of GraphCodeVec , we consider three downstream benchmark tasks (i.e., code comment generation, code authorship identification, and code clones detection) that are used in a prior benchmarking of code embeddings and add three new downstream tasks (i.e., source code classification, logging statements prediction, and software defect prediction), resulting in a total of six downstream tasks that are considered in our evaluation. For each downstream task, we apply the embeddings learned by GraphCodeVec and the embeddings learned from four baseline approaches and compare their respective performance. We find that GraphCodeVec outperforms all the baselines in five out of the six downstream tasks, and its performance is relatively stable across different tasks and datasets. In addition, we perform ablation experiments to understand the impacts of the training context (i.e., the graph context extracted from the abstract syntax trees) and the training model (i.e., the Graph Convolutional Networks) on the effectiveness of the generated embeddings. The results show that both the graph context and the Graph Convolutional Networks can benefit GraphCodeVec in producing high-quality embeddings for the downstream tasks, while the improvement by Graph Convolutional Networks is more robust across different downstream tasks and datasets. Our findings suggest that future research and practice may consider using graph-based deep learning methods to capture the structural information of the source code for SE tasks.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "48",
        "numpages": "43",
        "keywords": "Machine learning, source code representation, code embeddings, neural network"
    },
    "Efficient and Effective Feature Space Exploration for Testing Deep Learning Systems": {
        "type": "article",
        "key": "10.1145/3544792",
        "author": "Zohdinasab, Tahereh and Riccio, Vincenzo and Gambi, Alessio and Tonella, Paolo",
        "title": "Efficient and Effective Feature Space Exploration for Testing Deep Learning Systems",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3544792",
        "doi": "10.1145/3544792",
        "abstract": "Assessing the quality of Deep Learning (DL) systems is crucial, as they are increasingly adopted in safety-critical domains. Researchers have proposed several input generation techniques for DL systems. While such techniques can expose failures, they do not explain which features of the test inputs influenced the system\u2019s (mis-) behaviour. DeepHyperion was the first test generator to overcome this limitation by exploring the DL systems\u2019 feature space at large. In this article, we propose DeepHyperion-CS, a test generator for DL systems that enhances DeepHyperion by promoting the inputs that contributed more to feature space exploration during the previous search iterations. We performed an empirical study involving two different test subjects (i.e., a digit classifier and a lane-keeping system for self-driving cars). Our results proved that the contribution-based guidance implemented within DeepHyperion-CS outperforms state-of-the-art tools and significantly improves the efficiency and the effectiveness of DeepHyperion. DeepHyperion-CS exposed significantly more misbehaviours for five out of six feature combinations and was up to 65\\% more efficient than DeepHyperion in finding misbehaviour-inducing inputs and exploring the feature space. DeepHyperion-CS was useful for expanding the datasets used to train the DL systems, populating up to 200\\% more feature map cells than the original training set.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "49",
        "numpages": "38",
        "keywords": "Software testing, Deep Learning, search based software engineering, self-driving cars"
    },
    "Demystifying Hidden Sensitive Operations in Android Apps": {
        "type": "article",
        "key": "10.1145/3574158",
        "author": "Sun, Xiaoyu and Chen, Xiao and Li, Li and Cai, Haipeng and Grundy, John and Samhi, Jordan and Bissyand\\'{e}, Tegawend\\'{e} and Klein, Jacques",
        "title": "Demystifying Hidden Sensitive Operations in Android Apps",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3574158",
        "doi": "10.1145/3574158",
        "abstract": "Security of Android devices is now paramount, given their wide adoption among consumers. As researchers develop tools for statically or dynamically detecting suspicious apps, malware writers regularly update their attack mechanisms to hide malicious behavior implementation. This poses two problems to current research techniques: static analysis approaches, given their over-approximations, can report an overwhelming number of false alarms, while dynamic approaches will miss those behaviors that are hidden through evasion techniques. We propose in this work a static approach specifically targeted at highlighting hidden sensitive operations (HSOs), mainly sensitive data flows. The prototype version of HiSenDroid has been evaluated on a large-scale dataset of thousands of malware and goodware samples on which it successfully revealed anti-analysis code snippets aiming at evading detection by dynamic analysis. We further experimentally show that, with FlowDroid, some of the hidden sensitive behaviors would eventually lead to private data leaks. Those leaks would have been hard to spot either manually among the large number of false positives reported by the state-of-the-art static analyzers, or by dynamic tools. Overall, by putting the light on hidden sensitive operations, HiSenDroid helps security analysts in validating potentially sensitive data operations, which would be previously unnoticed.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "50",
        "numpages": "30",
        "keywords": "Android application, privacy leak, hidden sensitive operations, program analysis"
    },
    "Testing, Validation, and Verification of Robotic and Autonomous Systems: A Systematic Review": {
        "type": "article",
        "key": "10.1145/3542945",
        "author": "Araujo, Hugo and Mousavi, Mohammad Reza and Varshosaz, Mahsa",
        "title": "Testing, Validation, and Verification of Robotic and Autonomous Systems: A Systematic Review",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3542945",
        "doi": "10.1145/3542945",
        "abstract": "We perform a systematic literature review on testing, validation, and verification of robotic and autonomous systems (RAS). The scope of this review covers peer-reviewed research papers proposing, improving, or evaluating testing techniques, processes, or tools that address the system-level qualities of RAS. Our survey is performed based on a rigorous methodology structured in three phases. First, we made use of a set of 26 seed papers (selected by domain experts) and the SERP-TEST taxonomy to design our search query and (domain-specific) taxonomy. Second, we conducted a search in three academic search engines and applied our inclusion and exclusion criteria to the results. Respectively, we made use of related work and domain specialists (50 academics and 15 industry experts) to validate and refine the search query. As a result, we encountered 10,735 studies, out of which 195 were included, reviewed, and coded. Our objective is to answer four research questions, pertaining to (1) the type of models, (2) measures for system performance and testing adequacy, (3) tools and their availability, and (4) evidence of applicability, particularly in industrial contexts. We analyse the results of our coding to identify strengths and gaps in the domain and present recommendations to researchers and practitioners. Our findings show that variants of temporal logics are most widely used for modelling requirements and properties, while variants of state-machines and transition systems are used widely for modelling system behaviour. Other common models concern epistemic logics for specifying requirements and belief-desire-intention models for specifying system behaviour. Apart from time and epistemics, other aspects captured in models concern probabilities (e.g., for modelling uncertainty) and continuous trajectories (e.g., for modelling vehicle dynamics and kinematics). Many papers lack any rigorous measure of efficiency, effectiveness, or adequacy for their proposed techniques, processes, or tools. Among those that provide a measure of efficiency, effectiveness, or adequacy, the majority use domain-agnostic generic measures such as number of failures, size of state-space, or verification time were most used. There is a trend in addressing the research gap in this respect by developing domain-specific notions of performance and adequacy. Defining widely accepted rigorous measures of performance and adequacy for each domain is an identified research gap. In terms of tools, the most widely used tools are well-established model-checkers such as Prism and Uppaal, as well as simulation tools such as Gazebo; Matlab/Simulink is another widely used toolset in this domain. Overall, there is very limited evidence of industrial applicability in the papers published in this domain. There is even a gap considering consolidated benchmarks for various types of autonomous systems.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "51",
        "numpages": "61",
        "keywords": "Verification and validation, robotics, autonomous systems, testing, literature survey"
    },
    "Dissecting American Fuzzy Lop: A FuzzBench Evaluation": {
        "type": "article",
        "key": "10.1145/3580596",
        "author": "Fioraldi, Andrea and Mantovani, Alessandro and Maier, Dominik and Balzarotti, Davide",
        "title": "Dissecting American Fuzzy Lop: A FuzzBench Evaluation",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3580596",
        "doi": "10.1145/3580596",
        "abstract": "AFL is one of the most used and extended fuzzers, adopted by industry and academic researchers alike. Although the community agrees on AFL\u2019s effectiveness at discovering new vulnerabilities and its outstanding usability, many of its internal design choices remain untested to date. Security practitioners often clone the project \u201cas-is\u201d and use it as a starting point to develop new techniques, usually taking everything under the hood for granted. Instead, we believe that a careful analysis of the different parameters could help modern fuzzers improve their performance and explain how each choice can affect the outcome of security testing, either negatively or positively. The goal of this work is to provide a comprehensive understanding of the internal mechanisms of AFL by performing experiments and by comparing different metrics used to evaluate fuzzers. This can help to show the effectiveness of some techniques and to clarify which aspects are instead outdated. To perform our study, we performed nine unique experiments that we carried out on the popular Fuzzbench platform. Each test focuses on a different aspect of AFL, ranging from its mutation approach to the feedback encoding scheme and its scheduling methodologies. Our findings show that each design choice affects different factors of AFL. Some of these are positively correlated with the number of detected bugs or the coverage of the target application, whereas other features are related to usability and reliability. Most important, we believe that the outcome of our experiments indicates which parts of AFL we should preserve in the design of modern fuzzers.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "52",
        "numpages": "26",
        "keywords": "Fuzzing, AFL, FuzzBench"
    },
    "Fuzzing Configurations of Program Options": {
        "type": "article",
        "key": "10.1145/3580597",
        "author": "Zhang, Zenong and Klees, George and Wang, Eric and Hicks, Michael and Wei, Shiyi",
        "title": "Fuzzing Configurations of Program Options",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3580597",
        "doi": "10.1145/3580597",
        "abstract": "While many real-world programs are shipped with configurations to enable/disable functionalities, fuzzers have mostly been applied to test single configurations of these programs. In this work, we first conduct an empirical study to understand how program configurations affect fuzzing performance. We find that limiting a campaign to a single configuration can result in failing to cover a significant amount of code. We also observe that different program configurations contribute differing amounts of code coverage, challenging the idea that each one can be efficiently fuzzed individually. Motivated by these two observations, we propose ConfigFuzz , which can fuzz configurations along with normal inputs. ConfigFuzz transforms the target program to encode its program options within part of the fuzzable input, so existing fuzzers\u2019 mutation operators can be reused to fuzz program configurations. We instantiate ConfigFuzz on six configurable, common fuzzing targets, and integrate their executions in FuzzBench. In our evaluation, ConfigFuzz outperforms two baseline fuzzers in four targets, while the results are mixed in the other targets due to program size and configuration space. We also analyze the options fuzzed by ConfigFuzz and how they affect the performance.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "mar",
        "articleno": "53",
        "numpages": "21",
        "keywords": "Fuzzing, command-line option configurations"
    },
    "Dissecting American Fuzzy Lop \u2013 A FuzzBench Evaluation - RCR Report": {
        "type": "article",
        "key": "10.1145/3580600",
        "author": "Fioraldi, Andrea and Mantovani, Alessandro and Maier, Dominik and Balzarotti, Davide",
        "title": "Dissecting American Fuzzy Lop \u2013 A FuzzBench Evaluation - RCR Report",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3580600",
        "doi": "10.1145/3580600",
        "abstract": "This report describes the artifacts of the \u201cDissecting American Fuzzy Lop \u2013 A FuzzBench Evaluation\u201d paper. The artifacts are available online at  and archived at . American Fuzzy Lop (AFL) consists of the produced code, the setup to run the experiments in FuzzBench, and the generated reports. We claim the Functional badge as the patches to AFL are easy to enable and the experiments are easy to run thanks to the FuzzBench service, but the evaluations are self-contained and the modifications to AFL are as is. For the purpose of reproducing the experiments, no particular skills are needed as the process is straightforward and described in .",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "54",
        "numpages": "4",
        "keywords": "fuzzing, afl, fuzzbench"
    },
    "Fuzzing Configurations of Program Options - RCR Report": {
        "type": "article",
        "key": "10.1145/3580601",
        "author": "Zhang, Zenong and Klees, George and Wang, Eric and Hicks, Michael and Wei, Shiyi",
        "title": "Fuzzing Configurations of Program Options - RCR Report",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3580601",
        "doi": "10.1145/3580601",
        "abstract": "This artifact contains the source code and instructions to reproduce the evaluation results of the article \u201cFuzzing Configurations of Program Options.\u201d The source code includes the configuration grammars for six target programs, the scripts to generate configuration stubs, and the scripts to post-process fuzzing results. The README of the artifact includes the steps to prepare the experimental environment on a clean Ubuntu machine and step-by-step commands to reproduce the evaluation experiments. A VirtualBox image with ConfigFuzz properly set up is also included.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "55",
        "numpages": "3",
        "keywords": "Fuzzing, command-line option configurations"
    },
    "Single and Multi-objective Test Cases Prioritization for Self-driving Cars in Virtual Environments": {
        "type": "article",
        "key": "10.1145/3533818",
        "author": "Birchler, Christian and Khatiri, Sajad and Derakhshanfar, Pouria and Panichella, Sebastiano and Panichella, Annibale",
        "title": "Single and Multi-objective Test Cases Prioritization for Self-driving Cars in Virtual Environments",
        "year": "2023",
        "issue_date": "March 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "2",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3533818",
        "doi": "10.1145/3533818",
        "abstract": "Testing with simulation environments helps to identify critical failing scenarios for self-driving cars (SDCs). Simulation-based tests are safer than in-field operational tests and allow detecting software defects before deployment. However, these tests are very expensive and are too many to be run frequently within limited time constraints.In this article, we investigate test case prioritization techniques to increase the ability to detect SDC regression faults with virtual tests earlier. Our approach, called SDC-Prioritizer, prioritizes virtual tests for SDCs according to static features of the roads we designed to be used within the driving scenarios. These features can be collected without running the tests, which means that they do not require past execution results. We introduce two evolutionary approaches to prioritize the test cases using diversity metrics (black-box heuristics) computed on these static features. These two approaches, called SO-SDC-Prioritizer and MO-SDC-Prioritizer, use single-objective and multi-objective genetic algorithms (GA), respectively, to find trade-offs between executing the less expensive tests and the most diverse test cases earlier.Our empirical study conducted in the SDC domain shows that MO-SDC-Prioritizer significantly (P- value &lt;=0.1e-10) improves the ability to detect safety-critical failures at the same level of execution time compared to baselines: random and greedy-based test case orderings. Besides, our study indicates that multi-objective meta-heuristics outperform single-objective approaches when prioritizing simulation-based tests for SDCs.MO-SDC-Prioritizer prioritizes test cases with a large improvement in fault detection while its overhead (up to 0.45\\% of the test execution cost) is negligible.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "28",
        "numpages": "30",
        "keywords": "Autonomous systems, software simulation, test case prioritization"
    },
    "Patching Locking Bugs Statically with Crayons": {
        "type": "article",
        "key": "10.1145/3548684",
        "author": "Cruz-Carlon, Juan and Varshosaz, Mahsa and Le Goues, Claire and Wasowski, Andrzej",
        "title": "Patching Locking Bugs Statically with Crayons",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3548684",
        "doi": "10.1145/3548684",
        "abstract": "The Linux Kernel is a world-class operating system controlling most of our computing infrastructure: mobile devices, Internet routers and services, and most of the supercomputers. Linux is also an example of low-level software with no comprehensive regression test suite (for good reasons). The kernel\u2019s tremendous societal importance imposes strict stability and correctness requirements. These properties make Linux a challenging and relevant target for static automated program repair (APR). Over the past decade, a significant progress has been made in dynamic APR. However, dynamic APR techniques do not translate naturally to systems without tests. We present a static APR technique addressing sequential locking API misuse bugs in the Linux Kernel. We attack the key challenge of static APR, namely, the lack of detailed program specification, by combining static analysis with machine learning to complement the information presented by the static analyzer. In experiments on historical real-world bugs in the kernel, we were able to automatically re-produce or propose equivalent patches in 85\\% of the human-made patches, and automatically rank them among the top three candidates for 64\\% of the cases and among the top five for 74\\%.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "56",
        "numpages": "28",
        "keywords": "Automated repair, static program repair, api misuse"
    },
    "Storage State Analysis and Extraction of Ethereum Blockchain Smart Contracts": {
        "type": "article",
        "key": "10.1145/3548683",
        "author": "Ayub, Maha and Saleem, Tania and Janjua, Muhammad and Ahmad, Talha",
        "title": "Storage State Analysis and Extraction of Ethereum Blockchain Smart Contracts",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3548683",
        "doi": "10.1145/3548683",
        "abstract": "In migrating and upgrading an Ethereum smart contract, it is necessary to transfer both the code as well as the stored data. Various methods attempt to migrate or upgrade a smart contract, but they are mostly manual, error-prone, and applicable only before deployment. Further, they have challenges in extracting the storage state of complex mapping data structures along with their keys. In this work, we present Smartmuv as an automatic source-code-based static analysis tool to analyze and extract the state from the storage-trie of smart contracts. Based on the abstract syntax tree and the control flow graphs of the Solidity source code, the tool analyzes each state variable including mapping types along the inheritance hierarchy. It also provides the upgrade algorithm that initializes the extracted state in the constructor of new smart contract. Smartmuv safely approximates the origin of the keys used in the mapping to extract values and has been able to extract the mapping state of 23,673 smart contracts with 95.7\\% overall precision. Moreover, we also validate the Smartmuv\u2019s extracted state with the third-party tool Etherscan.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "57",
        "numpages": "32",
        "keywords": "Blockchain, Solidity, compiler, source code, Smartmuv, state extraction, upgrade"
    },
    "Parameter Coverage for Testing of Autonomous Driving Systems under Uncertainty": {
        "type": "article",
        "key": "10.1145/3550270",
        "author": "Laurent, Thomas and Klikovits, Stefan and Arcaini, Paolo and Ishikawa, Fuyuki and Ventresque, Anthony",
        "title": "Parameter Coverage for Testing of Autonomous Driving Systems under Uncertainty",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3550270",
        "doi": "10.1145/3550270",
        "abstract": "Autonomous Driving Systems (ADSs) are promising, but must show they are secure and trustworthy before adoption. Simulation-based testing is a widely adopted approach, where the ADS is run in a simulated environment over specific scenarios. Coverage criteria specify what needs to be covered to consider the ADS sufficiently tested. However, existing criteria do not guarantee to exercise the different decisions that the ADS can make, which is essential to assess its correctness. ADSs usually compute their decisions using parameterised rule-based systems and cost functions, such as cost components or decision thresholds. In this article, we argue that the parameters characterise the decision process, as their values affect the ADS\u2019s final decisions. Therefore, we propose parameter coverage, a criterion requiring to cover the ADS\u2019s parameters. A scenario covers a parameter if changing its value leads to different simulation results, meaning it is relevant for the driving decisions made in the scenario. Since ADS simulators are slightly uncertain, we employ statistical methods to assess multiple simulation runs for execution difference and coverage. Experiments using the Autonomoose ADS show that the criterion discriminates between different scenarios and that the cost of computing coverage can be managed with suitable heuristics.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "58",
        "numpages": "31",
        "keywords": "Software testing, autonomous driving, coverage criteria, mutation analysis"
    },
    "Is My Transaction Done Yet? An Empirical Study of Transaction Processing Times in the Ethereum Blockchain Platform": {
        "type": "article",
        "key": "10.1145/3549542",
        "author": "Pacheco, Michael and Oliva, Gustavo and Rajbahadur, Gopi Krishnan and Hassan, Ahmed",
        "title": "Is My Transaction Done Yet? An Empirical Study of Transaction Processing Times in the Ethereum Blockchain Platform",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3549542",
        "doi": "10.1145/3549542",
        "abstract": "Ethereum is one of the most popular platforms for the development of blockchain-powered applications. These applications are known as \\DH{}Apps. When engineering \\DH{}Apps, developers need to translate requests captured in the front-end of their application into one or more smart contract transactions. Developers need to pay for these transactions and, the more they pay (i.e., the higher the gas price), the faster the transaction is likely to be processed. Developing cost-effective \\DH{}Apps is far from trivial, as developers need to optimize the balance between cost (transaction fees) and user experience (transaction processing times). Online services have been developed to provide transaction issuers (e.g., \\DH{}App developers) with an estimate of how long transactions will take to be processed given a certain gas price. These estimation services are crucial in the Ethereum domain and several popular wallets such as Metamask rely on them. However, despite their key role, their accuracy has not been empirically investigated so far. In this article, we quantify the transaction processing times in Ethereum, investigate the relationship between processing times and gas prices, and determine the accuracy of state-of-the-practice estimation services. Our results indicate that transactions are processed in a median of 57 seconds and that 90\\% of the transactions are processed within 8 minutes. We also show that higher gas prices result in faster transaction processing times with diminishing returns. In particular, we observe no practical difference in processing time between expensive and very expensive transactions. With regards to the accuracy of processing time estimation services, we observe that they are equivalent. However, when stratifying transactions by gas prices, we observe that Etherscan\u2019s Gas Tracker is the most accurate estimation service for the very cheap and cheap transactions. EthGasStation\u2019s Gas Price API, in turn, is the most accurate estimation service for regular, expensive, and very expensive transactions. In a post-hoc study, we design a simple linear regression model with only one feature that outperforms the Gas Tracker for very cheap and cheap transactions and that performs as accurately as the EthGasStation model for the remaining categories. Based on our findings, \\DH{}App developers can make more informed decisions concerning the choice of the gas price of their application-issued transactions.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "59",
        "numpages": "46",
        "keywords": "Transaction processing time, decentralized applications (DApps), Ethereum, blockchain"
    },
    "SLR: From Saltzer and Schroeder to 2021\u202647 Years of Research on the Development and Validation of Security API Recommendations": {
        "type": "article",
        "key": "10.1145/3561383",
        "author": "Patnaik, Nikhil and Dwyer, Andrew and Hallett, Joseph and Rashid, Awais",
        "title": "SLR: From Saltzer and Schroeder to 2021\u202647 Years of Research on the Development and Validation of Security API Recommendations",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3561383",
        "doi": "10.1145/3561383",
        "abstract": "Producing secure software is challenging. The poor usability of security Application Programming Interfaces (APIs) makes this even harder. Many recommendations have been proposed to support developers by improving the usability of cryptography libraries\u2014rooted in wider best practice guidance in software engineering and API design. In this SLR, we systematize knowledge regarding these recommendations. We identify and analyze 65 papers, offering 883 recommendations. Through thematic analysis, we identify seven core ways to improve usability of APIs. Most of the recommendations focus on helping API developers to construct and structure their code and make it more usable and easier for programmers to understand. There is less focus, however, on documentation, writing requirements, code quality assessment, and the impact of organizational software development practices. By tracing and analyzing paper ancestry, we map how this knowledge becomes validated and translated over time. We find that very few API usability recommendations are empirically validated, and that recommendations specific to usable security APIs lag even further behind.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "60",
        "numpages": "31",
        "keywords": "API, usability, security, SLR, recommendations"
    },
    "Pied-Piper: Revealing the Backdoor Threats in Ethereum ERC Token Contracts": {
        "type": "article",
        "key": "10.1145/3560264",
        "author": "Ma, Fuchen and Ren, Meng and Ouyang, Lerong and Chen, Yuanliang and Zhu, Juan and Chen, Ting and Zheng, Yingli and Dai, Xiao and Jiang, Yu and Sun, Jiaguang",
        "title": "Pied-Piper: Revealing the Backdoor Threats in Ethereum ERC Token Contracts",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3560264",
        "doi": "10.1145/3560264",
        "abstract": "With the development of decentralized networks, smart contracts, especially those for ERC tokens, are attracting more and more Dapp users to implement their applications. There are some functions in ERC token contracts that only a specific group of accounts could invoke. Among those functions, some even can influence other accounts or the whole system without prior notice or permission. These functions are referred to as contract backdoors. Once exploited by an attacker, they can cause property losses and harm users\u2019 privacy.In this work, we propose Pied-Piper, a hybrid analysis method that integrates datalog analysis and directed fuzzing to detect backdoor threats in Ethereum ERC token contracts. First, datalog analysis is applied to abstract the data structures and identification rules related to the threats for preliminary static detection. Then, directed fuzzing is applied to eliminate false positives caused by the static analysis. We first evaluated Pied-Piper on 200 smart contracts, which are injected with different types of backdoors. It reported all problems without false positives, and none of the injected problems was missed. Then, we applied Pied-Piper on 13,484 real token contracts deployed on Ethereum. Pied-Piper reported 189 confirmed problems, four of which have been assigned unique CVE ids while others are still in the review process. Each contract takes 8.03 seconds for datalog analysis on average, and the fuzzing engine can eliminate the false positives within one minute.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "61",
        "numpages": "24",
        "keywords": "Smart contract, backdoor detection, datalog analysis, directed fuzzing"
    },
    "Precise Quantitative Analysis of Binarized Neural Networks: A BDD-based Approach": {
        "type": "article",
        "key": "10.1145/3563212",
        "author": "Zhang, Yedi and Zhao, Zhe and Chen, Guangke and Song, Fu and Chen, Taolue",
        "title": "Precise Quantitative Analysis of Binarized Neural Networks: A BDD-based Approach",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3563212",
        "doi": "10.1145/3563212",
        "abstract": "As a new programming paradigm, neural-network-based machine learning has expanded its application to many real-world problems. Due to the black-box nature of neural networks, verifying and explaining their behavior are becoming increasingly important, especially when they are deployed in safety-critical applications. Existing verification work mostly focuses on qualitative verification, which asks whether there exists an input (in a specified region) for a neural network such that a property (e.g., local robustness) is violated. However, in many practical applications, such an (adversarial) input almost surely exists, which makes a qualitative answer less meaningful. In this work, we study a more interesting yet more challenging problem, i.e., quantitative verification of neural networks, which asks how often a property is satisfied or violated. We target binarized neural networks (BNNs), the 1-bit quantization of general neural networks. BNNs have attracted increasing attention in deep learning recently, as they can drastically reduce memory storage and execution time with bit-wise operations, which is crucial in recourse-constrained scenarios, e.g., embedded devices for Internet of Things. Toward quantitative verification of BNNs, we propose a novel algorithmic approach for encoding BNNs as Binary Decision Diagrams (BDDs), a widely studied model in formal verification and knowledge representation. By exploiting the internal structure of the BNNs, our encoding translates the input-output relation of blocks in BNNs to cardinality constraints, which are then encoded by BDDs. Based on the new BDD encoding, we develop a quantitative verification framework for BNNs where precise and comprehensive analysis of BNNs can be performed. To improve the scalability of BDD encoding, we also investigate parallelization strategies at various levels. We demonstrate applications of our framework by providing quantitative robustness verification and interpretability for BNNs. An extensive experimental evaluation confirms the effectiveness and efficiency of our approach.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "62",
        "numpages": "51",
        "keywords": "Binarized neural networks, binary decision diagrams, formal verification, robustness, interpretability"
    },
    "How the Quality of Maintenance Tasks is Affected by Criteria for Selecting Engineers for Collaboration": {
        "type": "article",
        "key": "10.1145/3561384",
        "author": "P\\'{e}rez, Francisca and Lape\\~{n}a, Ra\\'{u}l and Marc\\'{e}n, Ana and Cetina, Carlos",
        "title": "How the Quality of Maintenance Tasks is Affected by Criteria for Selecting Engineers for Collaboration",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3561384",
        "doi": "10.1145/3561384",
        "abstract": "In industry, software projects might span over decades, with many engineers joining or leaving the company over time. In these circumstances, no single engineer has all of the knowledge when maintenance tasks such as Traceability Link Recovery (TLR), Bug Localization (BL), and Feature Location (FL) are performed. Thus, collaboration has the potential to boost the quality of maintenance tasks since the solution advanced by one engineer might be enhanced with contributions from other engineers. However, assembling a team of software engineers to collaborate may not be as intuitive as we might think. In the context of a worldwide industrial supplier of railway solutions, this work evaluates how the quality of TLR, BL, and FL is affected by the criteria for selecting engineers for collaboration. The criteria for collaboration are based on engineers\u2019 profile information to select the set of search queries that are involved in the maintenance task. Collaboration is achieved by applying automatic query reformulation, and the location relies on an evolutionary algorithm. Our work uncovers how software engineers who might be seen as not being relevant in the collaboration can lead to significantly better results. A focus group confirmed the relevance of the findings.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "63",
        "numpages": "22",
        "keywords": "Collaborative software engineering, search-based software engineering, model-driven engineering"
    },
    "Security Responses in Software Development": {
        "type": "article",
        "key": "10.1145/3563211",
        "author": "Lopez, Tamara and Sharp, Helen and Bandara, Arosha and Tun, Thein and Levine, Mark and Nuseibeh, Bashar",
        "title": "Security Responses in Software Development",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3563211",
        "doi": "10.1145/3563211",
        "abstract": "The pressure on software developers to produce secure software has never been greater. But what does security look like in environments that do not produce security-critical software? In answer to this question, this multi-sited ethnographic study characterizes security episodes and identifies five typical behaviors in software development. Using theory drawn from information security and motivation research in software engineering, this article characterizes key ways in which individual developers form security responses to meet the demands of particular circumstances, providing a framework managers and teams can use to recognize, understand, and alter security activity in their environments.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "64",
        "numpages": "29",
        "keywords": "Security, developers, software engineering"
    },
    "Seeing the Whole Elephant: Systematically Understanding and Uncovering Evaluation Biases in Automated Program Repair": {
        "type": "article",
        "key": "10.1145/3561382",
        "author": "Yang, Deheng and Lei, Yan and Mao, Xiaoguang and Qi, Yuhua and Yi, Xin",
        "title": "Seeing the Whole Elephant: Systematically Understanding and Uncovering Evaluation Biases in Automated Program Repair",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3561382",
        "doi": "10.1145/3561382",
        "abstract": "Evaluation is the foundation of automated program repair (APR), as it provides empirical evidence on strengths and weaknesses of APR techniques. However, the reliability of such evaluation is often threatened by various introduced biases. Consequently, bias exploration, which uncovers biases in the APR evaluation, has become a pivotal activity and performed since the early years when pioneer APR techniques were proposed. Unfortunately, there is still no methodology to support a systematic comprehension and discovery of evaluation biases in APR, which impedes the mitigation of such biases and threatens the evaluation of APR techniques.In this work, we propose to systematically understand existing evaluation biases by rigorously conducting the first systematic literature review on existing known biases and systematically uncover new biases by building a taxonomy that categorizes evaluation biases. As a result, we identify 17 investigated biases and uncover a new bias in the usage of patch validation strategies. To validate this new bias, we devise and implement an executable framework APRConfig, based on which we evaluate three typical patch validation strategies with four representative heuristic-based and constraint-based APR techniques on three bug datasets. Overall, this article distills 13 findings for bias understanding, discovery, and validation. The systematic exploration we performed and the open source executable framework we proposed in this article provide new insights as well as an infrastructure for future exploration and mitigation of biases in APR evaluation.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "65",
        "numpages": "37",
        "keywords": "Automated program repair, bias study, empirical evaluation"
    },
    "Anchor: Fast and Precise Value-flow Analysis for Containers via Memory Orientation": {
        "type": "article",
        "key": "10.1145/3565800",
        "author": "Wang, Chengpeng and Wang, Wenyang and Yao, Peisen and Shi, Qingkai and Zhou, Jinguo and Xiao, Xiao and Zhang, Charles",
        "title": "Anchor: Fast and Precise Value-flow Analysis for Containers via Memory Orientation",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3565800",
        "doi": "10.1145/3565800",
        "abstract": "Containers are ubiquitous data structures that support a variety of manipulations on the elements, inducing the indirect value flows in the program. Tracking value flows through containers is stunningly difficult, because it depends on container memory layouts, which are expensive to be discovered.This work presents a fast and precise value-flow analysis framework called Anchor for the programs using containers. We introduce the notion of anchored containers and propose the memory orientation analysis to construct a precise value-flow graph. Specifically, we establish a combined domain to identify anchored containers and apply strong updates to container memory layouts. Anchor finally conducts a demand-driven reachability analysis in the value-flow graph for a client. Experiments show that it removes 17.1\\% spurious statements from thin slices and discovers 20 null pointer exceptions with 9.1\\% as its false-positive ratio, while the smashing-based analysis reports 66.7\\% false positives. Anchor scales to millions of lines of code and checks the program with around 5.12 MLoC within 5 hours.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "66",
        "numpages": "39",
        "keywords": "Abstract interpretation, value-flow analysis, data structure analysis"
    },
    "Automated Identification and Qualitative Characterization of Safety Concerns Reported in UAV Software Platforms": {
        "type": "article",
        "key": "10.1145/3564821",
        "author": "Di Sorbo, Andrea and Zampetti, Fiorella and Visaggio, Aaron and Di Penta, Massimiliano and Panichella, Sebastiano",
        "title": "Automated Identification and Qualitative Characterization of Safety Concerns Reported in UAV Software Platforms",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3564821",
        "doi": "10.1145/3564821",
        "abstract": "Unmanned Aerial Vehicles (UAVs) are nowadays used in a variety of applications. Given the cyber-physical nature of UAVs, software defects in these systems can cause issues with safety-critical implications. An important aspect of the lifecycle of UAV software is to minimize the possibility of harming humans or damaging properties through a continuous process of hazard identification and safety risk management. Specifically, safety-related concerns typically emerge during the operation of UAV systems, reported by end-users and developers in the form of issue reports and pull requests. However, popular UAV systems daily receive tens or hundreds of reports of varying types and quality. To help developers timely identify and triage safety-critical UAV issues, we (i) experiment with automated approaches (previously used for issue classification) for detecting the safety-related matters appearing in the titles and descriptions of issues and pull requests reported in UAV platforms and (ii) propose a categorization of the main hazards and accidents discussed in such issues. Our results (i) show that shallow machine learning (ML)-based approaches can identify safety-related sentences with precision, recall, and F-measure values of about 80\\%; and (ii) provide a categorization and description of the relationships between safety issue hazards and accidents.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "67",
        "numpages": "37",
        "keywords": "Unmanned aerial vehicles, issue management, safety issues, machine learning, empirical study"
    },
    "Do Performance Aspirations Matter for Guiding Software Configuration Tuning? An Empirical Investigation under Dual Performance Objectives": {
        "type": "article",
        "key": "10.1145/3571853",
        "author": "Chen, Tao and Li, Miqing",
        "title": "Do Performance Aspirations Matter for Guiding Software Configuration Tuning? An Empirical Investigation under Dual Performance Objectives",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571853",
        "doi": "10.1145/3571853",
        "abstract": "Configurable software systems can be tuned for better performance. Leveraging on some Pareto optimizers, recent work has shifted from tuning for a single, time-related performance objective to two intrinsically different objectives that assess distinct performance aspects of the system, each with varying aspirations to be satisfied, e.g., \u201cthe latency is less than 10s\u201d while \u201cthe memory usage is no more than 1GB\u201d. Before we design better optimizers, a crucial engineering decision to make therein is how to handle the performance requirements with clear aspirations in the tuning process. For this, the community takes two alternative optimization models: either quantifying and incorporating the aspirations into the search objectives that guide the tuning, or not considering the aspirations during the search but purely using them in the later decision-making process only. However, despite being a crucial decision that determines how an optimizer can be designed and tailored, there is a rather limited understanding of which optimization model should be chosen under what particular circumstance, and why.In this article, we seek to close this gap. Firstly, we do that through a review of over 426 articles in the literature and 14 real-world requirements datasets, from which we summarize four performance requirement patterns that quantify the aspirations in the configuration tuning. Drawing on these, we then conduct a comprehensive empirical study that covers 15 combinations of the state-of-the-art performance requirement patterns, four types of aspiration space, three Pareto optimizers, and eight real-world systems/environments, leading to 1,296 cases of investigation. Our findings reveal that (1) the realism of aspirations is the key factor that determines whether they should be used to guide the tuning; (2) the given patterns and the position of the realistic aspirations in the objective landscape are less important for the choice, but they do matter to the extents of improvement; (3) the available tuning budget can also influence the choice for unrealistic aspirations but it is insignificant under realistic ones. To promote open science practice, we make our code and dataset publicly available at: .",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "68",
        "numpages": "41",
        "keywords": "Search-Based Software Engineering, software configuration tuning, performance requirement, performance aspiration, multi-objective optimization"
    },
    "What Is the Intended Usage Context of This Model? An Exploratory Study of Pre-Trained Models on Various Model Repositories": {
        "type": "article",
        "key": "10.1145/3569934",
        "author": "Gong, Lina and Zhang, Jingxuan and Wei, Mingqiang and Zhang, Haoxiang and Huang, Zhiqiu",
        "title": "What Is the Intended Usage Context of This Model? An Exploratory Study of Pre-Trained Models on Various Model Repositories",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3569934",
        "doi": "10.1145/3569934",
        "abstract": "There is a trend of researchers and practitioners to directly apply pre-trained models to solve their specific tasks. For example, researchers in software engineering (SE) have successfully exploited the pre-trained language models to automatically generate the source code and comments. However, there are domain gaps in different benchmark datasets. These data-driven (or machine learning based) models trained on one benchmark dataset may not operate smoothly on other benchmarks. Thus, the reuse of pre-trained models introduces large costs and additional problems of checking whether arbitrary pre-trained models are suitable for the task-specific reuse or not. To our knowledge, software engineers can leverage code contracts to maximize the reuse of existing software components or software services. Similar to the software reuse in the SE field, reuse SE could be extended to the area of pre-trained model reuse. Therefore, according to the model card\u2019s and FactSheet\u2019s guidance for suppliers of pre-trained models on what information they should be published, we propose model contracts including the pre- and post-conditions of pre-trained models to enable better model reuse. Furthermore, many non-trivial yet challenging issues have not been fully investigated, although many pre-trained models are readily available on the model repositories. Based on our model contract, we conduct an exploratory study of 1908 pre-trained models on six mainstream model repositories (i.e., the TensorFlow Hub, PyTorch Hub, Model Zoo, Wolfram Neural Net Repository, Nvidia, and Hugging Face) to investigate the gap between necessary pre- and post-condition information and actual specifications. Our results clearly show that (1) the model repositories tend to provide confusing information of the pre-trained models, especially the information about the task\u2019s type, model, training set, and (2) the model repositories cannot provide all of our proposed pre/post-condition information, especially the intended use, limitation, performance, and quantitative analysis. On the basis of our new findings, we suggest that (1) the developers of model repositories shall provide some necessary options (e.g., the training dataset, model algorithm, and performance measures) for each of pre/post-conditions of pre-trained models in each task type, (2) future researchers and practitioners provide more efficient metrics to recommend suitable pre-trained model, and (3) the suppliers of pre-trained models should report their pre-trained models in strict accordance with our proposed pre/post-condition and report their models according to the characteristics of each condition that has been reported in the model repositories.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "69",
        "numpages": "57",
        "keywords": "Software engineering for artificial intelligence, pre-trained models, model reuse, model contract"
    },
    "Simulating Software Evolution to Evaluate the Reliability of Early Decision-making among Design Alternatives toward Maintainability": {
        "type": "article",
        "key": "10.1145/3569931",
        "author": "Karanikolas, Chris and Dimitroulakos, Grigoris and Masselos, Konstantinos",
        "title": "Simulating Software Evolution to Evaluate the Reliability of Early Decision-making among Design Alternatives toward Maintainability",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3569931",
        "doi": "10.1145/3569931",
        "abstract": "Critical decisions among design altern seventh atives with regards to maintainability arise early in the software design cycle. Existing comparison models relayed on the structural evolution of the used design patterns are suitable to support such decisions. However, their effectiveness on predicting maintenance effort is usually verified on a limited number of case studies under heterogeneous metrics. In this article, a multi-variable simulation model for validating the decision-making reliability of the derived formal comparison models for the significant designing problem of recursive hierarchies of part-whole aggregations, proposed in our prior work, is introduced. In the absence of a strict validation, the simulation model has been thoroughly calibrated concerning its decision-making precision based on empirical distributions from time-series analysis, approximating the highly uncertain nature of actual maintenance process. The decision reliability of the formal models has been statistically validated on a sample of 1,000 instances of design attributes representing the entire design space of the problem. Despite the limited accuracy of measurements, the results show that the models demonstrate an increasing reliability in a long-term perspective, even under assumptions of high variability. Thus, the modeling theory discussed in our prior work delivers reliable models that significantly reduce decision-risk and relevant maintenance cost.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "70",
        "numpages": "38",
        "keywords": "Statistical validation, maintainability quality attribute requirement, software evolution, design pattern"
    },
    "Route: Roads Not Taken in UI Testing": {
        "type": "article",
        "key": "10.1145/3571851",
        "author": "Lin, Jun-Wei and Salehnamadi, Navid and Malek, Sam",
        "title": "Route: Roads Not Taken in UI Testing",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571851",
        "doi": "10.1145/3571851",
        "abstract": "Core features (functionalities) of an app can often be accessed and invoked in several ways, i.e., through alternative sequences of user-interface (UI) interactions. Given the manual effort of writing tests, developers often only consider the typical way of invoking features when creating the tests (i.e., the \u201csunny day scenario\u201d). However, the alternative ways of invoking a feature are as likely to be faulty. These faults would go undetected without proper tests. To reduce the manual effort of creating UI tests and help developers more thoroughly examine the features of apps, we present Route, an automated tool for feature-based UI test augmentation for Android apps. Route first takes a UI test and the app under test as input. It then applies novel heuristics to find additional high-quality UI tests, consisting of both inputs and assertions, that verify the same feature as the original test in alternative ways. Application of Route on several dozen tests for popular apps on Google Play shows that for 96\\% of the existing tests, Route was able to generate at least one alternative test. Moreover, the fault detection effectiveness of augmented test suites in our experiments showed substantial improvements of up to 39\\% over the original test suites.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "71",
        "numpages": "25",
        "keywords": "GUI test augmentation, test reuse, test amplification, mobile testing"
    },
    "Exploring Better Black-Box Test Case Prioritization via Log Analysis": {
        "type": "article",
        "key": "10.1145/3569932",
        "author": "Chen, Zhichao and Chen, Junjie and Wang, Weijing and Zhou, Jianyi and Wang, Meng and Chen, Xiang and Zhou, Shan and Wang, Jianmin",
        "title": "Exploring Better Black-Box Test Case Prioritization via Log Analysis",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3569932",
        "doi": "10.1145/3569932",
        "abstract": "Test case prioritization (TCP) has been widely studied in regression testing, which aims to optimize the execution order of test cases so as to detect more faults earlier. TCP has been divided into white-box test case prioritization (WTCP) and black-box test case prioritization (BTCP). WTCP can achieve better prioritization effectiveness by utilizing source code information, but is not applicable in many practical scenarios (where source code is unavailable, e.g., outsourced testing). BTCP has the benefit of not relying on source code information, but tends to be less effective than WTCP. That is, both WTCP and BTCP suffer from limitations in the practical use.To improve the practicability of TCP, we aim to explore better BTCP, significantly bridging the effectiveness gap between BTCP and WTCP. In this work, instead of statically analyzing test cases themselves in existing BTCP techniques, we conduct the first study to explore whether this goal can be achieved via log analysis. Specifically, we propose to mine test logs produced during test execution to more sufficiently reflect test behaviors, and design a new BTCP framework (called LogTCP), including log pre-processing, log representation, and test case prioritization components. Based on the LogTCP framework, we instantiate seven log-based BTCP techniques by combining different log representation strategies with different prioritization strategies.We conduct an empirical study to explore the effectiveness of LogTCP. Based on 10 diverse open-source Java projects from GitHub, we compared LogTCP with three representative BTCP techniques and four representative WTCP techniques. Our results show that all of our LogTCP techniques largely perform better than all the BTCP techniques in average fault detection, to the extent that they become competitive to the WTCP techniques. That demonstrates the great potential of logs in practical TCP.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "72",
        "numpages": "32",
        "keywords": "Test case prioritization, log analysis, regression testing"
    },
    "Continuous Integration and Delivery Practices for Cyber-Physical Systems: An Interview-Based Study": {
        "type": "article",
        "key": "10.1145/3571854",
        "author": "Zampetti, Fiorella and Tamburri, Damian and Panichella, Sebastiano and Panichella, Annibale and Canfora, Gerardo and Di Penta, Massimiliano",
        "title": "Continuous Integration and Delivery Practices for Cyber-Physical Systems: An Interview-Based Study",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571854",
        "doi": "10.1145/3571854",
        "abstract": "Continuous Integration and Delivery (CI/CD) practices have shown several benefits for software development and operations, such as faster release cycles and early discovery of defects. For Cyber-Physical System (CPS) development, CI/CD can help achieving required goals, such as high dependability, yet it may be challenging to apply. This article empirically investigates challenges, barriers, and their mitigation occurring when applying CI/CD practices to develop CPSs in 10 organizations working in eight different domains. The study has been conducted through semi-structured interviews, by applying an open card sorting procedure together with a member-checking survey within the same organizations, and by validating the results through a further survey involving 55 professional developers. The study reveals several peculiarities in the application of CI/CD to CPSs. These include the need for (i) combining continuous and periodic builds while balancing the use of Hardware-in-the-Loop and simulators, (ii) coping with difficulties in software deployment (iii) accounting for simulators and Hardware-in-the-Loop differing in their behavior, and (vi) combining hardware/software expertise in the development team. Our findings open the road toward recommenders aimed at supporting the setting and evolution of CI/CD pipelines, as well as university curricula requiring interdisciplinarity, such as knowledge about hardware, software, and their interplay.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "73",
        "numpages": "44",
        "keywords": "Continuous Integration and Delivery, Cyber-Physical Systems, empirical software engineering"
    },
    "A Theory of Scrum Team Effectiveness": {
        "type": "article",
        "key": "10.1145/3571849",
        "author": "Verwijs, Christiaan and Russo, Daniel",
        "title": "A Theory of Scrum Team Effectiveness",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571849",
        "doi": "10.1145/3571849",
        "abstract": "Scrum teams are at the heart of the Scrum framework. Nevertheless, an integrated and systemic theory that can explain what makes some Scrum teams more effective than others is still missing. To address this gap, we performed a 7-year-long mixed-methods investigation composed of two main phases. First, we induced a theoretical model from 13 exploratory field studies. Our model proposes that the effectiveness of Scrum teams depends on five high-level factors (responsiveness, stakeholder concern, continuous improvement, team autonomy, and management support) and 13 lower-level factors. In the second phase of our study, we validated our model with a covariance-based structural equation modeling analysis using data from about 5,000 developers and 2,000 Scrum teams that we gathered with a custom-built survey. Results suggest a very good fit of the empirical data in our theoretical model (CFI = 0.959, RMSEA = 0.038, SRMR = 0.035). Accordingly, this research allowed us to (1) propose and validate a generalizable theory for effective Scrum teams and (2) formulate clear recommendations for how organizations can better support Scrum teams.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "74",
        "numpages": "51",
        "keywords": "Agile, Scrum, teams, structural equation modeling, case studies"
    },
    "Similarity-based Web Element Localization for Robust Test Automation": {
        "type": "article",
        "key": "10.1145/3571855",
        "author": "Nass, Michel and Al\\'{e}groth, Emil and Feldt, Robert and Leotta, Maurizio and Ricca, Filippo",
        "title": "Similarity-based Web Element Localization for Robust Test Automation",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571855",
        "doi": "10.1145/3571855",
        "abstract": "Non-robust (fragile) test execution is a commonly reported challenge in GUI-based test automation, despite much research and several proposed solutions. A test script needs to be resilient to (minor) changes in the tested application but, at the same time, fail when detecting potential issues that require investigation. Test script fragility is a multi-faceted problem. However, one crucial challenge is how to reliably identify and locate the correct target web elements when the website evolves between releases or otherwise fail and report an issue. This article proposes and evaluates a novel approach called similarity-based web element localization (Similo), which leverages information from multiple web element locator parameters to identify a target element using a weighted similarity score. This experimental study compares Similo to a baseline approach for web element localization. To get an extensive empirical basis, we target 48 of the most popular websites on the Internet in our evaluation. Robustness is considered by counting the number of web elements found in a recent website version compared to how many of these existed in an older version. Results of the experiment show that Similo outperforms the baseline; it failed to locate the correct target web element in 91 out of 801 considered cases (i.e., 11\\%) compared to 214 failed cases (i.e., 27\\%) for the baseline approach. The time efficiency of Similo was also considered, where the average time to locate a web element was determined to be 4 milliseconds. However, since the cost of web interactions (e.g., a click) is typically on the order of hundreds of milliseconds, the additional computational demands of Similo can be considered negligible. This study presents evidence that quantifying the similarity between multiple attributes of web elements when trying to locate them, as in our proposed Similo approach, is beneficial. With acceptable efficiency, Similo gives significantly higher effectiveness (i.e., robustness) than the baseline web element localization approach.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "75",
        "numpages": "30",
        "keywords": "GUI testing, test automation, test case robustness, web element locators, XPath locators"
    },
    "Blindspots in Python and Java APIs Result in Vulnerable Code": {
        "type": "article",
        "key": "10.1145/3571850",
        "author": "Brun, Yuriy and Lin, Tian and Somerville, Jessie Elise and Myers, Elisha M. and Ebner, Natalie",
        "title": "Blindspots in Python and Java APIs Result in Vulnerable Code",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571850",
        "doi": "10.1145/3571850",
        "abstract": "Blindspots in APIs can cause software engineers to introduce vulnerabilities, but such blindspots are, unfortunately, common. We study the effect APIs with blindspots have on developers in two languages by replicating a 109-developer, 24-Java-API controlled experiment. Our replication applies to Python and involves 129 new developers and 22 new APIs. We find that using APIs with blindspots statistically significantly reduces the developers\u2019 ability to correctly reason about the APIs in both languages, but that the effect is more pronounced for Python. Interestingly, for Java, the effect increased with complexity of the code relying on the API, whereas for Python, the opposite was true. This suggests that Python developers are less likely to notice potential for vulnerabilities in complex code than in simple code, whereas Java developers are more likely to recognize the extra complexity and apply more care, but are more careless with simple code. Whether the developers considered API uses to be more difficult, less clear, and less familiar did not have an effect on their ability to correctly reason about them. Developers with better long-term memory recall were more likely to correctly reason about APIs with blindspots, but short-term memory, processing speed, episodic memory, and memory span had no effect. Surprisingly, professional experience and expertise did not improve the developers\u2019 ability to reason about APIs with blindspots across both languages, with long-term professionals with many years of experience making mistakes as often as relative novices. Finally, personality traits did not significantly affect the Python developers\u2019 ability to reason about APIs with blindspots, but less extroverted and more open developers were better at reasoning about Java APIs with blindspots. Overall, our findings suggest that blindspots in APIs are a serious problem across languages, and that experience and education alone do not overcome that problem, suggesting that tools are needed to help developers recognize blindspots in APIs as they write code that uses those APIs.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "76",
        "numpages": "31",
        "keywords": "Software vulnerabilities, Java, Python, APIs, API blindspots"
    },
    "Refactoring in Computational Notebooks": {
        "type": "article",
        "key": "10.1145/3576036",
        "author": "Liu, Eric S. and Lukes, Dylan A. and Griswold, William G.",
        "title": "Refactoring in Computational Notebooks",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3576036",
        "doi": "10.1145/3576036",
        "abstract": "Due to the exploratory nature of computational notebook development, a notebook can be extensively evolved even though it is small, potentially incurring substantial technical debt. Indeed, in interview studies notebook authors have attested to performing ongoing tidying and big cleanups. However, many notebook authors are not trained as software developers, and environments like JupyterLab possess few features to aid notebook maintenance. As software refactoring is traditionally a critical tool for reducing technical debt, we sought to better understand the unique and growing ecology of computational notebooks by investigating the refactoring of public Jupyter notebooks. We randomly selected 15,000 Jupyter notebooks hosted on GitHub and studied 200 with meaningful commit histories. We found that notebook authors do refactor, favoring a few basic classic refactorings as well as those involving the notebook cell construct. Those with a computing background refactored differently than others, but not more so. Exploration-focused notebooks had a unique refactoring profile compared to more exposition-focused notebooks. Authors more often refactored their code as they went along, rather than deferring maintenance to big cleanups. These findings point to refactoring being intrinsic to notebook development.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "77",
        "numpages": "24",
        "keywords": "Computational notebooks, end-user programming, refactoring"
    },
    "Influential Global and Local Contexts Guided Trace Representation for Fault Localization": {
        "type": "article",
        "key": "10.1145/3576043",
        "author": "Zhang, Zhuo and Lei, Yan and Su, Ting and Yan, Meng and Mao, Xiaoguang and Yu, Yue",
        "title": "Influential Global and Local Contexts Guided Trace Representation for Fault Localization",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3576043",
        "doi": "10.1145/3576043",
        "abstract": "Trace data is critical for fault localization (FL) to analyze suspicious statements potentially responsible for a failure. However, existing trace representation meets its bottleneck mainly in two aspects: (1) the trace information of a statement is restricted to a local context (i.e., a test case) without the consideration of a global context (i.e., all test cases of a test suite); (2) it just uses the \u2018occurrence\u2019 for representation without strong FL semantics. Thus, we propose UNITE: an inflUential coNtext-GuIded Trace rEpresentation, representing the trace from both global and local contexts with influential semantics for FL. UNITE embodies and implements two key ideas: (1) UNITE leverages the widely used weighting capability from local and global contexts of information retrieval to reflect how important a statement (a word) is to a test case (a document) in all test cases of a test suite (a collection), where a test case (a document) and all test cases of a test suite (a collection) represent local and global contexts respectively; (2) UNITE further elaborates the trace representation from \u2018occurrence\u2019 (weak semantics) to \u2018influence\u2019 (strong semantics) by combing program dependencies. The large-scale experiments on 12 FL techniques and 20 programs show that UNITE significantly improves FL effectiveness.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "78",
        "numpages": "27",
        "keywords": "Fault localization, trace representation, statement weighting, program dependence, suspiciousness"
    },
    "Black-box Safety Analysis and Retraining of DNNs based on Feature Extraction and Clustering": {
        "type": "article",
        "key": "10.1145/3550271",
        "author": "Attaoui, Mohammed and Fahmy, Hazem and Pastore, Fabrizio and Briand, Lionel",
        "title": "Black-box Safety Analysis and Retraining of DNNs based on Feature Extraction and Clustering",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3550271",
        "doi": "10.1145/3550271",
        "abstract": "Deep neural networks (DNNs) have demonstrated superior performance over classical machine learning to support many features in safety-critical systems. Although DNNs are now widely used in such systems (e.g., self driving cars), there is limited progress regarding automated support for functional safety analysis in DNN-based systems. For example, the identification of root causes of errors, to enable both risk analysis and DNN retraining, remains an open problem. In this article, we propose SAFE, a black-box approach to automatically characterize the root causes of DNN errors. SAFE relies on a transfer learning model pre-trained on ImageNet to extract the features from error-inducing images. It then applies a density-based clustering algorithm to detect arbitrary shaped clusters of images modeling plausible causes of error. Last, clusters are used to effectively retrain and improve the DNN. The black-box nature of SAFE is motivated by our objective not to require changes or even access to the DNN internals to facilitate adoption. Experimental results show the superior ability of SAFE in identifying different root causes of DNN errors based on case studies in the automotive domain. It also yields significant improvements in DNN accuracy after retraining, while saving significant execution time and memory when compared to alternatives.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "79",
        "numpages": "40",
        "keywords": "DNN explanation, DNN functional safety analysis, DNN debugging, clustering, transfer learning"
    },
    "I Know What You Are Searching for: Code Snippet Recommendation from Stack Overflow Posts": {
        "type": "article",
        "key": "10.1145/3550150",
        "author": "Gao, Zhipeng and Xia, Xin and Lo, David and Grundy, John and Zhang, Xindong and Xing, Zhenchang",
        "title": "I Know What You Are Searching for: Code Snippet Recommendation from Stack Overflow Posts",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3550150",
        "doi": "10.1145/3550150",
        "abstract": "Stack Overflow has been heavily used by software developers to seek programming-related information. More and more developers use Community Question and Answer forums, such as Stack Overflow, to search for code examples of how to accomplish a certain coding task. This is often considered to be more efficient than working from source documentation, tutorials, or full worked examples. However, due to the complexity of these online Question and Answer forums and the very large volume of information they contain, developers can be overwhelmed by the sheer volume of available information. This makes it hard to find and/or even be aware of the most relevant code examples to meet their needs. To alleviate this issue, in this work, we present a query-driven code recommendation tool, named Que2Code, that identifies the best code snippets for a user query from Stack Overflow posts. Our approach has two main stages: (i) semantically equivalent question retrieval and (ii) best code snippet recommendation. During the first stage, for a given query question formulated by a developer, we first generate paraphrase questions for the input query as a way of query boosting and then retrieve the relevant Stack Overflow posted questions based on these generated questions. In the second stage, we collect all of the code snippets within questions retrieved in the first stage and develop a novel scheme to rank code snippet candidates from Stack Overflow posts via pairwise comparisons. To evaluate the performance of our proposed model, we conduct a large-scale experiment to evaluate the effectiveness of the semantically equivalent question retrieval task and best code snippet recommendation task separately on Python and Java datasets in Stack Overflow. We also perform a human study to measure how real-world developers perceive the results generated by our model. Both the automatic and human evaluation results demonstrate the promising performance of our model, and we have released our code and data to assist other researchers.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "80",
        "numpages": "42",
        "keywords": "Code Search, Stack Overflow, paraphrase mining, Duplicate questions"
    },
    "Input Distribution Coverage: Measuring Feature Interaction Adequacy in Neural Network Testing": {
        "type": "article",
        "key": "10.1145/3576040",
        "author": "Dola, Swaroopa and Dwyer, Matthew B. and Soffa, Mary Lou",
        "title": "Input Distribution Coverage: Measuring Feature Interaction Adequacy in Neural Network Testing",
        "year": "2023",
        "issue_date": "May 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "3",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3576040",
        "doi": "10.1145/3576040",
        "abstract": "Testing deep neural networks (DNNs) has garnered great interest in the recent years due to their use in many applications. Black-box test adequacy measures are useful for guiding the testing process in covering the input domain. However, the absence of input specifications makes it challenging to apply black-box test adequacy measures in DNN testing. The Input Distribution Coverage (IDC) framework addresses this challenge by using a variational autoencoder to learn a low dimensional latent representation of the input distribution, and then using that latent space as a coverage domain for testing. IDC applies combinatorial interaction testing on a partitioning of the latent space to measure test adequacy. Empirical evaluation demonstrates that IDC is cost-effective, capable of detecting feature diversity in test inputs, and more sensitive than prior work to test inputs generated using different DNN test generation methods. The findings demonstrate that IDC overcomes several limitations of white-box DNN coverage approaches by discounting coverage from unrealistic inputs and enabling the calculation of test adequacy metrics that capture the feature diversity present in the input space of DNNs.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "apr",
        "articleno": "81",
        "numpages": "48",
        "keywords": "Software testing, deep neural networks, generative models, test coverage"
    },
    "SafeDrop: Detecting Memory Deallocation Bugs of Rust Programs via Static Data-flow Analysis": {
        "type": "article",
        "key": "10.1145/3542948",
        "author": "Cui, Mohan and Chen, Chengjun and Xu, Hui and Zhou, Yangfan",
        "title": "SafeDrop: Detecting Memory Deallocation Bugs of Rust Programs via Static Data-flow Analysis",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3542948",
        "doi": "10.1145/3542948",
        "abstract": "Rust is an emerging programming language that aims to prevent memory-safety bugs. However, the current design of Rust also brings side effects, which may increase the risk of memory-safety issues. In particular, it employs ownership-based resource management and enforces automatic deallocation of unused resources without using the garbage collector. It may therefore falsely deallocate reclaimed memory and lead to use-after-free or double-free issues. In this article, we study the problem of invalid memory deallocation and propose SafeDrop, a static path-sensitive data-flow analysis approach to detect such bugs. Our approach analyzes each function of a Rust crate iteratively in a flow-sensitive and field-sensitive way. It leverages a modified Tarjan algorithm to achieve scalable path-sensitive analysis and a cache-based strategy for efficient inter-procedural analysis. We have implemented our approach and integrated it into the Rust compiler. Experiment results show that the approach can successfully detect all such bugs in our experiments with a limited number of false positives and incurs a very small overhead compared to the original compilation time.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "82",
        "numpages": "21",
        "keywords": "Rust, data-flow analysis, meet over path, path sensitivity"
    },
    "Making Sense of the Unknown: How Managers Make Cyber Security Decisions": {
        "type": "article",
        "key": "10.1145/3548682",
        "author": "Shreeve, Benjamin and Gralha, Catarina and Rashid, Awais and Ara\\'{u}jo, Jo\\~{a}o and Goul\\~{a}o, Miguel",
        "title": "Making Sense of the Unknown: How Managers Make Cyber Security Decisions",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3548682",
        "doi": "10.1145/3548682",
        "abstract": "Managers rarely have deep knowledge of cyber security and yet are expected to make decisions with cyber security implications for software-based systems. We investigate the decision-making conversations of seven teams of senior managers from the same organisation as they complete the Decisions \\&amp; Disruptions cyber security exercise. We use grounded theory to situate our analysis of their decision-making and help us explore how these complex socio-cognitive interactions occur. We have developed a goal-model (using iStar 2.0) of the teams\u2019 dialogue that illustrates what cyber security goals teams identify and how they operationalise their decisions to reach these goals. We complement this with our model of cyber security reasoning that describes how these teams make their decisions, showing how each team members\u2019 experience, intuition, and understanding affects the team\u2019s overall shared reasoning and decision-making. Our findings show how managers with little cyber security expertise are able to use logic and traditional risk management thinking to make cyber security decisions. Despite their lack of cyber security\u2013specific training, they demonstrate reasoning that closely resembles the decision-making approaches espoused in cyber security\u2013specific standards (e.g., NIST/ISO). Our work demonstrates how organisations and practitioners can enrich goal modelling to capture not only what security goals an organisation has (and how they can operationalise them) but also how and why these goals have been identified. Ultimately, non\u2013cyber security experts can develop their cyber security model based on their current context (and update it when new requirements appear or new incidents happen), whilst capturing their reasoning at every stage.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "83",
        "numpages": "33",
        "keywords": "Cyber security decision-making, cyber security risk analysis, goal modelling"
    },
    "DeltaDroid: Dynamic Delivery Testing in Android": {
        "type": "article",
        "key": "10.1145/3563213",
        "author": "Ghorbani, Negar and Jabbarvand, Reyhaneh and Salehnamadi, Navid and Garcia, Joshua and Malek, Sam",
        "title": "DeltaDroid: Dynamic Delivery Testing in Android",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3563213",
        "doi": "10.1145/3563213",
        "abstract": "Android is a highly fragmented platform with a diverse set of devices and users. To support the deployment of apps in such a heterogeneous setting, Android has introduced dynamic delivery\u2014a new model of software deployment in which optional, device- or user-specific functionalities of an app, called Dynamic Feature Modules (DFMs), can be installed, as needed, after the app\u2019s initial installation. This model of app deployment, however, has exacerbated the challenges of properly testing Android apps. In this article, we first describe the results of an extensive study in which we formalized a defect model representing the various conditions under which DFM installations may fail. We then present DeltaDroid\u2014a tool aimed at assisting the developers with validating dynamic delivery behavior in their apps by augmenting their existing test suite. Our experimental evaluation using real-world apps corroborates DeltaDroid\u2019s ability to detect many crashes and unexpected behaviors that the existing automated testing tools cannot reveal.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "84",
        "numpages": "26",
        "keywords": "Software testing, dynamic delivery, test augmentation, Android applications"
    },
    "Arachne: Search-Based Repair of Deep Neural Networks": {
        "type": "article",
        "key": "10.1145/3563210",
        "author": "Sohn, Jeongju and Kang, Sungmin and Yoo, Shin",
        "title": "Arachne: Search-Based Repair of Deep Neural Networks",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3563210",
        "doi": "10.1145/3563210",
        "abstract": "The rapid and widespread adoption of Deep Neural Networks (DNNs) has called for ways to test their behaviour, and many testing approaches have successfully revealed misbehaviour of DNNs. However, it is relatively unclear what one can do to correct such behaviour after revelation, as retraining involves costly data collection and does not guarantee to fix the underlying issue. This article introduces Arachne, a novel program repair technique for DNNs, which directly repairs DNNs using their input-output pairs as a specification. Arachne localises neural weights on which it can generate effective patches and uses differential evolution to optimise the localised weights and correct the misbehaviour. An empirical study using different benchmarks shows that Arachne can fix specific misclassifications of a DNN without reducing general accuracy significantly. On average, patches generated by Arachne generalise to 61.3\\% of unseen misbehaviour, whereas those by a state-of-the-art DNN repair technique generalise only to 10.2\\% and sometimes to none while taking tens of times more than Arachne. We also show that Arachne can address fairness issues by debiasing a gender classification model. Finally, we successfully apply Arachne to a text sentiment model to show that it generalises beyond convolutional neural networks.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "85",
        "numpages": "26",
        "keywords": "Automatic program repair, deep learning"
    },
    "Hierarchical and Hybrid Organizational Structures in Open-source Software Projects: A Longitudinal Study": {
        "type": "article",
        "key": "10.1145/3569949",
        "author": "Joblin, Mitchell and Eckl, Barbara and Bock, Thomas and Schmid, Angelika and Siegmund, Janet and Apel, Sven",
        "title": "Hierarchical and Hybrid Organizational Structures in Open-source Software Projects: A Longitudinal Study",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3569949",
        "doi": "10.1145/3569949",
        "abstract": "Despite the absence of a formal process and a central command-and-control structure, developer organization in open-source software (OSS) projects are far from being a purely random process. Prior work indicates that, over time, highly successful OSS projects develop a hybrid organizational structure that comprises a hierarchical part and a non-hierarchical part. This suggests that hierarchical organization is not necessarily a global organizing principle and that a fundamentally different principle is at play below the lowest positions in the hierarchy. Given the vast proportion of developers are in the non-hierarchical part, we seek to understand the interplay between these two fundamentally differently organized groups, how this hybrid structure evolves, and the trajectory individual developers take through these structures over the course of their participation. We conducted a longitudinal study of the full histories of 20&nbsp;popular OSS projects, modeling their organizational structures as networks of developers connected by communication ties and characterizing developers\u2019 positions in terms of hierarchical (sub)structures in these networks. We observed a number of notable trends and patterns in the subject projects: (1)&nbsp;hierarchy is a pervasive structural feature of developer networks of OSS projects; (2)&nbsp;OSS projects tend to form hybrid organizational structures, consisting of a hierarchical and a non-hierarchical part; and (3)&nbsp;the positional trajectory of a developer starts loosely connected in the non-hierarchical part and then tightly integrate into the hierarchical part, which is associated with the acquisition of experience (tenure), in addition to coordination and coding activities. Our study (a)&nbsp;provides a methodological basis for further investigations of hierarchy formation, (b)&nbsp;suggests a number of hypotheses on prevalent organizational patterns and trends in OSS projects to be addressed in further work, and (c)&nbsp;may ultimately guide the governance of organizational structures.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "86",
        "numpages": "29",
        "keywords": "Open-source software projects, developer networks, organizational structure, hierarchy"
    },
    "1-to-1 or 1-to-n? Investigating the Effect of Function Inlining on Binary Similarity Analysis": {
        "type": "article",
        "key": "10.1145/3561385",
        "author": "Jia, Ang and Fan, Ming and Jin, Wuxia and Xu, Xi and Zhou, Zhaohui and Tang, Qiyi and Nie, Sen and Wu, Shi and Liu, Ting",
        "title": "1-to-1 or 1-to-n? Investigating the Effect of Function Inlining on Binary Similarity Analysis",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3561385",
        "doi": "10.1145/3561385",
        "abstract": "Binary similarity analysis is critical to many code-reuse-related issues, where function matching is its fundamental task. \u201c1-to-1\u201d mechanism has been applied in most binary similarity analysis works, in which one function in a binary file is matched against one function in a source file or binary file. However, we discover that the function mapping is a more complex problem of \u201c1-to-n\u201d (one binary function matches multiple source functions or binary functions) or even \u201cn-to-n\u201d (multiple binary functions match multiple binary functions) due to the existence of function inlining, different from traditional understanding. In this article, we investigate the effect of function inlining on binary similarity analysis. We carry out three studies to investigate the extent of function inlining, the performance of existing works under function inlining, and the effectiveness of existing inlining-simulation strategies. Firstly, a scalable and lightweight identification method is designed to recover function inlining in binaries. 88 projects (compiled in 288 versions and resulting in 32,460,156 binary functions) are collected and analyzed to construct four inlining-oriented datasets for four security tasks in the software supply chain, including code search, OSS (Open Source Software) reuse detection, vulnerability detection, and patch presence test. Datasets reveal that the proportion of function inlining ranges from 30\u201340\\% when using O3 and sometimes can reach nearly 70\\%. Then, we evaluate four existing works on our dataset. Results show most existing works neglect inlining and use the \u201c1-to-1\u201d mechanism. The mismatches cause a 30\\% loss in performance during code search and a 40\\% loss during vulnerability detection. Moreover, most inlined functions would be ignored during OSS reuse detection and patch presence test, thus leaving these functions risky. Finally, we analyze two inlining-simulation strategies on our dataset. It is shown that they miss nearly 40\\% of the inlined functions, and there is still a large space for promotion. By precisely recovering when function inlining happens, we discover that inlining is usually cumulative when optimization increases. Thus, conditional inlining and incremental inlining are recommended to design a low-cost and high-coverage inlining-simulation strategy.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "87",
        "numpages": "26",
        "keywords": "Binary similarity analysis, function inlining, 1-to-1, 1-to-n"
    },
    "Video Game Bad Smells: What They Are and How Developers Perceive Them": {
        "type": "article",
        "key": "10.1145/3563214",
        "author": "Nardone, Vittoria and Muse, Biruk and Abidi, Mouna and Khomh, Foutse and Di Penta, Massimiliano",
        "title": "Video Game Bad Smells: What They Are and How Developers Perceive Them",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3563214",
        "doi": "10.1145/3563214",
        "abstract": "Video games represent a substantial and increasing share of the software market. However, their development is particularly challenging as it requires multi-faceted knowledge, which is not consolidated in computer science education yet. This article aims at defining a catalog of bad smells related to video game development. To achieve this goal, we mined discussions on general-purpose and video game-specific forums. After querying such a forum, we adopted an open coding strategy on a statistically significant sample of 572 discussions, stratified over different forums. As a result, we obtained a catalog of 28 bad smells, organized into five categories, covering problems related to game design and logic, physics, animation, rendering, or multiplayer. Then, we assessed the perceived relevance of such bad smells by surveying 76 game development professionals. The survey respondents agreed with the identified bad smells but also provided us with further insights about the discussed smells. Upon reporting results, we discuss bad smell examples, their consequences, as well as possible mitigation/fixing strategies and trade-offs to be pursued by developers. The catalog can be used not only as a guideline for developers and educators but also can pave the way toward better automated tool support for video game developers.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "88",
        "numpages": "35",
        "keywords": "Video games, bad smells, Q&amp;A forums, empirical study"
    },
    "DAISY: Dynamic-Analysis-Induced Source Discovery for Sensitive Data": {
        "type": "article",
        "key": "10.1145/3569936",
        "author": "Zhang, Xueling and Heaps, John and Slavin, Rocky and Niu, Jianwei and Breaux, Travis and Wang, Xiaoyin",
        "title": "DAISY: Dynamic-Analysis-Induced Source Discovery for Sensitive Data",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3569936",
        "doi": "10.1145/3569936",
        "abstract": "Mobile apps are widely used and often process users\u2019 sensitive data. Many taint analysis tools have been applied to analyze sensitive information flows and report data leaks in apps. These tools require a list of sources (where sensitive data is accessed) as input, and researchers have constructed such lists within the Android platform by identifying Android API methods that allow access to sensitive data. However, app developers may also define methods or use third-party library\u2019s methods for accessing data. It is difficult to collect such source methods, because they are unique to the apps, and there are a large number of third-party libraries available on the market that evolve over time. To address this problem, we propose DAISY, a Dynamic-Analysis-Induced Source discoverY approach for identifying methods that return sensitive information from apps and third-party libraries. Trained on an automatically labeled dataset of methods and their calling context, DAISY identifies sensitive methods in unseen apps. We evaluated DAISY on real-world apps, and the results show that DAISY can achieve an overall precision of 77.9\\% when reporting the most confident results. Most of the identified sources and leaks cannot be detected by existing technologies.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "89",
        "numpages": "34",
        "keywords": "Privacy leak, mobile application, natural language processing"
    },
    "sem2vec: Semantics-aware Assembly Tracelet Embedding": {
        "type": "article",
        "key": "10.1145/3569933",
        "author": "Wang, Huaijin and Ma, Pingchuan and Wang, Shuai and Tang, Qiyi and Nie, Sen and Wu, Shi",
        "title": "sem2vec: Semantics-aware Assembly Tracelet Embedding",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3569933",
        "doi": "10.1145/3569933",
        "abstract": "Binary code similarity is the foundation of many security and software engineering applications. Recent works leverage deep neural networks (DNN) to learn a numeric vector representation (namely, embeddings) of assembly functions, enabling similarity analysis in the numeric space. However, existing DNN-based techniques capture syntactic-, control flow-, or data flow-level information of assembly code, which is too coarse-grained to represent program functionality. These methods can suffer from low robustness to challenging settings such as compiler optimizations and obfuscations.We present sem2vec, a binary code embedding framework that learns from semantics. Given the control-flow graph (CFG), 34 pages. of an assembly function, we divide it into tracelets, denoting continuous and short execution traces that are reachable from the function entry point. We use symbolic execution to extract symbolic constraints and other auxiliary information on each tracelet. We then train masked language models to compute embeddings of symbolic execution outputs. Last, we use graph neural networks, to aggregate tracelet embeddings into the CFG-level embedding for a function. Our evaluation shows that sem2vec extracts high-quality embedding and is robust against different compilers, optimizations, architectures, and popular obfuscation methods including virtualization obfuscation. We further augment a vulnerability search application with embeddings computed by sem2vec and demonstrate a significant improvement in vulnerability search accuracy.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "90",
        "numpages": "34",
        "keywords": "Symbolic execution, embedding, graph neural network, binary code similarity"
    },
    "On the Discoverability of npm Vulnerabilities in Node.js Projects": {
        "type": "article",
        "key": "10.1145/3571848",
        "author": "Alfadel, Mahmoud and Costa, Diego Elias and Shihab, Emad and Adams, Bram",
        "title": "On the Discoverability of npm Vulnerabilities in Node.js Projects",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571848",
        "doi": "10.1145/3571848",
        "abstract": "The reliance on vulnerable dependencies is a major threat to software systems. Dependency vulnerabilities are common and remain undisclosed for years. However, once the vulnerability is discovered and publicly known to the community, the risk of exploitation reaches its peak, and developers have to work fast to remediate the problem. While there has been a lot of research to characterize vulnerabilities in software ecosystems, none have explored the problem taking the discoverability into account. Therefore, we perform a large-scale empirical study examining 6,546 Node.js applications. We define three discoverability levels based on vulnerabilities lifecycle (undisclosed, reported, and public). We find that although the majority of the affected applications (99.42\\%) depend on undisclosed vulnerable packages, 206&nbsp;(4.63\\%) applications were exposed to dependencies with public vulnerabilities. The major culprit for the applications being affected by public vulnerabilities is the lack of dependency updates; in 90.8\\% of the cases, a fix is available but not patched by application maintainers. Moreover, we find that applications remain affected by public vulnerabilities for a long time (103 days). Finally, we devise DepReveal, a tool that supports our discoverability analysis approach, to help developers better understand vulnerabilities in their application dependencies and plan their project maintenance.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "91",
        "numpages": "27",
        "keywords": "Open source software, software packages, software ecosystems, dependency vulnerabilities"
    },
    "The Best of Both Worlds: Combining Learned Embeddings with Engineered Features for Accurate Prediction of Correct Patches": {
        "type": "article",
        "key": "10.1145/3576039",
        "author": "Tian, Haoye and Liu, Kui and Li, Yinghua and Kabor\\'{e}, Abdoul Kader and Koyuncu, Anil and Habib, Andrew and Li, Li and Wen, Junhao and Klein, Jacques and Bissyand\\'{e}, Tegawend\\'{e} F.",
        "title": "The Best of Both Worlds: Combining Learned Embeddings with Engineered Features for Accurate Prediction of Correct Patches",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3576039",
        "doi": "10.1145/3576039",
        "abstract": "A large body of the literature on automated program repair develops approaches where patches are automatically generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state-of-the-art explores research directions that require dynamic information or rely on manually-crafted heuristics, we study the benefit of learning code representations in order to learn deep features that may encode the properties of patch correctness. Our empirical work investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations of patch correctness identification, and assess the possibility of accurate classification of correct patch by combining learned embeddings with engineered features. Experimental results demonstrate the potential of learned embeddings to empower Leopard (a patch correctness predicting framework implemented in this work) with learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based learned embeddings associated with XGBoost achieves an AUC value of about 0.803 in the prediction of patch correctness on a new dataset of 2,147 labeled patches that we collected for the experiments. Our investigations show that deep learned embeddings can lead to complementary/better performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. By combining deep learned embeddings and engineered features, Panther (the upgraded version of Leopard implemented in this work) outperforms Leopard with higher scores in terms of AUC, +Recall and -Recall, and can accurately identify more (in)correct patches that cannot be predicted by the classifiers only with learned embeddings or engineered features. Finally, we use an explainable ML technique, SHAP, to empirically interpret how the learned embeddings and engineered features are contributed to the patch correctness prediction.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "92",
        "numpages": "34",
        "keywords": "Program repair, patch correctness, distributed representation learning, machine learning, embeddings, features combination, explanation"
    },
    "HybridCISave: A Combined Build and Test Selection Approach in Continuous Integration": {
        "type": "article",
        "key": "10.1145/3576038",
        "author": "Jin, Xianhao and Servant, Francisco",
        "title": "HybridCISave: A Combined Build and Test Selection Approach in Continuous Integration",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3576038",
        "doi": "10.1145/3576038",
        "abstract": "Continuous Integration (CI) is a popular practice in modern software engineering. Unfortunately, it is also a high-cost practice\u2014Google and Mozilla estimate their CI systems in millions of dollars. To reduce the computational cost in CI, researchers developed approaches to selectively execute builds or tests that are likely to fail (and skip those likely to pass). In this article, we present a novel hybrid technique (HybridCISave) to improve on the limitations of existing techniques: to provide higher cost savings and higher safety. To provide higher cost savings, HybridCISave combines techniques to predict and skip executions of both full builds that are predicted to pass and partial ones (only the tests in them predicted to pass). To provide higher safety, HybridCISave combines the predictions of multiple techniques to obtain stronger certainty before it decides to skip a build or test. We evaluated HybridCISave by comparing its effectiveness with the existing build selection techniques over 100 projects and found that it provided higher cost savings at the highest safety. We also evaluated each design decision in HybridCISave and found that skipping both full and partial builds increased its cost savings and that combining multiple test selection techniques made it safer.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "93",
        "numpages": "39",
        "keywords": "Software maintenance, Continuous Integration, build selection, test selection"
    },
    "I Depended on You and You Broke Me: An Empirical Study of Manifesting Breaking Changes in Client Packages": {
        "type": "article",
        "key": "10.1145/3576037",
        "author": "Venturini, Daniel and Cogo, Filipe Roseiro and Polato, Ivanilton and Gerosa, Marco A. and Wiese, Igor Scaliante",
        "title": "I Depended on You and You Broke Me: An Empirical Study of Manifesting Breaking Changes in Client Packages",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3576037",
        "doi": "10.1145/3576037",
        "abstract": "Complex software systems have a network of dependencies. Developers often configure package managers (e.g., npm) to automatically update dependencies with each publication of new releases containing bug fixes and new features. When a dependency release introduces backward-incompatible changes, commonly known as breaking changes, dependent packages may not build anymore. This may indirectly impact downstream packages, but the impact of breaking changes and how dependent packages recover from these breaking changes remain unclear. To close this gap, we investigated the manifestation of breaking changes in the npm ecosystem, focusing on cases where packages\u2019 builds are impacted by breaking changes from their dependencies. We measured the extent to which breaking changes affect dependent packages. Our analyses show that around 12\\% of the dependent packages and 14\\% of their releases were impacted by a breaking change during updates of non-major releases of their dependencies. We observed that, from all of the manifesting breaking changes, 44\\% were introduced in both minor and patch releases, which in principle should be backward compatible. Clients recovered themselves from these breaking changes in half of the cases, most frequently by upgrading or downgrading the provider\u2019s version without changing the versioning configuration in the package manager. We expect that these results help developers understand the potential impact of such changes and recover from them.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "94",
        "numpages": "26",
        "keywords": "Breaking changes, Semantic Version, npm, dependency management, change impact"
    },
    "Uncertainty-Aware Robustness Assessment of Industrial Elevator Systems": {
        "type": "article",
        "key": "10.1145/3576041",
        "author": "Han, Liping and Ali, Shaukat and Yue, Tao and Arrieta, Aitor and Arratibel, Maite",
        "title": "Uncertainty-Aware Robustness Assessment of Industrial Elevator Systems",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3576041",
        "doi": "10.1145/3576041",
        "abstract": "Industrial elevator systems are commonly used software systems in our daily lives, which operate in uncertain environments such as unpredictable passenger traffic, uncertain passenger attributes and behaviors, and hardware delays. Understanding and assessing the robustness of such systems under various uncertainties enable system designers to reason about uncertainties, especially those leading to low system robustness, and consequently improve their designs and implementations in terms of handling uncertainties. To this end, we present a comprehensive empirical study conducted with industrial elevator systems provided by our industrial partner Orona, which focuses on assessing the robustness of a dispatcher\u2014that is, a software component responsible for elevators\u2019 optimal scheduling. In total, we studied 90 industrial dispatchers in our empirical study. Based on the experience gained from the study, we derived an uncertainty-aware robustness assessment method (named UncerRobua) comprising a set of guidelines on how to conduct the robustness assessment and a newly proposed ranking algorithm, for supporting the robustness assessment of industrial elevator systems against uncertainties.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "95",
        "numpages": "51",
        "keywords": "Uncertainty-aware robustness assessment, empirical study"
    },
    "Reliable Fix Patterns Inferred from Static Checkers for Automated Program Repair": {
        "type": "article",
        "key": "10.1145/3579637",
        "author": "Liu, Kui and Zhang, Jingtang and Li, Li and Koyuncu, Anil and Kim, Dongsun and Ge, Chunpeng and Liu, Zhe and Klein, Jacques and Bissyand\\'{e}, Tegawend\\'{e} F.",
        "title": "Reliable Fix Patterns Inferred from Static Checkers for Automated Program Repair",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3579637",
        "doi": "10.1145/3579637",
        "abstract": "Fix pattern-based patch generation is a promising direction in automated program repair (APR). Notably, it has been demonstrated to produce more acceptable and correct patches than the patches obtained with mutation operators through genetic programming. The performance of pattern-based APR systems, however, depends on the fix ingredients mined from fix changes in development histories. Unfortunately, collecting a reliable set of bug fixes in repositories can be challenging. In this article, we propose investigating the possibility in an APR scenario of leveraging fix patterns inferred from code changes that address violations detected by static analysis tools. To that end, we build a fix pattern-based APR tool, Avatar, which exploits fix patterns of static analysis violations as ingredients for the patch generation of repairing semantic bugs. Evaluated on four benchmarks (i.e., Defects4J, Bugs.jar, BEARS, and QuixBugs), Avatar presents the potential feasibility of fixing semantic bugs with the fix patterns inferred from the patches for fixing static analysis violations and can correctly fix 26 semantic bugs when Avatar is implemented with the normal program repair pipeline. We also find that Avatar achieves performance metrics that are comparable to that of the closely related approaches in the literature. Compared with CoCoNut, Avatar can fix 18 new bugs in Defects4J and 3 new bugs in QuixBugs. When compared with HDRepair, JAID, and SketchFix, Avatar can newly fix 14 Defects4J bugs. In terms of the number of correctly fixed bugs, Avatar is also comparable to the program repair tools with the normal fault localization setting and presents better performance than most program repair tools. These results imply that Avatar is complementary to current program repair approaches. We further uncover that Avatar can present different bug-fixing performances when it is configured with different fault localization tools, and the stack trace information from the failed executions of test cases can be exploited to improve the bug-fixing performance of Avatar by fixing more bugs with fewer generated patch candidates. Overall, our study highlights the relevance of static bug-finding tools as indirect contributors of fix ingredients for addressing code defects identified with functional test cases (i.e., dynamic information).",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "96",
        "numpages": "38",
        "keywords": "Automated program repair, static analysis, fix pattern"
    },
    "Duplicate Bug Report Detection: How Far Are We?": {
        "type": "article",
        "key": "10.1145/3576042",
        "author": "Zhang, Ting and Han, Donggyun and Vinayakarao, Venkatesh and Irsan, Ivana Clairine and Xu, Bowen and Thung, Ferdian and Lo, David and Jiang, Lingxiao",
        "title": "Duplicate Bug Report Detection: How Far Are We?",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3576042",
        "doi": "10.1145/3576042",
        "abstract": "Many Duplicate Bug Report Detection (DBRD) techniques have been proposed in the research literature. The industry uses some other techniques. Unfortunately, there is insufficient comparison among them, and it is unclear how far we have been. This work fills this gap by comparing the aforementioned techniques. To compare them, we first need a benchmark that can estimate how a tool would perform if applied in a realistic setting today. Thus, we first investigated potential biases that affect the fair comparison of the accuracy of DBRD techniques. Our experiments suggest that data age and issue tracking system (ITS) choice cause a significant difference. Based on these findings, we prepared a new benchmark. We then used it to evaluate DBRD techniques to estimate better how far we have been. Surprisingly, a simpler technique outperforms recently proposed sophisticated techniques on most projects in our benchmark. In addition, we compared the DBRD techniques proposed in research with those used in Mozilla and VSCode. Surprisingly, we observe that a simple technique already adopted in practice can achieve comparable results as a recently proposed research tool. Our study gives reflections on the current state of DBRD, and we share our insights to benefit future DBRD research.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "97",
        "numpages": "32",
        "keywords": "Bug reports, duplicate bug report detection, deep learning, empirical study"
    },
    "Client-Specific Upgrade Compatibility Checking via Knowledge-Guided Discovery": {
        "type": "article",
        "key": "10.1145/3582569",
        "author": "Zhu, Chenguang and Zhang, Mengshi and Wu, Xiuheng and Xu, Xiufeng and Li, Yi",
        "title": "Client-Specific Upgrade Compatibility Checking via Knowledge-Guided Discovery",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3582569",
        "doi": "10.1145/3582569",
        "abstract": "Modern software systems are complex, and they heavily rely on external libraries developed by different teams and organizations. Such systems suffer from higher instability due to incompatibility issues caused by library upgrades. In this article, we address the problem by investigating the impact of a library upgrade on the behaviors of its clients. We developed CompCheck, an automated upgrade compatibility checking framework that generates incompatibility-revealing tests based on previous examples. CompCheck first establishes an offline knowledge base of incompatibility issues by mining from open source projects and their upgrades. It then discovers incompatibilities for a specific client project, by searching for similar library usages in the knowledge base and generating tests to reveal the problems. We evaluated CompCheck on 202 call sites of 37 open source projects and the results show that CompCheck successfully revealed incompatibility issues on 76 call sites, 72.7\\% and 94.9\\% more than two existing techniques, confirming CompCheck\u2019s applicability and effectiveness.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "98",
        "numpages": "31",
        "keywords": "Software upgrade, compatibility, test generation"
    },
    "Security Misconfigurations in Open Source Kubernetes Manifests: An Empirical Study": {
        "type": "article",
        "key": "10.1145/3579639",
        "author": "Rahman, Akond and Shamim, Shazibul Islam and Bose, Dibyendu Brinto and Pandita, Rahul",
        "title": "Security Misconfigurations in Open Source Kubernetes Manifests: An Empirical Study",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3579639",
        "doi": "10.1145/3579639",
        "abstract": "Context: Kubernetes has emerged as the de-facto tool for automated container orchestration. Business and government organizations are increasingly adopting Kubernetes for automated software deployments. Kubernetes is being used to provision applications in a wide range of domains, such as time series forecasting, edge computing, and high-performance computing. Due to such a pervasive presence, Kubernetes-related security misconfigurations can cause large-scale security breaches. Thus, a systematic analysis of security misconfigurations in Kubernetes manifests, i.e., configuration files used for Kubernetes, can help practitioners secure their Kubernetes clusters.Objective: The goal of this paper is to help practitioners secure their Kubernetes clusters by identifying security misconfigurations that occur in Kubernetes manifests.Methodology: We conduct an empirical study with 2,039 Kubernetes manifests mined from 92 open-source software repositories to systematically characterize security misconfigurations in Kubernetes manifests. We also construct a static analysis tool called Security Linter for Kubernetes Manifests (SLI-KUBE) to quantify the frequency of the identified security misconfigurations.Results: In all, we identify 11 categories of security misconfigurations, such as absent resource limit, absent securityContext, and activation of hostIPC. Specifically, we identify 1,051 security misconfigurations in 2,039 manifests. We also observe the identified security misconfigurations affect entities that perform mesh-related load balancing, as well as provision pods and stateful applications. Furthermore, practitioners agreed to fix 60\\% of 10 misconfigurations reported by us.Conclusion: Our empirical study shows Kubernetes manifests to include security misconfigurations, which necessitates security-focused code reviews and application of static analysis when Kubernetes manifests are developed.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "99",
        "numpages": "36",
        "keywords": "Configuration, container orchestration, devops, devsecops, empirical study, Kubernetes, misconfiguration, security"
    },
    "Katana: Dual Slicing Based Context for Learning Bug Fixes": {
        "type": "article",
        "key": "10.1145/3579640",
        "author": "Sintaha, Mifta and Nashid, Noor and Mesbah, Ali",
        "title": "Katana: Dual Slicing Based Context for Learning Bug Fixes",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3579640",
        "doi": "10.1145/3579640",
        "abstract": "Contextual information plays a vital role for software developers when understanding and fixing a bug. Consequently, deep learning based program repair techniques leverage context for bug fixes. However, existing techniques treat context in an arbitrary manner, by extracting code in close proximity of the buggy statement within the enclosing file, class, or method, without any analysis to find actual relations with the bug. To reduce noise, they use a predefined maximum limit on the number of tokens to be used as context. We present a program slicing based approach, in which instead of arbitrarily including code as context, we analyze statements that have a control or data dependency on the buggy statement. We propose a novel concept called dual slicing, which leverages the context of both buggy and fixed versions of the code to capture relevant repair ingredients. We present our technique and tool called Katana, the first to apply slicing-based context for a program repair task. The results show that Katana effectively preserves sufficient information for a model to choose contextual information while reducing noise. We compare against four recent state-of-the-art context-aware program repair techniques. Our results show that Katana fixes between 1.5 and 3.7 times more bugs than existing techniques.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "100",
        "numpages": "27",
        "keywords": "Program slicing, program repair, deep learning, contextual information, graph neural networks"
    },
    "IFDS-based Context Debloating for Object-Sensitive Pointer Analysis": {
        "type": "article",
        "key": "10.1145/3579641",
        "author": "He, Dongjie and Lu, Jingbo and Xue, Jingling",
        "title": "IFDS-based Context Debloating for Object-Sensitive Pointer Analysis",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3579641",
        "doi": "10.1145/3579641",
        "abstract": "Object-sensitive pointer analysis, which separates the calling contexts of a method by its receiver objects, is known to achieve highly useful precision for object-oriented languages such as Java. Despite recent advances, all object-sensitive pointer analysis algorithms still suffer from the scalability problem due to the combinatorial explosion of contexts in large programs. In this article, we introduce a new approach, Conch, that can be applied to debloat contexts for all object-sensitive pointer analysis algorithms, thereby improving significantly their efficiency while incurring a negligible loss of precision. Our key insight is to approximate a recently proposed set of two necessary conditions for an object in a program to be context-sensitive, i.e., context-dependent (whose precise verification is undecidable) with a set of three linearly verifiable conditions in terms of the number of edges in the pointer assignment graph (PAG) representation of the program. These three linearly verifiable conditions, which turn out to be almost always necessary in practice, are synthesized from three key observations regarding context-dependability for the objects created and used in real-world object-oriented programs. To develop a practical implementation for Conch, we introduce an IFDS-based algorithm for reasoning about object reachability in the PAG of a program, which runs linearly in terms of the number of edges in the PAG. By debloating contexts for three representative object-sensitive pointer analysis algorithms, which are applied to a set of representative Java programs, Conch can speed up these three baseline algorithms substantially at only a negligible loss of precision (less than 0.1\\%) with respect to several commonly used precision metrics. In addition, Conch also improves their scalability by enabling them to analyze substantially more programs to completion than before (under a time budget of 12 hours). Conch has been open-sourced (http://www.cse.unsw.edu.au/~corg/tools/conch), opening up new opportunities for other researchers and practitioners to further improve this research. To demonstrate this, we introduce one extension of Conch to accelerate further the three baselines without losing any precision, providing further insights on extending Conch to make precision-efficiency tradeoffs in future research.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "101",
        "numpages": "44",
        "keywords": "Pointer analysis, object sensitivity, context debloating, IFDS"
    },
    "Code-line-level Bugginess Identification: How Far have We Come, and How Far have We Yet to Go?": {
        "type": "article",
        "key": "10.1145/3582572",
        "author": "Guo, Zhaoqiang and Liu, Shiran and Liu, Xutong and Lai, Wei and Ma, Mingliang and Zhang, Xu and Ni, Chao and Yang, Yibiao and Li, Yanhui and Chen, Lin and Zhou, Guoqiang and Zhou, Yuming",
        "title": "Code-line-level Bugginess Identification: How Far have We Come, and How Far have We Yet to Go?",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3582572",
        "doi": "10.1145/3582572",
        "abstract": "Background. Code-line-level bugginess identification (CLBI) is a vital technique that can facilitate developers to identify buggy lines without expending a large amount of human effort. Most of the existing studies tried to mine the characteristics of source codes to train supervised prediction models, which have been reported to be able to discriminate buggy code lines amongst others in a target program.Problem. However, several simple and clear code characteristics, such as complexity of code lines, have been disregarded in the current literature. Such characteristics can be acquired and applied easily in an unsupervised way to conduct more accurate CLBI, which also can decrease the application cost of existing CLBI approaches by a large margin.Objective. We aim at investigating the status quo in the field of CLBI from the perspective of (1) how far we have really come in the literature, and (2) how far we have yet to go in the industry, by analyzing the performance of state-of-the-art (SOTA) CLBI approaches and tools, respectively.Method. We propose a simple heuristic baseline solution GLANCE (aiminG at controL- ANd ComplEx-statements) with three implementations (i.e., GLANCE-MD, GLANCE-EA, and GLANCE-LR). GLANCE is a two-stage CLBI framework: first, use a simple model to predict the potentially defective files; second, leverage simple code characteristics to identify buggy code lines in the predicted defective files. We use GLANCE as the baseline to investigate the effectiveness of the SOTA CLBI approaches, including natural language processing (NLP) based, model interpretation techniques (MIT) based, and popular static analysis tools (SAT).Result. Based on 19 open-source projects with 142 different releases, the experimental results show that GLANCE framework has a prediction performance comparable or even superior to the existing SOTA CLBI approaches and tools in terms of 8 different performance indicators.Conclusion. The results caution us that, if the identification performance is the goal, the real progress in CLBI is not being achieved as it might have been envisaged in the literature and there is still a long way to go to really promote the effectiveness of static analysis tools in industry. In addition, we suggest using GLANCE as a baseline in future studies to demonstrate the usefulness of any newly proposed CLBI approach.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "102",
        "numpages": "55",
        "keywords": "Code line, bugginess, defect prediction, quality assurance, static analysis tool"
    },
    "Structured Theorem for Quantum Programs and its Applications": {
        "type": "article",
        "key": "10.1145/3587154",
        "author": "Yu, Nengkun",
        "title": "Structured Theorem for Quantum Programs and its Applications",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3587154",
        "doi": "10.1145/3587154",
        "abstract": "This article proves a structured program theorem for flowchart quantum programs. The theorem states that any flowchart quantum program is equivalent to a single quantum program that repeatedly executes a quantum measurement and a subprogram, so long as the measurement outcome is true. Moreover, their expected runtime, variance, and general moments are the same. This theorem simplifies the quantum program\u2019s verification significantly.\u2013We derive an analytical characterization of the termination problem for quantum programs in polynomial time. Our procedure is more efficient and accurate with much simpler techniques than the analysis of this problem, as described in [29].\u2013We compute the expected runtime analytically and exactly for quantum programs in polynomial time. This result improves the methods based on the weakest precondition calculus for the question recently developed in [31, 34].\u2013We show that a single loop rule is a relatively complete Hoare logic for quantum programs after applying our structured theorem. Although using fewer rules, our method verifies a broader class of quantum programs, compared with the results in [45] and [56].",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "103",
        "numpages": "35",
        "keywords": "Quantum programming, flowchart language, while-language, structure programming"
    },
    "Simulator-based Explanation and Debugging of Hazard-triggering Events in DNN-based Safety-critical Systems": {
        "type": "article",
        "key": "10.1145/3569935",
        "author": "Fahmy, Hazem and Pastore, Fabrizio and Briand, Lionel and Stifter, Thomas",
        "title": "Simulator-based Explanation and Debugging of Hazard-triggering Events in DNN-based Safety-critical Systems",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3569935",
        "doi": "10.1145/3569935",
        "abstract": "When Deep Neural Networks (DNNs) are used in safety-critical systems, engineers should determine the safety risks associated with failures (i.e., erroneous outputs) observed during testing. For DNNs processing images, engineers visually inspect all failure-inducing images to determine common characteristics among them. Such characteristics correspond to hazard-triggering events (e.g., low illumination) that are essential inputs for safety analysis. Though informative, such activity is expensive and error prone.To support such safety analysis practices, we propose Simulator-based Explanations for DNN failurEs (SEDE), a technique that generates readable descriptions for commonalities in failure-inducing, real-world images and improves the DNN through effective retraining. SEDE leverages the availability of simulators, which are commonly used for cyber-physical systems. It relies on genetic algorithms to drive simulators toward the generation of images that are similar to failure-inducing, real-world images in the test set; it then employs rule learning algorithms to derive expressions that capture commonalities in terms of simulator parameter values. The derived expressions are then used to generate additional images to retrain and improve the DNN.With DNNs performing in-car sensing tasks, SEDE successfully characterized hazard-triggering events leading to a DNN accuracy drop. Also, SEDE enabled retraining leading to significant improvements in DNN accuracy, up to 18 percentage points.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "104",
        "numpages": "47",
        "keywords": "DNN explanation, DNN functional safety analysis, DNN debugging, heatmaps, explainable AI"
    },
    "Testing Feedforward Neural Networks Training Programs": {
        "type": "article",
        "key": "10.1145/3529318",
        "author": "Ben Braiek, Houssem and Khomh, Foutse",
        "title": "Testing Feedforward Neural Networks Training Programs",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3529318",
        "doi": "10.1145/3529318",
        "abstract": "At present, we are witnessing an increasing effort to improve the performance and trustworthiness of Deep Neural Networks (DNNs), with the aim to enable their adoption in safety critical systems such as self-driving cars or aircraft collision-avoidance systems. Multiple testing techniques are proposed to generate test cases that can expose inconsistencies in the behavior of DNN models. These techniques assume implicitly that the training program is bug-free and appropriately configured. However, satisfying this assumption for a novel problem requires significant engineering work to prepare the data, design the DNN, implement the training program, and tune the hyperparameters to produce the model for which current automated test data generators search for corner-case behaviors. All these model training steps can be error prone. Therefore, it is crucial to detect and correct errors throughout all the engineering steps of DNN-based software systems and not only on the resulting DNN model. In this article, we gather a catalog of training issues and based on their symptoms and their effects on the behavior of the training program, we propose practical verification routines to detect the aforementioned issues, automatically, by continuously validating that some important properties of the learning dynamics hold during the training. Then, we design TheDeepChecker, an end-to-end property-based debugging approach for DNN training programs and implement it as a TensorFlow-based library. As an empirical evaluation, we conduct a case study to assess the effectiveness of TheDeepChecker on synthetic and real-world buggy DL programs and compare its performance to that of the Amazon SageMaker Debugger (SMD). Results show that TheDeepChecker\u2019s on-execution validation of DNN-based program\u2019s properties through three sequential phases (pre-, on-, and post-fitting) succeeds in revealing several coding bugs and system misconfigurations errors early on and at a low cost. Moreover, our property-based approach outperforms the SMD\u2019s offline rules verification on training logs in terms of detection accuracy for unstable learning issues and coverage of additional DL bugs.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "105",
        "numpages": "61",
        "keywords": "Neural networks, training programs, property-based debugging"
    },
    "A Comprehensive Empirical Study of Bias Mitigation Methods for Machine Learning Classifiers": {
        "type": "article",
        "key": "10.1145/3583561",
        "author": "Chen, Zhenpeng and Zhang, Jie M. and Sarro, Federica and Harman, Mark",
        "title": "A Comprehensive Empirical Study of Bias Mitigation Methods for Machine Learning Classifiers",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3583561",
        "doi": "10.1145/3583561",
        "abstract": "Software bias is an increasingly important operational concern for software engineers. We present a large-scale, comprehensive empirical study of 17 representative bias mitigation methods for Machine Learning (ML) classifiers, evaluated with 11 ML performance metrics (e.g., accuracy), 4 fairness metrics, and 20 types of fairness-performance tradeoff assessment, applied to 8 widely-adopted software decision tasks. The empirical coverage is much more comprehensive, covering the largest numbers of bias mitigation methods, evaluation metrics, and fairness-performance tradeoff measures compared to previous work on this important software property. We find that (1) the bias mitigation methods significantly decrease ML performance in 53\\% of the studied scenarios (ranging between 42\\%\u223c66\\% according to different ML performance metrics); (2) the bias mitigation methods significantly improve fairness measured by the 4 used metrics in 46\\% of all the scenarios (ranging between 24\\%\u223c59\\% according to different fairness metrics); (3) the bias mitigation methods even lead to decrease in both fairness and ML performance in 25\\% of the scenarios; (4) the effectiveness of the bias mitigation methods depends on tasks, models, the choice of protected attributes, and the set of metrics used to assess fairness and ML performance; (5) there is no bias mitigation method that can achieve the best tradeoff in all the scenarios. The best method that we find outperforms other methods in 30\\% of the scenarios. Researchers and practitioners need to choose the bias mitigation method best suited to their intended application scenario(s).",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "106",
        "numpages": "30",
        "keywords": "Machine Learning, bias mitigation, fairness-performance trade-off"
    },
    "Modern Code Reviews\u2014Survey of Literature and Practice": {
        "type": "article",
        "key": "10.1145/3585004",
        "author": "Badampudi, Deepika and Unterkalmsteiner, Michael and Britto, Ricardo",
        "title": "Modern Code Reviews\u2014Survey of Literature and Practice",
        "year": "2023",
        "issue_date": "July 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "4",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3585004",
        "doi": "10.1145/3585004",
        "abstract": "Background: Modern Code Review (MCR) is a lightweight alternative to traditional code inspections. While secondary studies on MCR exist, it is uanknown whether the research community has targeted themes that practitioners consider important.Objectives: The objectives are to provide an overview of MCR research, analyze the practitioners\u2019 opinions on the importance of MCR research, investigate the alignment between research and practice, and propose future MCR research avenues.Method: We conducted a systematic mapping study to survey state of the art until and including 2021, employed the Q-Methodology to analyze the practitioners\u2019 perception of the relevance of MCR research, and analyzed the primary studies\u2019 research impact.Results: We analyzed 244 primary studies, resulting in five themes. As a result of the 1,300 survey data points, we found that the respondents are positive about research investigating the impact of MCR on product quality and MCR process properties. In contrast, they are negative about human factor\u2013 and support systems\u2013related research.Conclusion: These results indicate a misalignment between the state of the art and the themes deemed important by most survey respondents. Researchers should focus on solutions that can improve the state of MCR practice. We provide an MCR research agenda that can potentially increase the impact of MCR research.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "may",
        "articleno": "107",
        "numpages": "61",
        "keywords": "Modern code review, literature survey, practitioner survey"
    },
    "The Influence of Human Aspects on Requirements Engineering-related Activities: Software Practitioners\u2019 Perspective": {
        "type": "article",
        "key": "10.1145/3546943",
        "author": "Hidellaarachchi, Dulaji and Grundy, John and Hoda, Rashina and Mueller, Ingo",
        "title": "The Influence of Human Aspects on Requirements Engineering-related Activities: Software Practitioners\u2019 Perspective",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3546943",
        "doi": "10.1145/3546943",
        "abstract": "Requirements Engineering (RE)-related activities require high collaboration between various roles in software engineering (SE), such as requirements engineers, stakeholders, developers, and so on. Their demographics, views, understanding of technologies, working styles, communication and collaboration capabilities make RE highly human-dependent. Identifying how \u201chuman aspects\u201d\u2014such as motivation, domain knowledge, communication skills, personality, emotions, culture, and so on\u2014might impact RE-related activities would help us improve RE and SE in general. This study aims at better understanding current industry perspectives on the influence of human aspects on RE-related activities, specifically focusing on motivation and personality, by targeting software practitioners involved in RE-related activities. Our findings indicate that software practitioners consider motivation, domain knowledge, attitude, communication skills and personality as highly important human aspects when involved in RE-related activities. A set of factors were identified as software practitioners\u2019 key motivational factors when involved in RE-related activities, along with important personality characteristics to have when involved in RE. We also identified factors that made individuals less effective when involved in RE-related activities and obtained some feedback on measuring individuals\u2019 performance when involved in RE. The findings from our study suggest various areas needing more investigation, and we summarise a set of key recommendations for further research.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "108",
        "numpages": "37",
        "keywords": "Human aspects, requirements engineering, software engineering"
    },
    "Retrieving API Knowledge from Tutorials and Stack Overflow Based on Natural Language Queries": {
        "type": "article",
        "key": "10.1145/3565799",
        "author": "Wu, Di and Jing, Xiao-Yuan and Zhang, Hongyu and Feng, Yang and Chen, Haowen and Zhou, Yuming and Xu, Baowen",
        "title": "Retrieving API Knowledge from Tutorials and Stack Overflow Based on Natural Language Queries",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3565799",
        "doi": "10.1145/3565799",
        "abstract": "When encountering unfamiliar APIs, developers tend to seek help from API tutorials and Stack Overflow (SO). API tutorials help developers understand the API knowledge in a general context, while SO often explains the API knowledge in a specific programming task. Thus, tutorials and SO posts together can provide more API knowledge. However, it is non-trivial to retrieve API knowledge from both API tutorials and SO posts based on natural language queries. Two major problems are irrelevant API knowledge in two different resources and the lexical gap between the queries and documents. In this article, we regard a fragment in tutorials and a Question and Answering (Q&amp;A) pair in SO as a knowledge item (KI). We generate \u27e8 API, FRA\u27e9 pairs (FRA stands for fragment) from tutorial fragments and APIs and build \u27e8 API, QA\u27e9 pairs based on heuristic rules of SO posts. We fuse \u27e8 API, FRA\u27e9 pairs and \u27e8 API, QA\u27e9 pairs to generate API knowledge (AK for short) datasets, where each data item is an \u27e8 API, KI\u27e9 pair. We propose a novel approach, called PLAN, to automatically retrieve API knowledge from both API tutorials and SO posts based on natural language queries. PLAN contains three main stages: (1) API knowledge modeling, (2) query mapping, and (3) API knowledge retrieving. It first utilizes a deep-transfer-metric-learning-based relevance identification (DTML) model to effectively find relevant \u27e8 API, KI\u27e9 pairs containing two different knowledge items (\u27e8 API, QA\u27e9 pairs and \u27e8 API, FRA\u27e9 pairs) simultaneously. Then, PLAN generates several potential APIs as a way to reduce the lexical gap between the query and \u27e8 API, KI\u27e9 pairs. According to potential APIs, we can select relevant \u27e8 API, KI\u27e9 pairs to generate potential results. Finally, PLAN returns a list of ranked \u27e8 API, KI\u27e9 pairs that are related to the query. We evaluate the effectiveness of PLAN with 270 queries on Java and Android AK datasets containing 10,072 \u27e8 API, KI\u27e9 pairs. Our experimental results show that PLAN is effective and outperforms the state-of-the-art approaches. Our user study further confirms the effectiveness of PLAN in locating useful API knowledge.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "109",
        "numpages": "36",
        "keywords": "API tutorial, Stack Overflow, deep transfer metric learning, natural language queries"
    },
    "Open Source License Inconsistencies on GitHub": {
        "type": "article",
        "key": "10.1145/3571852",
        "author": "Wolter, Thomas and Barcomb, Ann and Riehle, Dirk and Harutyunyan, Nikolay",
        "title": "Open Source License Inconsistencies on GitHub",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571852",
        "doi": "10.1145/3571852",
        "abstract": "Almost all software, open or closed, builds on open source software and therefore needs to comply with the license obligations of the open source code. Not knowing which licenses to comply with poses a legal danger to anyone using open source software. This article investigates the extent of inconsistencies between licenses declared by an open source project at the top level of the repository and the licenses found in the code. We analyzed a sample of 1,000 open source GitHub repositories. We find that about half of the repositories did not fully declare all licenses found in the code. Of these, approximately 10\\% represented a permissive vs. copyleft license mismatch. Furthermore, existing tools cannot fully identify licences. We conclude that users of open source code should not just look at the declared licenses of the open source code they intend to use, but rather examine the software to understand its actual licenses.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "110",
        "numpages": "23",
        "keywords": "License management, license conflicts"
    },
    "Challenges of Working from Home in Software Development During Covid-19 Lockdowns": {
        "type": "article",
        "key": "10.1145/3579636",
        "author": "M\\\"{u}ller, Katharina and Koch, Christian and Riehle, Dirk and Stops, Michael and Harutyunyan, Nikolay",
        "title": "Challenges of Working from Home in Software Development During Covid-19 Lockdowns",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3579636",
        "doi": "10.1145/3579636",
        "abstract": "The COVID-19 pandemic in 2020/2021/2022 and the resulting lockdowns forced many companies to switch to working from home, swiftly, on a large scale, and without preparation. This situation created unique challenges for software development, where individual software professionals had to shift instantly from working together at a physical venue to working remotely from home. Our research questions focus on the challenges of software professionals who work from home due to the COVID-19 pandemic, which we studied empirically at a German bank. We conducted a case study employing a mixed methods approach. We aimed to cover both the breadth of challenges via a quantitative survey, as well as a deeper understanding of these challenges via the follow-up qualitative analysis of 15 semi-structured interviews. In this article, we present the key impediments employees faced during the crisis, as well as their similarities and differences to the known challenges in distributed software development (DSD). We also analyze the employees\u2019 job satisfaction and how the identified challenges impact job satisfaction. In our study, we focus on challenges in communication, collaboration, tooling, and management. The findings of the study provide insights into this emerging topic of high industry relevance. At the same time, the study contributes to the existing academic research on work from home and on the COVID-19 pandemic aftermath.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "111",
        "numpages": "41",
        "keywords": "Distributed software development, DSD, COVID-19, coronavirus, corona crisis, lockdown, mixed methods, open source, work from home, remote work"
    },
    "Extraction of Phrase-based Concepts in Vulnerability Descriptions through Unsupervised Labeling": {
        "type": "article",
        "key": "10.1145/3579638",
        "author": "Yitagesu, Sofonias and Xing, Zhenchang and Zhang, Xiaowang and Feng, Zhiyong and Li, Xiaohong and Han, Linyi",
        "title": "Extraction of Phrase-based Concepts in Vulnerability Descriptions through Unsupervised Labeling",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3579638",
        "doi": "10.1145/3579638",
        "abstract": "Software vulnerabilities, once disclosed, can be documented in vulnerability databases, which have great potential to advance vulnerability analysis and security research. People describe the key characteristics of software vulnerabilities in natural language mixed with domain-specific names and concepts. This textual nature poses a significant challenge for the automatic analysis of vulnerability knowledge embedded in text. Automatic extraction of key vulnerability aspects is highly desirable but demands significant effort to manually label data for model training. In this article, we propose unsupervised methods to label and extract important vulnerability concepts in textual vulnerability descriptions (TVDs). We focus on six types of phrase-based vulnerability concepts (vulnerability type, vulnerable component, root cause, attacker type, impact, and attack vector) as they are much more difficult to label and extract than name- or number-based entities (i.e., vendor, product, and version). Our approach is based on a key observation that the same-type of phrases, no matter how they differ in sentence structures and phrase expressions, usually share syntactically similar paths in the sentence parsing trees. Specifically, we present a source-target neural architecture that learns the Part-of-Speech (POS) tagging to identify a token\u2019s functional role within TVDs, where the source neural model is trained to capture common features found in the TVD corpus, and the target model is trained to identify linguistically malformed words specific to the security domain. Our evaluation confirms that the proposed tagger outperforms (4.45\\%\u20135.98\\%) the taggers designed on natural language notions and identifies a broad set of TVDs and natural language contents. Then, based on the key observations, we propose two path representations (absolute paths and relative paths) and use an auto-encoder to encode such syntactic similarities. To address the discrete nature of our paths, we enhance the traditional Variational Auto-encoder (VAE) with Gumble-Max trick for categorical data distribution and thus create a Categorical VAE (CaVAE). In the latent space of absolute and relative paths, we further apply unsupervised clustering techniques to generate clusters of the same-type of concepts. Our evaluation confirms the effectiveness of our CaVAE, which achieves a small (85.85) log-likelihood for encoding path representations and the accuracy (83\\%\u201389\\%) of vulnerability concepts in the resulting clusters. The resulting clusters accurately label six types of vulnerability concepts from a TVD corpus in an unsupervised way. Furthermore, these labeled vulnerability concepts can be mapped back to the corresponding phrases in the original TVDs, which produce labels of six types of vulnerability concepts. The resulting labeled TVDs can be used to train concept extraction models for other TVD corpora. In this work, we present two concept extraction methods (concept classification and sequence labeling model) to demonstrate the utility of the unsupervisedly labeled concepts. Our study shows that models trained with our unsupervisedly labeled vulnerability concepts outperform (3.9\\%\u20135.14\\%) those trained with the two manually labeled TVD datasets from previous work due to the consistent boundary and typing by our unsupervised labeling method.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "112",
        "numpages": "45",
        "keywords": "Textual vulnerability descriptions, phrase-based vulnerability concepts, unsupervised representation learning, clustering and concept labeling, supervised concept extraction"
    },
    "Digital Twin-based Anomaly Detection with Curriculum Learning in Cyber-physical Systems": {
        "type": "article",
        "key": "10.1145/3582571",
        "author": "Xu, Qinghua and Ali, Shaukat and Yue, Tao",
        "title": "Digital Twin-based Anomaly Detection with Curriculum Learning in Cyber-physical Systems",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3582571",
        "doi": "10.1145/3582571",
        "abstract": "Anomaly detection is critical to ensure the security of cyber-physical systems (CPS). However, due to the increasing complexity of attacks and CPS themselves, anomaly detection in CPS is becoming more and more challenging. In our previous work, we proposed a digital twin-based anomaly detection method, called ATTAIN, which takes advantage of both historical and real-time data of CPS. However, such data vary significantly in terms of difficulty. Therefore, similar to human learning processes, deep learning models (e.g., ATTAIN) can benefit from an easy-to-difficult curriculum. To this end, in this paper, we present a novel approach, named digitaL twin-based Anomaly deTecTion wIth Curriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum learning to optimize its learning paradigm. LATTICE attributes each sample with a difficulty score, before being fed into a training scheduler. The training scheduler samples batches of training data based on these difficulty scores such that learning from easy to difficult data can be performed. To evaluate LATTICE, we use five publicly available datasets collected from five real-world CPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art anomaly detectors. Evaluation results show that LATTICE outperforms the three baselines and ATTAIN by 0.906\\%-2.367\\% in terms of the F1 score. LATTICE also, on average, reduces the training time of ATTAIN by 4.2\\% on the five datasets and is on par with the baselines in terms of detection delay time.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "113",
        "numpages": "32",
        "keywords": "Cyber-physical system, digital twin, curriculum learning, deep learning, anomaly detection"
    },
    "Estimating Software Functional Size via Machine Learning": {
        "type": "article",
        "key": "10.1145/3582575",
        "author": "Lavazza, Luigi and Locoro, Angela and Liu, Geng and Meli, Roberto",
        "title": "Estimating Software Functional Size via Machine Learning",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3582575",
        "doi": "10.1145/3582575",
        "abstract": "Measuring software functional size via standard Function Points Analysis (FPA) requires the availability of fully specified requirements and specific competencies. Most of the time, the need to measure software functional size occurs well in advance with respect to these ideal conditions, under the lack of complete information or skilled experts. To work around the constraints of the official measurement process, several estimation methods&nbsp;for FPA have been proposed and are commonly used. Among these, the International Function Points User Group (IFPUG) has adopted the \u201cHigh-level FPA\u201d method (also known as the NESMA method). This method avoids weighting each data and transaction function by using fixed weights instead. Applying High-level FPA, or similar estimation methods, is faster and easier than carrying out the official measurement process but inevitably yields an approximation in the measures. In this article, we contribute to the problem of estimating software functional size measures by using machine learning. To the best of our knowledge, machine learning methods were never applied to the early estimation of software functional size. Our goal is to understand whether machine learning techniques yield estimates of FPA measures that are more accurate than those obtained with High-level FPA or similar methods. An empirical study on a large dataset of functional size predictors was carried out to train and test three of the most popular and robust machine learning methods, namely Random Forests, Support Vector Regression&nbsp;, and Neural Networks. A systematic experimental phase, with cycles of dataset filtering and splitting, parameter tuning, and model training and validation, is presented. The estimation accuracy of the obtained models was then evaluated and compared to that of fixed-weight models (e.g., High-level FPA) and linear regression models, also using a second dataset as the test set. We found that Support Vector Regression yields quite accurate estimation models. However, the obtained level of accuracy does not appear significantly better with respect to High-level FPA or to models built via ordinary least squares regression. Noticeably, fairly good accuracy levels were obtained by models that do not even require discerning among different types of transactions and data.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "114",
        "numpages": "27",
        "keywords": "Function Points, functional size measurement, NESMA Estimated, early size estimation, Function Point Analysis, High-level FPA, simple function points, SFP, SiFP, machine learning estimation, Neural Networks, Support Vector Regression, Random Forests"
    },
    "Toward Interpretable Graph Tensor Convolution Neural Network for Code Semantics Embedding": {
        "type": "article",
        "key": "10.1145/3582574",
        "author": "Yang, Jia and Fu, Cai and Deng, Fengyang and Wen, Ming and Guo, Xiaowei and Wan, Chuanhao",
        "title": "Toward Interpretable Graph Tensor Convolution Neural Network for Code Semantics Embedding",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3582574",
        "doi": "10.1145/3582574",
        "abstract": "Intelligent deep learning-based models have made significant progress for automated source code semantics embedding, and current research works mainly leverage natural language-based methods and graph-based methods. However, natural language-based methods do not capture the rich semantic structural information of source code, and graph-based methods do not utilize rich distant information of source code due to the high cost of message-passing steps.In this article, we propose a novel interpretable model, called graph tensor convolution neural network (GTCN), to generate accurate code embedding, which is capable of comprehensively capturing the distant information of code sequences and rich code semantics structural information. First, we propose to utilize a high-dimensional tensor to integrate various heterogeneous code graphs with node sequence features, such as control flow, data flow. Second, inspired by the current advantages of graph-based deep learning and efficient tensor computations, we propose a novel interpretable graph tensor convolution neural network for learning accurate code semantic embedding from the code graph tensor. Finally, we evaluate three popular applications on the GTCN model: variable misuse detection, source code prediction, and vulnerability detection. Compared with current state-of-the-art methods, our model achieves higher scores with respect to the top-1 accuracy while costing less training time.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "115",
        "numpages": "40",
        "keywords": "Tensor computation, code embedding, graph neural network"
    },
    "Assessing the Early Bird Heuristic (for Predicting Project Quality)": {
        "type": "article",
        "key": "10.1145/3583565",
        "author": "C., Shrikanth N. and Menzies, Tim",
        "title": "Assessing the Early Bird Heuristic (for Predicting Project Quality)",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3583565",
        "doi": "10.1145/3583565",
        "abstract": "Before researchers rush to reason across all available data or try complex methods, perhaps it is prudent to first check for simpler alternatives. Specifically, if the historical data has the most information in some small region, then perhaps a model learned from that region would suffice for the rest of the project.To support this claim, we offer a case study with 240 projects, where we find that the information in those projects \u201cclumps\u201d towards the earliest parts of the project. A quality prediction model learned from just the first 150 commits works as well, or better than state-of-the-art alternatives. Using just this \u201cearly bird\u201d data, we can build models very quickly and very early in the project life cycle. Moreover, using this early bird method, we have shown that a simple model (with just a few features) generalizes to hundreds of projects.Based on this experience, we doubt that prior work on generalizing quality models may have needlessly complicated an inherently simple process. Further, prior work that focused on later-life cycle data needs to be revisited, since their conclusions were drawn from relatively uninformative regions.Replication note: All our data and scripts are available here: https://github.com/snaraya7/early-bird.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "116",
        "numpages": "39",
        "keywords": "Quality prediction, defects, early, data-lite"
    },
    "Actor-Driven Decomposition of Microservices through Multi-level Scalability Assessment": {
        "type": "article",
        "key": "10.1145/3583563",
        "author": "Camilli, Matteo and Colarusso, Carmine and Russo, Barbara and Zimeo, Eugenio",
        "title": "Actor-Driven Decomposition of Microservices through Multi-level Scalability Assessment",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3583563",
        "doi": "10.1145/3583563",
        "abstract": "The microservices architectural style has gained widespread acceptance. However, designing applications according to this style is still challenging. Common difficulties concern finding clear boundaries that guide decomposition while ensuring performance and scalability. With the aim of providing software architects and engineers with a systematic methodology, we introduce a novel actor-driven decomposition strategy to complement the domain-driven design and overcome some of its limitations by reaching a finer modularization yet enforcing performance and scalability improvements. The methodology uses a multi-level scalability assessment framework that supports decision-making over iterative steps. At each iteration, architecture alternatives are quantitatively evaluated at multiple granularity levels. The assessment helps architects to understand the extent to which architecture alternatives increase or decrease performance and scalability. We applied the methodology to drive further decomposition of the core microservices of a real data-intensive smart mobility application and an existing open-source benchmark in the e-commerce domain. The results of an in-depth evaluation show that the approach can effectively support engineers in (i) decomposing monoliths or coarse-grained microservices into more scalable microservices and (ii) comparing among alternative architectures to guide decision-making for their deployment in modern infrastructures that orchestrate lightweight virtualized execution units.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "117",
        "numpages": "46",
        "keywords": "Microservices, decomposition process, architectural patterns, performance analysis, scalability assessment"
    },
    "Automated Identification of Toxic Code Reviews Using ToxiCR": {
        "type": "article",
        "key": "10.1145/3583562",
        "author": "Sarker, Jaydeb and Turzo, Asif Kamal and Dong, Ming and Bosu, Amiangshu",
        "title": "Automated Identification of Toxic Code Reviews Using ToxiCR",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3583562",
        "doi": "10.1145/3583562",
        "abstract": "Toxic conversations during software development interactions may have serious repercussions on a Free and Open Source Software (FOSS) development project. For example, victims of toxic conversations may become afraid to express themselves, therefore get demotivated, and may eventually leave the project. Automated filtering of toxic conversations may help a FOSS community maintain healthy interactions among its members. However, off-the-shelf toxicity detectors perform poorly on a software engineering dataset, such as one curated from code review comments. To counter this challenge, we present ToxiCR, a supervised learning based toxicity identification tool for code review interactions. ToxiCR includes a choice to select one of the 10 supervised learning algorithms, an option to select text vectorization techniques, eight preprocessing steps, and a large-scale labeled dataset of 19,651 code review comments. Two out of those eight preprocessing steps are software engineering domain specific. With our rigorous evaluation of the models with various combinations of preprocessing steps and vectorization techniques, we have identified the best combination for our dataset that boosts 95.8\\% accuracy and an 88.9\\% F1-score in identifying toxic texts. ToxiCR significantly outperforms existing toxicity detectors on our dataset. We have released our dataset, pre-trained models, evaluation results, and source code publicly, which is available at .",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "118",
        "numpages": "32",
        "keywords": "Toxicity, code review, sentiment analysis, Natural Language Processing, tool development"
    },
    "FaaSLight: General Application-level Cold-start Latency Optimization for Function-as-a-Service in Serverless Computing": {
        "type": "article",
        "key": "10.1145/3585007",
        "author": "Liu, Xuanzhe and Wen, Jinfeng and Chen, Zhenpeng and Li, Ding and Chen, Junkai and Liu, Yi and Wang, Haoyu and Jin, Xin",
        "title": "FaaSLight: General Application-level Cold-start Latency Optimization for Function-as-a-Service in Serverless Computing",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3585007",
        "doi": "10.1145/3585007",
        "abstract": "Serverless computing is a popular cloud computing paradigm that frees developers from server management. Function-as-a-Service (FaaS) is the most popular implementation of serverless computing, representing applications as event-driven and stateless functions. However, existing studies report that functions of FaaS applications severely suffer from cold-start latency.In this article, we propose an approach, namely, FaaSLight, to accelerating the cold start for FaaS applications through application-level optimization. We first conduct a measurement study to investigate the possible root cause of the cold-start problem of FaaS. The result shows that application code loading latency is a significant overhead. Therefore, loading only indispensable code from FaaS applications can be an adequate solution. Based on this insight, we identify code related to application functionalities by constructing the function-level call graph and separate other code (i.e., optional code) from FaaS applications. The separated optional code can be loaded on demand to avoid the inaccurate identification of indispensable code causing application failure. In particular, a key principle guiding the design of FaaSLight is inherently general, i.e., platform- and language-agnostic. In practice, FaaSLight can be effectively applied to FaaS applications developed in different programming languages (Python and JavaScript), and can be seamlessly deployed on popular serverless platforms such as AWS Lambda and Google Cloud Functions, without having to modify the underlying OSes or hypervisors, nor introducing any additional manual engineering efforts to developers. The evaluation results on real-world FaaS applications show that FaaSLight can significantly reduce the code loading latency (up to 78.95\\%, 28.78\\% on average), thereby reducing the cold-start latency. As a result, the total response latency of functions can be decreased by up to 42.05\\% (19.21\\% on average). Compared with the state-of-the-art, FaaSLight achieves a 21.25\\texttimes{} improvement in reducing the average total response latency.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "119",
        "numpages": "29",
        "keywords": "Serverless computing, cold start, performance optimization, optional function elimination"
    },
    "What\u2019s (Not) Working in Programmer User Studies?": {
        "type": "article",
        "key": "10.1145/3587157",
        "author": "Davis, Matthew C. and Aghayi, Emad and Latoza, Thomas D. and Wang, Xiaoyin and Myers, Brad A. and Sunshine, Joshua",
        "title": "What\u2019s (Not) Working in Programmer User Studies?",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3587157",
        "doi": "10.1145/3587157",
        "abstract": "A key goal of software engineering research is to improve the environments, tools, languages, and techniques programmers use to efficiently create quality software. Successfully designing these tools and demonstrating their effectiveness involves engaging with tool users\u2014software engineers. Researchers often want to conduct user studies of software engineers to collect direct evidence. However, running user studies can be difficult, and researchers may lack solution strategies to overcome the barriers, so they may avoid user studies. To understand the challenges researchers face when conducting programmer user studies, we interviewed 26 researchers. Based on the analysis of interview data, we contribute (i) a taxonomy of 18 barriers researchers encounter; (ii) 23 solution strategies some researchers use to address 8 of the 18 barriers in their own studies; and (iii) 4 design ideas, which we adapted from the behavioral science community, that may lower 8 additional barriers. To validate the design ideas, we held an in-person all-day focus group with 16 researchers.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "120",
        "numpages": "32",
        "keywords": "Empirical software engineering, user study, meta study, human participants, research methodology, human subjects, experiments"
    },
    "SEAL: Integrating Program Analysis and Repository Mining": {
        "type": "article",
        "key": "10.1145/3585008",
        "author": "Sattler, Florian and B\\\"{o}hm, Sebastian and Schubert, Philipp Dominik and Siegmund, Norbert and Apel, Sven",
        "title": "SEAL: Integrating Program Analysis and Repository Mining",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3585008",
        "doi": "10.1145/3585008",
        "abstract": "Software projects are complex technical and organizational systems involving large numbers of artifacts and developers. To understand and tame software complexity, a wide variety of program analysis techniques have been developed for bug detection, program comprehension, verification, and more. At the same time, repository mining techniques aim at obtaining insights into the inner socio-technical workings of software projects at a larger scale. While both program analysis and repository mining have been successful on their own, they are largely isolated, which leaves considerable potential for synergies untapped. We present SEAL, the first integrated approach that combines low-level program analysis with high-level repository information. SEAL maps repository information, mined from the development history of a project, onto a low-level intermediate program representation, making it available for state-of-the-art program analysis. SEAL\u2019s integrated approach allows us to efficiently address software engineering problems that span multiple levels of abstraction, from low-level data flow to high-level organizational information. To demonstrate its merits and practicality, we use SEAL to determine which code changes modify central parts of a given software project, how authors interact (indirectly) with each other through code, and we demonstrate that putting static analysis\u2019 results into a socio-technical context improves their expressiveness and interpretability.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "121",
        "numpages": "34",
        "keywords": "Static program analysis, software repository mining, socio-technical software analytics"
    },
    "White-Box Fuzzing RPC-Based APIs with EvoMaster: An Industrial Case Study": {
        "type": "article",
        "key": "10.1145/3585009",
        "author": "Zhang, Man and Arcuri, Andrea and Li, Yonggang and Liu, Yang and Xue, Kaiming",
        "title": "White-Box Fuzzing RPC-Based APIs with EvoMaster: An Industrial Case Study",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3585009",
        "doi": "10.1145/3585009",
        "abstract": "Remote Procedure Call (RPC) is a communication protocol to support client-server interactions among services over a network. RPC is widely applied in industry for building large-scale distributed systems, such as Microservices. Modern RPC frameworks include, for example, Thrift, gRPC, SOFARPC, and Dubbo. Testing such systems using RPC communications is very challenging, due to the complexity of distributed systems and various RPC frameworks the system could employ. To the best of our knowledge, there does not exist any tool or solution that could enable automated testing of modern RPC-based services. To fill this gap, in this article we propose the first approach in the literature, together with an open source tool, for fuzzing modern RPC-based APIs. The approach is in the context of white-box testing with search-based techniques. To tackle schema extraction of various RPC frameworks, we formulate a RPC schema specification along with a parser that allows the extraction from source code of any JVM RPC-based APIs. Then, with the extracted schema we employ a search to produce tests by maximizing white-box heuristics and newly defined heuristics specific to the RPC domain. We built our approach as an extension to an open source fuzzer (i.e., EvoMaster), and the approach has been integrated into a real industrial pipeline that could be applied to a real industrial development process for fuzzing RPC-based APIs. To assess our novel approach, we conducted an empirical study with two artificial and four industrial web services selected by our industrial partner. In addition, to further demonstrate its effectiveness and application in industrial settings, we report results of employing our tool for fuzzing another 50 industrial APIs autonomously conducted by our industrial partner in their testing processes. Results show that our novel approach is capable of enabling automated test case generation for industrial RPC-based APIs (i.e., 2 artificial and 54 industrial). We also compared with a simple gray-box technique and existing manually written tests. Our white-box solution achieves significant improvements on code coverage. Regarding fault detection, by conducting a careful review with our industrial partner of the tests generated by our novel approach in the selected four industrial APIs, a total of 41 real faults were identified, which have now been fixed. Another 8,377 detected faults are currently under investigation.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "122",
        "numpages": "38",
        "keywords": "Mircoservices, RPC, fuzzing, test generation, SBST, gRPC, Thrift"
    },
    "A Hypothesis Testing-based Framework for Software Cross-modal Retrieval in Heterogeneous Semantic Spaces": {
        "type": "article",
        "key": "10.1145/3591868",
        "author": "Wei, Hongwei and Su, Xiaohong and Gao, Cuiyun and Zheng, Weining and Tao, Wenxin",
        "title": "A Hypothesis Testing-based Framework for Software Cross-modal Retrieval in Heterogeneous Semantic Spaces",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3591868",
        "doi": "10.1145/3591868",
        "abstract": "Software cross-modal retrieval is a popular yet challenging direction, such as bug localization and code search. Previous studies generally map natural language texts and codes into a homogeneous semantic space for similarity measurement. However, it is not easy to accurately capture their similar semantics in a homogeneous semantic space due to the semantic gap. Therefore, we propose to map the multi-modal data into heterogeneous semantic spaces to capture their unique semantics. Specifically, we propose a novel software cross-modal retrieval framework named Deep Hypothesis Testing (DeepHT). In DeepHT, to capture the unique semantics of the code\u2019s control flow structure, all control flow paths (CFPs) in the control flow graph are mapped to a CFP sample set in the sample space. Meanwhile, the text is mapped to a CFP correlation distribution in the distribution space to model its correlation with different CFPs. The matching score is calculated according to how well the sample set obeys the distribution using hypothesis testing. The experimental results on two text-to-code retrieval tasks (i.e., bug localization and code search) and two code-to-text retrieval tasks (i.e., vulnerability knowledge retrieval and historical patch retrieval) show that DeepHT outperforms the baseline methods.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "123",
        "numpages": "28",
        "keywords": "Software cross-modal retrieval, hypothesis testing, deep learning"
    },
    "A Survey on Automated Driving System Testing: Landscapes and Trends": {
        "type": "article",
        "key": "10.1145/3579642",
        "author": "Tang, Shuncheng and Zhang, Zhenya and Zhang, Yi and Zhou, Jixiang and Guo, Yan and Liu, Shuang and Guo, Shengjian and Li, Yan-Fu and Ma, Lei and Xue, Yinxing and Liu, Yang",
        "title": "A Survey on Automated Driving System Testing: Landscapes and Trends",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3579642",
        "doi": "10.1145/3579642",
        "abstract": "Automated Driving Systems (ADS) have made great achievements in recent years thanks to the efforts from both academia and industry. A typical ADS is composed of multiple modules, including sensing, perception, planning, and control, which brings together the latest advances in different domains. Despite these achievements, safety assurance of ADS is of great significance, since unsafe behavior of ADS can bring catastrophic consequences. Testing has been recognized as an important system validation approach that aims to expose unsafe system behavior; however, in the context of ADS, it is extremely challenging to devise effective testing techniques, due to the high complexity and multidisciplinarity of the systems. There has been great much literature that focuses on the testing of ADS, and a number of surveys have also emerged to summarize the technical advances. Most of the surveys focus on the system-level testing performed within software simulators, and they thereby ignore the distinct features of different modules. In this article, we provide a comprehensive survey on the existing ADS testing literature, which takes into account both module-level and system-level testing. Specifically, we make the following contributions: (1) We survey the module-level testing techniques for ADS and highlight the technical differences affected by the features of different modules; (2) we also survey the system-level testing techniques, with focuses on the empirical studies that summarize the issues occurring in system development or deployment, the problems due to the collaborations between different modules, and the gap between ADS testing in simulators and the real world; and (3) we identify the challenges and opportunities in ADS testing, which pave the path to the future research in this field.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "124",
        "numpages": "62",
        "keywords": "ADS testing, module-level testing, system-level testing, system security"
    },
    "QuoTe: Quality-oriented Testing for Deep Learning Systems": {
        "type": "article",
        "key": "10.1145/3582573",
        "author": "Chen, Jialuo and Wang, Jingyi and Ma, Xingjun and Sun, Youcheng and Sun, Jun and Zhang, Peixin and Cheng, Peng",
        "title": "QuoTe: Quality-oriented Testing for Deep Learning Systems",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3582573",
        "doi": "10.1145/3582573",
        "abstract": "Recently, there has been significant growth of interest in applying software engineering techniques for the quality assurance of deep learning (DL) systems. One popular direction is DL testing\u2014that is, given a property of test, defects of DL systems are found either by fuzzing or guided search with the help of certain testing metrics. However, recent studies have revealed that the neuron coverage metrics, which are commonly used by most existing DL testing approaches, are not necessarily correlated with model quality (e.g., robustness, the most studied model property), and are also not an effective measurement on the confidence of the model quality after testing. In this work, we address this gap by proposing a novel testing framework called QuoTe (i.e., Quality-oriented Testing). A key part of QuoTe is a quantitative measurement on (1) the value of each test case in enhancing the model property of interest (often via retraining) and (2) the convergence quality of the model property improvement. QuoTe utilizes the proposed metric to automatically select or generate valuable test cases for improving model quality. The proposed metric is also a lightweight yet strong indicator of how well the improvement converged. Extensive experiments on both image and tabular datasets with a variety of model architectures confirm the effectiveness and efficiency of QuoTe in improving DL model quality\u2014that is, robustness and fairness. As a generic quality-oriented testing framework, future adaptations can be made to other domains (e.g., text) as well as other model properties.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "125",
        "numpages": "33",
        "keywords": "Deep learning, testing, robustness, fairness"
    },
    "A Comparative Study on Method Comment and Inline Comment": {
        "type": "article",
        "key": "10.1145/3582570",
        "author": "Huang, Yuan and Guo, Hanyang and Ding, Xi and Shu, Junhuai and Chen, Xiangping and Luo, Xiapu and Zheng, Zibin and Zhou, Xiaocong",
        "title": "A Comparative Study on Method Comment and Inline Comment",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3582570",
        "doi": "10.1145/3582570",
        "abstract": "Code comments are one of the important documents to help developers review and comprehend source code. In recent studies, researchers have proposed many deep learning models to generate the method header comments (i.e., method comment), which have achieved encouraging results. The comments in the method, which is called inline comment, are also important for program comprehension. Unfortunately, they have not received enough attention in automatic generation when comparing with the method comments. In this paper, we compare and analyze the similarities and differences between the method comments and the inline comments. By applying the existing models of generating method comments to the inline comment generation, we find that these existing models perform worse on the task of inline comment generation. We then further explore the possible reasons and obtain a number of new observations. For example, we find that there are a lot of templates (i.e., comments with the same or similar structures) in the method comment dataset, which makes the models perform better. Some terms were thought to be important (e.g., API calls) in the comment generation by previous study does not significantly affect the quality of the generated comments, which seems counter-intuitive. Our findings may give some implications for building the approaches of method comment or inline comment generation in the future.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "126",
        "numpages": "26",
        "keywords": "Code comment, comparative study, comment generation, method comment, inline comment"
    },
    "COMET: Coverage-guided Model Generation For Deep Learning Library Testing": {
        "type": "article",
        "key": "10.1145/3583566",
        "author": "Li, Meiziniu and Cao, Jialun and Tian, Yongqiang and Li, Tsz On and Wen, Ming and Cheung, Shing-Chi",
        "title": "COMET: Coverage-guided Model Generation For Deep Learning Library Testing",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3583566",
        "doi": "10.1145/3583566",
        "abstract": "Recent deep learning (DL) applications are mostly built on top of DL libraries. The quality assurance of these libraries is critical to the dependable deployment of DL applications. Techniques have been proposed to generate various DL models and apply them to test these libraries. However, their test effectiveness is constrained by the diversity of layer API calls in their generated DL models. Our study reveals that these techniques can cover at most 34.1\\% layer inputs, 25.9\\% layer parameter values, and 15.6\\% layer sequences. As a result, we find that many bugs arising from specific layer API calls (i.e., specific layer inputs, parameter values, or layer sequences) can be missed by existing techniques.Because of this limitation, we propose COMET to effectively generate DL models with diverse layer API calls for DL library testing. COMET: (1) designs a set of mutation operators and a coverage-based search algorithm to diversify layer inputs, layer parameter values, and layer sequences in DL models. (2) proposes a model synthesis method to boost the test efficiency without compromising the layer API call diversity. Our evaluation result shows that COMET outperforms baselines by covering twice as many layer inputs (69.7\\% vs. 34.1\\%), layer parameter values (50.2\\% vs. 25.9\\%), and layer sequences (39.0\\% vs. 15.6\\%) as those by the state-of-the-art. Moreover, COMET covers 3.4\\% more library branches than those by existing techniques. Finally, COMET detects 32 new bugs in the latest version of eight popular DL libraries, including TensorFlow and MXNet, with 21 of them confirmed by DL library developers and seven of those confirmed bugs have been fixed by developers.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "127",
        "numpages": "34",
        "keywords": "Deep learning testing, library testing, model generation, model diversity"
    },
    "Finding Deviated Behaviors of the Compressed DNN Models for Image Classifications": {
        "type": "article",
        "key": "10.1145/3583564",
        "author": "Tian, Yongqiang and Zhang, Wuqi and Wen, Ming and Cheung, Shing-Chi and Sun, Chengnian and Ma, Shiqing and Jiang, Yu",
        "title": "Finding Deviated Behaviors of the Compressed DNN Models for Image Classifications",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3583564",
        "doi": "10.1145/3583564",
        "abstract": "Model compression can significantly reduce the sizes of deep neural network (DNN) models and thus facilitate the dissemination of sophisticated, sizable DNN models, especially for deployment on mobile or embedded devices. However, the prediction results of compressed models may deviate from those of their original models. To help developers thoroughly understand the impact of model compression, it is essential to test these models to find those deviated behaviors before dissemination. However, this is a non-trivial task, because the architectures and gradients of compressed models are usually not available.To this end, we propose Dflare, a novel, search-based, black-box testing technique to automatically find triggering inputs that result in deviated behaviors in image classification tasks. Dflare iteratively applies a series of mutation operations to a given seed image until a triggering input is found. For better efficacy and efficiency, Dflare models the search problem as Markov Chains and leverages the Metropolis-Hasting algorithm to guide the selection of mutation operators in each iteration. Further, Dflare utilizes a novel fitness function to prioritize the mutated inputs that either cause large differences between two models\u2019 outputs or trigger previously unobserved models\u2019 probability vectors. We evaluated Dflare on 21 compressed models for image classification tasks with three datasets. The results show that Dflare not only constantly outperforms the baseline in terms of efficacy but also significantly improves the efficiency: Dflare is 17.84\\texttimes{}\u2013446.06\\texttimes{} as fast as the baseline in terms of time; the number of queries required by Dflare to find one triggering input is only 0.186\u20131.937\\% of those issued by the baseline. We also demonstrated that the triggering inputs found by Dflare can be used to repair up to 48.48\\% deviated behaviors in image classification tasks and further decrease the effectiveness of Dflare on the repaired models.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "128",
        "numpages": "32",
        "keywords": "Model dissemination, model compression, neural networks, image classification models"
    },
    "ArchRepair: Block-Level Architecture-Oriented Repairing for Deep Neural Networks": {
        "type": "article",
        "key": "10.1145/3585005",
        "author": "Qi, Hua and Wang, Zhijie and Guo, Qing and Chen, Jianlang and Juefei-Xu, Felix and Zhang, Fuyuan and Ma, Lei and Zhao, Jianjun",
        "title": "ArchRepair: Block-Level Architecture-Oriented Repairing for Deep Neural Networks",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3585005",
        "doi": "10.1145/3585005",
        "abstract": "Over the past few years, deep neural networks (DNNs) have achieved tremendous success and have been continuously applied in many application domains. However, during the practical deployment in industrial tasks, DNNs are found to be erroneous-prone due to various reasons such as overfitting and lacking of robustness to real-world corruptions during practical usage. To address these challenges, many recent attempts have been made to repair DNNs for version updates under practical operational contexts by updating weights (i.e., network parameters) through retraining, fine-tuning, or direct weight fixing at a neural level. Nevertheless, existing solutions often neglect the effects of neural network architecture and weight relationships across neurons and layers. In this work, as the first attempt, we initiate to repair DNNs by jointly optimizing the architecture and weights at a higher (i.e., block level).We first perform empirical studies to investigate the limitation of whole network-level and layer-level repairing, which motivates us to explore a novel repairing direction for DNN repair at the block level. To this end, we need to further consider techniques to address two key technical challenges, i.e., block localization, where we should localize the targeted block that we need to fix; and how to perform joint architecture and weight repairing. Specifically, we first propose adversarial-aware spectrum analysis for vulnerable block localization that considers the neurons\u2019 status and weights\u2019 gradients in blocks during the forward and backward processes, which enables more accurate candidate block localization for repairing even under a few examples. Then, we further propose the architecture-oriented search-based repairing that relaxes the targeted block to a continuous repairing search space at higher deep feature levels. By jointly optimizing the architecture and weights in that space, we can identify a much better block architecture. We implement our proposed repairing techniques as a tool, named ArchRepair, and conduct extensive experiments to validate the proposed method. The results show that our method can not only repair but also enhance accuracy and robustness, outperforming the state-of-the-art DNN repair techniques.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "129",
        "numpages": "31",
        "keywords": "Deep learning, DNN repair, neural architecture search"
    },
    "Securing the Ethereum from Smart Ponzi Schemes: Identification Using Static Features": {
        "type": "article",
        "key": "10.1145/3571847",
        "author": "Zheng, Zibin and Chen, Weili and Zhong, Zhijie and Chen, Zhiguang and Lu, Yutong",
        "title": "Securing the Ethereum from Smart Ponzi Schemes: Identification Using Static Features",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3571847",
        "doi": "10.1145/3571847",
        "abstract": "Malware detection approaches have been extensively studied for traditional software systems. However, the development of blockchain technology has promoted the birth of a new type of software system\u2013decentralized applications. Composed of smart contracts, a type of application that implements the Ponzi scheme logic (called smart Ponzi schemes) has caused irreversible loss and hindered the development of blockchain technology. These smart contracts generally had a short life but involved a large amount of money. Whereas identification of these Ponzi schemes before causing financial loss has been significantly important, existing methods suffer from three main deficiencies, i.e., the insufficient dataset, the reliance on the transaction records, and the low accuracy. In this study, we first build a larger dataset. Then, a large number of features from multiple views, including bytecode, semantic, and developers, are extracted. These features are independent of the transaction records. Furthermore, we leveraged machine learning methods to build our identification model, i.e., Multi-view Cascade Ensemble model (MulCas). The experiment results show that MulCas can achieve higher performance and robustness in the scope of our dataset. Most importantly, the proposed method can identify smart Ponzi scheme at the creation time.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "130",
        "numpages": "28",
        "keywords": "Blockchain, Ethereum, Ponzi schemes, malware detection"
    },
    "Rise of the Planet of Serverless Computing: A Systematic Review": {
        "type": "article",
        "key": "10.1145/3579643",
        "author": "Wen, Jinfeng and Chen, Zhenpeng and Jin, Xin and Liu, Xuanzhe",
        "title": "Rise of the Planet of Serverless Computing: A Systematic Review",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3579643",
        "doi": "10.1145/3579643",
        "abstract": "Serverless computing is an emerging cloud computing paradigm, being adopted to develop a wide range of software applications. It allows developers to focus on the application logic in the granularity of function, thereby freeing developers from tedious and error-prone infrastructure management. Meanwhile, its unique characteristic poses new challenges to the development and deployment of serverless-based applications. To tackle these challenges, enormous research efforts have been devoted. This article provides a comprehensive literature review to characterize the current research state of serverless computing. Specifically, this article covers 164 articles on 17 research directions of serverless computing, including performance optimization, programming framework, application migration, multi-cloud development, testing and debugging, and so on. It also derives research trends, focus, and commonly-used platforms for serverless computing, as well as promising research opportunities.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "131",
        "numpages": "61",
        "keywords": "Serverless computing, literature view"
    },
    "DatAFLow: Toward a Data-Flow-Guided Fuzzer": {
        "type": "article",
        "key": "10.1145/3587156",
        "author": "Herrera, Adrian and Payer, Mathias and Hosking, Antony L.",
        "title": "DatAFLow: Toward a Data-Flow-Guided Fuzzer",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3587156",
        "doi": "10.1145/3587156",
        "abstract": "Coverage-guided greybox fuzzers rely on control-flow coverage feedback to explore a target program and uncover bugs. Compared to control-flow coverage, data-flow coverage offers a more fine-grained approximation of program behavior. Data-flow coverage captures behaviors not visible as control flow and should intuitively discover more (or different) bugs. Despite this advantage, fuzzers guided by data-flow coverage have received relatively little attention, appearing mainly in combination with heavyweight program analyses (e.g., taint analysis, symbolic execution). Unfortunately, these more accurate analyses incur a high run-time penalty, impeding fuzzer throughput. Lightweight data-flow alternatives to control-flow fuzzing remain unexplored.We present datAFLow, a greybox fuzzer guided by lightweight data-flow profiling. We also establish a framework for reasoning about data-flow coverage, allowing the computational cost of exploration to be balanced with precision. Using this framework, we extensively evaluate datAFLow across different precisions, comparing it against state-of-the-art fuzzers guided by control flow, taint analysis, and data flow.Our results suggest that the ubiquity of control-flow-guided fuzzers is well-founded. The high run-time costs of data-flow-guided fuzzing (~10 \\texttimes{} higher than control-flow-guided fuzzing) significantly reduces fuzzer iteration rates, adversely affecting bug discovery and coverage expansion. Despite this, datAFLow uncovered bugs that state-of-the-art control-flow-guided fuzzers (notably, AFL++) failed to find. This was because data-flow coverage revealed states in the target not visible under control-flow coverage. Thus, we encourage the community to continue exploring lightweight data-flow profiling; specifically, to lower run-time costs and to combine this profiling with control-flow coverage to maximize bug-finding potential.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "132",
        "numpages": "31",
        "keywords": "Fuzzing, data flow, coverage"
    },
    "DatAFLow: Toward a Data-flow-guided Fuzzer": {
        "type": "article",
        "key": "10.1145/3587159",
        "author": "Herrera, Adrian and Payer, Mathias and Hosking, Antony L.",
        "title": "DatAFLow: Toward a Data-flow-guided Fuzzer",
        "year": "2023",
        "issue_date": "September 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "5",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3587159",
        "doi": "10.1145/3587159",
        "abstract": "This Replicating Computational Report (RCR) describes (a) our datAFLow fuzzer and (b) how to replicate the results in \u201cdatAFLow: Toward a Data-Flow-Guided Fuzzer.\u201d Our primary artifact is the datAFLow fuzzer. Unlike traditional coverage-guided greybox fuzzers\u2014which use control-flow coverage to drive program exploration\u2014datAFLow uses data-flow coverage to drive exploration. This is achieved through a set of LLVM-based analyses and transformations. In addition to datAFLow, we also provide a set of tools, scripts, and patches for (a) statically analyzing data flows in a target program, (b) compiling a target program with the datAFLow instrumentation, (c) evaluating datAFLow on the Magma benchmark suite, and (d) evaluating datAFLow on the DDFuzz dataset. datAFLow is available at https://github.com/HexHive/datAFLow.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "jul",
        "articleno": "133",
        "numpages": "7",
        "keywords": "Fuzzing, data flow, coverage"
    },
    "Fair Enough: Searching for Sufficient Measures of Fairness": {
        "type": "article",
        "key": "10.1145/3585006",
        "author": "Majumder, Suvodeep and Chakraborty, Joymallya and Bai, Gina R. and Stolee, Kathryn T. and Menzies, Tim",
        "title": "Fair Enough: Searching for Sufficient Measures of Fairness",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3585006",
        "doi": "10.1145/3585006",
        "abstract": "Testing machine learning software for ethical bias has become a pressing current concern. In response, recent research has proposed a plethora of new fairness metrics, for example, the dozens of fairness metrics in the IBM AIF360 toolkit. This raises the question: How can any fairness tool satisfy such a diverse range of goals? While we cannot completely simplify the task of fairness testing, we can certainly reduce the problem. This article shows that many of those fairness metrics effectively measure the same thing. Based on experiments using seven real-world datasets, we find that (a)&nbsp;26 classification metrics can be clustered into seven groups and (b)&nbsp;four dataset metrics can be clustered into three groups. Further, each reduced set may actually predict different things. Hence, it is no longer necessary (or even possible) to satisfy all fairness metrics. In summary, to simplify the fairness testing problem, we recommend the following steps: (1)&nbsp;determine what type of fairness is desirable (and we offer a handful of such types), then (2)&nbsp;lookup those types in our clusters, and then (3)&nbsp;just test for one item per cluster.For the purpose of reproducibility, our scripts and data are available at https://github.com/Repoanon ymous/Fairness_Metrics.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "134",
        "numpages": "22",
        "keywords": "empirical analysis, theoretical analysis, clustering, fairness metrics, Software fairness"
    },
    "Toward Understanding Deep Learning Framework Bugs": {
        "type": "article",
        "key": "10.1145/3587155",
        "author": "Chen, Junjie and Liang, Yihua and Shen, Qingchao and Jiang, Jiajun and Li, Shuochuan",
        "title": "Toward Understanding Deep Learning Framework Bugs",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3587155",
        "doi": "10.1145/3587155",
        "abstract": "DL frameworks are the basis of constructing all DL programs and models, and thus their bugs could lead to the unexpected behaviors of any DL program or model relying on them. Such a wide effect demonstrates the necessity and importance of guaranteeing DL frameworks\u2019 quality. Understanding the characteristics of DL framework bugs is a fundamental step for this quality assurance task, facilitating designing effective bug detection and debugging approaches. Hence, in this work, we conduct the most large-scale study on 1,000 bugs from four popular and diverse DL frameworks (i.e., TensorFlow, PyTorch, MXNet, and DL4J). By analyzing the root causes and symptoms of DL framework bugs associated with five components decomposed from DL frameworks, as well as measuring test coverage achieved by three state-of-the-art testing techniques, we obtain 12 major findings for the comprehensive understanding of DL framework bugs and the current status of existing DL framework testing practice, and then provide a series of actionable guidelines for better DL framework bug detection and debugging. Finally, based on the guidelines, we design and implement a prototype DL-framework testing tool, called TenFuzz, which is evaluated to be effective and finds three unknown bugs on the latest TensorFlow framework in a preliminary study, indicating the significance of our guidelines.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "135",
        "numpages": "31",
        "keywords": "deep learning testing, empirical study, bug analysis, Deep learning frameworks"
    },
    "UniLoc: Unified Fault Localization of Continuous Integration Failures": {
        "type": "article",
        "key": "10.1145/3593799",
        "author": "Hassan, Foyzul and Meng, Na and Wang, Xiaoyin",
        "title": "UniLoc: Unified Fault Localization of Continuous Integration Failures",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3593799",
        "doi": "10.1145/3593799",
        "abstract": "Continuous integration (CI) practices encourage developers to frequently integrate code into a shared repository. Each integration is validated by automatic build and testing such that errors are revealed as early as possible. When CI failures or integration errors are reported, existing techniques are insufficient to automatically locate the root causes for two reasons. First, a CI failure may be triggered by faults in source code and/or build scripts, whereas current approaches consider only source code. Second, a tentative integration can fail because of build failures and/or test failures, whereas existing tools focus on test failures only. This article presents UniLoc, the first unified technique to localize faults in both source code and build scripts given a CI failure log, without assuming the failure\u2019s location (source code or build scripts) and nature (a test failure or not). Adopting the information retrieval (IR) strategy, UniLoc locates buggy files by treating source code and build scripts as documents to search and by considering build logs as search queries. However, instead of na\\\"{\\i}vely applying an off-the-shelf IR technique to these software artifacts, for more accurate fault localization, UniLoc applies various domain-specific heuristics to optimize the search queries, search space, and ranking formulas. To evaluate UniLoc, we gathered 700 CI failure fixes in 72 open source projects that are built with Gradle. UniLoc could effectively locate bugs with the average mean reciprocal rank value as 0.49, mean average precision value as 0.36, and normalized discounted cumulative gain value as 0.54. UniLoc outperformed the state-of-the-art IR-based tool BLUiR and Locus. UniLoc has the potential to help developers diagnose root causes for CI failures more accurately and efficiently.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "136",
        "numpages": "31",
        "keywords": "information retrieval (IR), CI failures, Fault localization"
    },
    "TestSGD: Interpretable Testing of Neural Networks against Subtle Group Discrimination": {
        "type": "article",
        "key": "10.1145/3591869",
        "author": "Zhang, Mengdi and Sun, Jun and Wang, Jingyi and Sun, Bing",
        "title": "TestSGD: Interpretable Testing of Neural Networks against Subtle Group Discrimination",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3591869",
        "doi": "10.1145/3591869",
        "abstract": "Discrimination has been shown in many machine learning applications, which calls for sufficient fairness testing before their deployment in ethic-relevant domains. One widely concerning type of discrimination, testing against group discrimination, mostly hidden, is much less studied, compared with identifying individual discrimination. In this work, we propose TestSGD, an interpretable testing approach that systematically identifies and measures hidden (which we call \u201csubtle\u201d) group discrimination of a neural network characterized by conditions over combinations of the sensitive attributes. Specifically, given a neural network, TestSGD first automatically generates an interpretable rule set that categorizes the input space into two groups. Alongside, TestSGD also provides an estimated group discrimination score based on sampling the input space to measure the degree of the identified subtle group discrimination, which is guaranteed to be accurate up to an error bound. We evaluate TestSGD on multiple neural network models trained on popular datasets including both structured data and text data. The experiment results show that TestSGD is effective and efficient in identifying and measuring such subtle group discrimination that has never been revealed before. Furthermore, we show that the testing results of TestSGD can be used to mitigate such discrimination through retraining with negligible accuracy drop.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "137",
        "numpages": "24",
        "keywords": "fairness improvement, fairness testing, machine learning, Fairness"
    },
    "Automatic Core-Developer Identification on GitHub: A Validation Study": {
        "type": "article",
        "key": "10.1145/3593803",
        "author": "Bock, Thomas and Alznauer, Nils and Joblin, Mitchell and Apel, Sven",
        "title": "Automatic Core-Developer Identification on GitHub: A Validation Study",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3593803",
        "doi": "10.1145/3593803",
        "abstract": "Many open-source software projects are self-organized and do not maintain official lists with information on developer roles. So, knowing which developers take core and maintainer roles is, despite being relevant, often tacit knowledge. We propose a method to automatically identify core developers based on role permissions of privileged events triggered in GitHub issues and pull requests. In an empirical study on 25/GitHub projects, (1) we validate the set of automatically identified core developers with a sample of project-reported developer lists, and (2) we use our set of identified core developers to assess the accuracy of state-of-the-art unsupervised developer classification methods. Our results indicate that the set of core developers, which we extracted from privileged issue events, is sound and the accuracy of state-of-the-art unsupervised classification methods depends mainly on the data source (commit data versus issue data) rather than the network-construction method (directed versus undirected, etc.). In perspective, our results shall guide research and practice to choose appropriate unsupervised classification methods, and our method can help create reliable ground-truth data for training supervised classification methods.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "138",
        "numpages": "29",
        "keywords": "developer networks, developer classification, Open-source software projects"
    },
    "JavaScript SBST Heuristics to Enable Effective Fuzzing of NodeJS Web APIs": {
        "type": "article",
        "key": "10.1145/3593801",
        "author": "Zhang, Man and Belhadi, Asma and Arcuri, Andrea",
        "title": "JavaScript SBST Heuristics to Enable Effective Fuzzing of NodeJS Web APIs",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3593801",
        "doi": "10.1145/3593801",
        "abstract": "JavaScript is one of the most popular programming languages. However, its dynamic nature poses several challenges to automated testing techniques. In this paper, we propose an approach and open-source tool support to enable white-box testing of JavaScript applications using Search-Based Software Testing (SBST) techniques. We provide an automated approach to collect search-based heuristics like the common Branch Distance and to enable Testability Transformations. To empirically evaluate our results, we integrated our technique into the EvoMaster test generation tool, and carried out analyses on the automated system testing of RESTful and GraphQL APIs. Experiments on eight Web APIs running on NodeJS show that our technique leads to significantly better results than existing black-box and grey-box testing tools, in terms of code coverage and fault detection.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "139",
        "numpages": "29",
        "keywords": "Babel, fuzzer, SBST, white-box test generation, NodeJS, JavaScript instrumentation"
    },
    "XCoS: Explainable Code Search Based on Query Scoping and Knowledge Graph": {
        "type": "article",
        "key": "10.1145/3593800",
        "author": "Wang, Chong and Peng, Xin and Xing, Zhenchang and Zhang, Yue and Liu, Mingwei and Luo, Rong and Meng, Xiujie",
        "title": "XCoS: Explainable Code Search Based on Query Scoping and Knowledge Graph",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3593800",
        "doi": "10.1145/3593800",
        "abstract": "When searching code, developers may express additional constraints (e.g., functional constraints and nonfunctional constraints) on the implementations of desired functionalities in the queries. Existing code search tools treat the queries as a whole and ignore the different implications of different parts of the queries. Moreover, these tools usually return a ranked list of candidate code snippets without any explanations. Therefore, the developers often find it hard to choose the desired results and build confidence on them. In this article, we conduct a developer survey to better understand and address these issues and induct some insights from the survey results. Based on the insights, we propose XCoS, an explainable code search approach based on query scoping and knowledge graph. XCoS extracts a background knowledge graph from general knowledge bases like Wikidata and Wikipedia. Given a code search query, XCoS identifies different parts (i.e., functionalities, functional constraints, nonfunctional constraints) from it and use the expressions of functionalities and functional constraints to search the codebase. It then links both the query and the candidate code snippets to the concepts in the background knowledge graph and generates explanations based on the association paths between these two parts of concepts together with relevant descriptions. XCoS uses an interactive user interface that allows the user to better understand the associations between candidate code snippets and the query from different aspects and choose the desired results. Our evaluation shows that the quality of the extracted background knowledge and the concept linkings in codebase is generally high. Furthermore, the generated explanations are considered complete, concise, and readable, and the approach can help developers find the desired code snippets more accurately and confidently.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "140",
        "numpages": "28",
        "keywords": "concept, knowledge, explainability, Code search"
    },
    "Predicting the Change Impact of Resolving Defects by Leveraging the Topics of Issue Reports in Open Source Software Systems": {
        "type": "article",
        "key": "10.1145/3593802",
        "author": "Assi, Maram and Hassan, Safwat and Georgiou, Stefanos and Zou, Ying",
        "title": "Predicting the Change Impact of Resolving Defects by Leveraging the Topics of Issue Reports in Open Source Software Systems",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3593802",
        "doi": "10.1145/3593802",
        "abstract": "Upon receiving a new issue report, practitioners start by investigating the defect type, the potential fixing effort needed to resolve the defect and the change impact. Moreover, issue reports contain valuable information, such as, the title, description and severity, and researchers leverage the topics of issue reports as a collective metric portraying similar characteristics of a defect. Nonetheless, none of the existing studies leverage the defect topic, i.e., a semantic cluster of defects of the same nature, such as Performance, GUI, and Database, to estimate the change impact that represents the amount of change needed in terms of code churn and the number of files changed. To this end, in this article, we conduct an empirical study on 298,548 issue reports belonging to three large-scale open-source systems, i.e., Mozilla, Apache, and Eclipse, to estimate the change impact in terms of code churn or the number of files changed while leveraging the topics of issue reports. First, we adopt the Embedded Topic Model (ETM), a state-of-the-art topic modelling algorithm, to identify the topics. Second, we investigate the feasibility of predicting the change impact using the identified topics and other information extracted from the issue reports by building eight prediction models that classify issue reports requiring small or large change impact along two dimensions, i.e., the code churn size and the number of files changed. Our results suggest that XGBoost is the best-performing algorithm for predicting the change impact, with an AUC of 0.84, 0.76, and 0.73 for the code churn and 0.82, 0.71, and 0.73 for the number of files changed metric for Mozilla, Apache, and Eclipse, respectively. Our results also demonstrate that the topics of issue reports improve the recall of the prediction model by up to 45\\%.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "141",
        "numpages": "34",
        "keywords": "code churn, amount of change, change impact analysis, fixing effort, defect fixing, topics of issue reports, Issue reports"
    },
    "What Quality Aspects Influence the Adoption of Docker Images?": {
        "type": "article",
        "key": "10.1145/3603111",
        "author": "Rosa, Giovanni and Scalabrino, Simone and Bavota, Gabriele and Oliveto, Rocco",
        "title": "What Quality Aspects Influence the Adoption of Docker Images?",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3603111",
        "doi": "10.1145/3603111",
        "abstract": "Docker is a containerization technology that allows developers to ship software applications along with their dependencies in Docker images. Developers can extend existing images using them as base images when writing Dockerfiles. However, a lot of alternative functionally equivalent base images are available. Although many studies define and evaluate quality features that can be extracted from Docker artifacts, the criteria on which developers choose a base image over another remain unclear.In this article, we aim to fill this gap. First, we conduct a literature review through which we define a taxonomy of quality features, identifying two main groups: configuration-related features (i.e., mainly related to the Dockerfile and image build process), and externally observable features (i.e., what the Docker image users can observe). Second, we ran an empirical study considering the developers\u2019 preference for 2,441 Docker images in 1,911 open source software projects. We want to understand how the externally observable features influence the developers\u2019 preferences, and how they are related to the configuration-related features. Our results pave the way to the definition of a reliable quality measure for Docker artifacts, along with tools that support developers for a quality-aware development of them.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "142",
        "numpages": "30",
        "keywords": "Docker, container virtualization, software maintenance, Empirical software engineering"
    },
    "CodeEditor: Learning to Edit Source Code with Pre-trained Models": {
        "type": "article",
        "key": "10.1145/3597207",
        "author": "Li, Jia and Li, Ge and Li, Zhuo and Jin, Zhi and Hu, Xing and Zhang, Kechi and Fu, Zhiyi",
        "title": "CodeEditor: Learning to Edit Source Code with Pre-trained Models",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3597207",
        "doi": "10.1145/3597207",
        "abstract": "Developers often perform repetitive code editing activities (up to 70\\%) for various reasons (e.g., code refactoring) during software development. Many deep learning (DL) models have been proposed to automate code editing by learning from the code editing history. Among DL-based models, pre-trained code editing models have achieved the state-of-the-art (SOTA) results. Pre-trained models are first pre-trained with pre-training tasks and fine-tuned with the code editing task. Existing pre-training tasks mainly are code infilling tasks (e.g., masked language modeling), which are derived from the natural language processing field and are not designed for automatic code editing.In this article, we propose a novel pre-training task specialized in code editing and present an effective pre-trained code editing model named CodeEditor. Compared to previous code infilling tasks, our pre-training task further improves the performance and generalization ability of code editing models. Specifically, we collect lots of real-world code snippets as the ground truth and use a powerful generator to rewrite them into mutated versions. Then, we pre-train our CodeEditor to edit mutated versions into the corresponding ground truth, to learn edit patterns. We conduct experiments on four code editing datasets and evaluate the pre-trained CodeEditor in three settings (i.e., fine-tuning, few-shot, and zero-shot). (1) In the fine-tuning setting, we train the pre-trained CodeEditor with four datasets and evaluate it on the test data. CodeEditor outperforms the SOTA baselines by 15\\%, 25.5\\%, 9.4\\%, and 26.6\\% on four datasets. (2) In the few-shot setting, we train the pre-trained CodeEditor with limited data and evaluate it on the test data. CodeEditor substantially performs better than all baselines, even outperforming baselines that are fine-tuned with all data. (3) In the zero-shot setting, we evaluate the pre-trained CodeEditor on the test data without training. CodeEditor correctly edits 1,113 programs, while the SOTA baselines cannot work. The results show that the superiority of our pre-training task and the pre-trained CodeEditor is more effective in automatic code editing.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "143",
        "numpages": "22",
        "keywords": "deep learning, Pre-training, Source code editing"
    },
    "Open Problems in Fuzzing RESTful APIs: A Comparison of Tools": {
        "type": "article",
        "key": "10.1145/3597205",
        "author": "Zhang, Man and Arcuri, Andrea",
        "title": "Open Problems in Fuzzing RESTful APIs: A Comparison of Tools",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3597205",
        "doi": "10.1145/3597205",
        "abstract": "RESTful APIs are a type of web service that are widely used in industry. In the past few years, a lot of effort in the research community has been spent in designing novel techniques to automatically fuzz those APIs to find faults in them. Many real faults were automatically found in a large variety of RESTful APIs. However, usually the analyzed fuzzers treat the APIs as black-box, and no analysis of what is actually covered in these systems is done. Therefore, although these fuzzers are clearly useful for practitioners, we do not know their current limitations and actual effectiveness. Solving this is a necessary step to be able to design better, more efficient, and effective techniques. To address this issue, in this article we compare seven state-of-the-art fuzzers on 18 open source\u20141 industrial and 1 artificial\u2014RESTful APIs. We then analyze the source code for which parts of these APIs the fuzzers fail to generate tests. This analysis points to clear limitations of these current fuzzers, listing concrete follow-up challenges for the research community.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "144",
        "numpages": "45",
        "keywords": "comparison, REST, fuzzing, SBST, Automated test generation"
    },
    "Incorporating Signal Awareness in Source Code Modeling: An Application to Vulnerability Detection": {
        "type": "article",
        "key": "10.1145/3597202",
        "author": "Suneja, Sahil and Zhuang, Yufan and Zheng, Yunhui and Laredo, Jim and Morari, Alessandro and Khurana, Udayan",
        "title": "Incorporating Signal Awareness in Source Code Modeling: An Application to Vulnerability Detection",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3597202",
        "doi": "10.1145/3597202",
        "abstract": "AI models of code have made significant progress over the past few years. However, many models are actually not learning task-relevant source code features. Instead, they often fit non-relevant but correlated data, leading to a lack of robustness and generalizability, and limiting the subsequent practical use of such models. In this work, we focus on improving the model quality through signal awareness, i.e., learning the relevant signals in the input for making predictions. We do so by leveraging the heterogeneity of code samples in terms of their signal-to-noise content. We perform an end-to-end exploration of model signal awareness, comprising: (i) uncovering the reliance of AI models of code on task-irrelevant signals, via prediction-preserving input minimization; (ii) improving models\u2019 signal awareness by incorporating the notion of code complexity during model training, via curriculum learning; (iii) improving models\u2019 signal awareness by generating simplified signal-preserving programs and augmenting them to the training dataset; and (iv) presenting a novel interpretation of the model learning behavior from the perspective of the dataset, using its code complexity distribution. We propose a new metric to measure model signal awareness, Signal-aware Recall, which captures how much of the model\u2019s performance is attributable to task-relevant signal learning. Using a software vulnerability detection use-case, our model probing approach uncovers a significant lack of signal awareness in the models, across three different neural network architectures and three datasets. Signal-aware Recall is observed to be in the sub-50s for models with traditional Recall in the high 90s, suggesting that the models are presumably picking up a lot of noise or dataset nuances while learning their logic. With our code-complexity-aware model learning enhancement techniques, we are able to assist the models toward more task-relevant learning, recording up-to 4.8\\texttimes{} improvement in model signal awareness. Finally, we employ our model learning introspection approach to uncover the aspects of source code where the model is facing difficulty, and we analyze how our learning enhancement techniques alleviate it.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "145",
        "numpages": "40",
        "keywords": "explainability, data augmentation, curriculum learning, signal awareness, reliability, neural networks, Machine learning"
    },
    "An Empirical Study on GitHub Pull Requests\u2019 Reactions": {
        "type": "article",
        "key": "10.1145/3597208",
        "author": "Batoun, Mohamed Amine and Yung, Ka Lai and Tian, Yuan and Sayagh, Mohammed",
        "title": "An Empirical Study on GitHub Pull Requests\u2019 Reactions",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3597208",
        "doi": "10.1145/3597208",
        "abstract": "The pull request mechanism is commonly used to propose source code modifications and get feedback from the community before merging them into a software repository. On GitHub, practitioners can provide feedback on a pull request by either commenting on the pull request or simply reacting to it using a set of pre-defined GitHub reactions, i.e., \u201cThumbs-up\u201d, \u201cLaugh\u201d, \u201cHooray\u201d, \u201cHeart\u201d, \u201cRocket\u201d, \u201cThumbs-down\u201d, \u201cConfused\u201d, and \u201cEyes\u201d. While a large number of prior studies investigated how to improve different software engineering activities (e.g., code review and integration) by investigating the feedback on pull requests, they focused only on pull requests\u2019 comments as a source of feedback. However, the GitHub reactions, according to our preliminary study, contain feedback that is not manifested within the comments of pull requests. In fact, our preliminary analysis of six popular projects shows that a median of 100\\% of the practitioners who reacted to a pull request did not leave any comment suggesting that reactions can be a unique source of feedback to further improve the code review and integration process.To help future studies better leverage reactions as a feedback mechanism, we conduct an empirical study to understand the usage of GitHub reactions and understand their promises and limitations. We investigate in this article how reactions are used, when and who use them on what types of pull requests, and for what purposes. Our study considers a quantitative analysis on a set of 380 k reactions on 63 k pull requests of six popular open-source projects on GitHub and three qualitative analyses on a total number of 989 reactions from the same six projects. We find that the most common used GitHub reactions are the positive ones (i.e., \u201cThumbs-up\u201d, \u201cHooray\u201d, \u201cHeart\u201d, \u201cRocket\u201d, and \u201cLaugh\u201d). We observe that reactors use positive reactions to express positive attitude (e.g., approval, appreciation, and excitement) on the proposed changes in pull requests. A median of just 1.95\\% of the used reactions are negative ones, which are used by reactors who disagree with the proposed changes for six reasons, such as feature modifications that might have more downsides than upsides or the use of the wrong approach to address certain problems. Most (a median of 78.40\\%) reactions on a pull request come before the closing of the corresponding pull requests. Interestingly, we observe that non-contributors (i.e., outsiders who potentially are the \u201cend-users\u201d of the software) are also active on reacting to pull requests. On top of that, we observe that core contributors, peripheral contributors, casual contributors and outsiders have different behaviors when reacting to pull requests. For instance, most core contributors react in the early stages of a pull request, while peripheral contributors, casual contributors and outsiders react around the closing time or, in some cases, after a pull request is merged. Contributors tend to react to the pull request\u2019s source code, while outsiders are more concerned about the impact of the pull request on the end-user experience. Our findings shed light on common patterns of GitHub reactions usage on pull requests and provide taxonomies about the intention of reactors, which can inspire future studies better leverage pull requests\u2019 reactions.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "146",
        "numpages": "35",
        "keywords": "feedback, software collaboration, pull requests, GitHub reactions"
    },
    "Semantic-Enriched Code Knowledge Graph to Reveal Unknowns in Smart Contract Code Reuse": {
        "type": "article",
        "key": "10.1145/3597206",
        "author": "Huang, Qing and Liao, Dianshu and Xing, Zhenchang and Zuo, Zhengkang and Wang, Changjing and Xia, Xin",
        "title": "Semantic-Enriched Code Knowledge Graph to Reveal Unknowns in Smart Contract Code Reuse",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3597206",
        "doi": "10.1145/3597206",
        "abstract": "Programmers who work with smart contract development often encounter challenges in reusing code from repositories. This is due to the presence of two unknowns that can lead to non-functional and functional failures. These unknowns are implicit collaborations between functions and subtle differences among similar functions. Current code mining methods can extract syntax and semantic knowledge (known knowledge), but they cannot uncover these unknowns due to a significant gap between the known and the unknown. To address this issue, we formulate knowledge acquisition as a knowledge deduction task and propose an analytic flow that uses the function clone as a bridge to gradually deduce the known knowledge into the problem-solving knowledge that can reveal the unknowns. This flow comprises five methods: clone detection, co-occurrence probability calculation, function usage frequency accumulation, description propagation, and control flow graph annotation. This provides a systematic and coherent approach to knowledge deduction. We then structure all of the knowledge into a semantic-enriched code Knowledge Graph (KG) and integrate this KG into two software engineering tasks: code recommendation and crowd-scaled coding practice checking. As a proof of concept, we apply our approach to 5,140 smart contract files available on Etherscan.io and confirm high accuracy of our KG construction steps. In our experiments, our code KG effectively improved code recommendation accuracy by 6\\% to 45\\%, increased diversity by 61\\% to 102\\%, and enhanced NDCG by 1\\% to 21\\%. Furthermore, compared to traditional analysis tools and the debugging-with-the-crowd method, our KG improved time efficiency by 30 to 380 seconds, vulnerability determination accuracy by 20\\% to 33\\%, and vulnerability fixing accuracy by 24\\% to 40\\% for novice developers who identified and fixed vulnerable smart contract functions.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "147",
        "numpages": "37",
        "keywords": "crowd-scale coding practice checking, code recommendation, knowledge deduction, code knowledge graph, Smart contract"
    },
    "An Accurate Identifier Renaming Prediction and Suggestion Approach": {
        "type": "article",
        "key": "10.1145/3603109",
        "author": "Zhang, Jingxuan and Luo, Junpeng and Liang, Jiahui and Gong, Lina and Huang, Zhiqiu",
        "title": "An Accurate Identifier Renaming Prediction and Suggestion Approach",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3603109",
        "doi": "10.1145/3603109",
        "abstract": "Identifiers play an important role in helping developers analyze and comprehend source code. However, many identifiers exist that are inconsistent with the corresponding code conventions or semantic functions, leading to flawed identifiers. Hence, identifiers need to be renamed regularly. Even though researchers have proposed several approaches to identify identifiers that need renaming and further suggest correct identifiers for them, these approaches only focus on a single or a limited number of granularities of identifiers without universally considering all the granularities and suggest a series of sub-tokens for composing identifiers without completely generating new identifiers. In this article, we propose a novel identifier renaming prediction and suggestion approach. Specifically, given a set of training source code, we first extract all the identifiers in multiple granularities. Then, we design and extract five groups of features from identifiers to capture inherent properties of identifiers themselves and the relationships between identifiers and code conventions, as well as other related code entities, enclosing files, and change history. By parsing the change history of identifiers, we can figure out whether specific identifiers have been renamed or not. These identifier features and their renaming history are used to train a Random Forest classifier, which can be further used to predict whether a given new identifier needs to be renamed or not. Subsequently, for the identifiers that need renaming, we extract all the related code entities and their renaming change history. Based on the intuition that identifiers are co-evolved as their relevant code entities with similar patterns and renaming sequences, we could suggest and recommend a series of new identifiers for those identifiers. We conduct extensive experiments to validate our approach in both the Java projects and the Android projects. Experimental results demonstrate that our approach could identify identifiers that need renaming with an average F-measure of more than 89\\%, which outperforms the state-of-the-art approach by 8.30\\% in the Java projects and 21.38\\% in the Android projects. In addition, our approach achieves a Hit@10 of 48.58\\% and 40.97\\% in the Java and Android projects in suggesting correct identifiers and outperforms the state-of-the-art approach by 29.62\\% and 15.75\\%, respectively.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "148",
        "numpages": "51",
        "keywords": "mining code repository, code refactoring, source code analysis, Identifier renaming"
    },
    "Dependency Update Strategies and Package Characteristics": {
        "type": "article",
        "key": "10.1145/3603110",
        "author": "Javan Jafari, Abbas and Costa, Diego Elias and Shihab, Emad and Abdalkareem, Rabe",
        "title": "Dependency Update Strategies and Package Characteristics",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3603110",
        "doi": "10.1145/3603110",
        "abstract": "Managing project dependencies is a key maintenance issue in software development. Developers need to choose an update strategy that allows them to receive important updates and fixes while protecting them from breaking changes. Semantic Versioning was proposed to address this dilemma, but many have opted for more restrictive or permissive alternatives. This empirical study explores the association between package characteristics and the dependency update strategy selected by its dependents to understand how developers select and change their update strategies. We study over 112,000 Node Package Manager (npm) packages and use 19 characteristics to build a prediction model that identifies the common dependency update strategy for each package. Our model achieves a minimum improvement of 72\\% over the baselines and is much better aligned with community decisions than the npm default strategy. We investigate how different package characteristics can influence the predicted update strategy and find that dependent count, age, and release status to be the highest influencing features. We complement the work with qualitative analyses of 160 packages to investigate the evolution of update strategies. While the common update strategy remains consistent for many packages, certain events such as the release of the 1.0.0 version or breaking changes influence the selected update strategy over time.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "149",
        "numpages": "29",
        "keywords": "npm, software ecosystems, dependency management, Dependency update strategy"
    },
    "DeepPatch: Maintaining Deep Learning Model Programs to Retain Standard Accuracy with Substantial Robustness Improvement": {
        "type": "article",
        "key": "10.1145/3604609",
        "author": "Wei, Zhengyuan and Wang, Haipeng and Ashraf, Imran and Chan, Wing-Kwong",
        "title": "DeepPatch: Maintaining Deep Learning Model Programs to Retain Standard Accuracy with Substantial Robustness Improvement",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3604609",
        "doi": "10.1145/3604609",
        "abstract": "Maintaining a deep learning (DL) model by making the model substantially more robust through retraining with plenty of adversarial examples of non-trivial perturbation strength often reduces the model\u2019s standard accuracy. Many existing model repair or maintenance techniques sacrifice standard accuracy to produce a large gain in robustness or vice versa. This article proposes DeepPatch, a novel technique to maintain filter-intensive DL models. To the best of our knowledge, DeepPatch is the first work to address the challenge of standard accuracy retention while substantially improving the robustness of DL models with plenty of adversarial examples of non-trivial and diverse perturbation strengths. Rather than following the conventional wisdom to generalize all the components of a DL model over the union set of clean and adversarial samples, DeepPatch formulates a novel division of labor method to adaptively activate a subset of its inserted processing units to process individual samples. Its produced model can generate the original or replacement feature maps in each forward pass of the patched model, making the patched model carry an intrinsic property of behaving like the model under maintenance on demand. The overall experimental results show that DeepPatch successfully retains the standard accuracy of all pretrained models while improving the robustness accuracy substantially. However, the models produced by the peer techniques suffer from either large standard accuracy loss or small robustness improvement compared with the models under maintenance, rendering them unsuitable in general to replace the latter.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "150",
        "numpages": "49",
        "keywords": "accuracy recovery, maintenance, Model testing"
    },
    "Optimization Techniques for Model Checking Leads-to Properties in a Stratified Way": {
        "type": "article",
        "key": "10.1145/3604610",
        "author": "Do, Canh Minh and Phyo, Yati and Riesco, Adri\\'{a}n and Ogata, Kazuhiro",
        "title": "Optimization Techniques for Model Checking Leads-to Properties in a Stratified Way",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3604610",
        "doi": "10.1145/3604610",
        "abstract": "We devised the L+1-layer divide \\&amp; conquer approach to leads-to model checking (L+1-DCA2L2MC) and its parallel version, and developed sequential and parallel tools for L+1-DCA2L2MC. In a temporal logic called UNITY, designed by Chandy and Misra, the leads-to temporal connective plays an important role and many case studies have been conducted in UNITY, demonstrating that many systems requirements can be expressed as leads-to properties. Hence, it is worth dedicating to these properties. Counterexample generation is one of the main tasks in the L+1-DCA2L2MC technique that can be optimized to improve its running performance. This article proposes a technique to find all counterexamples at once in model checking with a new model checker. Furthermore, layer configuration selection is essential to make the best use of the L+1-DCA2L2MC technique. This work also proposes an approach to finding a good layer configuration for the technique with an analysis tool. Some experiments are conducted to demonstrate the power and usefulness of the two optimization techniques, respectively. Moreover, our sequential and parallel tools are compared with SPIN and LTSmin model checkers, showing a promising way to mitigate the state space explosion and improve the running performance of model checking when dealing with large state spaces.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "151",
        "numpages": "38",
        "keywords": "state space explosion, parallel model checking, Maude, master-worker model, Leads-to properties"
    },
    "Revisiting the Identification of the Co-evolution of Production and Test Code": {
        "type": "article",
        "key": "10.1145/3607183",
        "author": "Sun, Weifeng and Yan, Meng and Liu, Zhongxin and Xia, Xin and Lei, Yan and Lo, David",
        "title": "Revisiting the Identification of the Co-evolution of Production and Test Code",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3607183",
        "doi": "10.1145/3607183",
        "abstract": "Many software processes advocate that the test code should co-evolve with the production code. Prior work usually studies such co-evolution based on production-test co-evolution samples mined from software repositories. A production-test co-evolution sample refers to a pair of a test code change and a production code change where the test code change triggers or is triggered by the production code change. The quality of the mined samples is critical to the reliability of research conclusions. Existing studies mined production-test co-evolution samples based on the following assumption: if a test class and its associated production class change together in one commit, or a test class changes immediately after the changes of the associated production class within a short time interval, this change pair should be a production-test co-evolution sample. However, the validity of this assumption has never been investigated.To fill this gap, we present an empirical study, investigating the reasons for test code updates occurring after the associated production code changes, and revealing the pervasive existence of noise in the production-test co-evolution samples identified based on the aforementioned assumption by existing works. We define a taxonomy of such noise, including six categories (i.e., adaptive maintenance, perfective maintenance, corrective maintenance, indirectly related production code update, indirectly related test code update, and other reasons). Guided by the empirical findings, we propose CHOSEN (an identifiCation metHod Of production-teSt co-EvolutioN) based on a two-stage strategy. CHOSEN takes a test code change and its associated production code change as input, aiming to determine whether the production-test change pair is a production-test co-evolution sample. Such identified samples are the basis of or are useful for various downstream tasks. We conduct a series of experiments to evaluate our method. Results show that (1) CHOSEN achieves an AUC of 0.931 and an F1-score of 0.928, significantly outperforming existing identification methods, and (2) CHOSEN can help researchers and practitioners draw more accurate conclusions on studies related to the co-evolution of production and test code. For the task of Just-In-Time (JIT) obsolete test code detection, which can help detect whether a piece of test code should be updated when developers modify the production code, the test set constructed by CHOSEN can help measure the detection method\u2019s performance more accurately, only leading to 0.76\\% of average error compared with ground truth. In addition, the dataset constructed by CHOSEN can be used to train a better obsolete test code detection model, of which the average improvements on accuracy, precision, recall, and F1-score are 12.00\\%, 17.35\\%, 8.75\\%, and 13.50\\% respectively.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "152",
        "numpages": "37",
        "keywords": "software testing, software evolution, mining software repositories, Empirical software engineering"
    },
    "Exploring the Impact of Code Clones on Deep Learning Software": {
        "type": "article",
        "key": "10.1145/3607181",
        "author": "Mo, Ran and Zhang, Yao and Wang, Yushuo and Zhang, Siyuan and Xiong, Pu and Li, Zengyang and Zhao, Yang",
        "title": "Exploring the Impact of Code Clones on Deep Learning Software",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3607181",
        "doi": "10.1145/3607181",
        "abstract": "Deep learning (DL) is a really active topic in recent years. Code cloning is a common code implementation that could negatively impact software maintenance. For DL software, developers rely heavily on frameworks to implement DL features. Meanwhile, to guarantee efficiency, developers often reuse the steps and configuration settings for building DL models. These may bring code copy-pastes or reuses inducing code clones. However, there is little work exploring code clones\u2019 impact on DL software. In this article, we conduct an empirical study and show that: (1) code clones are prevalent in DL projects, about 16.3\\% of code fragments encounter clones, which is almost twice larger than the traditional projects; (2) 75.6\\% of DL projects contain co-changed clones, meaning changes are propagated among cloned fragments, which can bring maintenance difficulties; (3)&nbsp;Percentage of the clones and Number of clone lines are associated with the emergence of co-changes; (4) the prevalence of Code clones varies in DL projects with different frameworks, but the difference is not significant; (5) Type 1 co-changed clones often spread over different folders, but Types 2 and 3 co-changed clones mainly occur within the same files or folders; (6) 57.1\\% of all co-changed clones are involved in bugs.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "153",
        "numpages": "34",
        "keywords": "co-changed clone, code clone, Deep learning software"
    },
    "PatchCensor: Patch Robustness Certification for Transformers via Exhaustive Testing": {
        "type": "article",
        "key": "10.1145/3591870",
        "author": "Huang, Yuheng and Ma, Lei and Li, Yuanchun",
        "title": "PatchCensor: Patch Robustness Certification for Transformers via Exhaustive Testing",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3591870",
        "doi": "10.1145/3591870",
        "abstract": "In the past few years, Transformer has been widely adopted in many domains and applications because of its impressive performance. Vision Transformer (ViT), a successful and well-known variant, attracts considerable attention from both industry and academia thanks to its record-breaking performance in various vision tasks. However, ViT is also highly nonlinear like other classical neural networks and could be easily fooled by both natural and adversarial perturbations. This limitation could pose a threat to the deployment of ViT in the real industrial environment, especially in safety-critical scenarios. How to improve the robustness of ViT is thus an urgent issue that needs to be addressed. Among all kinds of robustness, patch robustness is defined as giving a reliable output when a random patch in the input domain is perturbed. The perturbation could be natural corruption, such as part of the camera lens being blurred. It could also be a distribution shift, such as an object that does not exist in the training data suddenly appearing in the camera. And in the worst case, there could be a malicious adversarial patch attack that aims to fool the prediction of a machine learning model by arbitrarily modifying pixels within a restricted region of an input image. This kind of attack is also called physical attack, as it is believed to be more real than digital attack. Although there has been some work on patch robustness improvement of Convolutional Neural Network, related studies on its counterpart ViT are still at an early stage as ViT is usually much more complex with far more parameters. It is harder to assess and improve its robustness, not to mention to provide a provable guarantee. In this work, we propose PatchCensor, aiming to certify the patch robustness of ViT by applying exhaustive testing. We try to provide a provable guarantee by considering the worst patch attack scenarios. Unlike empirical defenses against adversarial patches that may be adaptively breached, certified robust approaches can provide a certified accuracy against arbitrary attacks under certain conditions. However, existing robustness certifications are mostly based on robust training, which often requires substantial training efforts and the sacrifice of model performance on normal samples. To bridge the gap, PatchCensor seeks to improve the robustness of the whole system by detecting abnormal inputs instead of training a robust model and asking it to give reliable results for every input, which may inevitably compromise accuracy. Specifically, each input is tested by voting over multiple inferences with different mutated attention masks, where at least one inference is guaranteed to exclude the abnormal patch. This can be seen as complete-coverage testing, which could provide a statistical guarantee on inference at the test time. Our comprehensive evaluation demonstrates that PatchCensor is able to achieve high certified accuracy (e.g.,&nbsp;67.1\\% on ImageNet for 2\\%-pixel adversarial patches), significantly outperforming state-of-the-art techniques while achieving similar clean accuracy (81.8\\% on ImageNet). The clean accuracy is the same as vanilla ViT models. Meanwhile, our technique also supports flexible configurations to handle different adversarial patch sizes by simply changing the masking strategy.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "154",
        "numpages": "34",
        "keywords": "deep learning, certified accuracy, vision transformer, robustness certification, neural networks, Adversarial patch"
    },
    "Tiny, Always-on, and Fragile: Bias Propagation through Design Choices in On-device Machine Learning Workflows": {
        "type": "article",
        "key": "10.1145/3591867",
        "author": "Hutiri, Wiebke (Toussaint) and Ding, Aaron Yi and Kawsar, Fahim and Mathur, Akhil",
        "title": "Tiny, Always-on, and Fragile: Bias Propagation through Design Choices in On-device Machine Learning Workflows",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3591867",
        "doi": "10.1145/3591867",
        "abstract": "Billions of distributed, heterogeneous, and resource constrained IoT devices deploy on-device machine learning (ML) for private, fast, and offline inference on personal data. On-device ML is highly context dependent and sensitive to user, usage, hardware, and environment attributes. This sensitivity and the propensity toward bias in ML makes it important to study bias in on-device settings. Our study is one of the first investigations of bias in this emerging domain and lays important foundations for building fairer on-device ML. We apply a software engineering lens, investigating the propagation of bias through design choices in on-device ML workflows. We first identify reliability bias as a source of unfairness and propose a measure to quantify it. We then conduct empirical experiments for a keyword spotting task to show how complex and interacting technical design choices amplify and propagate reliability bias. Our results validate that design choices made during model training, like the sample rate and input feature type, and choices made to optimize models, like light-weight architectures, the pruning learning rate, and pruning sparsity, can result in disparate predictive performance across male and female groups. Based on our findings, we suggest low effort strategies for engineers to mitigate bias in on-device ML.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "155",
        "numpages": "37",
        "keywords": "personal data, audio keyword spotting, fairness, design choices, embedded machine learning, on-device machine learning, Bias"
    },
    "Rise of Distributed Deep Learning Training in the Big Model Era: From a Software Engineering Perspective": {
        "type": "article",
        "key": "10.1145/3597204",
        "author": "Liu, Xuanzhe and Gu, Diandian and Chen, Zhenpeng and Wen, Jinfeng and Zhang, Zili and Ma, Yun and Wang, Haoyu and Jin, Xin",
        "title": "Rise of Distributed Deep Learning Training in the Big Model Era: From a Software Engineering Perspective",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3597204",
        "doi": "10.1145/3597204",
        "abstract": "Deep learning (DL) has become a key component of modern software. In the \u201cbig model\u201d era, the rich features of DL-based software (i.e., DL software) substantially rely on powerful DL models, e.g., BERT, GPT-3, and the recently emerging GPT-4, which are trained on the powerful cloud with large datasets. Hence, training effective DL models has become a vital stage in the whole software lifecycle. When training deep learning models, especially those big models, developers need to parallelize and distribute the computation and memory resources amongst multiple devices (e.g., a cluster of GPUs) in the training process, which is known as distributed deep learning training, or distributed training for short. However, the unique challenges that developers encounter in distributed training process have not been studied in the software engineering community. Given the increasingly heavy dependence of current DL-based software on distributed training, this paper aims to fill in the knowledge gap and presents the first comprehensive study on developers\u2019 issues in distributed training. To this end, we focus on popular DL frameworks that support distributed training (including TensorFlow, PyTorch, Keras, and Horovod) and analyze 1,131 real-world developers\u2019 issues about using these frameworks reported on Stack Overflow and GitHub. We construct a fine-grained taxonomy consisting of 30 categories regarding the fault symptoms and summarize common fix patterns for different symptoms. We find that: (1) many distributed-specific faults and non-distributed-specific faults inherently share the same fault symptoms, making it challenging to debug; (2) most of the fault symptoms have frequent fix patterns; (3) about half of the faults are related to system-level configurations. Based on the results, we suggest actionable implications on research avenues that can potentially facilitate the distributed training to develop DL-based software, such as focusing on the frequent and common fix patterns when designing testing or debugging tools, developing efficient testing and debugging techniques for communication configuration along with the synthesis of network configuration analysis, designing new multi-device checkpoint-and-replay techniques to help reproduction, and designing serverless APIs for cloud platforms.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "156",
        "numpages": "26",
        "keywords": "software engineering, distributed training, Empirical study"
    },
    "Pre-implementation Method Name Prediction for Object-oriented Programming": {
        "type": "article",
        "key": "10.1145/3597203",
        "author": "Wang, Shangwen and Wen, Ming and Lin, Bo and Liu, Yepang and Bissyand\\'{e}, Tegawend\\'{e} F. and Mao, Xiaoguang",
        "title": "Pre-implementation Method Name Prediction for Object-oriented Programming",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3597203",
        "doi": "10.1145/3597203",
        "abstract": "Method naming is a challenging development task in object-oriented programming. In recent years, several research efforts have been undertaken to provide automated tool support for assisting developers in this task. In general, literature approaches assume the availability of method implementation to infer its name. Methods, however, are usually named before their implementations. In this work, we fill the gap in the literature about method name prediction by developing an approach that predicts the names of all methods to be implemented within a class. Our work considers the class name as the input: The overall intuition is that classes with semantically similar names tend to provide similar functionalities, and hence similar method names. We first conduct a large-scale empirical analysis on 258K+ classes from real-world projects to validate our hypotheses. Then, we propose a hybrid big code-driven approach, Mario, to predict method names based on the class name: We combine a deep learning model with heuristics summarized from code analysis. Extensive experiments on 22K+ classes yielded promising results: compared to the state-of-the-art code2seq model (which leverages method implementation data), our approach achieves comparable results in terms of F-score at token-level prediction; our approach, additionally, outperforms code2seq in prediction at the name level. We further show that our approach significantly outperforms several other baselines.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "157",
        "numpages": "35",
        "keywords": "naming convention, Method name prediction"
    },
    "Towards Practical Binary Code Similarity Detection: Vulnerability Verification via Patch Semantic Analysis": {
        "type": "article",
        "key": "10.1145/3604608",
        "author": "Yang, Shouguo and Xu, Zhengzi and Xiao, Yang and Lang, Zhe and Tang, Wei and Liu, Yang and Shi, Zhiqiang and Li, Hong and Sun, Limin",
        "title": "Towards Practical Binary Code Similarity Detection: Vulnerability Verification via Patch Semantic Analysis",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3604608",
        "doi": "10.1145/3604608",
        "abstract": "Vulnerability is a major threat to software security. It has been proven that binary code similarity detection approaches are efficient to search for recurring vulnerabilities introduced by code sharing in binary software. However, these approaches suffer from high false-positive rates (FPRs) since they usually take the patched functions as vulnerable, and they usually do not work well when binaries are compiled with different compilation settings. To this end, we propose an approach, named Robin, to confirm recurring vulnerabilities by filtering out patched functions. Robin is powered by a lightweight symbolic execution to solve the set of function inputs that can lead to the vulnerability-related code. It then executes the target functions with the same inputs to capture the vulnerable or patched behaviors for patched function filtration. Experimental results show that Robin achieves high accuracy for patch detection across different compilers and compiler optimization levels respectively on 287 real-world vulnerabilities of 10 different software. Based on accurate patch detection, Robin significantly reduces the false-positive rate of state-of-the-art vulnerability detection tools (by 94.3\\% on average), making them more practical. Robin additionally detects 12 new potentially vulnerable functions.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "158",
        "numpages": "29",
        "keywords": "malicious function input, under constrained symbolic execution, vulnerability detection, Patch detection"
    },
    "A Systematic Review of Automated Query Reformulations in Source Code Search": {
        "type": "article",
        "key": "10.1145/3607179",
        "author": "Rahman, Mohammad Masudur and Roy, Chanchal K.",
        "title": "A Systematic Review of Automated Query Reformulations in Source Code Search",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3607179",
        "doi": "10.1145/3607179",
        "abstract": "Fixing software bugs and adding new features are two of the major maintenance tasks. Software bugs and features are reported as change requests. Developers consult these requests and often choose a few keywords from them as an ad hoc query. Then they execute the query with a search engine to find the exact locations within software code that need to be changed. Unfortunately, even experienced developers often fail to choose appropriate queries, which leads to costly trials and errors during a code search. Over the years, many studies have attempted to reformulate the ad hoc queries from developers to support them. In this systematic literature review, we carefully select 70 primary studies on query reformulations from 2,970 candidate studies, perform an in-depth qualitative analysis (e.g., Grounded Theory), and then answer seven research questions with major findings. First, to date, eight major methodologies (e.g., term weighting, term co-occurrence analysis, thesaurus lookup) have been adopted to reformulate queries. Second, the existing studies suffer from several major limitations (e.g., lack of generalizability, the vocabulary mismatch problem, subjective bias) that might prevent their wide adoption. Finally, we discuss the best practices and future opportunities to advance the state of research in search query reformulations.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "159",
        "numpages": "79",
        "keywords": "systematic literature review, machine learning, query quality analysis, term weighting, automated query reformulation, Internet-scale code search, bug localization, Concept location"
    },
    "NSFuzz: Towards Efficient and State-Aware Network Service Fuzzing": {
        "type": "article",
        "key": "10.1145/3580598",
        "author": "Qin, Shisong and Hu, Fan and Ma, Zheyu and Zhao, Bodong and Yin, Tingting and Zhang, Chao",
        "title": "NSFuzz: Towards Efficient and State-Aware Network Service Fuzzing",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3580598",
        "doi": "10.1145/3580598",
        "abstract": "As an essential component responsible for communication, network services are security critical, thus, it is vital to find their vulnerabilities. Fuzzing is currently one of the most popular software vulnerability discovery techniques, widely adopted due to its high efficiency and low false positives. However, existing coverage-guided fuzzers mainly aim at stateless local applications, leaving stateful network services underexplored. Recently, some fuzzers targeting network services have been proposed but have certain limitations, for example, insufficient or inaccurate state representation and low testing efficiency.In this article, we propose a new fuzzing solution NSFuzz for stateful network services. We studied typical implementations of network service programs to determine how they represent states and interact with clients. Accordingly, we propose (1) a program variable\u2013based state representation scheme and (2) an efficient interaction synchronization mechanism to improve fuzzing efficiency. We implemented a prototype of NSFuzz, which uses static analysis and annotation application programming interfaces (APIs) to identify synchronization points and state variables within the services. It then achieves fast I/O synchronization and accurate service state tracing to carry out efficient state-aware fuzzing via lightweight compile-time instrumentation. The evaluation results show that compared with other network service fuzzers, including AFLnet and StateAFL, our solution NSFuzz could infer a more accurate state model during fuzzing and improve fuzzing throughput by up to 200\\texttimes{}. In addition, NSFuzz could improve code coverage by up to 25\\% and trigger more crashes in less time. We also performed a fuzzing campaign to find new bugs in the latest version of the target services; 8 zero-day vulnerabilities have been found by NSFuzz.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "160",
        "numpages": "26",
        "keywords": "vulnerability discovery, fuzzing, Network service"
    },
    "NSFuzz: Towards Efficient and State-Aware Network Service Fuzzing - RCR Report": {
        "type": "article",
        "key": "10.1145/3580599",
        "author": "Hu, Fan and Qin, Shisong and Ma, Zheyu and Zhao, Bodong and Yin, Tingting and Zhang, Chao",
        "title": "NSFuzz: Towards Efficient and State-Aware Network Service Fuzzing - RCR Report",
        "year": "2023",
        "issue_date": "November 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "6",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3580599",
        "doi": "10.1145/3580599",
        "abstract": "We provide artifacts to reproduce the evaluation results of our article: \u201cNSFuzz: Towards Efficient and State-Aware Network Service Fuzzing\u201d. The provided artifacts can be downloaded from . It includes 14 docker containers, several scripts for execution and analysis, one additional proof for the crash results, and six related documents for the running of experiments. We claim for all three badges, i.e., Available, Functional, and Reusable. This report gives instructions on how to reproduce the answers which mainly involve basic operations on the Ubuntu operating system.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "sep",
        "articleno": "161",
        "numpages": "8",
        "keywords": "vulnerability discovery, fuzzing, Network service"
    },
    "Consent Verification Monitoring": {
        "type": "article",
        "key": "10.1145/3490754",
        "author": "Robol, Marco and Breaux, Travis D. and Paja, Elda and Giorgini, Paolo",
        "title": "Consent Verification Monitoring",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3490754",
        "doi": "10.1145/3490754",
        "abstract": "Advances in personalization of digital services are driven by low-cost data collection and processing, in addition to the wide variety of third-party frameworks for authentication, storage, and marketing. New privacy regulations, such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act, increasingly require organizations to explicitly state their data practices in privacy policies. When data practices change, a new version of the policy is released. This can occur a few times a year, when data collection or processing requirements are rapidly changing. Consent evolution raises specific challenges to ensuring GDPR compliance. We propose a formal consent framework to support organizations, data users, and data subjects in their understanding of policy evolution under a consent regime that supports both the retroactive and non-retroactive granting and withdrawal of consent. The contributions include (i) a formal framework to reason about data collection and access under multiple consent granting and revocation scenarios, (ii) a scripting language that implements the consent framework for encoding and executing different scenarios, (iii) five consent evolution use cases that illustrate how organizations would evolve their policies using this framework, and (iv) a scalability evaluation of the reasoning framework. The framework models are used to verify when user consent prevents or detects unauthorized data collection and access. The framework can be integrated into a runtime architecture to monitor policy violations as data practices evolve in real time. The framework was evaluated using the five use cases and a simulation to measure the framework scalability. The simulation results show that the approach is computationally scalable for use in runtime consent monitoring under a standard model of data collection and access and practice and policy evolution.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "2",
        "numpages": "33",
        "keywords": "analysis, logs, verification, evolution, description logic, formal framework, retroactivity, consent revocation, consent, GDPR, Privacy"
    },
    "Coverage-directed Differential Testing of X.509 Certificate Validation in SSL/TLS Implementations": {
        "type": "article",
        "key": "10.1145/3510416",
        "author": "Nie, Pengbo and Wan, Chengcheng and Zhu, Jiayu and Lin, Ziyi and Chen, Yuting and Su, Zhendong",
        "title": "Coverage-directed Differential Testing of X.509 Certificate Validation in SSL/TLS Implementations",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3510416",
        "doi": "10.1145/3510416",
        "abstract": "Secure Sockets Layer (SSL) and Transport Security (TLS) are two secure protocols for creating secure connections over the Internet. X.509 certificate validation is important for security and needs to be performed before an SSL/TLS connection is established. Some advanced testing techniques, such as frankencert, have revealed, through randomly mutating Internet accessible certificates, that there exist unexpected, sometimes critical, validation differences among different SSL/TLS implementations. Despite these efforts, X.509 certificate validation still needs to be thoroughly tested as this work shows. This article tackles this challenge by proposing transcert, a coverage-directed technique to much more effectively test real-world certificate validation code. Our core insight is to (1) leverage easily accessible Internet certificates as seed certificates and (2) use code coverage to direct certificate mutation toward generating a set of diverse certificates. The generated certificates are then used to reveal discrepancies, thus potential flaws, among different certificate validation implementations. We implement transcert and evaluate it against frankencert, NEZHA, and RFCcert (three advanced fuzzing techniques) on five widely used SSL/TLS implementations. The evaluation results clearly show the strengths of transcert: During 10,000 iterations, transcert reveals 71 unique validation differences, 12\\texttimes{}, 1.4\\texttimes{}, and 7\\texttimes{} as many as those revealed by frankencert, NEZHA, and RFCcert, respectively; it also supplements RFCcert in conformance testing of the SSL/TLS implementations against 120 validation rules, 85 of which are exclusively covered by transcert-generated certificates. We identify 17 root causes of validation differences, all of which have been confirmed and 11 have never been reported previously. The transcert-generated X.509 certificates also reveal that the primary goal of certificate chain validation is stated ambiguously in the widely adopted public key infrastructure standard RFC 5280.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "3",
        "numpages": "32",
        "keywords": "certificate validation, certification mutation, differential testing, Coverage transfer graph"
    },
    "Preference-wise Testing of Android Apps via Test Amplification": {
        "type": "article",
        "key": "10.1145/3511804",
        "author": "Pan, Minxue and Lu, Yifei and Pei, Yu and Zhang, Tian and Li, Xuandong",
        "title": "Preference-wise Testing of Android Apps via Test Amplification",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3511804",
        "doi": "10.1145/3511804",
        "abstract": "Preferences, the setting options provided by Android, are an essential part of Android apps. Preferences allow users to change app features and behaviors dynamically, and therefore their impacts need to be considered when testing the apps. Unfortunately, few test cases explicitly specify the assignments of valid values to the preferences, or configurations, under which they should be executed, and few existing mobile testing tools take the impact of preferences into account or provide help to testers in identifying and setting up the configurations for running the tests. This article presents the Prefest approach to effective testing of Android apps with preferences. Given an Android app and a set of test cases for the app, Prefest amplifies the test cases with a small number of configurations to exercise more behaviors and detect more bugs that are related to preferences. In an experimental evaluation conducted on real-world Android apps, amplified test cases produced by Prefest from automatically generated test cases covered significantly more code of the apps and detected seven real bugs, and the tool\u2019s test amplification time was at the same order of magnitude as the running time of the input test cases. Prefest\u2019s effectiveness and efficiency in amplifying programmer-written test cases was comparable with that in amplifying automatically generated test cases.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "4",
        "numpages": "37",
        "keywords": "preference-wise testing, Android testing, Android apps"
    },
    "The Weights Can Be Harmful: Pareto Search versus Weighted Search in Multi-objective Search-based Software Engineering": {
        "type": "article",
        "key": "10.1145/3514233",
        "author": "Chen, Tao and Li, Miqing",
        "title": "The Weights Can Be Harmful: Pareto Search versus Weighted Search in Multi-objective Search-based Software Engineering",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3514233",
        "doi": "10.1145/3514233",
        "abstract": "In presence of multiple objectives to be optimized in Search-Based Software Engineering (SBSE), Pareto search has been commonly adopted. It searches for a good approximation of the problem\u2019s Pareto-optimal solutions, from which the stakeholders choose the most preferred solution according to their preferences. However, when clear preferences of the stakeholders (e.g., a set of weights that reflect relative importance between objectives) are available prior to the search, weighted search is believed to be the first choice, since it simplifies the search via converting the original multi-objective problem into a single-objective one and enables the search to focus on what only the stakeholders are interested in.This article questions such a \u201cweighted search first\u201d belief. We show that the weights can, in fact, be harmful to the search process even in the presence of clear preferences. Specifically, we conduct a large-scale empirical study that consists of 38 systems/projects from three representative SBSE problems, together with two types of search budget and nine sets of weights, leading to 604 cases of comparisons. Our key finding is that weighted search reaches a certain level of solution quality by consuming relatively less resources at the early stage of the search; however, Pareto search is significantly better than its weighted counterpart the majority of the time (up to 77\\% of the cases), as long as we allow a sufficient, but not unrealistic search budget. This is a beneficial result, as it discovers a potentially new \u201crule-of-thumb\u201d for the SBSE community: Even when clear preferences are available, it is recommended to always consider Pareto search by default for multi-objective SBSE problems, provided that solution quality is more important. Weighted search, in contrast, should only be preferred when the resource/search budget is limited, especially for expensive SBSE problems. This, together with other findings and actionable suggestions in the article, allows us to codify pragmatic and comprehensive guidance on choosing weighted and Pareto search for SBSE under the circumstance that clear preferences are available. All code and data can be accessed at .",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "5",
        "numpages": "40",
        "keywords": "self-adaptive systems, adaptive systems, configurable systems, user preference, quality indicator, quality evaluation, pareto optimization, multi-objective optimization, Search-based software engineering"
    },
    "Fold2Vec: Towards a Statement-Based Representation of Code for Code Comprehension": {
        "type": "article",
        "key": "10.1145/3514232",
        "author": "Bertolotti, Francesco and Cazzola, Walter",
        "title": "Fold2Vec: Towards a Statement-Based Representation of Code for Code Comprehension",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3514232",
        "doi": "10.1145/3514232",
        "abstract": "We introduce a novel approach to source code representation to be used in combination with neural networks. Such a representation is designed to permit the production of a continuous vector for each code statement. In particular, we present how the representation is produced in the case of Java source code. We test our representation for three tasks: code summarization, statement separation, and code search. We compare with the state-of-the-art non-autoregressive and end-to-end models for these tasks. We conclude that all tasks benefit from the proposed representation to boost their performance in terms of F1-score, accuracy, and mean reciprocal rank, respectively. Moreover, we show how models trained on code summarization and models trained on statement separation can be combined to address methods with tangled responsibilities, meaning that these models can be used to detect code misconduct.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "6",
        "numpages": "31",
        "keywords": "intent identification, method name suggestion, learning representations, Big code"
    },
    "Scanner++: Enhanced Vulnerability Detection of Web Applications with Attack Intent Synchronization": {
        "type": "article",
        "key": "10.1145/3517036",
        "author": "Yin, Zijing and Xu, Yiwen and Ma, Fuchen and Gao, Haohao and Qiao, Lei and Jiang, Yu",
        "title": "Scanner++: Enhanced Vulnerability Detection of Web Applications with Attack Intent Synchronization",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3517036",
        "doi": "10.1145/3517036",
        "abstract": "Scanners are commonly applied for detecting vulnerabilities in web applications. Various scanners with different strategies are widely in use, but their performance is challenged by the increasing diversity of target applications that have more complex attack surfaces (i.e., website paths) and covert vulnerabilities that can only be exploited by more sophisticated attack vectors (i.e., payloads). In this paper, we propose Scanner++, a framework that improves web vulnerability detection of existing scanners through combining their capabilities with attack intent synchronization. We design Scanner++ as a proxy-based architecture while using a package-based intent synchronization approach. Scanner++ first uses a purification mechanism to aggregate and refine attack intents, consisting of attack surfaces and attack vectors extracted from the base scanners\u2019 request packets. Then, Scanner++ uses a runtime intent synchronization mechanism to select relevant attack intents according to the scanners\u2019 detection spots to guide their scanning process. Consequently, base scanners can expand their attack surfaces, generate more diverse attack vectors and achieve better vulnerability detection performance.For evaluation, we implemented and integrated Scanner++ together with four widely used scanners, BurpSuite, AWVS, Arachni, and ZAP, testing it on ten benchmark web applications and three well-tested real-world web applications of a critical financial platform from our industry partner. Working under the Scanner++ framework helps BurpSuite, AWVS, Arachni, and ZAP cover 15.26\\%, 37.14\\%, 59.21\\%, 68.54\\% more pages, construct 12.95\\texttimes{}, 1.13\\texttimes{}, 15.03\\texttimes{}, 52.66\\texttimes{} more attack packets, and discover 77, 55, 77, 176 more bugs, respectively. Furthermore, Scanner++ detected eight serious previously unknown vulnerabilities on real-world applications, while the base scanners only found three of them.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "7",
        "numpages": "30",
        "keywords": "synchronization, attack intent, scanner, Web security"
    },
    "Bash in the Wild: Language Usage, Code Smells, and Bugs": {
        "type": "article",
        "key": "10.1145/3517193",
        "author": "Dong, Yiwen and Li, Zheyang and Tian, Yongqiang and Sun, Chengnian and Godfrey, Michael W. and Nagappan, Meiyappan",
        "title": "Bash in the Wild: Language Usage, Code Smells, and Bugs",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3517193",
        "doi": "10.1145/3517193",
        "abstract": "The Bourne-again shell (Bash) is a prevalent scripting language for orchestrating shell commands and managing resources in Unix-like environments. It is one of the mainstream shell dialects that is available on most GNU Linux systems. However, the unique syntax and semantics of Bash could easily lead to unintended behaviors if carelessly used. Prior studies primarily focused on improving the reliability of Bash scripts or facilitating writing Bash scripts; there is yet no empirical study on the characteristics of Bash programs written in reality, e.g., frequently used language features, common code smells, and bugs. In this article, we perform a large-scale empirical study of Bash usage, based on analyses over one million open source Bash scripts found in Github repositories. We identify and discuss which features and utilities of Bash are most often used. Using static analysis, we find that Bash scripts are often error-prone, and the error-proneness has a moderately positive correlation with the size of the scripts. We also find that the most common problem areas concern quoting, resource management, command options, permissions, and error handling. We envision that these findings can be beneficial for learning Bash and future research that aims to improve shell and command-line productivity and reliability.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "8",
        "numpages": "22",
        "keywords": "bugs, code smells, language features, bash, shell scripts, Empirical studies"
    },
    "Semantics Foundation for Cyber-physical Systems Using Higher-order UTP": {
        "type": "article",
        "key": "10.1145/3517192",
        "author": "Xu, Xiong and Talpin, Jean-Pierre and Wang, Shuling and Zhan, Bohua and Zhan, Naijun",
        "title": "Semantics Foundation for Cyber-physical Systems Using Higher-order UTP",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3517192",
        "doi": "10.1145/3517192",
        "abstract": "Model-based design has become the predominant approach to the design of hybrid and cyber-physical systems (CPSs). It advocates the use of mathematically founded models to capture heterogeneous digital and analog behaviours from domain-specific formalisms, allowing all engineering tasks of verification, code synthesis, and validation to be performed within a single semantic body. Guaranteeing the consistency among the different views and heterogeneous models of a system at different levels of abstraction, however, poses significant challenges. To address these issues, Hoare and He\u2019s Unifying Theories of Programming (UTP) proposes a calculus to capture domain-specific programming and modelling paradigms into a unified semantic framework. Our goal is to extend UTP to form a semantic foundation for CPS design. Higher-order UTP (HUTP) is a conservative extension to Hoare and He\u2019s theory that supports the specification of discrete, real-time, and continuous dynamics, concurrency and communication, and higher-order quantification. Within HUTP, we define a calculus of normal hybrid designs to model, analyse, compose, refine, and verify heterogeneous hybrid system models. In addition, we define respective formal semantics for Hybrid Communicating Sequential Processes and Simulink using HUTP.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "9",
        "numpages": "48",
        "keywords": "semantic model, model-based design, CPS, UTP"
    },
    "Parametric Timed Pattern Matching": {
        "type": "article",
        "key": "10.1145/3517194",
        "author": "Waga, Masaki and Andr\\'{e}, \\'{E}tienne and Hasuo, Ichiro",
        "title": "Parametric Timed Pattern Matching",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3517194",
        "doi": "10.1145/3517194",
        "abstract": "Given a log and a specification, timed pattern matching aims at exhibiting for which start and end dates a specification holds on that log. For example, \u201ca given action is always followed by another action before a given deadline\u201d. This problem has strong connections with monitoring real-time systems. We address here timed pattern matching in the presence of an uncertain specification, i.e., that may contain timing parameters (e.g., the deadline can be uncertain or unknown). We want to know for which start and end dates, and for what values of the timing parameters, a property holds. For instance, we look for the minimum or maximum deadline (together with the corresponding start and end dates) for which the property holds. We propose two frameworks for parametric timed pattern matching. The first one is based on parametric timed model checking. In contrast to most parametric timed problems, the solution is effectively computable. The second one is a dedicated method; not only we largely improve the efficiency compared to the first method, but we further propose optimizations with skipping. Our experiment results suggest that our algorithms, especially the second one, are efficient and practically relevant.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "10",
        "numpages": "35",
        "keywords": "parametric timed automata, real-time systems, Monitoring"
    },
    "There\u2019s no Such Thing as a Free Lunch: Lessons Learned from Exploring the Overhead Introduced by the Greenkeeper Dependency Bot in Npm": {
        "type": "article",
        "key": "10.1145/3522587",
        "author": "Rombaut, Benjamin and Cogo, Filipe R. and Adams, Bram and Hassan, Ahmed E.",
        "title": "There\u2019s no Such Thing as a Free Lunch: Lessons Learned from Exploring the Overhead Introduced by the Greenkeeper Dependency Bot in Npm",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3522587",
        "doi": "10.1145/3522587",
        "abstract": "Dependency management bots are increasingly being used to support the software development process, for example, to automatically update a dependency when a new version is available. Yet, human intervention is often required to either accept or reject any action or recommendation the bot creates. In this article, our objective is to study the extent to which dependency management bots create additional, and sometimes unnecessary, work for their users. To accomplish this, we analyze 93,196 issue reports opened by Greenkeeper, a popular dependency management bot used in open source software projects in the npm ecosystem. We find that Greenkeeper is responsible for half of all issues reported in client projects, inducing a significant amount of overhead that must be addressed by clients, since many of these issues were created as a result of Greenkeeper taking incorrect action on a dependency update (i.e., false alarms). Reverting a broken dependency update to an older version, which is a potential solution that requires the least overhead and is automatically attempted by Greenkeeper, turns out to not be an effective mechanism. Finally, we observe that 56\\% of the commits referenced by Greenkeeper issue reports only change the client\u2019s dependency specification file to resolve the issue. Based on our findings, we argue that dependency management bots should (i) be configurable to allow clients to reduce the amount of generated activity by the bots, (ii) take into consideration more sources of information than only the pass/fail status of the client\u2019s build pipeline to help eliminate false alarms, and (iii) provide more effective incentives to encourage clients to resolve dependency issues.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "11",
        "numpages": "40",
        "keywords": "overhead, greenkeeper, mining software repositories, software bots, Dependency management"
    },
    "ActivFORMS: A Formally Founded Model-based Approach to Engineer Self-adaptive Systems": {
        "type": "article",
        "key": "10.1145/3522585",
        "author": "Weyns, Danny and Iftikhar, Usman M.",
        "title": "ActivFORMS: A Formally Founded Model-based Approach to Engineer Self-adaptive Systems",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3522585",
        "doi": "10.1145/3522585",
        "abstract": "Self-adaptation equips a computing system with a feedback loop that enables it to deal with change caused by uncertainties during operation, such as changing availability of resources and fluctuating workloads. To ensure that the system complies with the adaptation goals, recent research suggests the use of formal techniques at runtime. Yet, existing approaches have three limitations that affect their practical applicability: (i) they ignore correctness of the behavior of the feedback loop, (ii) they rely on exhaustive verification at runtime to select adaptation options to realize the adaptation goals, which is time- and resource-demanding, and (iii) they provide limited or no support for changing adaptation goals at runtime. To tackle these shortcomings, we present ActivFORMS (Active FORmal Models for Self-adaptation). ActivFORMS contributes an end-to-end approach for engineering self-adaptive systems, spanning four main stages of the life cycle of a feedback loop: design, deployment, runtime adaptation, and evolution. We also present ActivFORMS-ta, a tool-supported instance of ActivFORMS that leverages timed automata models and statistical model checking at runtime. We validate the research results using an IoT application for building security monitoring that is deployed in Leuven. The experimental results demonstrate that ActivFORMS supports correctness of the behavior of the feedback loop, achieves the adaptation goals in an efficient way, and supports changing adaptation goals at runtime.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "12",
        "numpages": "48",
        "keywords": "Internet of Things, statistical model checking, executable models, formal techniques, MAPE-K, Self-adaptation"
    },
    "Combatting Energy Issues for Mobile Applications": {
        "type": "article",
        "key": "10.1145/3527851",
        "author": "Li, Xueliang and Chen, Junyang and Liu, Yepang and Wu, Kaishun and Gallagher, John P.",
        "title": "Combatting Energy Issues for Mobile Applications",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3527851",
        "doi": "10.1145/3527851",
        "abstract": "Energy efficiency is an important criterion to judge the quality of mobile apps, but one third of our arbitrarily sampled apps suffer from energy issues that can quickly drain battery power. To understand these issues, we conduct an empirical study on 36 well-maintained apps such as Chrome and Firefox, whose issue tracking systems are publicly accessible. Our study involves issue causes, manifestation, fixing efforts, detection techniques, reasons of no-fixes, and debugging techniques. Inspired by the empirical study, we propose a novel testing framework for detecting energy issues in real-world mobile apps. Our framework examines apps with well-designed input sequences and runtime context. We develop leading edge technologies, e.g., pre-designing input sequences with potential energy overuse and tuning tests on-the-fly, to achieve high efficacy in detecting energy issues. A large-scale evaluation shows that 90.4\\% of the detected issues in our experiments were previously unknown to developers. On average, these issues can double the energy consumption of the test cases where the issues were detected. And our test achieves a low number of false positives. Finally, we show how our test reports can help developers fix the issues.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "13",
        "numpages": "44",
        "keywords": "android, energy bugs, energy issues, Mobile applications"
    },
    "Mutation Testing in Evolving Systems: Studying the Relevance of Mutants to Code Evolution": {
        "type": "article",
        "key": "10.1145/3530786",
        "author": "Ojdanic, Milos and Soremekun, Ezekiel and Degiovanni, Renzo and Papadakis, Mike and Le Traon, Yves",
        "title": "Mutation Testing in Evolving Systems: Studying the Relevance of Mutants to Code Evolution",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3530786",
        "doi": "10.1145/3530786",
        "abstract": "Context:When software evolves, opportunities for introducing faults appear. Therefore, it is important to test the evolved program behaviors during each evolution cycle. However, while software evolves, its complexity is also evolving, introducing challenges to the testing process. To deal with this issue, testing techniques should be adapted to target the effect of the program changes instead of the entire program functionality. To this end, commit-aware mutation testing, a powerful testing technique, has been proposed. Unfortunately, commit-aware mutation testing is challenging due to the complex program semantics involved. Hence, it is pertinent to understand the characteristics, predictability, and potential of the technique.Objective: We conduct an exploratory study to investigate the properties of commit-relevant mutants, i.e., the test elements of commit-aware mutation testing, by proposing a general definition and an experimental approach to identify them. We thus aim at investigating the prevalence, location, and comparative advantages of commit-aware mutation testing over time (i.e., the program evolution). We also investigate the predictive power of several commit-related features in identifying and selecting commit-relevant mutants to understand the essential properties for its best-effort application case.Method: Our commit-relevant definition relies on the notion of observational slicing, approximated by higher-order mutation. Specifically, our approach utilizes the impact of mutants, effects of one mutant on another in capturing and analyzing the implicit interactions between the changed and unchanged code parts. The study analyses millions of mutants (over 10 million), 288 commits, five (5) different open-source software projects involving over 68,213 CPU days of computation and sets a ground truth where we perform our analysis.Results: Our analysis shows that commit-relevant mutants are located mainly outside of program commit change (81\\%), suggesting a limitation in previous work. We also note that effective selection of commit-relevant mutants has the potential of reducing the number of mutants by up to 93\\%. In addition, we demonstrate that commit relevant mutation testing is significantly more effective and efficient than state-of-the-art baselines, i.e., random mutant selection and analysis of only mutants within the program change. In our analysis of the predictive power of mutants and commit-related features (e.g., number of mutants within a change, mutant type, and commit size) in predicting commit-relevant mutants, we found that most proxy features do not reliably predict commit-relevant mutants.Conclusion: This empirical study highlights the properties of commit-relevant mutants and demonstrates the importance of identifying and selecting commit-relevant mutants when testing evolving software systems.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "14",
        "numpages": "39",
        "keywords": "evolving-systems, continuous integration, mutation testing, Software testing"
    },
    "On Wasted Contributions: Understanding the Dynamics of Contributor-Abandoned Pull Requests\u2013A Mixed-Methods Study of 10 Large Open-Source Projects": {
        "type": "article",
        "key": "10.1145/3530785",
        "author": "Khatoonabadi, Sayedhassan and Costa, Diego Elias and Abdalkareem, Rabe and Shihab, Emad",
        "title": "On Wasted Contributions: Understanding the Dynamics of Contributor-Abandoned Pull Requests\u2013A Mixed-Methods Study of 10 Large Open-Source Projects",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3530785",
        "doi": "10.1145/3530785",
        "abstract": "Pull-based development has enabled numerous volunteers to contribute to open-source projects with fewer barriers. Nevertheless, a considerable amount of pull requests (PRs) with valid contributions are abandoned by their contributors, wasting the effort and time put in by both the contributors and maintainers. To better understand the underlying dynamics of contributor-abandoned PRs, we conduct a mixed-methods study using both quantitative and qualitative methods. We curate a dataset consisting of 265,325 PRs including 4,450 abandoned ones from ten popular and mature GitHub projects and measure 16 features characterizing PRs, contributors, review processes, and projects. Using statistical and machine learning techniques, we find that complex PRs, novice contributors, and lengthy reviews have a higher probability of abandonment and the rate of PR abandonment fluctuates alongside the projects\u2019 maturity or workload. To identify why contributors abandon their PRs, we also manually examine a random sample of 354 abandoned PRs. We observe that the most frequent abandonment reasons are related to the obstacles faced by contributors, followed by the hurdles imposed by maintainers during the review process. Finally, we survey the top core maintainers of the studied projects to understand their perspectives on dealing with PR abandonment and on our findings.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "15",
        "numpages": "39",
        "keywords": "mixed-methods research, open-source software, social coding platforms, modern code review, pull-based development, Socio-technical factors"
    },
    "Microservice Security Metrics for Secure Communication, Identity Management, and Observability": {
        "type": "article",
        "key": "10.1145/3532183",
        "author": "Zdun, Uwe and Queval, Pierre-Jean and Simhandl, Georg and Scandariato, Riccardo and Chakravarty, Somik and Jelic, Marjan and Jovanovic, Aleksandar",
        "title": "Microservice Security Metrics for Secure Communication, Identity Management, and Observability",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3532183",
        "doi": "10.1145/3532183",
        "abstract": "Microservice architectures are increasingly being used to develop application systems. Despite many guidelines and best practices being published, architecting microservice systems for security is challenging. Reasons are the size and complexity of microservice systems, their polyglot nature, and the demand for the continuous evolution of these systems. In this context, to manually validate that security architecture tactics are employed as intended throughout the system is a time-consuming and error-prone task. In this article, we present an approach to avoid such manual validation before each continuous evolution step in a microservice system, which we demonstrate using three widely used categories of security tactics: secure communication, identity management, and observability. Our approach is based on a review of existing security guidelines, the gray literature, and the scientific literature, from which we derived Architectural Design Decisions (ADDs) with the found security tactics as decision options. In our approach, we propose novel detectors to detect these decision options automatically and formally defined metrics to measure the conformance of a system to the different options of the ADDs. We apply the approach to a case study data set of 10 open source microservice systems, plus another 20 variants of these systems, for which we manually inspected the source code for security tactics. We demonstrate and assess the validity and appropriateness of our metrics by performing an assessment of their conformance to the ADDs in our systems\u2019 dataset through statistical methods.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "16",
        "numpages": "34",
        "keywords": "software architecture detectors, software architecture metrics, microservice security, Microservice architecture"
    },
    "Some Seeds Are Strong: Seeding Strategies for Search-based Test Case Selection": {
        "type": "article",
        "key": "10.1145/3532182",
        "author": "Arrieta, Aitor and Valle, Pablo and Agirre, Joseba A. and Sagardui, Goiuria",
        "title": "Some Seeds Are Strong: Seeding Strategies for Search-based Test Case Selection",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3532182",
        "doi": "10.1145/3532182",
        "abstract": "The time it takes software systems to be tested is usually long. Search-based test selection has been a widely investigated technique to optimize the testing process. In this article, we propose a set of seeding strategies for the test case selection problem that generates the initial population of Pareto-based multi-objective algorithms, with the goals of (1) helping to find an overall better set of solutions and (2) enhancing the convergence of the algorithms. The seeding strategies were integrated with four state-of-the-art multi-objective search algorithms and applied into two contexts where regression-testing is paramount: (1) Simulation-based testing of Cyber-physical Systems and (2) Continuous Integration. For the first context, we evaluated our approach by using six fitness function combinations and six independent case studies, whereas in the second context, we derived a total of six fitness function combinations and employed four case studies. Our evaluation suggests that some of the proposed seeding strategies are indeed helpful for solving the multi-objective test case selection problem. Specifically, the proposed seeding strategies provided a higher convergence of the algorithms towards optimal solutions in 96\\% of the studied scenarios and an overall cost-effectiveness with a standard search budget in 85\\% of the studied scenarios.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "17",
        "numpages": "47",
        "keywords": "regression testing, search-based software testing, Test case selection"
    },
    "Automated Identification of Uniqueness in JUnit Tests": {
        "type": "article",
        "key": "10.1145/3533313",
        "author": "Wu, Jianwei and Clause, James",
        "title": "Automated Identification of Uniqueness in JUnit Tests",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3533313",
        "doi": "10.1145/3533313",
        "abstract": "In the context of testing, descriptive test names are desirable because they document the purpose of tests and facilitate comprehension tasks during maintenance. Unfortunately, prior work has shown that tests often do not have descriptive names. To address this limitation, techniques have been developed to automatically generate descriptive names. However, they often generated names that are invalid or do not meet developer approval. To help address these limitations, we present a novel approach to extract the attributes of a given test that make it unique among its siblings. Because such attributes often serve as the basis for descriptive names, identifying them is an important first step towards improving test name generation approaches. To evaluate the approach, we created a prototype implementation for JUnit tests and compared its output with human judgment. The results of the evaluation demonstrate that the attributes identified by the approach are consistent with human judgment and are likely to be useful for future name generation techniques.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "18",
        "numpages": "32",
        "keywords": "formal concept analysis, Unit testing"
    },
    "The Co-evolution of the WordPress Platform and Its Plugins": {
        "type": "article",
        "key": "10.1145/3533700",
        "author": "Lin, Jiahuei and Sayagh, Mohammed and Hassan, Ahmed E.",
        "title": "The Co-evolution of the WordPress Platform and Its Plugins",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3533700",
        "doi": "10.1145/3533700",
        "abstract": "One can extend the features of a software system by installing a set of additional components called plugins. WordPress, as a typical example of such plugin-based software ecosystems, is used by millions of websites and has a large number (i.e., 54,777) of available plugins. These plugin-based software ecosystems are different from traditional ecosystems (e.g., NPM dependencies) in the sense that there is high coupling between a platform and its plugins compared to traditional ecosystems for which components might not necessarily depend on each other (e.g., NPM libraries do not depend on a specific version of NPM or a specific version of a client software system). The high coupling between a plugin and its platform and other plugins causes incompatibility issues that occur during the co-evolution of a plugin and its platform as well as other plugins. In fact, incompatibility issues represent a major challenge when upgrading WordPress or its plugins. According to our study of the top 500 most-released WordPress plugins, we observe that incompatibility issues represent the third major cause for bad releases, which are rapidly (within the next 24 hours) fixed via urgent releases. Thirty-two percent of these incompatibilities are between a plugin and WordPress while 19\\% are between peer plugins. In this article, we study how plugins co-evolve with the underlying platform as well as other plugins, in an effort to understand the practices that are related support such co-evolution and reduce incompatibility issues. In particular, we investigate how plugins support the latest available versions of WordPress, as well as how plugins are related to each other, and how they co-evolve. We observe that a plugin\u2019s support of new versions of WordPress with a large amount of code change is risky, as the releases that declare such support have a higher chance to be followed by an urgent release compared to ordinary releases. Although plugins support the latest WordPress version, plugin developers omit important changes such as deleting the use of removed WordPress APIs, which are removed a median of 873 days after the APIs have been removed from the source code of WordPress. Plugins introduce new releases that are made according to a median of five other plugins, which we refer to as peer-triggered releases. A median of 20\\% of the peer-triggered releases are urgent releases that fix problems in their previous releases. The most common goal of peer-triggered releases is the fixing of incompatibility issues that a plugin detects as late as after a median of 36 days since the last release of another plugin. Our work sheds light on the co-evolution of WordPress plugins with their platform as well as peer plugins in an effort to uncover the practices of plugin evolution, so WordPress can accordingly design approaches to avoid incompatibility issues.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "19",
        "numpages": "24",
        "keywords": "plugins co-evolution, incompatibility issues, Plugin-based ecosystems"
    },
    "Feedback-Directed Metamorphic Testing": {
        "type": "article",
        "key": "10.1145/3533314",
        "author": "Sun, Chang-Ai and Dai, Hepeng and Liu, Huai and Chen, Tsong Yueh",
        "title": "Feedback-Directed Metamorphic Testing",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3533314",
        "doi": "10.1145/3533314",
        "abstract": "Over the past decade, metamorphic testing has gained rapidly increasing attention from both academia and industry, particularly thanks to its high efficacy on revealing real-life software faults in a wide variety of application domains. On the basis of a set of metamorphic relations among multiple software inputs and their expected outputs, metamorphic testing not only provides a test case generation strategy by constructing new (or follow-up) test cases from some original (or source) test cases, but also a test result verification mechanism through checking the relationship between the outputs of source and follow-up test cases. Many efforts have been made to further improve the cost-effectiveness of metamorphic testing from different perspectives. Some studies attempted to identify \u201cgood\u201d metamorphic relations, while other studies were focused on applying effective test case generation strategies especially for source test cases. In this article, we propose improving the cost-effectiveness of metamorphic testing by leveraging the feedback information obtained in the test execution process. Consequently, we develop a new approach, namely feedback-directed metamorphic testing, which makes use of test execution information to dynamically adjust the selection of metamorphic relations and selection of source test cases. We conduct an empirical study to evaluate the proposed approach based on four laboratory programs, one GNU program, and one industry program. The empirical results show that feedback-directed metamorphic testing can use fewer test cases and take less time than the traditional metamorphic testing for detecting the same number of faults. It is clearly demonstrated that the use of feedback information about test execution does help enhance the cost-effectiveness of metamorphic testing. Our work provides a new perspective to improve the efficacy and applicability of metamorphic testing as well as many other software testing techniques.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "20",
        "numpages": "34",
        "keywords": "adaptive partition testing, random testing, feedback control, test execution, metamorphic relation, Metamorphic testing"
    },
    "A Taxonomy of Information Attributes for Test Case Prioritisation: Applicability, Machine Learning": {
        "type": "article",
        "key": "10.1145/3511805",
        "author": "Ram\\'{\\i}rez, Aurora and Feldt, Robert and Romero, Jos\\'{e} Ra\\'{u}l",
        "title": "A Taxonomy of Information Attributes for Test Case Prioritisation: Applicability, Machine Learning",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3511805",
        "doi": "10.1145/3511805",
        "abstract": "Most software companies have extensive test suites and re-run parts of them continuously to ensure that recent changes have no adverse effects. Since test suites are costly to execute, industry needs methods for test case prioritisation (TCP). Recently, TCP methods use machine learning (ML) to exploit the information known about the system under test and its test cases. However, the value added by ML-based TCP methods should be critically assessed with respect to the cost of collecting the information. This article analyses two decades of TCP research and presents a taxonomy of 91 information attributes that have been used. The attributes are classified with respect to their information sources and the characteristics of their extraction process. Based on this taxonomy, TCP methods validated with industrial data and those applying ML are analysed in terms of information availability, attribute combination and definition of data features suitable for ML. Relying on a high number of information attributes, assuming easy access to system under test code and simplified testing environments are identified as factors that might hamper industrial applicability of ML-based TCP. The TePIA taxonomy provides a reference framework to unify terminology and evaluate alternatives considering the cost-benefit of the information attributes.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "21",
        "numpages": "42",
        "keywords": "industry, test case prioritisation, machine learning, taxonomy, Regression testing"
    },
    "LiDetector: License Incompatibility Detection for Open Source Software": {
        "type": "article",
        "key": "10.1145/3518994",
        "author": "Xu, Sihan and Gao, Ya and Fan, Lingling and Liu, Zheli and Liu, Yang and Ji, Hua",
        "title": "LiDetector: License Incompatibility Detection for Open Source Software",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3518994",
        "doi": "10.1145/3518994",
        "abstract": "Open-source software (OSS) licenses dictate the conditions, which should be followed to reuse, distribute, and modify software. Apart from widely-used licenses such as the MIT License, developers are also allowed to customize their own licenses (called custom license), whose descriptions are more flexible. The presence of such various licenses imposes challenges to understand licenses and their compatibility. To avoid financial and legal risks, it is essential to ensure license compatibility when integrating third-party packages or reusing code accompanied with licenses. In this work, we propose LiDetector, an effective tool that extracts and interprets OSS licenses (including both official licenses and custom licenses), and detects license incompatibility among these licenses. Specifically, LiDetector introduces a learning-based method to automatically identify meaningful license terms from an arbitrary license, and employs Probabilistic Context-Free Grammar (PCFG) to infer rights and obligations for incompatibility detection. Experiments demonstrate that LiDetector outperforms existing methods with 93.28\\% precision for term identification, and 91.09\\% accuracy for right and obligation inference, and can effectively detect incompatibility with 10.06\\% FP rate and 2.56\\% FN rate. Furthermore, with LiDetector, our large-scale empirical study on 1,846 projects reveals that 72.91\\% of the projects are suffering from license incompatibility, including popular ones such as the MIT License and the Apache License. We highlighted lessons learned from perspectives of different stakeholders and made all related data and the replication package publicly available to facilitate follow-up research.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "22",
        "numpages": "28",
        "keywords": "incompatibility detection, license, Open source software"
    },
    "Code Structure\u2013Guided Transformer for Source Code Summarization": {
        "type": "article",
        "key": "10.1145/3522674",
        "author": "Gao, Shuzheng and Gao, Cuiyun and He, Yulan and Zeng, Jichuan and Nie, Lunyiu and Xia, Xin and Lyu, Michael",
        "title": "Code Structure\u2013Guided Transformer for Source Code Summarization",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3522674",
        "doi": "10.1145/3522674",
        "abstract": "Code summaries help developers comprehend programs and reduce their time to infer the program functionalities during software maintenance. Recent efforts resort to deep learning techniques such as sequence-to-sequence models for generating accurate code summaries, among which Transformer-based approaches have achieved promising performance. However, effectively integrating the code structure information into the Transformer is under-explored in this task domain. In this article, we propose a novel approach named SG-Trans to incorporate code structural properties into Transformer. Specifically, we inject the local symbolic information (e.g., code tokens and statements) and global syntactic structure (e.g., dataflow graph) into the self-attention module of Transformer as inductive bias. To further capture the hierarchical characteristics of code, the local information and global structure are designed to distribute in the attention heads of lower layers and high layers of Transformer. Extensive evaluation shows the superior performance of SG-Trans over the state-of-the-art approaches. Compared with the best-performing baseline, SG-Trans still improves 1.4\\% and 2.0\\% on two benchmark datasets, respectively, in terms of METEOR score, a metric widely used for measuring generation quality.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "23",
        "numpages": "32",
        "keywords": "code structure, multi-head attention, Transformer, Code summary"
    },
    "APIRO: A Framework for Automated Security Tools API Recommendation": {
        "type": "article",
        "key": "10.1145/3512768",
        "author": "Sworna, Zarrin Tasnim and Islam, Chadni and Babar, Muhammad Ali",
        "title": "APIRO: A Framework for Automated Security Tools API Recommendation",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3512768",
        "doi": "10.1145/3512768",
        "abstract": "Security Orchestration, Automation, and Response (SOAR) platforms integrate and orchestrate a wide variety of security tools to accelerate the operational activities of Security Operation Center (SOC). Integration of security tools in a SOAR platform is mostly done manually using APIs, plugins, and scripts. SOC teams need to navigate through API calls of different security tools to find a suitable API to define or update an incident response action. Analyzing various types of API documentation with diverse API format and presentation structure involves significant challenges such as data availability, data heterogeneity, and semantic variation for automatic identification of security tool APIs specific to a particular task. Given these challenges can have negative impact on SOC team\u2019s ability to handle security incident effectively and efficiently, we consider it important to devise suitable automated support solutions to address these challenges. We propose a novel learning-based framework for automated security tool API Recommendation for security Orchestration, automation, and response, APIRO. To mitigate data availability constraint, APIRO enriches security tool API description by applying a wide variety of data augmentation techniques. To learn data heterogeneity of the security tools and semantic variation in API descriptions, APIRO consists of an API-specific word embedding model and a Convolutional Neural Network (CNN) model that are used for prediction of top three relevant APIs for a task. We experimentally demonstrate the effectiveness of APIRO in recommending APIs for different tasks using three security tools and 36 augmentation techniques. Our experimental results demonstrate the feasibility of APIRO for achieving 91.9\\% Top-1 Accuracy. Compared to the state-of-the-art baseline, APIRO is 26.93\\%, 23.03\\%, and 20.87\\% improved in terms of Top-1, Top-2, and Top-3 Accuracy and outperforms the baseline by 23.7\\% in terms of Mean Reciprocal Rank (MRR).",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "24",
        "numpages": "42",
        "keywords": "SOAR, API Recommendation, Security Operation Center, security tool API, Incident Response Plan, Security Orchestration"
    },
    "An In-depth Study of Java Deserialization Remote-Code Execution Exploits and Vulnerabilities": {
        "type": "article",
        "key": "10.1145/3554732",
        "author": "Sayar, Imen and Bartel, Alexandre and Bodden, Eric and Le Traon, Yves",
        "title": "An In-depth Study of Java Deserialization Remote-Code Execution Exploits and Vulnerabilities",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3554732",
        "doi": "10.1145/3554732",
        "abstract": "Nowadays, an increasing number of applications use deserialization. This technique, based on rebuilding the instance of objects from serialized byte streams, can be dangerous since it can open the application to attacks such as remote code execution (RCE) if the data to deserialize is originating from an untrusted source. Deserialization vulnerabilities are so critical that they are in OWASP\u2019s list of top 10 security risks for web applications. This is mainly caused by faults in the development process of applications and by flaws in their dependencies, i.e., flaws in the libraries used by these applications. No previous work has studied deserialization attacks in-depth: How are they performed? How are weaknesses introduced and patched? And for how long are vulnerabilities present in the codebase? To yield a deeper understanding of this important kind of vulnerability, we perform two main analyses: one on attack gadgets, i.e., exploitable pieces of code, present in Java libraries, and one on vulnerabilities present in Java applications. For the first analysis, we conduct an exploratory large-scale study by running 256515 &nbsp;experiments in which we vary the versions of libraries for each of the 19 publicly available exploits. Such attacks rely on a combination of gadgets present in one or multiple Java libraries. A gadget is a method which is using objects or fields that can be attacker-controlled. Our goal is to precisely identify library versions containing gadgets and to understand how gadgets have been introduced and how they have been patched. We observe that the modification of one innocent-looking detail in a class \u2013 such as making it public \u2013 can already introduce a gadget. Furthermore, we noticed that among the studied libraries, 37.5\\% are not patched, leaving gadgets available for future attacks.For the second analysis, we manually analyze 104 deserialization vulnerabilities CVEs to understand how vulnerabilities are introduced and patched in real-life Java applications. Results indicate that the vulnerabilities are not always completely patched or that a workaround solution is proposed. With a workaround solution, applications are still vulnerable since the code itself is unchanged.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "25",
        "numpages": "45",
        "keywords": "remote code execution RCE, gadget, vulnerabilities, deserialization, Serialization"
    },
    "TokenAware: Accurate and Efficient Bookkeeping Recognition for Token Smart Contracts": {
        "type": "article",
        "key": "10.1145/3560263",
        "author": "He, Zheyuan and Song, Shuwei and Bai, Yang and Luo, Xiapu and Chen, Ting and Zhang, Wensheng and He, Peng and Li, Hongwei and Lin, Xiaodong and Zhang, Xiaosong",
        "title": "TokenAware: Accurate and Efficient Bookkeeping Recognition for Token Smart Contracts",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3560263",
        "doi": "10.1145/3560263",
        "abstract": "Tokens have become an essential part of blockchain ecosystem, so recognizing token transfer behaviors is crucial for applications depending on blockchain. Unfortunately, existing solutions cannot recognize token transfer behaviors accurately and efficiently because of their incomplete patterns and inefficient designs. This work proposes TokenAware, a novel online system for recognizing token transfer behaviors. To improve accuracy, TokenAware infers token transfer behaviors from modifications of internal bookkeeping of a token smart contract for recording the information of token holders (e.g., their addresses and shares). However, recognizing bookkeeping is challenging, because smart contract bytecode does not contain type information. TokenAware overcomes the challenge by first learning the instruction sequences for locating basic types and then deriving the instruction sequences for locating sophisticated types that are composed of basic types. To improve efficiency, TokenAware introduces four optimizations. We conduct extensive experiments to evaluate TokenAware with real blockchain data. Results show that TokenAware can automatically identify new types of bookkeeping and recognize 107,202 tokens with 98.7\\% precision. TokenAware with optimizations merely incurs 4\\% overhead, which is 1/345 of the overhead led by the counterpart with no optimization. Moreover, we develop an application based on TokenAware to demonstrate how it facilitates malicious behavior detection.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "26",
        "numpages": "35",
        "keywords": "bookkeeping recognition, token, smart contract, Ethereum"
    },
    "Defining a Knowledge Graph Development Process Through a Systematic Review": {
        "type": "article",
        "key": "10.1145/3522586",
        "author": "Tama\\v{s}auskaitundefined, Gytundefined and Groth, Paul",
        "title": "Defining a Knowledge Graph Development Process Through a Systematic Review",
        "year": "2023",
        "issue_date": "January 2023",
        "publisher": "Association for Computing Machinery",
        "address": "New York, NY, USA",
        "volume": "32",
        "number": "1",
        "issn": "1049-331X",
        "url": "https://doi.org/10.1145/3522586",
        "doi": "10.1145/3522586",
        "abstract": "Knowledge graphs are widely used in industry and studied within the academic community. However, the models applied in the development of knowledge graphs vary. Analysing and providing a synthesis of the commonly used approaches to knowledge graph development would provide researchers and practitioners a better understanding of the overall process and methods involved. Hence, this article aims at defining the overall process of knowledge graph development and its key constituent steps. For this purpose, a systematic review and a conceptual analysis of the literature was conducted. The resulting process was compared to case studies to evaluate its applicability. The proposed process suggests a unified approach and provides guidance for both researchers and practitioners when constructing and managing knowledge graphs.",
        "journal": "ACM Trans. Softw. Eng. Methodol.",
        "month": "feb",
        "articleno": "27",
        "numpages": "40",
        "keywords": "information integration, development process semantic network, knowledge graph construction, Knowledge graphs"
    }
}