# arXiv2023

Number of papers: 15

## [LLMs: Understanding Code Syntax and Semantics for Code Analysis](paper_1.md)
- **Authors**: Ma, Wei and Liu, Shangqing and Lin, Zhihao and Wang, Wenhan and Hu, Qiang and Liu, Ye and Zhang, Cen and Nie, Liming and Li, Li and Liu, Yang
- **Abstract**: Large language models~(LLMs) demonstrate significant potential to revolutionize software engineering (SE) by exhibiting outstanding performance in SE tasks such as code and document generation. However, the high reliability and risk control requirements in software engineering raise concerns about t...
- **Link**: [Read Paper](No Link Available)
- **Labels**: static analysis, fundamental analysis, code model, training, source code model, empirical study

## [Lmpa: Improving decompilation by synergy of large language model and program analysis](paper_2.md)
- **Authors**: Xu, Xiangzhe and Zhang, Zhuo and Feng, Shiwei and Ye, Yapeng and Su, Zian and Jiang, Nan and Cheng, Siyuan and Tan, Lin and Zhang, Xiangyu
- **Abstract**: Decompilation aims to recover the source code form of a binary executable. It has many applications in security and software engineering such as malware analysis, vulnerability detection and code reuse. A prominent challenge in decompilation is to recover variable names. We propose a novel method th...
- **Link**: [Read Paper](No Link Available)
- **Labels**: code model, training, binary code model

## [How Far Have We Gone in Vulnerability Detection Using Large Language Models](paper_3.md)
- **Authors**: Zeyu Gao and Hao Wang and Yuchen Zhou and Wenyu Zhu and Chao Zhang
- **Abstract**: As software becomes increasingly complex and prone to vulnerabilities, automated vulnerability detection is critically important, yet challenging. Given the significant successes of large language models (LLMs) in various tasks, there is growing anticipation of their efficacy in vulnerability detect...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2311.12420)
- **Labels**: static analysis, bug detection, benchmark

## [Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities](paper_4.md)
- **Authors**: Avishree Khare and Saikat Dutta and Ziyang Li and Alaia Solko{-}Breslin and Rajeev Alur and Mayur Naik
- **Abstract**: While automated vulnerability detection techniques have made promising progress in detecting security vulnerabilities, their scalability and applicability remain challenging. The remarkable performance of Large Language Models (LLMs), such as GPT-4 and CodeLlama, on code-related tasks has prompted r...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2311.16169)
- **Labels**: static analysis, bug detection, empirical study

## [Do Language Models Learn Semantics of Code? {A} Case Study in Vulnerability Detection](paper_5.md)
- **Authors**: Benjamin Steenhoek and Md Mahbubur Rahman and Shaila Sharmin and Wei Le
- **Abstract**: Recently, pretrained language models have shown state-of-the-art performance on the vulnerability detection task. These models are pretrained on a large corpus of source code, then fine-tuned on a smaller supervised vulnerability dataset. Due to the different training objectives and the performance ...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2311.04109)
- **Labels**: static analysis, bug detection, empirical study

## [SkipAnalyzer: An Embodied Agent for Code Analysis with Large Language Models](paper_6.md)
- **Authors**: Mohammad Mahdi Mohajer and Reem Aleithan and Nima Shiri Harzevili and Moshi Wei and Alvine Boaye Belle and Hung Viet Pham and Song Wang
- **Abstract**: We introduce SkipAnalyzer, a large language model (LLM)-powered tool for static code analysis. SkipAnalyzer has three components: 1) an LLM-based static bug detector that scans source code and reports specific types of bugs, 2) an LLM-based false-positive filter that can identify false-positive bugs...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2310.18532)
- **Labels**: static analysis, bug detection, agent design

## [Harnessing the power of llm to support binary taint analysis](paper_7.md)
- **Authors**: Liu, Puzhuo and Sun, Chengnian and Zheng, Yaowen and Feng, Xuan and Qin, Chuan and Wang, Yuncheng and Li, Zhi and Sun, Limin
- **Abstract**: This paper proposes LATTE, the first static binary taint analysis that is powered by a large language model (LLM). LATTE is superior to the state of the art (e.g., Emtaint, Arbiter, Karonte) in three aspects. First, LATTE is fully automated while prior static binary taint analyzers need rely on huma...
- **Link**: [Read Paper](No Link Available)
- **Labels**: static analysis, bug detection

## [Do you still need a manual smart contract audit?](paper_8.md)
- **Authors**: David, Isaac and Zhou, Liyi and Qin, Kaihua and Song, Dawn and Cavallaro, Lorenzo and Gervais, Arthur
- **Abstract**: We investigate the feasibility of employing large language models (LLMs) for conducting the security audit of smart contracts, a traditionally time-consuming and costly process. Our research focuses on the optimization of prompt engineering for enhanced security analysis, and we evaluate the perform...
- **Link**: [Read Paper](No Link Available)
- **Labels**: static analysis, bug detection

## [Large language model-powered smart contract vulnerability detection: New perspectives](paper_9.md)
- **Authors**: Hu, Sihao and Huang, Tiansheng and {\.I}lhan, Fatih and Tekin, Selim Furkan and Liu, Ling
- **Abstract**: This paper provides a systematic analysis of the opportunities, challenges, and potential solutions of harnessing Large Language Models (LLMs) such as GPT-4 to dig out vulnerabilities within smart contracts based on our ongoing research. For the task of smart contract vulnerability detection, achiev...
- **Link**: [Read Paper](No Link Available)
- **Labels**: static analysis, bug detection

## [Finding inductive loop invariants using large language models](paper_10.md)
- **Authors**: Kamath, Adharsh and Senthilnathan, Aditya and Chakraborty, Saikat and Deligiannis, Pantazis and Lahiri, Shuvendu K and Lal, Akash and Rastogi, Aseem and Roy, Subhajit and Sharma, Rahul
- **Abstract**:     Loop invariants are fundamental to reasoning about programs with loops. They establish properties about a given loop's behavior. When they additionally are inductive, they become useful for the task of formal verification that seeks to establish strong mathematical guarantees about program's run...
- **Link**: [Read Paper](No Link Available)
- **Labels**: static analysis, program verification, invariant generation

## [Impact of large language models on generating software specifications](paper_11.md)
- **Authors**: Xie, Danning and Yoo, Byungwoo and Jiang, Nan and Kim, Mijung and Tan, Lin and Zhang, Xiangyu and Lee, Judy S
- **Abstract**: Software specifications are essential for ensuring the reliability of software systems. Existing specification extraction approaches, however, suffer from limited generalizability and require manual efforts. The recent emergence of Large Language Models (LLMs), which have been successfully applied t...
- **Link**: [Read Paper](No Link Available)
- **Labels**: static analysis, specification inference

## [A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions](paper_12.md)
- **Authors**: Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others
- **Abstract**: The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. Nevertheless, alongside these strides, LLMs exhibit a critical tendency to produce hallucinations, result...
- **Link**: [Read Paper](No Link Available)
- **Labels**: hallucination in reasoning, survey

## [Cumulative reasoning with large language models](paper_13.md)
- **Authors**: Zhang, Yifan and Yang, Jingqin and Yuan, Yang and Yao, Andrew Chi-Chih
- **Abstract**: While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), ...
- **Link**: [Read Paper](No Link Available)
- **Labels**: hallucination in reasoning, prompt strategy

## [Cognitive architectures for language agents](paper_14.md)
- **Authors**: Sumers, Theodore R and Yao, Shunyu and Narasimhan, Karthik and Griffiths, Thomas L
- **Abstract**: The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executabl...
- **Link**: [Read Paper](No Link Available)
- **Labels**: agent design, survey

## [The rise and potential of large language model based agents: A survey](paper_15.md)
- **Authors**: Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others
- **Abstract**: For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been mad...
- **Link**: [Read Paper](No Link Available)
- **Labels**: survey, agent design

