# EMNLP-main2024

Number of papers: 21

## [Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation](paper_1.md)
- **Authors**: Salim, Saiful Islam and Yang, Rubin Yuchan and Cooper, Alexander and Ray, Suryashree and Debray, Saumya and Rahaman, Sazzadur
- **Abstract**: While Large language model (LLM)-based programming assistants such as CoPilot and ChatGPT can help improve the productivity of professional software developers, they can also facilitate cheating in introductory computer programming courses. Assuming instructors have limited control over the industri...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.27)
- **Labels**: code generation, program synthesis, empirical study

## [AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation](paper_2.md)
- **Authors**: Luo, Ziyang and Li, Xin and Lin, Hongzhan and Ma, Jing and Bing, Lidong
- **Abstract**: The impressive performance of proprietary LLMs like GPT4 in code generation has led to a trend to replicate these capabilities in open-source models through knowledge distillation (e.g. Code Evol-Instruct). However, these efforts often neglect the crucial aspect of response quality, relying heavily ...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.66)
- **Labels**: code generation, program synthesis, code model, training, source code model

## [LLM4Decompile: Decompiling Binary Code with Large Language Models](paper_3.md)
- **Authors**: Tan, Hanzhuo and Luo, Qi and Li, Jing and Zhang, Yuqun
- **Abstract**: Decompilation aims to convert binary code to high-level source code, but traditional tools like Ghidra often produce results that are difficult to read and execute. Motivated by the advancements in Large Language Models (LLMs), we propose LLM4Decompile, the first and largest open-source LLM series (...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.203)
- **Labels**: code generation, program decompilation, code model, training, binary code model

## [PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL](paper_4.md)
- **Authors**: Luo, Ruilin and Wang, Liyuan and Lin, Binghuai and Lin, Zicheng and Yang, Yujiu
- **Abstract**: Large Language Models (LLMs) have emerged as powerful tools for Text-to-SQL tasks, exhibiting remarkable reasoning capabilities. Different from tasks such as math word problem and commonsense reasoning, SQL solutions have a relatively fixed pattern. This facilitates the investigation of whether LLMs...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.221)
- **Labels**: code generation, program synthesis, empirical study

## [How Do Humans Write Code? Large Models Do It the Same Way Too](paper_5.md)
- **Authors**: Li, Long and He, Xuzheng and Wang, Haozhe and Wang, Linlin and He, Liang
- **Abstract**: Program-of-Thought (PoT) replaces natural language-based Chain-of-Thought (CoT) as the most popular method in Large Language Models (LLMs) mathematical reasoning tasks by utilizing external tool calls to circumvent computational errors. However, our evaluation of the GPT-4 and Llama series reveals t...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.267)
- **Labels**: code generation, program synthesis, empirical study

## [Language-to-Code Translation with a Single Labeled Example](paper_6.md)
- **Authors**: Bostrom, Kaj and Jhamtani, Harsh and Fang, Hao and Thomson, Sam and Shin, Richard and Xia, Patrick and Van Durme, Benjamin and Eisner, Jason and Andreas, Jacob
- **Abstract**: Tools for translating natural language into code promise natural, open-ended interaction with databases, web APIs, and other software systems. However, this promise is complicated by the diversity and continual development of these systems, each with its own interface and distinct set of features. B...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.462)
- **Labels**: code generation, program synthesis, benchmark

## [RealVul: Can We Detect Vulnerabilities in Web Applications with LLM?](paper_7.md)
- **Authors**: Cao, Di and Liao, Yong and Shang, Xiuwei
- **Abstract**: The latest advancements in large language models (LLMs) have sparked interest in their potential for software vulnerability detection. However, there is currently a lack of research specifically focused on vulnerabilities in the PHP language, and challenges in data sampling and processing persist, h...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.472)
- **Labels**: static analysis, bug detection

## [Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs](paper_8.md)
- **Authors**: Puerto, Haritz and Tutek, Martin and Aditya, Somak and Zhu, Xiaodan and Gurevych, Iryna
- **Abstract**: Reasoning is a fundamental component of language understanding. Recent prompting techniques, such as chain of thought, have consistently improved LLMs’ performance on various reasoning tasks. Nevertheless, there is still little understanding of what triggers reasoning abilities in LLMs in the infere...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.629)
- **Labels**: prompt strategy, reason with code

## [CodeAgent: Autonomous Communicative Agents for Code Review](paper_9.md)
- **Authors**: Tang, Xunzhu and Kim, Kisub and Song, Yewei and Lothritz, Cedric and Li, Bei and Ezzini, Saad and Tian, Haoye and Klein, Jacques and Bissyandé, Tegawendé F.
- **Abstract**: Code review, which aims at ensuring the overall quality and reliability of software, is a cornerstone of software development. Unfortunately, while crucial, Code review is a labor-intensive process that the research community is looking to automate. Existing automated methods rely on single input-ou...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.632)
- **Labels**: software maintenance and deployment, code review, agent design

## [Empowering Multi-step Reasoning across Languages via Program-Aided Language Models](paper_10.md)
- **Authors**: Ranaldi, Leonardo and Pucci, Giulia and Haddow, Barry and Birch, Alexandra
- **Abstract**: In-context learning methods are popular inference strategies where Large Language Models (LLMs) are elicited to solve a task using provided demonstrations without parameter updates. Among these approaches are the reasoning methods, best exemplified by Chain-of-Thought (CoT) and Program-Aided Languag...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.678)
- **Labels**: prompt strategy, reason with code

## [DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models](paper_11.md)
- **Authors**: Huang, Yiming and Luo, Jianwen and Yu, Yan and Zhang, Yitong and Lei, Fangyu and Wei, Yifan and He, Shizhu and Huang, Lifu and Liu, Xiao and Zhao, Jun and Liu, Kang
- **Abstract**: We introduce DA-Code, a code generation benchmark specifically designed to assess LLMs on agent-based data science tasks. This benchmark features three core elements: First, the tasks within DA-Code are inherently challenging, setting them apart from traditional code generation tasks and demanding a...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.748)
- **Labels**: code generation, program synthesis, benchmark

## [Leveraging Context-Aware Prompting for Commit Message Generation](paper_12.md)
- **Authors**: Jiang, Zhihua and Chen, Jianwei and Rao, Dongning and Ye, Guanghui
- **Abstract**: Writing comprehensive commit messages is tedious yet important, because these messages describe changes of code, such as fixing bugs or adding new features. However, most existing methods focus on either only the changed lines or nearest context lines, without considering the effectiveness of select...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.749)
- **Labels**: software maintenance and deployment, commit message generation

## [How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data](paper_13.md)
- **Authors**: Wang, Yejie and He, Keqing and Fu, Dayuan and GongQue, Zhuoma and Xu, Heyang and Chen, Yanxu and Wang, Zhexu and Fu, Yujia and Dong, Guanting and Diao, Muxi and Wang, Jingang and Zhang, Mengdi and Cai, Xunliang and Xu, Weiran
- **Abstract**: Recently, there has been a growing interest in studying how to construct better code instruction tuning data. However, we observe Code models trained with these datasets exhibit high performance on HumanEval but perform worse on other benchmarks such as LiveCodeBench. Upon further investigation, we ...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.777)
- **Labels**: code generation, code model, training, source code model

## [ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?](paper_14.md)
- **Authors**: Waghjale, Siddhant and Veerendranath, Vishruth and Wang, Zhiruo and Fried, Daniel
- **Abstract**: Although large language models (LLMs) have been largely successful in generating functionally correct programs, conditioning models to produce efficient solutions while ensuring correctness remains a challenge. Further, unreliability in benchmarking code efficiency is a hurdle across varying hardwar...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.859)
- **Labels**: code generation, program synthesis

## [Re-Reading Improves Reasoning in Large Language Models](paper_15.md)
- **Authors**: Xu, Xiaohan and Tao, Chongyang and Shen, Tao and Xu, Can and Xu, Hongbo and Long, Guodong and Lou, Jian-Guang and Ma, Shuai
- **Abstract**: To enhance the reasoning capabilities of off-the-shelf Large Language Models (LLMs), we introduce a simple, yet general and effective prompting method, RE2, i.e., Re-Reading the question as input. Unlike most thought-eliciting prompting methods, such as Chain-of-Thought (CoT), which aim to elicit th...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.871)
- **Labels**: prompt strategy

## [DocCGen: Document-based Controlled Code Generation](paper_16.md)
- **Authors**: Pimparkhede, Sameer and Kammakomati, Mehant and Tamilselvam, Srikanth G. and Kumar, Prince and Kumar, Ashok Pon and Bhattacharyya, Pushpak
- **Abstract**: Recent developments show that Large Language Models (LLMs) produce state-of-the-art performance on natural language (NL) to code generation for resource-rich general-purpose languages like C++, Java, and Python. However, their practical usage for structured domain-specific languages (DSLs) such as Y...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.1040)
- **Labels**: code generation, program synthesis

## [CoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing](paper_17.md)
- **Authors**: He, Xinyi and Zou, Jiaru and Lin, Yun and Zhou, Mengyu and Han, Shi and Yuan, Zejian and Zhang, Dongmei
- **Abstract**: Large Language Models have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lac...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.1082)
- **Labels**: code generation, program synthesis, benchmark

## [CodeJudge: Evaluating Code Generation with Large Language Models](paper_18.md)
- **Authors**: Tong, Weixi and Zhang, Tianyi
- **Abstract**: Large Language Models (LLMs) have shown promising performance in code generation. However, how to reliably evaluate code generated by LLMs remains an unresolved problem. This paper presents CodeJudge, a code evaluation framework that leverages LLMs to evaluate the semantic correctness of generated c...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.1118)
- **Labels**: code generation, program synthesis

## [EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records](paper_19.md)
- **Authors**: Shi, Wenqi and Xu, Ran and Zhuang, Yuchen and Yu, Yue and Zhang, Jieyu and Wu, Hang and Zhu, Yuanda and Ho, Joyce C. and Yang, Carl and Wang, May Dongmei
- **Abstract**: Clinicians often rely on data engineers to retrieve complex patient information from electronic health record (EHR) systems, a process that is both inefficient and time-consuming. We propose EHRAgent, a large language model (LLM) agent empowered with accumulative domain knowledge and robust coding c...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.1245)
- **Labels**: prompt strategy, reason with code

## [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](paper_20.md)
- **Authors**: Chae, Hyungjoo and Kim, Yeonghyeon and Kim, Seungone and Ong, Kai Tzu-iunn and Kwak, Beong-woo and Kim, Moohyeon and Kim, Sunghwan and Kwon, Taeyoon and Chung, Jiwan and Yu, Youngjae and Yeo, Jinyoung
- **Abstract**: Algorithmic reasoning tasks that involve complex logical patterns, such as completing Dyck language, pose challenges for large language models (LLMs), despite their recent success. Prior work has used LLMs to generate programming language and applied external compilers for such tasks. Yet, when on t...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.1253)
- **Labels**: prompt strategy, reason with code

## [Coffee-Gym: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code](paper_21.md)
- **Authors**: Chae, Hyungjoo and Kwon, Taeyoon and Moon, Seungjun and Song, Yongho and Kang, Dongjin and Ong, Kai Tzu-iunn and Kwak, Beong-woo and Bae, Seonghyeon and Hwang, Seung-won and Yeo, Jinyoung
- **Abstract**: This paper presents Coffee-Gym, a comprehensive RL environment for training models that provide feedback on code editing. Coffee-Gym includes two major components: (1) Coffee, a dataset containing humans’ code edit traces for coding questions and human-written feedback for editing erroneous code; (2...
- **Link**: [Read Paper](https://aclanthology.org/2024.emnlp-main.1254)
- **Labels**: code generation, program repair, benchmark

