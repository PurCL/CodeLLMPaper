# S&P2024

Number of papers: 4

## [LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities (Yet?): A Comprehensive Evaluation, Framework, and Benchmarks](paper_1.md)
- **Authors**: Ullah, Saad and Han, Mingji and Pujar, Saurabh and Pearce, Hammond and Coskun, Ayse and Stringhini, Gianluca
- **Abstract**: Large Language Models (LLMs) have been suggested for use in automated vulnerability repair, but benchmarks showing they can consistently identify security-related bugs are lacking. We thus develop SecLLMHolmes, a fully automated evaluation framework that performs the most detailed investigation to d...
- **Link**: [Read Paper](No Link Available)
- **Labels**: static analysis, bug detection, code generation, program repair, empirical study

## [LLMIF: Augmented Large Language Model for Fuzzing IoT Devices](paper_2.md)
- **Authors**: Wang, Jincheng and Yu, Le and Luo, Xiapu
- **Abstract**: Despite the efficacy of fuzzing in verifying the implementation correctness of network protocols, existing IoT protocol fuzzing approaches grapple with several limitations, including obfuscated message formats, unresolved message dependencies, and a lack of evaluations on the testing cases. These li...
- **Link**: [Read Paper](No Link Available)
- **Labels**: program testing, fuzzing

## [TrojanPuzzle: Covertly Poisoning Code-Suggestion Models](paper_3.md)
- **Authors**: Aghakhani, Hojjat and Dai, Wei and Manoel, Andre and Fernandes, Xavier and Kharkar, Anant and Kruegel, Christopher and Vigna, Giovanni and Evans, David and Zorn, Ben and Sim, Robert
- **Abstract**: With tools like GitHub Copilot, automatic code suggestion is no longer a dream in software engineering. These tools, based on large language models, are typically trained on massive corpora of code mined from unvetted public sources. As a result, these models are susceptible to data poisoning attack...
- **Link**: [Read Paper](No Link Available)
- **Labels**: code model, security, attack, code generation, code completion

## [Smartinv: Multimodal learning for smart contract invariant inference](paper_4.md)
- **Authors**: Wang, Sally Junsong and Pei, Kexin and Yang, Junfeng
- **Abstract**: Smart contracts are software programs that enable diverse business activities on the blockchain. Recent research has identified new classes of "machine un-auditable" bugs that arise from source code not meeting underlying transaction contexts. Existing detection methods require human understanding o...
- **Link**: [Read Paper](No Link Available)
- **Labels**: static analysis, bug detection

