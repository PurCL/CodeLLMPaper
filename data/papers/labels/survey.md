# Survey

## Agent Design

- [Cognitive architectures for language agents](../venues/arXiv2023/paper_15.md), ([arXiv2023](../venues/arXiv2023/README.md))

  - **Abstract**: The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs' training data. Speci...
  - **Labels**: [agent design](agent_design.md), [survey](survey.md)

- [From System 1 to System 2: A Survey of Reasoning Large Language Models](../venues/arXiv2025/paper_22.md), ([arXiv2025](../venues/arXiv2025/README.md))

  - **Abstract**: Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning. While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more accurate judgments and reduced biases. Foundational Large Language Models (LLMs) excel at fast decision-making but lack the depth for complex reasoning, as they have not yet fully embraced the step-by-step analysis characteristic of true System 2 t...
  - **Labels**: [agent design](agent_design.md), [hallucination in reasoning](hallucination_in_reasoning.md), [survey](survey.md)

- [If llm is the wizard, then code is the wand: A survey on how code empowers large language models to serve as intelligent agents](../venues/arXiv2024/paper_33.md), ([arXiv2024](../venues/arXiv2024/README.md))

  - **Abstract**: The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs' training data. Speci...
  - **Labels**: [survey](survey.md), [agent design](agent_design.md), [reason with code](reason_with_code.md)

- [Large language model-based agents for software engineering: A survey](../venues/arXiv2024/paper_32.md), ([arXiv2024](../venues/arXiv2024/README.md))

  - **Abstract**: The recent advance in Large Language Models (LLMs) has shaped a new paradigm of AI agents, i.e., LLM-based agents. Compared to standalone LLMs, LLM-based agents substantially extend the versatility and expertise of LLMs by enhancing LLMs with the capabilities of perceiving and utilizing external resources and tools. To date, LLM-based agents have been applied and shown remarkable effectiveness in Software Engineering (SE). The synergy between multiple agents and human interaction brings further ...
  - **Labels**: [survey](survey.md), [agent design](agent_design.md)

- [Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing](../venues/ACMSurvey2023/paper_1.md), ([ACMSurvey2023](../venues/ACMSurvey2023/README.md))

  - **Abstract**: This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfi...
  - **Labels**: [survey](survey.md), [agent design](agent_design.md), [prompt strategy](prompt_strategy.md)

- [The rise and potential of large language model based agents: A survey](../venues/arXiv2023/paper_16.md), ([arXiv2023](../venues/arXiv2023/README.md))

  - **Abstract**: For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the commu...
  - **Labels**: [survey](survey.md), [agent design](agent_design.md)

## Code Generation

- [A Survey on Large Language Models for Code Generation](../venues/arXiv2024/paper_10.md), ([arXiv2024](../venues/arXiv2024/README.md))

  - **Abstract**: Large Language Models (LLMs) have garnered remarkable advancements across diverse code-related tasks, known as Code LLMs, particularly in code generation that generates source code with LLM from natural language descriptions. This burgeoning field has captured significant interest from both academic researchers and industry professionals due to its practical significance in software development, e.g., GitHub Copilot. Despite the active exploration of LLMs for a variety of code tasks, either from...
  - **Labels**: [survey](survey.md), [code generation](code_generation.md)

- [AI Software Engineer: Programming with Trust](../venues/arXiv2025/paper_21.md), ([arXiv2025](../venues/arXiv2025/README.md))

  - **Abstract**: Large Language Models (LLMs) have shown surprising proficiency in generating code snippets, promising to automate large parts of software engineering via artificial intelligence (AI). We argue that successfully deploying AI software engineers requires a level of trust equal to or even greater than the trust established by human-driven software engineering practices. The recent trend toward LLM agents offers a path toward integrating the power of LLMs to create new code with the power of analysis...
  - **Labels**: [code generation](code_generation.md), [survey](survey.md)

- [Large Language Models Meet NL2Code: A Survey](../venues/ACL2023/paper_4.md), ([ACL2023](../venues/ACL2023/README.md))

  - **Abstract**: The task of generating code from a natural language description, or NL2Code, is considered a pressing and significant challenge in code intelligence. Thanks to the rapid development of pre-training techniques, surging large language models are being proposed for code, sparking the advances in NL2Code. To facilitate further research and applications in this field, in this paper, we present a comprehensive survey of 27 existing large language models for NL2Code, and also review benchmarks and metr...
  - **Labels**: [survey](survey.md), [code generation](code_generation.md), [program synthesis](program_synthesis.md)

## Code Model

- [Security of Language Models for Code: A Systematic Literature Review](../venues/arXiv2024/paper_1.md), ([arXiv2024](../venues/arXiv2024/README.md))

  - **Abstract**: Language models for code (CodeLMs) have emerged as powerful tools for code-related tasks, outperforming traditional methods and standard machine learning approaches. However, these models are susceptible to security vulnerabilities, drawing increasing research attention from domains such as software engineering, artificial intelligence, and cybersecurity. Despite the growing body of research focused on the security of CodeLMs, a comprehensive survey in this area remains absent. To address this g...
  - **Labels**: [code model](code_model.md), [code model security](code_model_security.md), [survey](survey.md)

## General Coding Task

- [Large language models for software engineering: A systematic literature review](../venues/TOSEM2023/paper_1.md), ([TOSEM2023](../venues/TOSEM2023/README.md))

  - **Abstract**: Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and...
  - **Labels**: [survey](survey.md), [general coding task](general_coding_task.md)

- [Unifying the perspectives of nlp and software engineering: A survey on language models for code](../venues/TMLR2024/paper_1.md), ([TMLR2024](../venues/TMLR2024/README.md))

  - **Abstract**: In this work we systematically review the recent advancements in software engineering with language models, covering 70+ models, 40+ evaluation tasks, 180+ datasets, and 900 related works. Unlike previous works, we integrate software engineering (SE) with natural language processing (NLP) by discussing the perspectives of both sides: SE applies language models for development automation, while NLP adopts SE tasks for language model evaluation. We break down code processing models into general la...
  - **Labels**: [general coding task](general_coding_task.md), [survey](survey.md)

## Hallucination In Reasoning

- [A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions](../venues/arXiv2023/paper_13.md), ([arXiv2023](../venues/arXiv2023/README.md))

  - **Abstract**: The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. Nevertheless, alongside these strides, LLMs exhibit a critical tendency to produce hallucinations, resulting in content that is inconsistent with real-world facts or user inputs. This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in...
  - **Labels**: [hallucination in reasoning](hallucination_in_reasoning.md), [survey](survey.md)

- [Formal Mathematical Reasoning: A New Frontier in AI](../venues/arXiv2024/paper_27.md), ([arXiv2024](../venues/arXiv2024/README.md))

  - **Abstract**: AI for Mathematics (AI4Math) is not only intriguing intellectually but also crucial for AI-driven discovery in science, engineering, and beyond. Extensive efforts on AI4Math have mirrored techniques in NLP, in particular, training large language models on carefully curated math datasets in text form. As a complementary yet less explored avenue, formal mathematical reasoning is grounded in formal systems such as proof assistants, which can verify the correctness of reasoning and provide automatic...
  - **Labels**: [hallucination in reasoning](hallucination_in_reasoning.md), [survey](survey.md)

- [From System 1 to System 2: A Survey of Reasoning Large Language Models](../venues/arXiv2025/paper_22.md), ([arXiv2025](../venues/arXiv2025/README.md))

  - **Abstract**: Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning. While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more accurate judgments and reduced biases. Foundational Large Language Models (LLMs) excel at fast decision-making but lack the depth for complex reasoning, as they have not yet fully embraced the step-by-step analysis characteristic of true System 2 t...
  - **Labels**: [agent design](agent_design.md), [hallucination in reasoning](hallucination_in_reasoning.md), [survey](survey.md)

## Program Testing

- [Large Language Models Based Fuzzing Techniques: A Survey](../venues/arXiv2024/paper_38.md), ([arXiv2024](../venues/arXiv2024/README.md))

  - **Abstract**: In the modern era where software plays a pivotal role, software security and vulnerability analysis have become essential for software development. Fuzzing test, as an efficient software testing method, are widely used in various domains. Moreover, the rapid development of Large Language Models (LLMs) has facilitated their application in the field of software testing, demonstrating remarkable performance. Considering existing fuzzing test techniques are not entirely automated and software vulner...
  - **Labels**: [program testing](program_testing.md), [fuzzing](fuzzing.md), [survey](survey.md)

- [Software Testing With Large Language Models: Survey, Landscape, and Vision](../venues/TSE2024/paper_8.md), ([TSE2024](../venues/TSE2024/README.md))

  - **Abstract**: Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability of software products. As the scope and complexity of software systems continue to grow, the need for more effect...
  - **Labels**: [program testing](program_testing.md), [survey](survey.md)

- [When fuzzing meets llms: Challenges and opportunities](../venues/FSE2024/paper_27.md), ([FSE2024](../venues/FSE2024/README.md))

  - **Abstract**: Fuzzing, a widely-used technique for bug detection, has seen advancements through Large Language Models (LLMs). Despite their potential, LLMs face specific challenges in fuzzing. In this paper, we identified five major challenges of LLM-assisted fuzzing. To support our findings, we revisited the most recent papers from top-tier conferences, confirming that these challenges are widespread. As a remedy, we propose some actionable recommendations to help improve applying LLM in Fuzzing and conduct ...
  - **Labels**: [program testing](program_testing.md), [fuzzing](fuzzing.md), [survey](survey.md)

## Static Analysis

- [Language Models for Code Optimization: Survey, Challenges and Future Directions](../venues/arXiv2025/paper_5.md), ([arXiv2025](../venues/arXiv2025/README.md))

  - **Abstract**: Language models (LMs) built upon deep neural networks (DNNs) have recently demonstrated breakthrough effectiveness in software engineering tasks such as code generation, completion, and repair. This has paved the way for the emergence of LM-based code optimization techniques, which are crucial for enhancing the performance of existing programs, such as accelerating program execution time. However, a comprehensive survey dedicated to this specific application has been lacking. To fill this gap, w...
  - **Labels**: [static analysis](static_analysis.md), [program optimization](program_optimization.md), [survey](survey.md)

- [Survey of Code Search Based on Deep Learning](../venues/TOSEM2024/paper_10.md), ([TOSEM2024](../venues/TOSEM2024/README.md))

  - **Abstract**: Code writing is repetitive and predictable, inspiring us to develop various code intelligence techniques. This survey focuses on code search, that is, to retrieve code that matches a given natural language query by effectively capturing the semantic similarity between the query and code. Deep learning, being able to extract complex semantics information, has achieved great success in this field. Recently, various deep learning methods, such as graph neural networks and pretraining models, have b...
  - **Labels**: [survey](survey.md), [static analysis](static_analysis.md), [code search](code_search.md)
