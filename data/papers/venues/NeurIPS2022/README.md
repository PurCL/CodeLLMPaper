# NeurIPS2022

Number of papers: 2

## [React: Synergizing reasoning and acting in language models](paper_1.md)
- **Authors**: Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan
- **Abstract**: While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics...
- **Link**: [Read Paper](https://arxiv.org/abs/2210.03629)
- **Labels**: hallucination in reasoning, prompt strategy

## [Self-consistency improves chain of thought reasoning in language models](paper_2.md)
- **Authors**: Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny
- **Abstract**: Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a div...
- **Link**: [Read Paper](https://arxiv.org/abs/2203.11171)
- **Labels**: hallucination in reasoning, prompt strategy

