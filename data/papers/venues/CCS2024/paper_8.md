# Enhance Hardware Domain Specific Large Language Model with Reinforcement Learning for Resilience

**Authors**: Fu, Weimin and Zhao, Yifang and Jin, Yier and Guo, Xiaolong

**Abstract**:

To enhance the performance of large language models (LLMs) on hardware design tasks, we focus on training with reinforcement learning(RL) to improve LLMs' syntax synthesis and functional verification performance. We observed significant gains in power, performance, and area (PPA) metrics by applying RL. Specifically, DeepSeek Code saw a 23.6\% performance increase, while the RTLCoder improved by 7.86\%. Our findings demonstrate the effectiveness of RL in refining LLMs for more accurate hardware generation, considering power and area consumption. This approach offers a promising direction for generating hardware resilient to side-channel attacks in computer systems.

**Link**: [Read Paper](https://doi.org/10.1145/3658644.3691384)

**Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md)
