# arXiv2024

Number of papers: 27

## [â‰ˆw](paper_1.md)
- **Authors**: Chen, Yuchen and Sun, Weisong and Fang, Chunrong and Chen, Zhenpeng and Ge, Yifei and Han, Tingxu and Zhang, Quanjun and Liu, Yang and Chen, Zhenyu and Xu, Baowen
- **Abstract**: Language models for code (CodeLMs) have emerged as powerful tools for code-related tasks, outperforming traditional methods and standard machine learning approaches. However, these models are susceptible to security vulnerabilities, drawing increasing research attention from domains such as software...
- **Link**: [Read Paper](https://arxiv.org/pdf/2410.15631)
- **Labels**: code model, code model security, survey

## [Codemind: A framework to challenge large language models for code reasoning](paper_2.md)
- **Authors**: Liu, Changshu and Zhang, Shizhuo Dylan and Ibrahimzada, Ali Reza and Jabbarvand, Reyhaneh
- **Abstract**: Solely relying on test passing to evaluate Large Language Models (LLMs) for code synthesis may result in unfair assessment or promoting models with data leakage. As an alternative, we introduce CodeMind, a framework designed to gauge the code reasoning abilities of LLMs. CodeMind currently supports ...
- **Link**: [Read Paper](https://arxiv.org/pdf/2402.09664)
- **Labels**: general coding task, empirical study

## [Constrained Decoding for Secure Code Generation](paper_3.md)
- **Authors**: Fu, Yanjun and Baker, Ethan and Ding, Yu and Chen, Yizheng
- **Abstract**: Code Large Language Models (Code LLMs) have been increasingly used by developers to boost productivity, but they often generate vulnerable code. Thus, there is an urgent need to ensure that code generated by Code LLMs is correct and secure. Previous research has primarily focused on generating secur...
- **Link**: [Read Paper](https://arxiv.org/pdf/2405.00218)
- **Labels**: code generation, code model, code model security, defense

## [EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories](paper_4.md)
- **Authors**: Li, Jia and Li, Ge and Zhang, Xuanming and Dong, Yihong and Jin, Zhi
- **Abstract**: How to evaluate Large Language Models (LLMs) in code generation is an open question. Existing benchmarks demonstrate poor alignment with real-world code repositories and are insufficient to evaluate the coding abilities of LLMs. This paper proposes a new benchmark - EvoCodeBench to address the prece...
- **Link**: [Read Paper](https://arxiv.org/pdf/2404.00599)
- **Labels**: benchmark, code generation

## [CodeBenchGen: Creating Scalable Execution-based Code Generation Benchmarks](paper_5.md)
- **Authors**: Xie, Yiqing and Xie, Alex and Sheth, Divyanshu and Liu, Pengfei and Fried, Daniel and Rose, Carolyn
- **Abstract**: To facilitate evaluation of code generation systems across diverse scenarios, we present CodeBenchGen, a framework to create scalable execution-based benchmarks that only requires light guidance from humans. Specifically, we leverage a large language model (LLM) to convert an arbitrary piece of code...
- **Link**: [Read Paper](https://arxiv.org/pdf/2404.00566)
- **Labels**: code generation, benchmark

## [A Survey on Large Language Models for Code Generation](paper_6.md)
- **Authors**: Jiang, Juyong and Wang, Fan and Shen, Jiasi and Kim, Sungju and Kim, Sunghun
- **Abstract**: Large Language Models (LLMs) have garnered remarkable advancements across diverse code-related tasks, known as Code LLMs, particularly in code generation that generates source code with LLM from natural language descriptions. This burgeoning field has captured significant interest from both academic...
- **Link**: [Read Paper](https://arxiv.org/pdf/2406.00515)
- **Labels**: survey, code generation

## [Repairagent: An autonomous, llm-based agent for program repair](paper_7.md)
- **Authors**: Bouzenia, Islem and Devanbu, Premkumar and Pradel, Michael
- **Abstract**: Automated program repair has emerged as a powerful technique to mitigate the impact of software bugs on system reliability and user experience. This paper introduces RepairAgent, the first work to address the program repair challenge through an autonomous agent based on a large language model (LLM)....
- **Link**: [Read Paper](https://arxiv.org/pdf/2403.17134)
- **Labels**: code generation, program repair, agent design, planning

## [Automatic Programming: Large Language Models and Beyond](paper_8.md)
- **Authors**: Lyu, Michael R and Ray, Baishakhi and Roychoudhury, Abhik and Tan, Shin Hwei and Thongtanunam, Patanamon
- **Abstract**: Automatic programming has seen increasing popularity due to the emergence of tools like GitHub Copilot which rely on Large Language Models (LLMs). At the same time, automatically generated code faces challenges during deployment due to concerns around quality and trust. In this article, we study aut...
- **Link**: [Read Paper](https://arxiv.org/pdf/2405.02213)
- **Labels**: general coding task, empirical study

## [Rectifier: Code translation with corrector via llms](paper_9.md)
- **Authors**: Yin, Xin and Ni, Chao and Nguyen, Tien N and Wang, Shaohua and Yang, Xiaohu
- **Abstract**: Software migration is garnering increasing attention with the evolution of software and society. Early studies mainly relied on handcrafted translation rules to translate between two languages, the translation process is error-prone and time-consuming. In recent years, researchers have begun to expl...
- **Link**: [Read Paper](https://arxiv.org/pdf/2407.07472)
- **Labels**: code generation, program transformation

## [Enabling Memory Safety of C Programs using LLMs](paper_10.md)
- **Authors**: Mohammed, Nausheen and Lal, Akash and Rastogi, Aseem and Roy, Subhajit and Sharma, Rahul
- **Abstract**: Memory safety violations in low-level code, written in languages like C, continues to remain one of the major sources of software vulnerabilities. One method of removing such violations by construction is to port C code to a safe C dialect. Such dialects rely on programmer-supplied annotations to gu...
- **Link**: [Read Paper](https://arxiv.org/pdf/2404.01096.pdf)
- **Labels**: code generation, program transformation

## [VulEval: Towards Repository-Level Evaluation of Software Vulnerability Detection](paper_11.md)
- **Authors**: Xin{-}Cheng Wen and Xinchen Wang and Yujia Chen and Ruida Hu and David Lo and Cuiyun Gao
- **Abstract**: Deep Learning (DL)-based methods have proven to be effective for software vulnerability detection, with a potential for substantial productivity enhancements for detecting vulnerabilities. Current methods mainly focus on detecting single functions (i.e., intra-procedural vulnerabilities), ignoring t...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2404.15596)
- **Labels**: static analysis, bug detection, benchmark

## [A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection](paper_12.md)
- **Authors**: Benjamin Steenhoek and Md Mahbubur Rahman and Monoshi Kumar Roy and Mirza Sanjida Alam and Earl T. Barr and Wei Le
- **Abstract**: Large Language Models (LLMs) have demonstrated great potential for code generation and other software engineering tasks. Vulnerability detection is of crucial importance to maintaining the security, integrity, and trustworthiness of software systems. Precise vulnerability detection requires reasonin...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2403.17218)
- **Labels**: static analysis, bug detection, empirical study

## [Source Code Vulnerability Detection: Combining Code Language Models and Code Property Graphs](paper_13.md)
- **Authors**: Ruitong Liu and Yanbin Wang and Haitao Xu and Bin Liu and Jianguo Sun and Zhenhao Guo and Wenrui Ma
- **Abstract**: Currently, deep learning successfully applies to code vulnerability detection by learning from code sequences or property graphs. However, sequence-based methods often overlook essential code attributes such as syntax, control flow, and data dependencies, whereas graph-based approaches might underes...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2404.14719)
- **Labels**: static analysis, bug detection, code model, code model training, source code model

## [Your Instructions Are Not Always Helpful: Assessing the Efficacy of Instruction Fine-tuning for Software Vulnerability Detection](paper_14.md)
- **Authors**: Imam Nur Bani Yusuf and Lingxiao Jiang
- **Abstract**: Software, while beneficial, poses potential cybersecurity risks due to inherent vulnerabilities. Detecting these vulnerabilities is crucial, and deep learning has shown promise as an effective tool for this task due to its ability to perform well without extensive feature engineering. However, a cha...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2401.07466)
- **Labels**: static analysis, bug detection, code model, code model training, source code model

## [LLM4Vuln: {A} Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning](paper_15.md)
- **Authors**: Yuqiang Sun and Daoyuan Wu and Yue Xue and Han Liu and Wei Ma and Lyuye Zhang and Miaolei Shi and Yang Liu
- **Abstract**: Large language models (LLMs) have demonstrated significant potential in various tasks, including vulnerability detection. However, current efforts in this area are preliminary, lacking clarity on whether LLMs' vulnerability reasoning capabilities stem from the models themselves or external aids such...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2401.16185)
- **Labels**: static analysis, bug detection, benchmark

## [Top Score on the Wrong Exam: On Benchmarking in Machine Learning for Vulnerability Detection](paper_16.md)
- **Authors**: Niklas Risse and Marcel B{\"{o}hme
- **Abstract**: According to our survey of the machine learning for vulnerability detection (ML4VD) literature published in the top Software Engineering conferences, every paper in the past 5 years defines ML4VD as a binary classification problem: Given a function, does it contain a security flaw?In this paper, we ...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2408.12986)
- **Labels**: static analysis, bug detection, empirical study

## [Generating API Parameter Security Rules with LLM for API Misuse Detection](paper_17.md)
- **Authors**: Liu, Jinghua and Yang, Yi and Chen, Kai and Lin, Miaoqian
- **Abstract**: In this paper, we present a new framework, named GPTAid, for automatic APSRs generation by analyzing API source code with LLM and detecting API misuse caused by incorrect parameter use. To validate the correctness of the LLM-generated APSRs, we propose an execution feedback-checking approach based o...
- **Link**: [Read Paper](https://arxiv.org/abs/2409.09288)
- **Labels**: static analysis, specification inference

## [LLM-Assisted Static Analysis for Detecting Security Vulnerabilities](paper_18.md)
- **Authors**: Li, Ziyang and Dutta, Saikat and Naik, Mayur
- **Abstract**: Software is prone to security vulnerabilities. Program analysis tools to detect them have limited effectiveness in practice due to their reliance on human labeled specifications. Large language models (or LLMs) have shown impressive code generation capabilities but they cannot do complex reasoning o...
- **Link**: [Read Paper](https://arxiv.org/abs/2405.17238)
- **Labels**: static analysis, bug detection

## [SpecGen: Automated Generation of Formal Program Specifications via Large Language Models](paper_19.md)
- **Authors**: Ma, Lezhi and Liu, Shangqing and Li, Yi and Xie, Xiaofei and Bu, Lei
- **Abstract**: In software development, formal program specifications play a crucial role in various stages. However, manually crafting formal program specifications is rather difficult, making the job time-consuming and labor-intensive. Moreover, it is even more challenging to write specifications that correctly ...
- **Link**: [Read Paper](https://arxiv.org/pdf/2401.08807.pdf)
- **Labels**: static analysis, specification inference

## [SpecEval: Evaluating Code Comprehension in Large Language Models via Program Specifications](paper_20.md)
- **Authors**: Ma, Lezhi and Liu, Shangqing and Bu, Lei and Li, Shangru and Wang, Yida and Liu, Yang
- **Abstract**: Large Language models have achieved impressive performance in automated software engineering. Extensive efforts have been made to evaluate the abilities of code LLMs in various aspects, with an increasing number of benchmarks and evaluation frameworks proposed. Apart from the most sought-after capab...
- **Link**: [Read Paper](https://arxiv.org/abs/2409.12866)
- **Labels**: static analysis, specification inference

## [Program Slicing in the Era of Large Language Models](paper_21.md)
- **Authors**: Shahandashti, Kimya Khakzad and Mohajer, Mohammad Mahdi and Belle, Alvine Boaye and Wang, Song and Hemmati, Hadi
- **Abstract**: Program slicing is a critical technique in software engineering, enabling developers to isolate relevant portions of code for tasks such as bug detection, code comprehension, and debugging. In this study, we investigate the application of large language models (LLMs) to both static and dynamic progr...
- **Link**: [Read Paper](https://arxiv.org/pdf/2409.12369)
- **Labels**: static analysis, fundamental analysis

## [Llm4fuzz: Guided fuzzing of smart contracts with large language models](paper_22.md)
- **Authors**: Shou, Chaofan and Liu, Jing and Lu, Doudou and Sen, Koushik
- **Abstract**: As blockchain platforms grow exponentially, millions of lines of smart contract code are being deployed to manage extensive digital assets. However, vulnerabilities in this mission-critical code have led to significant exploitations and asset losses. Thorough automated security analysis of smart con...
- **Link**: [Read Paper](https://arxiv.org/pdf/2401.11108.pdf)
- **Labels**: program testing, fuzzing

## [LLMorpheus: Mutation Testing using Large Language Models](paper_23.md)
- **Authors**: Tip, Frank and Bell, Jonathan and Sch{\"a}fer, Max
- **Abstract**: In mutation testing, the quality of a test suite is evaluated by introducing faults into a program and determining whether the program's tests detect them. Most existing approaches for mutation testing involve the application of a fixed set of mutation operators, e.g., replacing a "+" with a "-" or ...
- **Link**: [Read Paper](https://arxiv.org/pdf/2404.09952)
- **Labels**: program testing, mutation testing

## [Teams of LLM Agents can Exploit Zero-Day Vulnerabilities](paper_24.md)
- **Authors**: Fang, Richard and Bindu, Rohan and Gupta, Akul and Zhan, Qiusi and Kang, Daniel
- **Abstract**: LLM agents have become increasingly sophisticated, especially in the realm of cybersecurity. Researchers have shown that LLM agents can exploit real-world vulnerabilities when given a description of the vulnerability and toy capture-the-flag problems. However, these agents still perform poorly on re...
- **Link**: [Read Paper](https://arxiv.org/abs/2406.01637)
- **Labels**: program testing, vulnerability exploitation

## [Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models](paper_25.md)
- **Authors**: Zhang, Andy K and Perry, Neil and Dulepet, Riya and Ji, Joey and Lin, Justin W and Jones, Eliot and Menders, Celeste and Hussein, Gashon and Liu, Samantha and Jasper, Donovan and others
- **Abstract**: Language Model (LM) agents for cybersecurity that are capable of autonomously identifying vulnerabilities and executing exploits have the potential to cause real-world impact. Policymakers, model providers, and other researchers in the AI and cybersecurity communities are interested in quantifying t...
- **Link**: [Read Paper](https://arxiv.org/abs/2408.08926)
- **Labels**: program testing, vulnerability exploitation, benchmark

## [Large language model-based agents for software engineering: A survey](paper_26.md)
- **Authors**: Liu, Junwei and Wang, Kaixin and Chen, Yixuan and Peng, Xin and Chen, Zhenpeng and Zhang, Lingming and Lou, Yiling
- **Abstract**: The recent advance in Large Language Models (LLMs) has shaped a new paradigm of AI agents, i.e., LLM-based agents. Compared to standalone LLMs, LLM-based agents substantially extend the versatility and expertise of LLMs by enhancing LLMs with the capabilities of perceiving and utilizing external res...
- **Link**: [Read Paper](https://arxiv.org/pdf/2409.02977)
- **Labels**: survey, agent design

## [If llm is the wizard, then code is the wand: A survey on how code empowers large language models to serve as intelligent agents](paper_27.md)
- **Authors**: Yang, Ke and Liu, Jiateng and Wu, John and Yang, Chaoqi and Fung, Yi R and Li, Sha and Huang, Zixuan and Cao, Xu and Wang, Xingyao and Wang, Yiquan and others
- **Abstract**: The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executabl...
- **Link**: [Read Paper](https://arxiv.org/pdf/2401.00812.pdf)
- **Labels**: survey, agent design, reason with code

