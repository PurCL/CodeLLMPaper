# ICSE2025

Number of papers: 70

## [A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs](paper_52.md)
- **Authors**: Kim, Myeongsoo and Stennett, Tyler and Sinha, Saurabh and Orso, Alessandro
- **Abstract**: As modern web services increasingly rely on REST APIs, their thorough testing has become crucial. Furthermore, the advent of REST API documentation languages, such as the OpenAPI Specification, has led to the emergence of many black-box REST API testing tools. However, these tools often focus on individual test elements in isolation (e.g., APIs, parameters, values), resulting in lower coverage and less effectiveness in fault detection. To address these limitations, we present AutoRestTest, the f...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00179)
- **Labels**: [program testing](../../labels/program_testing.md), [library testing](../../labels/library_testing.md)


## [A Multiple Representation Transformer with Optimized Abstract Syntax Tree for Efficient Code Clone Detection](paper_23.md)
- **Authors**: Yu, Tianchen and Yuan, Li and Lin, Liannan and He, Hongkui
- **Abstract**: Over the past decade, the application of deep learning in code clone detection has produced remarkable results. However, the current approaches have two limitations: (a) code representation approaches with low information utilization, such as vanilla Abstract Syntax Tree (AST), leading to information redundancy which results in performance degradation; (b) low efficiency of clone detection on evaluation, resulting in excessive time costs during practical use. In this paper, we propose a Multiple...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00050)
- **Labels**: [code model](../../labels/code_model.md), [code model training](../../labels/code_model_training.md), [static analysis](../../labels/static_analysis.md), [code similarity analysis](../../labels/code_similarity_analysis.md)


## [Aligning the Objective of LLM-Based Program Repair](paper_49.md)
- **Authors**: Xu, Junjielong and Fu, Ying and Tan, Shin Hwei and He, Pinjia
- **Abstract**: Large language models (LLMs) have achieved decent results on automated program repair (APR). However, the next token prediction training objective of decoder-only LLMs (e.g., GPT-4) is misaligned with the masked span prediction objective of current infilling-style methods, which impedes LLMs from fully leveraging pre-trained knowledge for program repair. In addition, while some LLMs can locate and repair bugs in certain functions using the related artifacts (e.g., test cases), existing methods s...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00169)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [An Empirical Study on Automatically Detecting AI-Generated Source Code: How Far are We?](paper_25.md)
- **Authors**: Suh, Hyunjae and Tafreshipour, Mahan and Li, Jiawei and Bhattiprolu, Adithya and Ahmed, Iftekhar
- **Abstract**: Artificial Intelligence (AI) techniques, especially Large Language Models (LLMs), have started gaining popularity among researchers and software developers for generating source code. However, LLMs have been shown to generate code with quality issues and also incurred copyright/licensing infringements. Therefore, detecting whether a piece of source code is written by humans or AI has become necessary. This study first presents an empirical analysis to investigate the effectiveness of the existin...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00064)
- **Labels**: [code model](../../labels/code_model.md), [code model security](../../labels/code_model_security.md), [empirical study](../../labels/empirical_study.md)


## [An Empirical Study on Commit Message Generation Using LLMs via In-Context Learning](paper_30.md)
- **Authors**: Wu, Yifan and Wang, Yunpeng and Li, Ying and Tao, Wei and Yu, Siyu and Yang, Haowen and Jiang, Wei and Li, Jianguo
- **Abstract**: Commit messages concisely describe code changes in natural language and are important for software maintenance. Several approaches have been proposed to automatically generate commit messages, but they still suffer from critical limitations, such as time-consuming training and poor generalization ability. To tackle these limitations, we propose to borrow the weapon of large language models (LLMs) and in-context learning (ICL). Our intuition is based on the fact that the training corpora of LLMs ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00091)
- **Labels**: [software maintenance and deployment](../../labels/software_maintenance_and_deployment.md), [commit message generation](../../labels/commit_message_generation.md), [empirical study](../../labels/empirical_study.md)


## [An Exploratory Study of ML Sketches and Visual Code Assistants](paper_37.md)
- **Authors**: Gomes, Luis F. and Hellendoorn, Vincent J. and Aldrich, Jonathan and Abreu, Rui
- **Abstract**: This paper explores the integration of Visual Code Assistants in Integrated Development Environments (IDEs). In Software Engineering, whiteboard sketching is often the initial step before coding, serving as a crucial collaboration tool for developers. Previous studies have investigated patterns in SE sketches and how they are used in practice, yet methods for directly using these sketches for code generation remain limited. The emergence of visually-equipped large language models presents an opp...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00124)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md), [software maintenance and deployment](../../labels/software_maintenance_and_deployment.md)


## [An LLM-Based Agent-Oriented Approach for Automated Code Design Issue Localization](paper_33.md)
- **Authors**: Batole, Fraol and OBrien, David and Nguyen, Tien N. and Dyer, Robert and Rajan, Hridesh
- **Abstract**: Maintaining software design quality is crucial for the long-term maintainability and evolution of systems. However, design issues such as poor modularity and excessive complexity often emerge as codebases grow. Developers rely on external tools, such as program analysis techniques, to identify such issues. This work leverages Large Language Models (LLMs) to develop an automated approach for analyzing and localizing design issues. Large language models have demonstrated significant performance on...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00100)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md)


## [Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers](paper_9.md)
- **Authors**: Shi, Yuling and Zhang, Hongyu and Wan, Chengcheng and Gu, Xiaodong
- **Abstract**: Large language models have catalyzed an unprece-dented wave in code generation. While achieving significant advances, they blur the distinctions between machine- and human-authored source code, causing integrity and authenticity issues of software artifacts. Previous methods such as DetectGPthave proven effective in discerning machine-generated texts, but they do not identify and harness the unique patterns of machine-generated code. Thus, its applicability falters when applied to code. In this ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00005)
- **Labels**: [code model](../../labels/code_model.md)


## [Boosting Static Resource Leak Detection via LLM-based Resource-Oriented Intention Inference](paper_38.md)
- **Authors**: Wang, Chong and Liu, Jianan and Peng, Xin and Liu, Yang and Lou, Yiling
- **Abstract**: Resource leaks, caused by resources not being released after acquisition, often lead to performance issues and system crashes. Existing static detection techniques rely on mechanical matching of predefined resource acquisition/release APIs and null-checking conditions to find unreleased resources, suffering from both (1) false negatives caused by the incompleteness of predefined resource acquisition/release APIs and (2) false positives caused by the incompleteness of resource reachability valida...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00131)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md)


## [COCA: Generative Root Cause Analysis for Distributed Systems with Code Knowledge](paper_66.md)
- **Authors**: Li, Yichen and Wu, Yulun and Liu, Jinyang and Jiang, Zhihan and Chen, Zhuangbin and Yu, Guangba and Lyu, Michael R.
- **Abstract**: Runtime failures are commonplace in modern distributed systems. When such issues arise, users often turn to platforms such as Github or JIRA to report them and request assistance. Automatically identifying the root cause of these failures is critical for ensuring high reliability and availability. However, prevailing automatic root cause analysis (RCA) approaches rely significantly on comprehensive runtime monitoring data, which is often not fully available in issue platforms. Recent methods lev...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00234)
- **Labels**: [program testing](../../labels/program_testing.md), [debugging](../../labels/debugging.md), [bug reproduction](../../labels/bug_reproduction.md)


## [Calibration and Correctness of Language Models for Code](paper_20.md)
- **Authors**: Spiess, Claudio and Gros, David and Pai, Kunal Suresh and Pradel, Michael and Rabin, Md Rafiqul Islam and Alipour, Amin and Jha, Susmit and Devanbu, Prem and Ahmed, Toufique
- **Abstract**: Machine learning models are widely used, but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or not. For example, outputs can be associated with a confidence measure; if this confidence measure is strongly associated with likelihood of correctness, then the model is said to be well-calibrated. A well-calibrated confidence measure can serve as a basi...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00040)
- **Labels**: [code model](../../labels/code_model.md), [code model robustness](../../labels/code_model_robustness.md)


## [Chatgpt-Based Test Generation for Refactoring Engines Enhanced by Feature Analysis on Examples](paper_58.md)
- **Authors**: Dong, Chunhao and Jiang, Yanjie and Zhang, Yuxia and Zhang, Yang and Liu, Hui
- **Abstract**: Software refactoring is widely employed to improve software quality. However, conducting refactorings manually is tedious, time-consuming, and error-prone. Consequently, automated and semi-automated tool support is highly desirable for software refactoring in the industry, and most of the main-stream IDEs provide powerful tool support for refactoring. However, complex refactoring engines are prone to errors, which in turn may result in imperfect and incorrect refactorings. To this end, in this p...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00210)
- **Labels**: [program testing](../../labels/program_testing.md), [differential testing](../../labels/differential_testing.md)


## [Closing the Gap: A User Study on the Real-world Usefulness of AI-powered Vulnerability Detection & Repair in the IDE](paper_1.md)
- **Authors**: Benjamin Steenhoek, Kalpathy Sivaraman, Renata Saldivar Gonzalez, Yevhen Mohylevskyy, Roshanak Zilouchian Moghaddam, Wei Le
- **Abstract**: This paper presents the first empirical study of a vulnerability detection and fix tool with professional software developers on real projects that they own. We implemented DeepVulGuard, an IDE-integrated tool based on state-of-the-art detection and fix models, and show that it has promising performance on benchmarks of historic vulnerability data. DeepVulGuard scans code for vulnerabilities (including identifying the vulnerability type and vulnerable region of code), suggests fixes, provides na...
- **Link**: [Read Paper](https://www.arxiv.org/abs/2412.14306)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md), [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md), [empirical study](../../labels/empirical_study.md)


## [Clozemaster: Fuzzing Rust Compiler by Harnessing Llms for Infilling Masked Real Programs](paper_50.md)
- **Authors**: Gao, Hongyan and Yang, Yibiao and Sun, Maolin and Wu, Jiangchang and Zhou, Yuming and Xu, Baowen
- **Abstract**: Ensuring the reliability of the Rust compiler is of paramount importance, given increasing adoption of Rust for critical systems development, due to its emphasis on memory and thread safety. However, generating valid test programs for the Rust compiler poses significant challenges, given Rust's complex syntax and strict requirements. With the growing popularity of large language models (LLMs), much research in software testing has explored using LLMs to generate test cases. Still, directly using...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00175)
- **Labels**: [program testing](../../labels/program_testing.md), [fuzzing](../../labels/fuzzing.md), [compiler testing](../../labels/compiler_testing.md)


## [Code Comment Inconsistency Detection and Rectification Using a Large Language Model](paper_19.md)
- **Authors**: Rong, Guoping and Yu, Yongda and Liu, Song and Tan, Xin and Zhang, Tianyi and Shen, Haifeng and Hu, Jidong
- **Abstract**: Comments are widely used in source code. If a comment is consistent with the code snippet it intends to annotate, it would aid code comprehension. Otherwise, Code Comment Inconsistency (CCI) is not only detrimental to the understanding of code, but more importantly, it would negatively impact the development, testing, and maintenance of software. To tackle this issue, existing research has been primarily focused on detecting inconsistencies with varied performance. It is evident that detection a...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00035)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md)


## [CodeImprove: Program Adaptation for Deep Code Models](paper_42.md)
- **Authors**: Rathnasuriya, Ravishka and Zhao, Zijie and Yang, Wei
- **Abstract**: Leveraging deep learning (DL)-based code analysis tools to solve software engineering tasks is becoming increasingly popular. Code models often suffer performance degradation due to various reasons (e.g., code data shifts). Retraining is often required to address these issues, but frequent model updates are costly in labeling and deployment. In this paper, we explore an alternative solution: Adapting the program inputs to the code models. This can be achieved by two steps: 1) input validation th...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00139)
- **Labels**: [general coding task](../../labels/general_coding_task.md), [code generation](../../labels/code_generation.md), [code model](../../labels/code_model.md), [code model robustness](../../labels/code_model_robustness.md)


## [Combining Fine-Tuning and LLM-Based Agents for Intuitive Smart Contract Auditing with Justifications](paper_16.md)
- **Authors**: Ma, Wei and Wu, Daoyuan and Sun, Yuqiang and Wang, Tianwen and Liu, Shangqing and Zhang, Jian and Xue, Yue and Liu, Yang
- **Abstract**: Smart contracts are decentralized applications built atop blockchains like Ethereum. Recent research has shown that large language models (LLMs) have potential in auditing smart contracts, but the state-of-the-art indicates that even GPT-4 can achieve only 30% precision (when both decision and justification are correct). This is likely because off-the-shelf LLMs were primarily pre-trained on a general text/code corpus and not fine-tuned on the specific domain of Solidity smart contract auditing....
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00027)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md)


## [Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing with Justifications](paper_6.md)
- **Authors**: Ma, Wei and Wu, Daoyuan and Sun, Yuqiang and Wang, Tianwen and Liu, Shangqing and Zhang, Jian and Xue, Yue and Liu, Yang
- **Abstract**: Smart contracts are decentralized applications built atop blockchains like Ethereum. Recent research has shown that large language models (LLMs) have potential in auditing smart contracts, but the state-of-the-art indicates that even GPT-4 can achieve only 30% precision (when both decision and justification are correct). This is likely because off-the-shelf LLMs were primarily pre-trained on a general text/code corpus and not fine-tuned on the specific domain of Solidity smart contract auditing....
- **Link**: [Read Paper](https://arxiv.org/pdf/2403.16073)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md), [agent design](../../labels/agent_design.md)


## [Decoding Secret Memorization in Code LLMs Through Token-Level Characterization](paper_63.md)
- **Authors**: Nie, Yuqing and Wang, Chong and Wang, Kailong and Xu, Guoai and Xu, Guosheng and Wang, Haoyu
- **Abstract**: Code Large Language Models (LLMs) have demonstrated remarkable capabilities in generating, understanding, and manipulating programming code. However, their training process inadvertently leads to the memorization of sensitive information, posing severe privacy risks. Existing studies on memorization in LLMs primarily rely on prompt engineering techniques, which suffer from limitations such as widespread hallucination and inefficient extraction of the target sensitive information. In this paper, ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00229)
- **Labels**: [code model](../../labels/code_model.md), [code model security](../../labels/code_model_security.md)


## [DesignRepair: Dual-Stream Design Guideline-Aware Frontend Repair with Large Language Models](paper_36.md)
- **Authors**: Yuan, Mingyue and Chen, Jieshan and Xing, Zhenchang and Quigley, Aaron and Luo, Yuyu and Luo, Tianqi and Mohammadi, Gelareh and Lu, Qinghua and Zhu, Liming
- **Abstract**: The rise of Large Language Models (LLMs) has streamlined frontend interface creation through tools like Vercel's v0, yet surfaced challenges in design quality (e.g., accessibility, and usability). Current solutions, often limited by their focus, generalisability, or data dependency, fall short in addressing these complexities. Moreover, none of them examine the quality of LLM-generated UI design. In this work, we introduce DesignRepair, a novel dual-stream design guideline-aware system to examin...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00109)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [Does GenAI Make Usability Testing Obsolete?](paper_41.md)
- **Authors**: Pourasad, Ali Ebrahimi and Maalej, Walid
- **Abstract**: Ensuring usability is crucial for the success of mobile apps. Usability issues can compromise user experience and negatively impact the perceived app quality. This paper presents UX-LLM, a novel tool powered by a Large Vision-Language Model that predicts usability issues in iOS apps. To evaluate the performance of UX-LLM, we predicted usability issues in two open-source apps of a medium complexity and asked two usability experts to assess the predictions. We also performed traditional usability ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00138)
- **Labels**: [program testing](../../labels/program_testing.md)


## [Enhancing Code Generation via Bidirectional Comment-Level Mutual Grounding](paper_48.md)
- **Authors**: Di, Yifeng and Zhang, Tianyi
- **Abstract**: Large Language Models (LLMs) have demonstrated unprecedented capability in code generation. However, LLM-generated code is still plagued with a wide range of functional errors, especially for complex programming tasks that LLMs have not seen before. Recent studies have shown that developers often struggle with inspecting and fixing incorrect code generated by LLMs, diminishing their productivity and trust in LLM-based code generation. Inspired by the mutual grounding theory in communication, we ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00165)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md)


## [FIXDRIVE: Automatically Repairing Autonomous Vehicle Driving Behaviour for $0.08 per Violation](paper_60.md)
- **Authors**: Sun, Yang and Poskitt, Christopher M. and Wang, Kun and Sun, Jun
- **Abstract**: Autonomous Vehicles (AVs) are advancing rapidly, with Level-4 AVs already operating in real-world conditions. Current AVs, however, still lag behind human drivers in adaptability and performance, often exhibiting overly conservative behaviours and occasionally violating traffic laws. Existing solutions, such as runtime enforcement, mitigate this by automatically repairing the AV's planned trajectory at runtime, but such approaches lack transparency and should be a measure of last resort. It woul...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00216)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [Fixing Large Language Models' Specification Misunderstanding for Better Code Generation](paper_35.md)
- **Authors**: Tian, Zhao and Chen, Junjie and Zhang, Xiangyu
- **Abstract**: Code generation is to automatically generate source code conforming to a given programming specification, which has received extensive attention especially with the development of large language models (LLMs). Due to the inherent difficulty of code generation, the code generated by LLMs may not be aligned with the specification. Although thought-eliciting prompting techniques have been proposed to enhance the code generation performance of LLMs, producing correct understanding for complicated pr...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00108)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [HumanEvo: An Evolution-Aware Benchmark for More Realistic Evaluation of Repository-Level Code Generation](paper_62.md)
- **Authors**: Zheng, Dewu and Wang, Yanlin and Shi, Ensheng and Zhang, Ruikai and Ma, Yuchi and Zhang, Hongyu and Zheng, Zibin
- **Abstract**: To evaluate the repository-level code generation capabilities of Large Language Models (LLMs) in complex real-world software development scenarios, many evaluation methods have been developed. These methods typically leverage contextual code from the latest version of a project to assist LLMs in accurately generating the desired function. However, such evaluation methods fail to consider the dynamic evolution of software projects over time, which we refer to as evolution-ignored settings. This i...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00228)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md), [empirical study](../../labels/empirical_study.md), [benchmark](../../labels/benchmark.md)


## [Hyperion: Unveiling DApp Inconsistencies Using LLM and Dataflow-Guided Symbolic Execution](paper_11.md)
- **Authors**: Yang, Shuo and Lin, Xingwei and Chen, Jiachi and Zhong, Qingyuan and Xiao, Lei and Huang, Renke and Wang, Yanlin and Zheng, Zibin
- **Abstract**: The rapid advancement of blockchain platforms has significantly accelerated the growth of decentralized applications (DApps). Similar to traditional applications, DApps integrate front-end descriptions that showcase their features to attract users, and back-end smart contracts for executing their business logic. However, inconsistencies between the features promoted in front-end descriptions and those actually implemented in the contract can confuse users and undermine DApps's trustworthiness. I...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00015)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md)


## [INTERTRANS: Leveraging Transitive Intermediate Translations to Enhance LLM-Based Code Translation](paper_67.md)
- **Authors**: Macedo, Marcos and Tian, Yuan and Nie, Pengyu and Cogo, Filipe R. and Adams, Bram
- **Abstract**: Code translation aims to convert a program from one programming language (PL) to another. This long-standing software engineering task is crucial for modernizing legacy systems, ensuring cross-platform compatibility, enhancing performance, and more. However, automating this process remains challenging due to many syntactic and semantic differences between PLs. Recent studies show that even advanced techniques such as large language models (LLMs), especially open-source LLMs, still struggle with ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00236)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md)


## [Intention is All you Need: Refining your Code from your Intention](paper_55.md)
- **Authors**: Guo, Qi and Xie, Xiaofei and Liu, Shangqing and Hu, Ming and Li, Xiaohong and Bu, Lei
- **Abstract**: Code refinement aims to enhance existing code by addressing issues, refactoring, and optimizing to improve quality and meet specific requirements. As software projects scale in size and complexity, the traditional iterative exchange between re-viewers and developers becomes increasingly burdensome. While recent deep learning techniques have been explored to accelerate this process, their performance remains limited, primarily due to challenges in accurately understanding reviewers' intents. This...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00191)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md), [static analysis](../../labels/static_analysis.md), [code summarization](../../labels/code_summarization.md)


## [Iterative Generation of Adversarial Example for Deep Code Models](paper_27.md)
- **Authors**: Huang, Li and Sun, Weifeng and Yan, Meng
- **Abstract**: Deep code models are vulnerable to adversarial attacks, making it possible for semantically identical inputs to trigger different responses. Current black-box attack methods typically prioritize the impact of identifiers on the model based on custom importance scores or program context and incrementally replace identifiers to generate adversarial examples. However, these methods often fail to fully leverage feedback from failed attacks to guide subsequent attacks, resulting in problems such as l...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00086)
- **Labels**: [code model](../../labels/code_model.md), [code model robustness](../../labels/code_model_robustness.md)


## [Knowledge-Enhanced Program Repair for Data Science Code](paper_69.md)
- **Authors**: Ouyang, Shuyin and Zhang, Jie M. and Sun, Zeyu and Penuela, Albert Merono
- **Abstract**: This paper introduces DSrepair, a knowledge-enhanced program repair approach designed to repair the buggy code generated by LLMs in the data science domain. DSrepair uses knowledge graph based RAG for API knowledge retrieval and bug knowledge enrichment to construct repair prompts for LLMs. Specifically, to enable knowledge graph-based API retrieval, we construct DS-KG (Data Science Knowledge Graph) for widely used data science libraries. For bug knowledge enrichment, we employ an abstract synta...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00246)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [LLM Assistance for Memory Safety](paper_15.md)
- **Authors**: Mohammed, Nausheen and Lal, Akash and Rastogi, Aseem and Sharma, Rahul and Roy, Subhajit
- **Abstract**: Memory safety violations in low-level code, written in languages like C, continues to remain one of the major sources of software vulnerabilities. One method of removing such violations by construction is to port C code to a safe C dialect. Such dialects rely on programmer-supplied annotations to guarantee safety with minimal runtime overhead. This porting, however, is a manual process that imposes significant burden on the programmer and, hence, there has been limited adoption of this technique...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00023)
- **Labels**: [code generation](../../labels/code_generation.md), [program transformation](../../labels/program_transformation.md), [static analysis](../../labels/static_analysis.md), [specification inference](../../labels/specification_inference.md)


## [LLM Based Input Space Partitioning Testing for Library APIs](paper_45.md)
- **Authors**: Li, Jiageng and Dong, Zhen and Wang, Chong and You, Haozhen and Zhang, Cen and Liu, Yang and Peng, Xin
- **Abstract**: Automated library APIs testing is difficult as it requires exploring a vast space of parameter inputs that may involve objects with complex data types. Existing search based approaches, with limited knowledge of relations between object states and program branches, often suffer from the low efficiency issue, i.e., tending to generate invalid inputs. Symbolic execution based approaches can effectively identify such relations, but fail to scale to large programs. In this work, we present an LLM-ba...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00153)
- **Labels**: [program testing](../../labels/program_testing.md), [library testing](../../labels/library_testing.md)


## [LLM-Aided Automatic Modeling for Security Protocol Verification](paper_56.md)
- **Authors**: Mao, Ziyu and Wang, Jingyi and Sun, Jun and Qin, Shengchao and Xiong, Jiawen
- **Abstract**: Symbolic protocol analysis serves as a pivotal technique for protocol design, security analysis, and the safeguarding of information assets. Several modern tools such as Tamarin and ProVerif have been proven successful in modeling and verifying real-world protocols, including complex protocols like TLS 1.3 and 5G AKA. However, developing formal models for protocol verification is a non-trivial task, which hinders the wide adoption of these powerful tools in practical protocol analysis. In this w...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00197)
- **Labels**: [static analysis](../../labels/static_analysis.md), [program verification](../../labels/program_verification.md)


## [LLM-based Resource-Oriented Intention Inference for Static Resource Detection](paper_5.md)
- **Authors**: Wang, Chong and Liu, Jianan and Peng, Xin and Liu, Yang and Lou, Yiling
- **Abstract**: Resource leaks, caused by resources not being released after acquisition, often lead to performance issues and system crashes. Existing static detection techniques rely on mechanical matching of predefined resource acquisition/release APIs and null-checking conditions to find unreleased resources, suffering from both (1) false negatives caused by the incompleteness of predefined resource acquisition/release APIs and (2) false positives caused by the unsoundness of resource reachability validatio...
- **Link**: [Read Paper](https://arxiv.org/abs/2311.04448)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md)


## [LLMs Meet Library Evolution: Evaluating Deprecated API Usage in LLM-Based Code Completion](paper_68.md)
- **Authors**: Wang, Chong and Huang, Kaifeng and Zhang, Jian and Feng, Yebo and Zhang, Lyuye and Liu, Yang and Peng, Xin
- **Abstract**: Large language models (LLMs), pre-trained or fine-tuned on large code corpora, have shown effectiveness in generating code completions. However, in LLM-based code completion, LLMs may struggle to use correct and up-to-date Application Programming Interfaces (APIs) due to the rapid and continuous evolution of libraries. While existing studies have highlighted issues with predicting incorrect APIs, the specific problem of deprecated API usage in LLM-based code completion has not been thoroughly in...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00245)
- **Labels**: [code generation](../../labels/code_generation.md), [code completion](../../labels/code_completion.md)


## [LWDIFF: an LLM-Assisted Differential Testing Framework for Webassembly Runtimes](paper_65.md)
- **Authors**: Zhou, Shiyao and Wang, Jincheng and Ye, He and Zhou, Hao and Goues, Claire Le and Luo, Xiapu
- **Abstract**: WebAssembly (Wasm) runtimes execute Wasm programs, a popular low-level language for efficiently executing high-level languages in browsers, with broad applications across diverse domains. The correctness of those runtimes is critical for both functionality and security of Wasm execution, motivating testing approaches that target Wasm runtimes specifically. However, existing Wasm testing frameworks fail to generate test cases that effectively test all three phases of runtime, i.e., decoding, vali...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00233)
- **Labels**: [program testing](../../labels/program_testing.md), [differential testing](../../labels/differential_testing.md)


## [Large Language Models for Safe Minimization](paper_57.md)
- **Authors**: Yadavally, Aashish and Rong, Xiaokai and Nguyen, Phat and Nguyen, Tien N.
- **Abstract**: Several tasks in program analysis, verification, and testing are modeled as constraint solving problems, utilizing SMT solvers as the reasoning engine. In this work, we aim to investigate the reasoning capabilities of large language models (LLMs) toward reducing the size of an infeasible string constraint system by exploiting inter-constraint interactions such that the remaining ones are still unsatisfiable. We term this safe minimization. Motivated by preliminary observations of hallucination a...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00203)
- **Labels**: [static analysis](../../labels/static_analysis.md), [program verification](../../labels/program_verification.md)


## [Leveraging Large Language Models to Detect NPM Malicious Packages](paper_44.md)
- **Authors**: Zahan, Nusrat and Burckhardt, Philipp and Lysenko, Mikola and Aboukhadijeh, Feross and Williams, Laurie
- **Abstract**: Existing malicious code detection techniques demand the integration of multiple tools to detect different malware patterns, often suffering from high misclassification rates. Therefore, malicious code detection techniques could be enhanced by adopting advanced, more automated approaches to achieve high accuracy and a low misclassification rate. The goal of this study is to aid security analysts in detecting malicious packages by empirically studying the effectiveness of Large Language Models (LL...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00146)
- **Labels**: [program testing](../../labels/program_testing.md), [bug detection](../../labels/bug_detection.md)


## [LiSSA: Toward Generic Traceability Link Recovery Through Retrieval- Augmented Generation](paper_54.md)
- **Authors**: FuchB, Dominik and Hey, Tobias and Keim, Jan and Liu, Haoyu and Ewald, Niklas and Thirolf, Tobias and Koziolek, Anne
- **Abstract**: There are a multitude of software artifacts which need to be handled during the development and maintenance of a software system. These artifacts interrelate in multiple, complex ways. Therefore, many software engineering tasks are enabled - and even empowered - by a clear understanding of artifact interrelationships and also by the continued advancement of techniques for automated artifact linking. However, current approaches in automatic Traceability Link Recovery (TLR) target mostly the links...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00186)
- **Labels**: [software maintenance and deployment](../../labels/software_maintenance_and_deployment.md), [static analysis](../../labels/static_analysis.md), [code summarization](../../labels/code_summarization.md), [code search](../../labels/code_search.md)


## [Licoeval: Evaluating LLMs on License Compliance in Code Generation](paper_24.md)
- **Authors**: Xu, Weiwei and Gao, Kai and He, Hao and Zhou, Minghui
- **Abstract**: Recent advances in Large Language Models (LLMs) have revolutionized code generation, leading to widespread adoption of AI coding tools by developers. However, LLMs can generate license-protected code without providing the necessary license information, leading to potential intellectual property violations during software production. This paper addresses the critical, yet underexplored, issue of license compliance in LLM-generated code by establishing a benchmark to evaluate the ability of LLMs t...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00052)
- **Labels**: [empirical study](../../labels/empirical_study.md), [code generation](../../labels/code_generation.md)


## [Metamorphic-Based Many-Objective Distillation of LLMs for Code-Related Tasks](paper_64.md)
- **Authors**: Panichella, Annibale
- **Abstract**: Knowledge distillation compresses large language models (LLMs) into more compact and efficient versions that achieve similar accuracy on code-related tasks. However, as we demonstrate in this study, compressed models are four times less robust than the original LLMs when evaluated with metamorphic code. They exhibit a $\mathbf{4 4 0 \%}$ higher probability of misclassifying code clones due to minor changes in the code fragment under analysis, such as replacing parameter names with synonyms. To a...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00230)
- **Labels**: [code model](../../labels/code_model.md), [code model training](../../labels/code_model_training.md), [code model robustness](../../labels/code_model_robustness.md)


## [Model Editing for LLMs4Code: How Far are we?](paper_22.md)
- **Authors**: Li, Xiaopeng and Wang, Shangwen and Li, Shasha and Ma, Jun and Yu, Jie and Liu, Xiaodong and Wang, Jing and Ji, Bin and Zhang, Weimin
- **Abstract**: Large Language Models for Code (LLMs4Code) have been found to exhibit outstanding performance in the software engineering domain, especially the remarkable performance in coding tasks. However, even the most advanced LLMs4Code can inevitably contain incorrect or outdated code knowledge. Due to the high cost of training LLMs4Code, it is impractical to re-train the models for fixing these problematic code knowledge. Model editing is a new technical field for effectively and efficiently correcting ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00049)
- **Labels**: [code model](../../labels/code_model.md), [benchmark](../../labels/benchmark.md), [empirical study](../../labels/empirical_study.md)


## [NIODebugger: A Novel Approach to Repair Non-Idempotent-Outcome Tests with LLM-Based Agent](paper_61.md)
- **Authors**: Ke, Kaiyao
- **Abstract**: Flaky tests, characterized by inconsistent results across repeated executions, present significant challenges in software testing, especially during regression testing. Recently, there has been emerging research interest in non-idempotentoutcome (NIO) flaky tests-tests that pass on the initial run but fail on subsequent executions within the same environment. Despite progress in utilizing Large Language Models (LLMs) to address flaky tests, existing methods have not tackled NIO flaky tests. The ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00226)
- **Labels**: [program testing](../../labels/program_testing.md), [debugging](../../labels/debugging.md), [bug reproduction](../../labels/bug_reproduction.md), [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [Neurosymbolic Modular Refinement Type Inference](paper_29.md)
- **Authors**: Sakkas, Georgios and Sahu, Pratyush and Ong, Kyeling and Jhala, Ranjit
- **Abstract**: Refinement types, a type-based generalization of Floyd-Hoare logics, are an expressive and modular means of statically ensuring a wide variety of correctness, safety, and security properties of software. However, their expressiveness and modularity means that to use them, a developer must laboriously annotate all the functions in their code with potentially complex type specifications that specify the contract for that function. We present LHC, a neurosymbolic agent that uses LLMs to automatical...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00090)
- **Labels**: [static analysis](../../labels/static_analysis.md), [type inference](../../labels/type_inference.md)


## [Planning a Large Language Model for Static Detection of Runtime Errors in Code Snippets](paper_34.md)
- **Authors**: Patel, Smit and Yadavally, Aashish and Dhulipala, Hridya and Nguyen, Tien N.
- **Abstract**: Large Language Models (LLMs) have been excellent in generating and reasoning about source code and natural-language texts. They can recognize patterns, syntax, and semantics in code, making them effective in several software engineering tasks. However, they exhibit weaknesses in reasoning about the program execution. They primarily operate on static code representations, failing to capture the dynamic behavior and state changes that occur during program execution. In this paper, we advance the c...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00102)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md)


## [QEDCartographer: Automating Formal Verification Using Reward-Free Reinforcement Learning](paper_3.md)
- **Authors**: Alex Sanchez-Stern, Abhishek Varghese, Zhanna Kaufman, Dylan Zhang, Talia Ringer, Yuriy Brun
- **Abstract**: Formal verification is a promising method for producing reliable software, but the difficulty of manually writing verification proofs severely limits its utility in practice. Recent methods have automated some proof synthesis by guiding a search through the proof space using a theorem prover. Unfortunately, the theorem prover provides only the crudest estimate of progress, resulting in effectively undirected search. To address this problem, we create QEDCartographer, an automated proof-synthesis...
- **Link**: [Read Paper](https://arxiv.org/abs/2408.09237)
- **Labels**: [static analysis](../../labels/static_analysis.md), [program verification](../../labels/program_verification.md)


## [ROCODE: Integrating Backtracking Mechanism and Program Analysis in Large Language Models for Code Generation](paper_40.md)
- **Authors**: Jiang, Xue and Dong, Yihong and Tao, Yongding and Liu, Huanyu and Jin, Zhi and Li, Ge
- **Abstract**: Large language models (LLMs) have achieved impressive performance in code generation recently, offering programmers revolutionary assistance in software development. However, due to the auto-regressive nature of LLMs, they are susceptible to error accumulation during code generation. Once an error is produced, LLMs can merely continue to generate the subsequent code conditioned on it, given their inability to adjust previous outputs. Existing LLM-based approaches typically consider post-revising...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00133)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md), [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md)


## [Reasoning Runtime Behavior of a Program with LLM: How Far are We?](paper_10.md)
- **Authors**: Chen, Junkai and Pan, Zhiyuan and Hu, Xing and Li, Zhenhao and Li, Ge and Xia, Xin
- **Abstract**: Large language models for code (i.e., code LLMs) have shown strong code understanding and generation capabilities. To evaluate the capabilities of code LLMs in various aspects, many benchmarks have been proposed (e.g., HumanEval and ClassEval). Code reasoning is one of the most essential abilities of code LLMs (i.e., predicting code execution behaviors such as program output and execution path), but existing benchmarks for code reasoning are not sufficient. Typically, they focus on predicting th...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00012)
- **Labels**: [program testing](../../labels/program_testing.md), [debugging](../../labels/debugging.md), [benchmark](../../labels/benchmark.md), [empirical study](../../labels/empirical_study.md)


## [RepairAgent: An Autonomous, LLM-Based Agent for Program Repair](paper_46.md)
- **Authors**: Bouzenia, Islem and Devanbu, Premkumar and Pradel, Michael
- **Abstract**: Automated program repair has emerged as a powerful technique to mitigate the impact of software bugs on system reliability and user experience. This paper introduces Repair Agent, the first work to address the program repair challenge through an autonomous agent based on a large language model (LLM). Unlike existing deep learning-based approaches, which prompt a model with a fixed prompt or in a fixed feedback loop, our work treats the LLM as an agent capable of autonomously planning and executi...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00157)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md), [agent design](../../labels/agent_design.md)


## [Revisiting Unnaturalness for Automated Program Repair in the Era of Large Language Models](paper_28.md)
- **Authors**: Yang, Aidan Z.H. and Kolak, Sophia and Hellendoorn, Vincent and Martins, Ruben and Goues, Claire Le
- **Abstract**: The problem of software quality has motivated the development of a variety of techniques for Automatic Program Repair (APR). Meanwhile, recent advances in AI and Large Language Models (LLMs) have produced orders of magnitude performance improvements over previous code generation techniques, affording promising opportunities for program repair and its constituent subproblems (e.g., fault localization, patch generation). Because models are trained on large volumes of code in which defects are rela...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00089)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [Rug: Turbo Llm for Rust Unit Test Generation](paper_31.md)
- **Authors**: Cheng, Xiang and Sang, Fan and Zhai, Yizhuo and Zhang, Xiaokuan and Kim, Taesoo
- **Abstract**: Unit testing improves software quality by evaluating isolated sections of the program. This approach alleviates the need for comprehensive program-wide testing and confines the potential error scope within the software. However, unit test development is time-consuming, requiring developers to create appropriate test contexts and determine input values to cover different code regions. This problem is particularly pronounced in Rust due to its intricate type system, making traditional unit test ge...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00097)
- **Labels**: [program testing](../../labels/program_testing.md), [unit testing](../../labels/unit_testing.md), [fuzzing](../../labels/fuzzing.md)


## [RustAssistant: Using LLMs to Fix Compilation Errors in Rust Code](paper_14.md)
- **Authors**: Deligiannis, Pantazis and Lal, Akash and Mehrotra, Nikita and Poddar, Rishi and Rastogi, Aseem
- **Abstract**: The Rust programming language, with its safety guarantees, has established itself as a viable choice for low-level systems programming language over the traditional, unsafe alternatives like C/C++. These guarantees come from a strong ownership-based type system, as well as primitive support for features like closures, pattern matching, etc., that make the code more concise and amenable to reasoning. These unique Rust features also pose a steep learning curve for programmers. This paper presents ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00022)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents](paper_43.md)
- **Authors**: Lin, Feng and Kim, Dong Jae and Chen, Tse-Hsun
- **Abstract**: Software process models are essential to facilitate collaboration and communication among software teams to solve complex development tasks. Inspired by these software engineering practices, we present FlowGen - a code generation framework that emulates software process models based on multiple Large Language Model (LLM) agents. We emulate three process models, FlowGenWaterfall, FlowGenTDD, and FlowGenScrum, by assigning LLM agents to embody roles (i.e., requirement engineer, architect, develope...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00140)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md), [agent design](../../labels/agent_design.md)


## [Search-Based LLMs for Code Optimization](paper_13.md)
- **Authors**: Gao, Shuzheng and Gao, Cuiyun and Gu, Wenchao and Lyu, Michael R.
- **Abstract**: The code written by developers usually suffers from efficiency problems and contain various performance bugs. These inefficiencies necessitate the research of automated refactoring methods for code optimization. Early research in code optimization employs rule-based methods and focuses on specific inefficiency issues, which are labor-intensive and suffer from the low coverage issue. Recent work regards the task as a sequence generation problem, and resorts to deep learning (DL) techniques such a...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00021)
- **Labels**: [code generation](../../labels/code_generation.md), [program transformation](../../labels/program_transformation.md), [static analysis](../../labels/static_analysis.md), [program optimization](../../labels/program_optimization.md)


## [Show Me Your Code! Kill Code Poisoning: A Lightweight Method Based on Code Naturalness](paper_70.md)
- **Authors**: Sun, Weisong and Chen, Yuchen and Yuan, Mengzhe and Fang, Chunrong and Chen, Zhenpeng and Wang, Chong and Liu, Yang and Xu, Baowen and Chen, Zhenyu
- **Abstract**: Neural code models (NCMs) have demonstrated extraordinary capabilities in code intelligence tasks. Meanwhile, the security of NCMs and NCMs-based systems has garnered increasing attention. In particular, NCMs are often trained on large-scale data from potentially untrustworthy sources, providing attackers with the opportunity to manipulate them by inserting crafted samples into the data. This type of attack is called a code poisoning attack (also known as a backdoor attack). It allows attackers ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00247)
- **Labels**: [code model](../../labels/code_model.md), [code model security](../../labels/code_model_security.md)


## [Source Code Summarization in the Era of Large Language Models](paper_18.md)
- **Authors**: Sun, Weisong and Miao, Yun and Li, Yuekang and Zhang, Hongyu and Fang, Chunrong and Liu, Yi and Deng, Gelei and Liu, Yang and Chen, Zhenyu
- **Abstract**: To support software developers in understanding and maintaining programs, various automatic (source) code summarization techniques have been proposed to generate a concise natural language summary (i.e., comment) for a given code snippet. Recently, the emergence of large language models (LLMs) has led to a great boost in the performance of coderelated tasks. In this paper, we undertake a systematic and comprehensive study on code summarization in the era of LLMs, which covers multiple aspects in...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00034)
- **Labels**: [static analysis](../../labels/static_analysis.md), [code summarization](../../labels/code_summarization.md), [empirical study](../../labels/empirical_study.md)


## [SpecGen: Automated Generation of Formal Program Specifications via Large Language Models](paper_7.md)
- **Authors**: Ma, Lezhi and Liu, Shangqing and Li, Yi and Xie, Xiaofei and Bu, Lei
- **Abstract**: In the software development process, formal program specifications play a crucial role in various stages, including requirement analysis, software testing, and verification. However, manually crafting formal program specifications is rather difficult, making the job time-consuming and labor-intensive. Moreover, it is even more challenging to write specifications that correctly and comprehensively describe the semantics of complex programs. To reduce the burden on software developers, automated s...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00129)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md), [static analysis](../../labels/static_analysis.md), [specification inference](../../labels/specification_inference.md), [program verification](../../labels/program_verification.md)


## [SpecRover: Code Intent Extraction via LLMs](paper_2.md)
- **Authors**: Ruan, Haifeng and Zhang, Yuntong and Roychoudhury, Abhik
- **Abstract**: Autonomous program improvement typically involves automatically producing bug fixes and feature additions. Such program improvement can be accomplished by a combination of large language model (LLM) and program analysis capabilities, in the form of an LLM agent. Since program repair or program improvement typically requires a specification of intended behavior - specification inference can be useful for producing high quality program patches. In this work, we examine efficient and low-cost workf...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00080)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md), [static analysis](../../labels/static_analysis.md), [specification inference](../../labels/specification_inference.md)


## [TIGER: A Generating-Then-Ranking Framework for Practical Python Type Inference](paper_12.md)
- **Authors**: Wang, Chong and Zhang, Jian and Lou, Yiling and Liu, Mingwei and Sun, Weisong and Liu, Yang and Peng, Xin
- **Abstract**: Python's dynamic typing system offers flexibility and expressiveness but can lead to type-related errors, prompting the need for automated type inference to enhance type hinting. While existing learning-based approaches show promising inference accuracy, they struggle with practical challenges in comprehensively handling various types, including complex parameterized types and (unseen) user-defined types. In this paper, we introduce TIGER, a two-stage generating-then-ranking (GTR) framework, des...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00019)
- **Labels**: [static analysis](../../labels/static_analysis.md), [type inference](../../labels/type_inference.md)


## [TOGLL: Correct and Strong Test Oracle Generation with LLMS](paper_32.md)
- **Authors**: Hossain, Soneya Binta and Dwyer, Matthew B.
- **Abstract**: Test oracles play a crucial role in software testing, enabling effective bug detection. Despite initial promise, neural methods for automated test oracle generation often result in a large number of false positives and weaker test oracles. While LLMs have shown impressive effectiveness in various software engineering tasks, including code generation, test case creation, and bug fixing, there remains a notable absence of large-scale studies exploring their effectiveness in test oracle generation....
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00098)
- **Labels**: [program testing](../../labels/program_testing.md), [empirical study](../../labels/empirical_study.md)


## [Template-Guided Program Repair in the Era of Large Language Models](paper_17.md)
- **Authors**: Huang, Kai and Zhang, Jian and Meng, Xiangxin and Liu, Yang
- **Abstract**: Recent advancements in automated program repair (APR) have been significantly driven by the application of Large Language Models (LLMs). In particular, the integration of LLMs with traditional template-based repair methods has demonstrated effective outcomes. Despite this, the synergy between the strengths of traditional methods and LLMs remains underexploited. This oversight originates from the indiscriminate use of templates and their insufficient coverage. Also, using small-scale LLMs within ...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00030)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [The Fact Selection Problem in LLM-Based Program Repair](paper_47.md)
- **Authors**: Parasaram, Nikhil and Yan, Huijie and Yang, Boyu and Flahy, Zineb and Qudsi, Abriele and Ziaber, Damian and Barr, Earl T. and Mechtaev, Sergey
- **Abstract**: Recent research has shown that incorporating bug-related facts, such as stack traces and GitHub issues, into prompts enhances the bug-fixing capabilities of large language models (LLMs). Considering the ever-increasing context window of these models, a critical question arises: what and how many facts should be included in prompts to maximise the chance of correctly fixing bugs? To answer this question, we conducted a large-scale study, employing over 19K prompts featuring various combinations o...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00162)
- **Labels**: [code generation](../../labels/code_generation.md), [program repair](../../labels/program_repair.md)


## [The Seeds of the Future Sprout from History: Fuzzing for Unveiling Vulnerabilities in Prospective Deep-Learning Libraries](paper_39.md)
- **Authors**: Li, Zhiyuan and Wu, Jingzheng and Ling, Xiang and Luo, Tianyue and Rui, Zhiqing and Wu, Yanjun
- **Abstract**: The widespread application of large language models (LLMs) underscores the importance of deep learning (DL) technologies that rely on foundational DL libraries such as PyTorch and TensorFlow. Despite their robust features, these libraries face challenges with scalability and adaptation to rapid advancements in the LLM community. In response, tech giants like Apple and Huawei are developing their own DL libraries to enhance performance, increase scalability, and safeguard intellectual property. E...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00132)
- **Labels**: [program testing](../../labels/program_testing.md), [fuzzing](../../labels/fuzzing.md), [vulnerability exploitation](../../labels/vulnerability_exploitation.md)


## [Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming](paper_8.md)
- **Authors**: Chakraborty, Saikat and Ebner, Gabriel and Bhat, Siddharth and Fakhoury, Sarah and Fatima, Sakina and Lahiri, Shuvendu and Swamy, Nikhil
- **Abstract**: Proof-oriented programs mix computational content with proofs of program correctness. However, the human effort involved in programming and proving is still substantial, despite the use of Satisfiability Modulo Theories (SMT) solvers to automate proofs in languages such as F*. Seeking to spur research on using AI to automate the construction of proof-oriented programs, we curate a dataset of 600K lines of open-source F* programs and proofs, including software used in production systems ranging f...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00002)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md), [static analysis](../../labels/static_analysis.md), [program verification](../../labels/program_verification.md), [benchmark](../../labels/benchmark.md), [empirical study](../../labels/empirical_study.md)


## [Towards Understanding the Characteristics of Code Generation Errors Made by Large Language Models](paper_53.md)
- **Authors**: Wang, Zhijie and Zhou, Zijie and Song, Da and Huang, Yuheng and Chen, Shengmai and Ma, Lei and Zhang, Tianyi
- **Abstract**: Large Language Models (LLMs) have demonstrated unprecedented capabilities in code generation. However, there remains a limited understanding of code generation errors that LLMs can produce. To bridge the gap, we conducted an in-depth analysis of code generation errors across six representative LLMs on the HumanEval dataset. Specifically, we first employed open coding and thematic analysis to distill a comprehensive taxonomy of code generation errors. We analyzed two dimensions of error character...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00180)
- **Labels**: [code generation](../../labels/code_generation.md), [program synthesis](../../labels/program_synthesis.md), [empirical study](../../labels/empirical_study.md)


## [Treefix: Enabling Execution with a Tree of Prefixes](paper_59.md)
- **Authors**: Souza, Beatriz and Pradel, Michael
- **Abstract**: The ability to execute code is a prerequisite for various dynamic program analyses. Learning-guided execution has been proposed as an approach to enable the execution of arbitrary code snippets by letting a neural model predict likely values for any missing variables. Although state-of-the-art learning-guided execution approaches, such as LExecutor, can enable the execution of a relative high amount of code, they are limited to predicting a restricted set of possible values and do not use any fe...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00215)
- **Labels**: [program testing](../../labels/program_testing.md), [debugging](../../labels/debugging.md)


## [Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar](paper_26.md)
- **Authors**: Zhang, Yuanliang and Xie, Yifan and Lit, Shanshan and Liu, Ke and Wang, Chong and Jia, Zhouyang and Huang, Xiangbing and Song, Jie and Luo, Chaopeng and Zheng, Zhizheng and Xu, Rulin and Liu, Yitong and Zheng, Si and Liao, Xiangke
- **Abstract**: Recently, large language models (LLMs) have shown strong potential in code generation tasks. However, there are still gaps before they can be fully applied in actual software development processes. Accurately assessing the code generation capabilities of large language models has become an important basis for evaluating and improving the models. Some existing works have constructed datasets to evaluate the capabilities of these models. However, the current evaluation process may encounter the il...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00082)
- **Labels**: [code generation](../../labels/code_generation.md), [empirical study](../../labels/empirical_study.md)


## [Vulnerability Detection with Code Language Models: How Far Are We?](paper_4.md)
- **Authors**: Yangruibo Ding and Yanjun Fu and Omniyyah Ibrahim and Chawin Sitawarin and Xinyun Chen and Basel Alomair and David A. Wagner and Baishakhi Ray and Yizheng Chen
- **Abstract**: In the context of the rising interest in code language models (code LMs) and vulnerability detection, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representat...
- **Link**: [Read Paper](https://doi.org/10.48550/arXiv.2403.18624)
- **Labels**: [static analysis](../../labels/static_analysis.md), [bug detection](../../labels/bug_detection.md), [benchmark](../../labels/benchmark.md)


## [Your Fix Is My Exploit: Enabling Comprehensive DL Library API Fuzzing with Large Language Models](paper_21.md)
- **Authors**: Zhang, Kunpeng and Wang, Shuai and Han, Jitao and Zhu, Xiaogang and Li, Xian and Wang, Shaohua and Wen, Sheng
- **Abstract**: Deep learning (DL) libraries are widely used to form the basis of various AI applications in computer vision, natural language processing, and software engineering domains. Despite their popularity, DL libraries are known to have vulnerabilities, such as buffer overflows, use-after-free, and integer overflows, that can be exploited to compromise the security or effectiveness of the underlying libraries. While traditional fuzzing techniques have been used to find bugs in software, they are not we...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00041)
- **Labels**: [program testing](../../labels/program_testing.md), [fuzzing](../../labels/fuzzing.md)


## [exLong: Generating Exceptional Behavior Tests with Large Language Models](paper_51.md)
- **Authors**: Zhang, Jiyang and Liu, Yu and Nie, Pengyu and Li, Junyi Jessy and Gligoric, Milos
- **Abstract**: Many popular programming languages, including C#, Java, and Python, support exceptions. Exceptions are thrown during program execution if an unwanted event happens, e.g., a method is invoked with an illegal argument value. Software developers write exceptional behavior tests (EBTs) to check that their code detects unwanted events and throws appropriate exceptions. Prior research studies have shown the importance of EBTs, but those studies also highlighted that developers put most of their effort...
- **Link**: [Read Paper](https://doi.ieeecomputersociety.org/10.1109/ICSE55347.2025.00176)
- **Labels**: [program testing](../../labels/program_testing.md), [general testing](../../labels/general_testing.md)
