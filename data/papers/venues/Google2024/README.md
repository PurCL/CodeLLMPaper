# Google2024

Number of papers: 2

## [Evaluating Offensive Security Capabilities of Large Language Models](paper_2.md)
- **Authors**: Google
- **Abstract**: At Project Zero, we constantly seek to expand the scope and effectiveness of our vulnerability research. Though much of our work still relies on traditional methods like manual source code audits and reverse engineering, we're always looking for new approaches....
- **Link**: [Read Paper](https://googleprojectzero.blogspot.com/2024/06/project-naptime.html)
[program testing](../../labels/program_testing.md), [vulnerability exploitation](../../labels/vulnerability_exploitation.md)

## [From Naptime to Big Sleep: Using Large Language Models To Catch Vulnerabilities In Real-World Code](paper_1.md)
- **Authors**: Google
- **Abstract**: In our previous post, Project Naptime: Evaluating Offensive Security Capabilities of Large Language Models, we introduced our framework for large-language-model-assisted vulnerability research and demonstrated its potential by improving the state-of-the-art performance on Meta's CyberSecEval2 benchmarks. Since then, Naptime has evolved into Big Sleep, a collaboration between Google Project Zero and Google DeepMind....
- **Link**: [Read Paper](https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html)
[program testing](../../labels/program_testing.md), [vulnerability exploitation](../../labels/vulnerability_exploitation.md)